{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ENEE439d-TEXTML/TextML/blob/master/practice.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/ENEE439d-TEXTML/TextML/blob/master/practice.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxL5oVlOj0yG"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJXWN-MVX38W",
        "outputId": "bfefd1fd-43be-4bed-a180-76af92789988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j2p0QDZ1YpJL"
      },
      "outputs": [],
      "source": [
        "data  = pd.read_csv(\"/content/drive/MyDrive/UMD - senior year/spring 2022/439D/project/data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BPUojn71Pbi"
      },
      "source": [
        "# exmaple code : \n",
        "https://towardsdatascience.com/word-embeddings-for-sentiment-analysis-65f42ea5d26e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KmduYKb_OGE"
      },
      "source": [
        "## Setup necessary libraries\n",
        "> the imports and stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EjWwnQx51f3F"
      },
      "outputs": [],
      "source": [
        "#import all necessary libraries for this tutorial\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aiVmZq0v0MqX"
      },
      "outputs": [],
      "source": [
        "#parameters that will be used in tutorial\n",
        "\n",
        "NB_WORDS = 10000  # Parameter indicating the number of words we'll put in the dictionary\n",
        "VAL_SIZE = 1000  # Size of the validation set\n",
        "NB_START_EPOCHS = 10  # Number of epochs we usually start to train with\n",
        "BATCH_SIZE = 512  # Size of the batches used in the mini-batch gradient descent\n",
        "MAX_LEN = 24  # Maximum number of words in a sequence\n",
        "GLOVE_DIM = 100  # Number of dimensions of the GloVe word embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "9NeRxCOV305A",
        "outputId": "1be9b37a-b81f-41ce-b81c-19669e67004f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e41ffded-d78c-4a1f-9633-9838795d7613\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no</th>\n",
              "      <th>paper</th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A00-1043</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>H05-1033</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e41ffded-d78c-4a1f-9633-9838795d7613')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e41ffded-d78c-4a1f-9633-9838795d7613 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e41ffded-d78c-4a1f-9633-9838795d7613');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   no     paper cited_paper  label  \\\n",
              "0   0  A00-1043    A00-2024      0   \n",
              "1   1  H05-1033    A00-2024      0   \n",
              "2   2  I05-2009    A00-2024      0   \n",
              "3   3  I05-2009    A00-2024      0   \n",
              "4   4  I05-2009    A00-2024      0   \n",
              "\n",
              "                                                text  \n",
              "0  We analyzed a set of articles and identified s...  \n",
              "1  Table 3: Example compressions Compression AvgL...  \n",
              "2  5.3 Related works and discussion Our two-step ...  \n",
              "3  (1999) proposed a summarization system based o...  \n",
              "4  We found that the deletion of lead parts did n...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0cs52sdnnvI"
      },
      "source": [
        "## Removing non-alphabetic characters\n",
        "> remove words and characters that aren't useful from sentences in dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4Xfp9GbE6s9l"
      },
      "outputs": [],
      "source": [
        "#define functions to things with no sentiment value (irrelevant words)\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
        "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
        "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
        "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
        "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
        "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
        "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
        "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
        "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
        "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "\n",
        "characters = [\"\"]\n",
        "\n",
        "#function to remove stopwords\n",
        "def remove_stopwords(data):\n",
        "  data['review_without_stopwords'] = data['text'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
        "  return data\n",
        "\n",
        "#function to remove non-alphabetical tags\n",
        "def remove_tags(string):\n",
        "    #result = re.sub('[\\d<.*?:>()-,;|/@!#$%^&*~`_=+]','',string)\n",
        "\n",
        "    pattern = re.compile('[\\W_0-9]+')\n",
        "    dirty_list = string.split()\n",
        "    clean_list = [pattern.sub('', word) for word in dirty_list]\n",
        "    result = ' '.join(clean_list)\n",
        "    \n",
        "    # result = re.sub('[\\W_0-9]+','',string)    #see https://blog.finxter.com/how-to-remove-all-non-alphabet-characters-from-a-string/ for explanation\n",
        "    # result = re.sub('  ',' ',result)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tlq-liJ-Gpb9"
      },
      "outputs": [],
      "source": [
        "#remove stopwords\n",
        "clean_dataset = remove_stopwords(data)\n",
        "clean_dataset['w/o stopwords or tags']= clean_dataset['review_without_stopwords'].apply(lambda cw : remove_tags(cw))\n",
        "clean_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "nnYYCly6BWQA",
        "outputId": "793b403e-8c7c-4f6d-e33a-8f8b6880a9f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d1b36ddc-3707-4a50-9821-3b3bd951aaa4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no</th>\n",
              "      <th>paper</th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>review_without_stopwords</th>\n",
              "      <th>w/o stopwords or tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A00-1043</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "      <td>We analyzed set articles identified six major ...</td>\n",
              "      <td>We analyzed set articles identified six major ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>H05-1033</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "      <td>Table  Example compressions Compression AvgLen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "      <td>5.3 Related works discussion Our two-step mode...</td>\n",
              "      <td>Related works discussion Our twostep model es...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "      <td>(1999) proposed summarization system based dra...</td>\n",
              "      <td>proposed summarization system based draft rev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "      <td>We found deletion lead parts not occur often s...</td>\n",
              "      <td>We found deletion lead parts not occur often s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>994</td>\n",
              "      <td>N09-1053</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>While we can only compare class models with wo...</td>\n",
              "      <td>While can compare class models word models lar...</td>\n",
              "      <td>While can compare class models word models lar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>995</td>\n",
              "      <td>P01-1046</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) and Lee (1999)) can be generally divide...</td>\n",
              "      <td>(1999) Lee (1999)) can generally divided three...</td>\n",
              "      <td>Lee  can generally divided three types discou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>996</td>\n",
              "      <td>P01-1046</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>Classes can be induced directly from the corpu...</td>\n",
              "      <td>Classes can induced directly corpus (Pereira e...</td>\n",
              "      <td>Classes can induced directly corpus Pereira et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>997</td>\n",
              "      <td>P01-1068</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>And we consider that word pairs that have a sm...</td>\n",
              "      <td>And consider word pairs small distance vectors...</td>\n",
              "      <td>And consider word pairs small distance vectors...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>998</td>\n",
              "      <td>P02-1016</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>Words are encoded through an automatic cluster...</td>\n",
              "      <td>Words encoded automatic clustering algorithm (...</td>\n",
              "      <td>Words encoded automatic clustering algorithm B...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>999 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1b36ddc-3707-4a50-9821-3b3bd951aaa4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1b36ddc-3707-4a50-9821-3b3bd951aaa4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1b36ddc-3707-4a50-9821-3b3bd951aaa4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      no     paper cited_paper  label  \\\n",
              "0      0  A00-1043    A00-2024      0   \n",
              "1      1  H05-1033    A00-2024      0   \n",
              "2      2  I05-2009    A00-2024      0   \n",
              "3      3  I05-2009    A00-2024      0   \n",
              "4      4  I05-2009    A00-2024      0   \n",
              "..   ...       ...         ...    ...   \n",
              "994  994  N09-1053    J92-4003      0   \n",
              "995  995  P01-1046    J92-4003      0   \n",
              "996  996  P01-1046    J92-4003      0   \n",
              "997  997  P01-1068    J92-4003      0   \n",
              "998  998  P02-1016    J92-4003      0   \n",
              "\n",
              "                                                  text  \\\n",
              "0    We analyzed a set of articles and identified s...   \n",
              "1    Table 3: Example compressions Compression AvgL...   \n",
              "2    5.3 Related works and discussion Our two-step ...   \n",
              "3    (1999) proposed a summarization system based o...   \n",
              "4    We found that the deletion of lead parts did n...   \n",
              "..                                                 ...   \n",
              "994  While we can only compare class models with wo...   \n",
              "995  (1999) and Lee (1999)) can be generally divide...   \n",
              "996  Classes can be induced directly from the corpu...   \n",
              "997  And we consider that word pairs that have a sm...   \n",
              "998  Words are encoded through an automatic cluster...   \n",
              "\n",
              "                              review_without_stopwords  \\\n",
              "0    We analyzed set articles identified six major ...   \n",
              "1    Table 3: Example compressions Compression AvgL...   \n",
              "2    5.3 Related works discussion Our two-step mode...   \n",
              "3    (1999) proposed summarization system based dra...   \n",
              "4    We found deletion lead parts not occur often s...   \n",
              "..                                                 ...   \n",
              "994  While can compare class models word models lar...   \n",
              "995  (1999) Lee (1999)) can generally divided three...   \n",
              "996  Classes can induced directly corpus (Pereira e...   \n",
              "997  And consider word pairs small distance vectors...   \n",
              "998  Words encoded automatic clustering algorithm (...   \n",
              "\n",
              "                                 w/o stopwords or tags  \n",
              "0    We analyzed set articles identified six major ...  \n",
              "1    Table  Example compressions Compression AvgLen...  \n",
              "2     Related works discussion Our twostep model es...  \n",
              "3     proposed summarization system based draft rev...  \n",
              "4    We found deletion lead parts not occur often s...  \n",
              "..                                                 ...  \n",
              "994  While can compare class models word models lar...  \n",
              "995   Lee  can generally divided three types discou...  \n",
              "996  Classes can induced directly corpus Pereira et...  \n",
              "997  And consider word pairs small distance vectors...  \n",
              "998  Words encoded automatic clustering algorithm B...  \n",
              "\n",
              "[999 rows x 7 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRM1Jrfqntz7"
      },
      "source": [
        "## Splitting sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gD1ibjxCS_n8"
      },
      "outputs": [],
      "source": [
        "# split into test and training data\n",
        "X_train, X_test,Y_train, Y_test = train_test_split(clean_dataset['w/o stopwords or tags'], clean_dataset['label'], test_size=0.2, random_state = 45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXux9vwUTF87"
      },
      "outputs": [],
      "source": [
        "# create list of unique words in sentences\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "#creates dictionary of each {word: index}\n",
        "words_to_index = tokenizer.word_index\n",
        "words_to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5sUYAwLcTQTB"
      },
      "outputs": [],
      "source": [
        "#function to read GloCe Vector file\n",
        "\n",
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "\n",
        "\n",
        "\n",
        "  return word_to_vec_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bKL3mwqoEbmi"
      },
      "outputs": [],
      "source": [
        "# read in GloVe vector from Google Drive (premade mapping of words to be used for sentiment analysis)\n",
        "word_to_vec_map = read_glove_vector('/content/drive/MyDrive/UMD - senior year/spring 2022/439D/project/glove.6B.50d.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTcUebCepIyB"
      },
      "outputs": [],
      "source": [
        "# get maxLen for the maximum length of a text \n",
        "maxLen = max(clean_dataset['w/o stopwords or tags'].apply(len))\n",
        "\n",
        "#the row of the maxLen text\n",
        "clean_dataset.loc[clean_dataset['w/o stopwords or tags'].apply(len) == max(clean_dataset['w/o stopwords or tags'].apply(len))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvZBe8J2uu0i"
      },
      "outputs": [],
      "source": [
        "# sizes of texts \n",
        "#clean_dataset['clean_text'].apply(len).sort_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "dDR2aGCvpwr0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "\n",
        "# create embedding matrix (all words in GloVe vector assigned to correct value matrix, all others assigend to 0 vector)\n",
        "vocab_len = len(words_to_index) + 1\n",
        "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
        "\n",
        "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
        "\n",
        "for word, index in words_to_index.items():\n",
        "  embedding_vector = word_to_vec_map.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    emb_matrix[index, :] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hXCWYlRH0N3J"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vC7ntmuVuOPi"
      },
      "outputs": [],
      "source": [
        "# create model architecture\n",
        "def imdb_rating(input_shape):\n",
        "\n",
        "  X_indices = Input(input_shape)\n",
        "\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(embeddings)\n",
        "\n",
        "  X = Dropout(0.6)(X)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(X)\n",
        "\n",
        "  X = Dropout(0.6)(X)\n",
        "\n",
        "  X = LSTM(128)(X)\n",
        "\n",
        "  X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2Wa3GFZozF2x"
      },
      "outputs": [],
      "source": [
        "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "rF-_RMpzzIsA",
        "outputId": "0b34f5b9-d877-45dc-b7b2-850982045c40"
      },
      "outputs": [
        {
          "ename": "InternalError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-c0e677f290fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb_rating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxLen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-46b48eabea93>\u001b[0m in \u001b[0;36mimdb_rating\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;31m# Compute the qr factorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m     \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m     \u001b[0;31m# Make Q uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_diag_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Qr: stream did not block host until done; was already in an error state [Op:Qr]"
          ]
        }
      ],
      "source": [
        "model = imdb_rating((maxLen,))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_indices, Y_train, batch_size=64, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSvxbmX_0d_v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXYwjVRm0dwp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6KmduYKb_OGE",
        "FRM1Jrfqntz7"
      ],
      "name": "practice",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
