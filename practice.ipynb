{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice",
      "provenance": [],
      "collapsed_sections": [
        "6KmduYKb_OGE",
        "g0cs52sdnnvI"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ENEE439d-TEXTML/TextML/blob/master/practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "kxL5oVlOj0yG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJXWN-MVX38W",
        "outputId": "e7990977-cfbf-4934-bc00-a89f66184dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data  = pd.read_csv(\"/content/drive/MyDrive/UMD - senior year/spring 2022/439D/project/data.csv\")"
      ],
      "metadata": {
        "id": "j2p0QDZ1YpJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# exmaple code : \n",
        "https://towardsdatascience.com/word-embeddings-for-sentiment-analysis-65f42ea5d26e"
      ],
      "metadata": {
        "id": "_BPUojn71Pbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup necessary libraries\n",
        "> the imports and stuff"
      ],
      "metadata": {
        "id": "6KmduYKb_OGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import all necessary libraries for this tutorial\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import keras"
      ],
      "metadata": {
        "id": "EjWwnQx51f3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parameters that will be used in tutorial\n",
        "\n",
        "NB_WORDS = 10000  # Parameter indicating the number of words we'll put in the dictionary\n",
        "VAL_SIZE = 1000  # Size of the validation set\n",
        "NB_START_EPOCHS = 10  # Number of epochs we usually start to train with\n",
        "BATCH_SIZE = 512  # Size of the batches used in the mini-batch gradient descent\n",
        "MAX_LEN = 24  # Maximum number of words in a sequence\n",
        "GLOVE_DIM = 100  # Number of dimensions of the GloVe word embeddings\n"
      ],
      "metadata": {
        "id": "aiVmZq0v0MqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "9NeRxCOV305A",
        "outputId": "ea7b96ce-cbf4-4bd2-ae1b-b857e0d93fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   no     paper cited_paper  label  \\\n",
              "0   0  A00-1043    A00-2024      0   \n",
              "1   1  H05-1033    A00-2024      0   \n",
              "2   2  I05-2009    A00-2024      0   \n",
              "3   3  I05-2009    A00-2024      0   \n",
              "4   4  I05-2009    A00-2024      0   \n",
              "\n",
              "                                                text  \n",
              "0  We analyzed a set of articles and identified s...  \n",
              "1  Table 3: Example compressions Compression AvgL...  \n",
              "2  5.3 Related works and discussion Our two-step ...  \n",
              "3  (1999) proposed a summarization system based o...  \n",
              "4  We found that the deletion of lead parts did n...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f1a5eed-cd02-49fc-a4c4-43c818160bb6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no</th>\n",
              "      <th>paper</th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A00-1043</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>H05-1033</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f1a5eed-cd02-49fc-a4c4-43c818160bb6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f1a5eed-cd02-49fc-a4c4-43c818160bb6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f1a5eed-cd02-49fc-a4c4-43c818160bb6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing non-alphabetic characters\n",
        "> remove words and characters that aren't useful from sentences in dataset"
      ],
      "metadata": {
        "id": "g0cs52sdnnvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define functions to things with no sentiment value (irrelevant words)\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
        "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
        "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
        "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
        "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
        "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
        "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
        "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
        "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
        "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "\n",
        "characters = [\"\"]\n",
        "\n",
        "#function to remove stopwords\n",
        "def remove_stopwords(data):\n",
        "  data['review_without_stopwords'] = data['text'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
        "  return data\n",
        "\n",
        "#function to remove non-alphabetical tags\n",
        "def remove_tags(string):\n",
        "    #result = re.sub('[\\d<.*?:>()-,;|/@!#$%^&*~`_=+]','',string)\n",
        "\n",
        "    pattern = re.compile('[\\W_0-9]+')\n",
        "    dirty_list = string.split()\n",
        "    clean_list = [pattern.sub('', word) for word in dirty_list]\n",
        "    result = ' '.join(clean_list)\n",
        "    \n",
        "    # result = re.sub('[\\W_0-9]+','',string)    #see https://blog.finxter.com/how-to-remove-all-non-alphabet-characters-from-a-string/ for explanation\n",
        "    # result = re.sub('  ',' ',result)\n",
        "    return result"
      ],
      "metadata": {
        "id": "4Xfp9GbE6s9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove stopwords\n",
        "clean_dataset = remove_stopwords(data)\n",
        "clean_dataset['w/o stopwords or tags']= clean_dataset['review_without_stopwords'].apply(lambda cw : remove_tags(cw))\n",
        "clean_dataset"
      ],
      "metadata": {
        "id": "Tlq-liJ-Gpb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "f1257ba7-daf6-44cd-b1ba-0118aa5dcb69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      no     paper cited_paper  label  \\\n",
              "0      0  A00-1043    A00-2024      0   \n",
              "1      1  H05-1033    A00-2024      0   \n",
              "2      2  I05-2009    A00-2024      0   \n",
              "3      3  I05-2009    A00-2024      0   \n",
              "4      4  I05-2009    A00-2024      0   \n",
              "..   ...       ...         ...    ...   \n",
              "994  994  N09-1053    J92-4003      0   \n",
              "995  995  P01-1046    J92-4003      0   \n",
              "996  996  P01-1046    J92-4003      0   \n",
              "997  997  P01-1068    J92-4003      0   \n",
              "998  998  P02-1016    J92-4003      0   \n",
              "\n",
              "                                                  text  \\\n",
              "0    We analyzed a set of articles and identified s...   \n",
              "1    Table 3: Example compressions Compression AvgL...   \n",
              "2    5.3 Related works and discussion Our two-step ...   \n",
              "3    (1999) proposed a summarization system based o...   \n",
              "4    We found that the deletion of lead parts did n...   \n",
              "..                                                 ...   \n",
              "994  While we can only compare class models with wo...   \n",
              "995  (1999) and Lee (1999)) can be generally divide...   \n",
              "996  Classes can be induced directly from the corpu...   \n",
              "997  And we consider that word pairs that have a sm...   \n",
              "998  Words are encoded through an automatic cluster...   \n",
              "\n",
              "                              review_without_stopwords  \\\n",
              "0    We analyzed set articles identified six major ...   \n",
              "1    Table 3: Example compressions Compression AvgL...   \n",
              "2    5.3 Related works discussion Our two-step mode...   \n",
              "3    (1999) proposed summarization system based dra...   \n",
              "4    We found deletion lead parts not occur often s...   \n",
              "..                                                 ...   \n",
              "994  While can compare class models word models lar...   \n",
              "995  (1999) Lee (1999)) can generally divided three...   \n",
              "996  Classes can induced directly corpus (Pereira e...   \n",
              "997  And consider word pairs small distance vectors...   \n",
              "998  Words encoded automatic clustering algorithm (...   \n",
              "\n",
              "                                 w/o stopwords or tags  \n",
              "0    We analyzed set articles identified six major ...  \n",
              "1    Table  Example compressions Compression AvgLen...  \n",
              "2     Related works discussion Our twostep model es...  \n",
              "3     proposed summarization system based draft rev...  \n",
              "4    We found deletion lead parts not occur often s...  \n",
              "..                                                 ...  \n",
              "994  While can compare class models word models lar...  \n",
              "995   Lee  can generally divided three types discou...  \n",
              "996  Classes can induced directly corpus Pereira et...  \n",
              "997  And consider word pairs small distance vectors...  \n",
              "998  Words encoded automatic clustering algorithm B...  \n",
              "\n",
              "[999 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6550741-a0ab-4afb-8aed-91f7fccf728f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no</th>\n",
              "      <th>paper</th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>review_without_stopwords</th>\n",
              "      <th>w/o stopwords or tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A00-1043</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "      <td>We analyzed set articles identified six major ...</td>\n",
              "      <td>We analyzed set articles identified six major ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>H05-1033</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "      <td>Table  Example compressions Compression AvgLen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "      <td>5.3 Related works discussion Our two-step mode...</td>\n",
              "      <td>Related works discussion Our twostep model es...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "      <td>(1999) proposed summarization system based dra...</td>\n",
              "      <td>proposed summarization system based draft rev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "      <td>We found deletion lead parts not occur often s...</td>\n",
              "      <td>We found deletion lead parts not occur often s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>994</td>\n",
              "      <td>N09-1053</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>While we can only compare class models with wo...</td>\n",
              "      <td>While can compare class models word models lar...</td>\n",
              "      <td>While can compare class models word models lar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>995</td>\n",
              "      <td>P01-1046</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) and Lee (1999)) can be generally divide...</td>\n",
              "      <td>(1999) Lee (1999)) can generally divided three...</td>\n",
              "      <td>Lee  can generally divided three types discou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>996</td>\n",
              "      <td>P01-1046</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>Classes can be induced directly from the corpu...</td>\n",
              "      <td>Classes can induced directly corpus (Pereira e...</td>\n",
              "      <td>Classes can induced directly corpus Pereira et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>997</td>\n",
              "      <td>P01-1068</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>And we consider that word pairs that have a sm...</td>\n",
              "      <td>And consider word pairs small distance vectors...</td>\n",
              "      <td>And consider word pairs small distance vectors...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>998</td>\n",
              "      <td>P02-1016</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>Words are encoded through an automatic cluster...</td>\n",
              "      <td>Words encoded automatic clustering algorithm (...</td>\n",
              "      <td>Words encoded automatic clustering algorithm B...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>999 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6550741-a0ab-4afb-8aed-91f7fccf728f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6550741-a0ab-4afb-8aed-91f7fccf728f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6550741-a0ab-4afb-8aed-91f7fccf728f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "nnYYCly6BWQA",
        "outputId": "2e30cbea-7dbb-4667-ce46-d3baf72f2794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      no     paper cited_paper  label  \\\n",
              "0      0  A00-1043    A00-2024      0   \n",
              "1      1  H05-1033    A00-2024      0   \n",
              "2      2  I05-2009    A00-2024      0   \n",
              "3      3  I05-2009    A00-2024      0   \n",
              "4      4  I05-2009    A00-2024      0   \n",
              "..   ...       ...         ...    ...   \n",
              "994  994  N09-1053    J92-4003      0   \n",
              "995  995  P01-1046    J92-4003      0   \n",
              "996  996  P01-1046    J92-4003      0   \n",
              "997  997  P01-1068    J92-4003      0   \n",
              "998  998  P02-1016    J92-4003      0   \n",
              "\n",
              "                                                  text  \\\n",
              "0    We analyzed a set of articles and identified s...   \n",
              "1    Table 3: Example compressions Compression AvgL...   \n",
              "2    5.3 Related works and discussion Our two-step ...   \n",
              "3    (1999) proposed a summarization system based o...   \n",
              "4    We found that the deletion of lead parts did n...   \n",
              "..                                                 ...   \n",
              "994  While we can only compare class models with wo...   \n",
              "995  (1999) and Lee (1999)) can be generally divide...   \n",
              "996  Classes can be induced directly from the corpu...   \n",
              "997  And we consider that word pairs that have a sm...   \n",
              "998  Words are encoded through an automatic cluster...   \n",
              "\n",
              "                              review_without_stopwords  \\\n",
              "0    We analyzed set articles identified six major ...   \n",
              "1    Table 3: Example compressions Compression AvgL...   \n",
              "2    5.3 Related works discussion Our two-step mode...   \n",
              "3    (1999) proposed summarization system based dra...   \n",
              "4    We found deletion lead parts not occur often s...   \n",
              "..                                                 ...   \n",
              "994  While can compare class models word models lar...   \n",
              "995  (1999) Lee (1999)) can generally divided three...   \n",
              "996  Classes can induced directly corpus (Pereira e...   \n",
              "997  And consider word pairs small distance vectors...   \n",
              "998  Words encoded automatic clustering algorithm (...   \n",
              "\n",
              "                                 w/o stopwords or tags  \n",
              "0    We analyzed set articles identified six major ...  \n",
              "1    Table  Example compressions Compression AvgLen...  \n",
              "2     Related works discussion Our twostep model es...  \n",
              "3     proposed summarization system based draft rev...  \n",
              "4    We found deletion lead parts not occur often s...  \n",
              "..                                                 ...  \n",
              "994  While can compare class models word models lar...  \n",
              "995   Lee  can generally divided three types discou...  \n",
              "996  Classes can induced directly corpus Pereira et...  \n",
              "997  And consider word pairs small distance vectors...  \n",
              "998  Words encoded automatic clustering algorithm B...  \n",
              "\n",
              "[999 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef8b1328-13c9-4c75-8e95-ddcd777d330a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no</th>\n",
              "      <th>paper</th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>review_without_stopwords</th>\n",
              "      <th>w/o stopwords or tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A00-1043</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "      <td>We analyzed set articles identified six major ...</td>\n",
              "      <td>We analyzed set articles identified six major ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>H05-1033</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "      <td>Table  Example compressions Compression AvgLen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "      <td>5.3 Related works discussion Our two-step mode...</td>\n",
              "      <td>Related works discussion Our twostep model es...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "      <td>(1999) proposed summarization system based dra...</td>\n",
              "      <td>proposed summarization system based draft rev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I05-2009</td>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "      <td>We found deletion lead parts not occur often s...</td>\n",
              "      <td>We found deletion lead parts not occur often s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>994</td>\n",
              "      <td>N09-1053</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>While we can only compare class models with wo...</td>\n",
              "      <td>While can compare class models word models lar...</td>\n",
              "      <td>While can compare class models word models lar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>995</td>\n",
              "      <td>P01-1046</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) and Lee (1999)) can be generally divide...</td>\n",
              "      <td>(1999) Lee (1999)) can generally divided three...</td>\n",
              "      <td>Lee  can generally divided three types discou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>996</td>\n",
              "      <td>P01-1046</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>Classes can be induced directly from the corpu...</td>\n",
              "      <td>Classes can induced directly corpus (Pereira e...</td>\n",
              "      <td>Classes can induced directly corpus Pereira et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>997</td>\n",
              "      <td>P01-1068</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>And we consider that word pairs that have a sm...</td>\n",
              "      <td>And consider word pairs small distance vectors...</td>\n",
              "      <td>And consider word pairs small distance vectors...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>998</td>\n",
              "      <td>P02-1016</td>\n",
              "      <td>J92-4003</td>\n",
              "      <td>0</td>\n",
              "      <td>Words are encoded through an automatic cluster...</td>\n",
              "      <td>Words encoded automatic clustering algorithm (...</td>\n",
              "      <td>Words encoded automatic clustering algorithm B...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>999 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef8b1328-13c9-4c75-8e95-ddcd777d330a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef8b1328-13c9-4c75-8e95-ddcd777d330a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef8b1328-13c9-4c75-8e95-ddcd777d330a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove data that is too large"
      ],
      "metadata": {
        "id": "aIIKwIH7ttGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get maxLen for the maximum length of a text \n",
        "maxLen = max(clean_dataset['w/o stopwords or tags'].apply(len))\n",
        "\n",
        "#the row of the maxLen text\n",
        "clean_dataset.loc[clean_dataset['w/o stopwords or tags'].apply(len) == max(clean_dataset['w/o stopwords or tags'].apply(len))]"
      ],
      "metadata": {
        "id": "pTcUebCepIyB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "54176892-a33f-4dbf-ec15-8c73bfd4d895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      no     paper cited_paper  label  \\\n",
              "225  225  W99-0505    C94-2113      0   \n",
              "\n",
              "                                                  text  \\\n",
              "225  Towards a Meaning-Full Comparison of Lexieal R...   \n",
              "\n",
              "                              review_without_stopwords  \\\n",
              "225  Towards Meaning-Full Comparison Lexieal Resour...   \n",
              "\n",
              "                                 w/o stopwords or tags  \n",
              "225  Towards MeaningFull Comparison Lexieal Resourc...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5e4f4de-81ad-4a23-8fac-5229eb1b76ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no</th>\n",
              "      <th>paper</th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>review_without_stopwords</th>\n",
              "      <th>w/o stopwords or tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>225</td>\n",
              "      <td>W99-0505</td>\n",
              "      <td>C94-2113</td>\n",
              "      <td>0</td>\n",
              "      <td>Towards a Meaning-Full Comparison of Lexieal R...</td>\n",
              "      <td>Towards Meaning-Full Comparison Lexieal Resour...</td>\n",
              "      <td>Towards MeaningFull Comparison Lexieal Resourc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5e4f4de-81ad-4a23-8fac-5229eb1b76ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5e4f4de-81ad-4a23-8fac-5229eb1b76ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5e4f4de-81ad-4a23-8fac-5229eb1b76ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sizes of texts \n",
        "clean_dataset['w/o stopwords or tags'].apply(len).sort_values()"
      ],
      "metadata": {
        "id": "ZvZBe8J2uu0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try removing thousand word lines from dataset to make training easier\n",
        "smaller_clean_dataset = clean_dataset.loc[clean_dataset['w/o stopwords or tags'].apply(len) < 1000]\n",
        "smaller_clean_dataset['w/o stopwords or tags'].apply(len).sort_values()"
      ],
      "metadata": {
        "id": "IuizTg6gjNf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#redefine maxlen as length of new longest sentence\n",
        "maxLen = max(smaller_clean_dataset['w/o stopwords or tags'].apply(len))"
      ],
      "metadata": {
        "id": "zTYu-8LfuuN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting sentences"
      ],
      "metadata": {
        "id": "FRM1Jrfqntz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split into test and training data\n",
        "X_train, X_test,Y_train, Y_test = train_test_split(smaller_clean_dataset['w/o stopwords or tags'], smaller_clean_dataset['label'], test_size=0.2, random_state = 45)"
      ],
      "metadata": {
        "id": "gD1ibjxCS_n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create list of unique words in sentences\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "#creates dictionary of each {word: index}\n",
        "words_to_index = tokenizer.word_index\n",
        "words_to_index"
      ],
      "metadata": {
        "id": "MXux9vwUTF87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to read GloCe Vector file\n",
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "\n",
        "\n",
        "\n",
        "  return word_to_vec_map"
      ],
      "metadata": {
        "id": "5sUYAwLcTQTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in GloVe vector from Google Drive (premade mapping of words to be used for sentiment analysis)\n",
        "word_to_vec_map = read_glove_vector('/content/drive/MyDrive/UMD - senior year/spring 2022/439D/project/glove.6B.50d.txt')"
      ],
      "metadata": {
        "id": "bKL3mwqoEbmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ajxppUm9naUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "\n",
        "# create embedding matrix (all words in GloVe vector assigned to correct value matrix, all others assigend to 0 vector)\n",
        "vocab_len = len(words_to_index) + 1\n",
        "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
        "\n",
        "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
        "\n",
        "\n",
        "#get glove coordinates of words that are in BOTH glove list and in training data sentences \n",
        "for word, index in words_to_index.items():\n",
        "  embedding_vector = word_to_vec_map.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    emb_matrix[index, :] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)"
      ],
      "metadata": {
        "id": "dDR2aGCvpwr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "hXCWYlRH0N3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model architecture\n",
        "def imdb_rating(input_shape):\n",
        "\n",
        "  X_indices = Input(input_shape)\n",
        "\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(embeddings)\n",
        "\n",
        "  X = Dropout(0.6)(X)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(X)\n",
        "\n",
        "  X = Dropout(0.6)(X)\n",
        "\n",
        "  X = LSTM(128)(X)\n",
        "\n",
        "  #X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "  X = Dense(3, activation='softmax')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "vC7ntmuVuOPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer converts words in the sentence into its corresponding indexe \n",
        "print(X_train.iloc[-1])  \n",
        "print(tokenizer.texts_to_sequences(X_train)[-1])\n",
        "print('the word since, the first word of the last sentence in the dataset has index: ', words_to_index['regardless'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmly2plyq00p",
        "outputId": "62968554-28ce-4cb5-985f-5fa4d1f91bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regardless whether takes form dictionaries Lesk  Guthrie et al  Dagan Itai Schwall  Karov Edelman  thesauri Yarowsky  Walker Amsler  bilingual corpora Brown et al  Church Gale  handlabeled training sets Hearst  Leacock Towell Voorhees  Niwa Nitta  Bruce Wiebe  providing information sense definitions can considerable burden\n",
            "[3871, 472, 748, 229, 484, 906, 807, 2, 1, 125, 1738, 3872, 3873, 3874, 674, 154, 3875, 3876, 568, 99, 26, 2, 1, 3, 269, 3877, 35, 265, 1833, 709, 1834, 980, 1771, 1772, 1835, 1153, 3878, 5, 140, 599, 17, 584, 3879]\n",
            "the word since, the first word of the last sentence in the dataset has index:  3871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert training data sentence words into its corresponding indexes\n",
        "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "#pad sentences of indexes so all same length\n",
        "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')\n",
        "print('the shape of the new training data is 796 samples, each with 835 words (bc of padding): ', X_train_indices.shape)"
      ],
      "metadata": {
        "id": "2Wa3GFZozF2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433bcace-bdd3-4cc3-dae8-809c4bf1529c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the shape of the new training data is 796 samples, each with 835 words (bc of padding):  (796, 835)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model\n",
        "model = imdb_rating((maxLen,))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_indices, Y_train, batch_size=64, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "rF-_RMpzzIsA",
        "outputId": "784af952-8ec4-482e-c50b-2d40c3b86339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-3e06de715ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1932, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5247, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 3) vs (None, 1)).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the testing data sentence words into its corresponding indexes\n",
        "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "#pad sentences of indexes so all same length\n",
        "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')\n",
        "print('the shape of the new training data is 200 samples, each with 835 words (bc of padding): ', X_test_indices.shape)\n",
        "\n",
        "\n",
        "model.evaluate(X_test_indices, Y_test)"
      ],
      "metadata": {
        "id": "NSvxbmX_0d_v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "outputId": "f2a1f55e-1b00-4a11-9d77-780b1e845135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the shape of the new training data is 200 samples, each with 835 words (bc of padding):  (200, 835)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-7aa571050846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1473, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1932, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5247, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 3) vs (None, 1)).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_predictions = model.predict(X_test_indices)"
      ],
      "metadata": {
        "id": "BXYwjVRm0dwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF-6BmGUxBSR",
        "outputId": "a31249dd-84cc-47c4-f01f-aae19c0bf255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476176],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476176],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476179],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476178],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476178],\n",
              "       [0.05476177],\n",
              "       [0.05476178],\n",
              "       [0.05476178],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476178],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476179],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476178],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476176],\n",
              "       [0.05476178],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476178],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476178],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476176],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177],\n",
              "       [0.05476177]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smaller_clear_dataset['label'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyh992k7xPR4",
        "outputId": "dbc0b50b-6d0e-461f-a594-0f6c653cd14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    }
  ]
}