{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h7Lr7k5d1jd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ENEE439d-TEXTML/TextML/blob/master/input.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/ENEE439d-TEXTML/TextML/blob/master/input.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPiicLOUd1jj"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U \"tensorflow-text==2.8.*\" # A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q tf-models-official==2.7.0 # For adamW\n",
        "!pip install focal-loss # focal loss implmnetion for tf\n",
        "!pip install pdfminer.six #pdf text extratction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52FpqTzrPr-t",
        "outputId": "5e566534-6316-47d2-ac5e-f6dbb84d5d9f"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: focal-loss in /usr/local/lib/python3.7/dist-packages (0.0.7)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal-loss) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (14.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (4.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.14.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.44.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.25.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.5.3)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal-loss) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2->focal-loss) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.2.0)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.7/dist-packages (20220506)\n",
            "Requirement already satisfied: cryptography~=36.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (36.0.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (2.0.12)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography~=36.0.0->pdfminer.six) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography~=36.0.0->pdfminer.six) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "BPnv0Vlcd3KI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #basic imports\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split # https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization, bert  # to create AdamW optimizer\n",
        "from focal_loss import SparseCategoricalFocalLoss\n",
        "import official.nlp.bert.tokenization"
      ],
      "metadata": {
        "id": "dkxbtcKbP4AU"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import StringIO\n",
        "\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfdocument import PDFDocument\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.pdfparser import PDFParser"
      ],
      "metadata": {
        "id": "Xx7DXy_KYgAE"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data read in"
      ],
      "metadata": {
        "id": "Q-Dc1EsOuQA0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "465BADPxeNII",
        "outputId": "5d78c9a1-bf44-46b2-d840-18aacd1bef7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Sk1zTIA6eOM5",
        "outputId": "6eb70d12-e2df-4c85-d985-2f033c18b846"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  cited_paper  label                                               text\n",
              "0    A00-2024      0  We analyzed a set of articles and identified s...\n",
              "1    A00-2024      0  Table 3: Example compressions Compression AvgL...\n",
              "2    A00-2024      0  5.3 Related works and discussion Our two-step ...\n",
              "3    A00-2024      0  (1999) proposed a summarization system based o...\n",
              "4    A00-2024      0  We found that the deletion of lead parts did n..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-082aff95-0166-4a04-8c36-7d9df1b7419f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-082aff95-0166-4a04-8c36-7d9df1b7419f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-082aff95-0166-4a04-8c36-7d9df1b7419f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-082aff95-0166-4a04-8c36-7d9df1b7419f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "filepath = '/content/drive/MyDrive/Text-ML/full_sentiment_dataset.csv' #'data.csv'\n",
        "df= pd.read_csv(filepath)\n",
        "df1=df.drop(['no','paper','context_a','context_b'],axis=1)\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImSOYF6Py2J8",
        "outputId": "be2d3b91-6b1b-4710-cfec-d2b0f925f131"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    7627\n",
              " 1     829\n",
              "-1     280\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filtering by regex"
      ],
      "metadata": {
        "id": "FHIvNaLfuUoe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytc03_FI-b5L",
        "outputId": "99cf582a-5207-4cc7-c6fd-53e17a4a2666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\[*\\]|\\(\\d{4}\\)|\\(?((\\(?((\\w+, )*(\\w+ )+)((and|&) ((\\w+ *))?)?,? \\(?\\d{4}\\)?|((\\w+, )*(\\w+ )+)et al\\. ?,? \\(?\\d{4}\\)?\\)?)((; )|( (and|&) ))*)+\n"
          ]
        }
      ],
      "source": [
        "context=df1['text']\n",
        "\n",
        "re1= \"\\(((([A-Za-z]+ *)+(, \\d+))+(; )*)+\\)\" # matches author and author, year\n",
        "re_year=\",? \\(?\\d{4}\\)?\" # match , {4 digits} which may be wrapped in () \n",
        "re_and=\"(and|&) \"\n",
        "re_auth=\"((\\w+, )*(\\w+ )+)\"\n",
        "re_et= re_auth+\"et al\\. ?\"+re_year # matches author et al. , year\n",
        "re_2a= re_auth+\"(\"+re_and+\"((\\w+ *))?)?\"+re_year # matches author and author, year\n",
        "re_sep=\"((; )|( \"+re_and+\"))*\"# match the '; ' gap or ' and ' gap\n",
        "re_para_year=\"\\(\\d{4}\\)\"\n",
        "re_in_brack=\"\\[*\\]\"\n",
        "re_apa =re_in_brack+\"|\"+re_para_year+\"|\"+\"\\(?(\"+\"(\\(?\"+re_2a+\"|\"+re_et+\"\\)?)\"+re_sep+\")+\"\n",
        "print(re_apa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "NEZIAWQtykDg"
      },
      "outputs": [],
      "source": [
        "def remove_matches(text,regex=re_apa):\n",
        "  text1=text\n",
        "  rem_len=0\n",
        "  pattern= re.compile(regex)\n",
        "  while True:\n",
        "    matches=pattern.search(text1)\n",
        "    #print(matches)\n",
        "    if matches == None:\n",
        "      break\n",
        "\n",
        "    spn=matches.span()\n",
        "    text1=text1[0:spn[0]]+text1[spn[1]:-1]\n",
        "    cit_len=spn[1]-spn[0]\n",
        "    rem_len+=cit_len\n",
        "  \n",
        "  if len(text) >0:\n",
        "    percent_removed=rem_len/len(text)\n",
        "  else:\n",
        "    percent_removed=1\n",
        "  return text1,percent_removed \n",
        "\n",
        "# print(context[5])\n",
        "# remove_citation(context[5],regex=re_apa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "TmjjH1gp9A6T"
      },
      "outputs": [],
      "source": [
        "output=df1['text'].apply(lambda x: remove_matches(text=x,regex=re_apa)) #df['col1'] = df.apply(lambda x: complex_function(x['col1']), axis=1)\n",
        "df_o = pd.DataFrame(list(output), columns =['clean','p_rem'])\n",
        "output_1=df_o['clean'].apply(lambda x: remove_matches(text=x,regex='[^\\w_0-9 ]+')) \n",
        "df_o_1 = pd.DataFrame(list(output_1), columns =['clean','p_rem'])\n",
        "#df_o.head()\n",
        "\n",
        "df1['text_clean']=df_o_1['clean']\n",
        "df1['text_clean_len']=df_o_1['clean'].apply(len)\n",
        "df1['p_rem']=df_o['p_rem']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OVt3NtaJDDrx",
        "outputId": "0c380576-919b-45ec-e535-a9adf96a72bd"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cited_paper  label                                               text  \\\n",
              "0       A00-2024      0  We analyzed a set of articles and identified s...   \n",
              "1       A00-2024      0  Table 3: Example compressions Compression AvgL...   \n",
              "2       A00-2024      0  5.3 Related works and discussion Our two-step ...   \n",
              "3       A00-2024      0  (1999) proposed a summarization system based o...   \n",
              "4       A00-2024      0  We found that the deletion of lead parts did n...   \n",
              "...          ...    ...                                                ...   \n",
              "8731    W96-0213      1  He has achieved state-of-the art results by ap...   \n",
              "8732    W96-0213      0  B = (Brill and Wu, 1998); M = (Magerman, 1995)...   \n",
              "8733    W96-0213      0  The model we use is similar to that of (Ratnap...   \n",
              "8734    W96-0213      1  Our model exploits the same kind of tag-n-gram...   \n",
              "8735    W96-0213      0  In that table, TBL stands for Brill's transfor...   \n",
              "\n",
              "                                             text_clean  text_clean_len  \\\n",
              "0     We analyzed a set of articles and identified s...             425   \n",
              "1     Table 3 Example compressions Compression AvgLe...             229   \n",
              "2     53 Related works and discussion Our twostep mo...             105   \n",
              "3      proposed a summarization system based on the ...             321   \n",
              "4     We found that the deletion of lead parts did n...              73   \n",
              "...                                                 ...             ...   \n",
              "8731  He has achieved stateofthe art results by appl...             139   \n",
              "8732   B  M  Magerman 1995 O  our data R  Ratnaparkhi 1              48   \n",
              "8733  The model we use is similar to that of Ratnapa...              55   \n",
              "8734  Our model exploits the same kind of tagngram i...             157   \n",
              "8735  In that table TBL stands for Brills transforma...             288   \n",
              "\n",
              "         p_rem  \n",
              "0     0.098765  \n",
              "1     0.260745  \n",
              "2     0.308176  \n",
              "3     0.078804  \n",
              "4     0.408000  \n",
              "...        ...  \n",
              "8731  0.151515  \n",
              "8732  0.421488  \n",
              "8733  0.000000  \n",
              "8734  0.000000  \n",
              "8735  0.000000  \n",
              "\n",
              "[8736 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b56ce6a-4e8f-4959-bd3c-cdccda157d96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_clean_len</th>\n",
              "      <th>p_rem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "      <td>425</td>\n",
              "      <td>0.098765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "      <td>Table 3 Example compressions Compression AvgLe...</td>\n",
              "      <td>229</td>\n",
              "      <td>0.260745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "      <td>53 Related works and discussion Our twostep mo...</td>\n",
              "      <td>105</td>\n",
              "      <td>0.308176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "      <td>proposed a summarization system based on the ...</td>\n",
              "      <td>321</td>\n",
              "      <td>0.078804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "      <td>73</td>\n",
              "      <td>0.408000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>1</td>\n",
              "      <td>He has achieved state-of-the art results by ap...</td>\n",
              "      <td>He has achieved stateofthe art results by appl...</td>\n",
              "      <td>139</td>\n",
              "      <td>0.151515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8732</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>B = (Brill and Wu, 1998); M = (Magerman, 1995)...</td>\n",
              "      <td>B  M  Magerman 1995 O  our data R  Ratnaparkhi 1</td>\n",
              "      <td>48</td>\n",
              "      <td>0.421488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8733</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>The model we use is similar to that of (Ratnap...</td>\n",
              "      <td>The model we use is similar to that of Ratnapa...</td>\n",
              "      <td>55</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8734</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>1</td>\n",
              "      <td>Our model exploits the same kind of tag-n-gram...</td>\n",
              "      <td>Our model exploits the same kind of tagngram i...</td>\n",
              "      <td>157</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8735</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>In that table, TBL stands for Brill's transfor...</td>\n",
              "      <td>In that table TBL stands for Brills transforma...</td>\n",
              "      <td>288</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8736 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b56ce6a-4e8f-4959-bd3c-cdccda157d96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b56ce6a-4e8f-4959-bd3c-cdccda157d96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b56ce6a-4e8f-4959-bd3c-cdccda157d96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove under and over sized samples\n",
        "large samples appear to be poorly written"
      ],
      "metadata": {
        "id": "pkNPWqAHKLxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getMidLen(data,label,labelKey='label',lenKey='text_clean_len',lowMod=1,highMod=1):\n",
        "  df1 =data.loc[data[labelKey] == label]\n",
        "  neu_mean=np.mean(list(df1[lenKey]))\n",
        "  neu_std=np.std(list(df1[lenKey]))\n",
        "  df1_no_high = df1.loc[df1[lenKey] < highMod*(neu_mean +neu_std)]\n",
        "  # print(neu_mean)\n",
        "  # print(neu_std)\n",
        "\n",
        "  while neu_std > neu_mean:\n",
        "    neu_mean=np.mean(list(df1_no_high['text_clean_len']))\n",
        "    neu_std=np.std(list(df1_no_high['text_clean_len']))\n",
        "    # print(neu_mean)\n",
        "    # print(neu_std)\n",
        "    df1_no_high = df1.loc[df1['text_clean_len'] < highMod*(neu_mean +neu_std)]\n",
        "\n",
        "  df1_mid = df1_no_high.loc[df1_no_high['text_clean_len'] > lowMod*(neu_mean -neu_std)]\n",
        "\n",
        "  return df1_mid\n",
        "\n",
        "df2 = df1.loc[df1['p_rem'] < .5] #keep sampels with less than half of it are citation\n",
        "\n",
        "df_neu=getMidLen(df2,0,lowMod=2)\n",
        "df_pos=getMidLen(df2,1,lowMod=1,highMod=2)\n",
        "df_neg=getMidLen(df2,-1,lowMod=1,highMod=2)\n",
        "df3= pd.concat([df_neg,df_neu,df_pos])\n",
        "df3['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq-BsMfleXID",
        "outputId": "6a27635b-e951-4c82-f365-cfa3e65dc898"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    2524\n",
              " 1     746\n",
              "-1     246\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def catagorize(data,labelKey='label'):\n",
        "  rows=len(data.index)\n",
        "  onehots=np.zeros((rows,3),dtype=int)\n",
        "  for i,lab in enumerate(data[labelKey]):\n",
        "    onehots[i][lab+1]=1\n",
        "  return onehots\n",
        "\n",
        "hots=catagorize(df3)\n",
        "df3['label_onehot']=list(hots)\n",
        "df3['label_index']=df3['label']+1"
      ],
      "metadata": {
        "id": "VnsKnaB0AU4i"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq= np.array(list(df3['label_index'].value_counts(normalize=True,sort=False)))\n",
        "print(freq)\n",
        "class_ratio= 1/freq\n",
        "class_ratio"
      ],
      "metadata": {
        "id": "Mbn2dX1C2Ixs",
        "outputId": "ff805d42-0f63-4203-fb01-5ee5be951304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06996587 0.71786121 0.21217292]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14.29268293,  1.39302694,  4.71313673])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Model"
      ],
      "metadata": {
        "id": "QtrXZF4_unOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(list(df3['text_clean']), list(df3['label_index']), test_size=0.2, random_state=42)\n",
        "X_train= [[s] for s in X_train]\n",
        "X_test= [[s] for s in X_test]\n",
        "y_train=[[s] for s in list(y_train)]\n",
        "y_test=[[s] for s in list(y_test)]"
      ],
      "metadata": {
        "id": "kKtJq5Baj1Wl"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose a BERT model to fine-tune (Taken from tutorial)\n",
        "\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "metadata": {
        "id": "9WK-J5dQpprm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc687c56-83eb-4e7f-9eb2-68c69642414b"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check model passes"
      ],
      "metadata": {
        "id": "91uobQaIu-iE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "metadata": {
        "id": "YINTv-Uu8HP5"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = X_train[1]\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGAgJwGg08-j",
        "outputId": "749f90f6-1fc2-413f-c9a4-7000e8e91afe"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_mask', 'input_word_ids', 'input_type_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [  101  1999  5688 11416  6024  4275  2024  4738  2000 25845  1996  4101]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "metadata": {
        "id": "U2o1JW9b9MHu"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW0iEt6Z9PKt",
        "outputId": "e49abc80-9db0-463c-c2bb-2569c37fde1b"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.99835694 -0.7678578  -0.21300124  0.08411987 -0.08593949  0.98550844\n",
            "  0.9732349  -0.8306031  -0.55687106 -0.95725054 -0.3960305  -0.94115573]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[ 3.8915187e-01  2.3267061e-01  6.1780311e-02 ... -9.2866874e-01\n",
            "   4.3027106e-01  8.3279318e-01]\n",
            " [ 4.5310837e-01  7.2308904e-01 -3.2866317e-01 ... -1.1163950e-04\n",
            "  -3.3482751e-01  5.7274055e-01]\n",
            " [-2.5876865e-01  1.4199525e+00 -4.2525381e-01 ...  4.9038833e-01\n",
            "   1.4491324e-01  5.7048750e-01]\n",
            " ...\n",
            " [ 2.6529512e-01 -2.3668993e-01  8.4921330e-02 ...  2.0211086e-02\n",
            "   3.9103544e-01  8.9449620e-01]\n",
            " [ 2.9499257e-01  5.8424294e-01 -6.7344594e-01 ... -1.6148384e+00\n",
            "   1.3211843e+00 -6.0517174e-01]\n",
            " [-1.8697177e-01  5.2527428e-01  9.2377967e-01 ... -5.6088662e-01\n",
            "   1.0293359e+00 -7.8856331e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## full model setup"
      ],
      "metadata": {
        "id": "GSyS6XhXvGXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(3, activation='softmax', name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "XWtmKUBu_3kJ"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = build_classifier_model()"
      ],
      "metadata": {
        "id": "Z17Cu4Awc3jA"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check loss function"
      ],
      "metadata": {
        "id": "KgOUUHifvD3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(bert_raw_result)\n",
        "\n",
        "l =  SparseCategoricalFocalLoss(gamma=2,class_weight=class_ratio)\n",
        "test =tf.convert_to_tensor([1.0])\n",
        "l(test,bert_raw_result)"
      ],
      "metadata": {
        "id": "jHqpunBDTKym",
        "outputId": "4117fdc7-ece9-4c13-ccf8-099c3c53c804",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.09427555 0.03744136 0.8682831 ]], shape=(1, 3), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=4.2398114>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Save and Log"
      ],
      "metadata": {
        "id": "hTEGlj9RvLg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "steps_per_epoch = 200 #tf.data.experimental.cardinality(X_train).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 2e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n",
        "\n",
        "# def auc_wrapper(y_true,y_pred):\n",
        "#   print(y_true,y_pred)\n",
        "\n",
        "#   y_true=tf.reshape(y_true,[1])\n",
        "#   print(y_true)\n",
        "#   y_true= tf.cast(y_true, tf.int32)\n",
        "#   print(y_true)\n",
        "#   y_true=tf.one_hot(y_true,depth=3)\n",
        "#   print(y_true)\n",
        "#   return tf.keras.metrics.AUC(multi_label=True)(y_true,y_pred)\n",
        "\n",
        "\n",
        "loss =  SparseCategoricalFocalLoss(gamma=2,class_weight=class_ratio) #tf.keras.losses.MeanSquaredError()\n",
        "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]#, auc_wrapper]#, tf.keras.metrics.AUC(multi_label=True)]\n",
        "\n",
        "\n",
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"citation_BERT_{epoch}\",\n",
        "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
        "        monitor=\"val_sparse_categorical_accuracy\",\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n",
        "]\n"
      ],
      "metadata": {
        "id": "MB9Af5RMCuqP"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Training model with {tfhub_handle_encoder}')\n",
        "# history = classifier_model.fit(x=X_train,y=y_train, validation_data=(X_test,y_test),epochs=epochs,callbacks= callbacks, verbose=True)"
      ],
      "metadata": {
        "id": "89v_3XqEE3HN"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier_model.save_weights(''/content/drive/MyDrive/Text-ML/checkpoint1')"
      ],
      "metadata": {
        "id": "Pox0n2xZjdtX"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect model"
      ],
      "metadata": {
        "id": "Z_fseNCGvY4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "00eGEQhDdMUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "998b6294-e6ec-4622-97ca-2a153e1d2214"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorboard --logdir=logs"
      ],
      "metadata": {
        "id": "Gszh9ZNBbQXe"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.load_weights('/content/drive/MyDrive/Text-ML/checkpoint')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMRXTmWvmBNn",
        "outputId": "90c7a6a1-5d05-466d-c3d7-be10509c2f89"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f82acc3f0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preds=classifier_model.predict(X_train,verbose=1)"
      ],
      "metadata": {
        "id": "vCgZJCYsvdMe"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preds_t=classifier_model.predict(X_test,verbose=1)"
      ],
      "metadata": {
        "id": "Wu5a35I1wlOi"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns; sns.set_theme()"
      ],
      "metadata": {
        "id": "Q-NxIjYJx8S1"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c_mat=tf.math.confusion_matrix(np.argmax(preds,-1),y_train)\n",
        "# ax = sns.heatmap(c_mat,annot=True,linewidths=.5)"
      ],
      "metadata": {
        "id": "_5R4bXyzxoql"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c_mat=tf.math.confusion_matrix(np.argmax(preds_t,-1),y_test)\n",
        "# ax = sns.heatmap(c_mat,annot=True,linewidths=.5)"
      ],
      "metadata": {
        "id": "RPkpGRdDyCz6"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get attention colorings"
      ],
      "metadata": {
        "id": "ZRca_y_Kvq86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1\n"
      ],
      "metadata": {
        "id": "aSNvnkyoJdqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.layers"
      ],
      "metadata": {
        "id": "PR_gDYEQofck",
        "outputId": "2ef9ab73-d810-4fea-e530-b487141a9ae3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f829e584dd0>,\n",
              " <tensorflow_hub.keras_layer.KerasLayer at 0x7f82aa8eee50>,\n",
              " <tensorflow_hub.keras_layer.KerasLayer at 0x7f82aa8ee350>,\n",
              " <keras.layers.core.dropout.Dropout at 0x7f829cafd510>,\n",
              " <keras.layers.core.dense.Dense at 0x7f829cb98b90>]"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from official.nlp import bert \n",
        "import official.nlp.bert.tokenization"
      ],
      "metadata": {
        "id": "bC2uW7zrx7VR"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = bert.tokenization.FullTokenizer(vocab_file='/content/drive/MyDrive/Text-ML/vocab.txt')\n",
        "preprocesser_model = keras.Model(inputs=classifier_model.input,outputs=classifier_model.get_layer('preprocessing').output)\n",
        "encoder_model = keras.Model(inputs=classifier_model.input,outputs=classifier_model.get_layer('BERT_encoder').output)"
      ],
      "metadata": {
        "id": "Lnb_ie7zxpbc"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocab size:\", len(tokenizer.vocab))"
      ],
      "metadata": {
        "id": "mjgJ0WAwRjYb",
        "outputId": "0853e3b5-9817-44ee-83ec-495b8576a281",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 30522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attnetion token mapping"
      ],
      "metadata": {
        "id": "z7DPKDmPI9yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attn(context,prep,encoder): # assume stirng array input\n",
        "  t_context=tf.convert_to_tensor(context)\n",
        "\n",
        "  p_out=prep(t_context)\n",
        "  #print(p_out)\n",
        "  stop_index=0\n",
        "  while(stop_index< p_out[\"input_mask\"].shape[1] and p_out[\"input_mask\"][0][stop_index] == 1):\n",
        "    stop_index+=1\n",
        "  \n",
        "  if stop_index >= 128:\n",
        "    stop_index=127\n",
        "\n",
        "  output = encoder(t_context)\n",
        "  #print(output[\"sequence_output\"].shape)\n",
        "  valid_entries=output[\"sequence_output\"][:,1:stop_index-1,:]\n",
        "  a=tf.math.reduce_mean(valid_entries,-1)\n",
        "  mean=tf.math.reduce_mean(a,-1,keepdims=True)\n",
        "  std=tf.math.reduce_std(a,-1,keepdims=True)\n",
        "  a1=(a-mean)/std\n",
        "\n",
        "  return a1"
      ],
      "metadata": {
        "id": "NC_Cyexu9TQI"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attn_for_words(context,tokenizer,prep,encoder):\n",
        "  attn = get_attn(context,prep,encoder).numpy()\n",
        "  tokens = tokenizer.tokenize(context[0]) \n",
        "\n",
        "  indicies=np.ones((len(tokens)),dtype=int)\n",
        "  for i,tok in enumerate(tokens):\n",
        "    if '##' in tok:\n",
        "      indicies[i]=0\n",
        "\n",
        "  full_words=tokens.copy()\n",
        "  ix=-1\n",
        "  for i,tok in enumerate(tokens):\n",
        "    if not indicies[i]:\n",
        "      attn[0][ix]+=attn[0][i]\n",
        "      full_words[ix]+=tok[2:]\n",
        "    else:\n",
        "      ix=i\n",
        "\n",
        "  t_f=tf.convert_to_tensor(full_words) #stores as byte string...\n",
        "  masked_f=tf.boolean_mask(t_f,indicies)\n",
        "  t_a=tf.convert_to_tensor(attn)[0]\n",
        "  masked_a=tf.boolean_mask(t_a[:len(indicies)],indicies)\n",
        "  \n",
        "\n",
        "  return masked_f.numpy(),masked_a.numpy()\n",
        "\n",
        "#words, at=get_attn_for_words(processed,tokenizer,preprocesser_model,encoder_model)"
      ],
      "metadata": {
        "id": "iyhKVIiY121W"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## converters and annotation"
      ],
      "metadata": {
        "id": "kj_6JUFQIvG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_for_input(raw_context):\n",
        "  c1,_ =remove_matches(text=raw_context,regex=re_apa)\n",
        "  c2,_ =remove_matches(text=c1,regex='[^\\w_\\-0-9 ]+')\n",
        "  return [c2]\n",
        "\n",
        "#process_for_input(example)"
      ],
      "metadata": {
        "id": "PTVxz5uFJZyI"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_bytes_strs(words):\n",
        "  return [w.decode('UTF-8') for w in list(words)]"
      ],
      "metadata": {
        "id": "uFUPhtLDH5SS"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_to_color(attn): #blue pos red neg\n",
        "  rgbs = np.zeros((len(attn),3),dtype=int)\n",
        "  for i,score in enumerate(attn):\n",
        "    if score < 0:\n",
        "      rgbs[i][0]=-255*score//2\n",
        "    else:\n",
        "      rgbs[i][2]=255*score//2\n",
        "  \n",
        "  return rgbs"
      ],
      "metadata": {
        "id": "yDhvZkOFMFJ3"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coloring(text,fore=None,back=None):\n",
        "    txt=text\n",
        "    if fore != None and fore[0] != -1:\n",
        "      txt = \"\\033[38;2;{};{};{}m\".format(fore[0], fore[1], fore[2])+txt\n",
        "    if back != None and back[0] != -1:\n",
        "      txt = \"\\033[48;2;{};{};{}m\".format(back[0], back[1], back[2])+txt\n",
        "    return txt\n",
        "\n",
        "#print(coloring('Hello',back=[500,0,0]) + coloring('Hello', back=(0,0,255)))"
      ],
      "metadata": {
        "id": "X8GvqhLvOR8H"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## full pipeline"
      ],
      "metadata": {
        "id": "spUdAeqoI0Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def color_by_attn(text,toker,preper,encoder):\n",
        "  all_words_original=text.split()\n",
        "  all_words=text.lower().split()\n",
        "  processed= process_for_input(text)\n",
        "\n",
        "  words, at=get_attn_for_words(processed,tokenizer,preprocesser_model,encoder_model)\n",
        "\n",
        "  ws=conv_bytes_strs(words)\n",
        "  conv=conv_to_color(at)\n",
        "  mapping=dict(zip(ws,conv))\n",
        "  orig_mapping=dict(zip(all_words,all_words_original))\n",
        "\n",
        "  for i,w in enumerate(all_words):\n",
        "    if w not in mapping:\n",
        "      mapping[w]=[0,0,0] #make black\n",
        "    else:\n",
        "      mapping[w]=list(mapping[w])\n",
        "\n",
        "  colored=[coloring(orig_mapping[word],fore=[255,255,255],back=mapping[word]) for word in all_words]\n",
        "  printed=' '.join(colored)\n",
        "  return printed\n",
        "\n",
        "example=list(df3['text'])[0]\n",
        "p=color_by_attn(example,tokenizer,preprocesser_model,encoder_model)\n",
        "print(p)\n",
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hossOHKtZ1Wn",
        "outputId": "935958f4-9884-435d-e32d-6a7c7cbb9013"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[48;2;12;0;0m\u001b[38;2;255;255;255mMany \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mapproaches \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mfor \u001b[48;2;140;0;0m\u001b[38;2;255;255;255mPOS \u001b[48;2;103;0;0m\u001b[38;2;255;255;255mtagging \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mhave \u001b[48;2;22;0;0m\u001b[38;2;255;255;255mbeen \u001b[48;2;188;0;0m\u001b[38;2;255;255;255mdeveloped \u001b[48;2;0;0;46m\u001b[38;2;255;255;255min \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpast, \u001b[48;2;0;0;281m\u001b[38;2;255;255;255mincluding \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrule-based \u001b[48;2;103;0;0m\u001b[38;2;255;255;255mtagging \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(Brill, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1995), \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mHMM \u001b[48;2;316;0;0m\u001b[38;2;255;255;255mtaggers \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(Brants, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2000; \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mCutting \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mothers, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1992), \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmaximum-entropy \u001b[48;2;0;0;41m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(Rathnaparki, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1996), \u001b[48;2;0;0;97m\u001b[38;2;255;255;255mcyclic \u001b[48;2;61;0;0m\u001b[38;2;255;255;255mdependency \u001b[48;2;0;0;45m\u001b[38;2;255;255;255mnetworks \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(Toutanova \u001b[48;2;0;0;0m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2003), \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmemory-based \u001b[48;2;0;0;84m\u001b[38;2;255;255;255mlearning \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(Daelemans \u001b[48;2;0;0;0m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1996), \u001b[48;2;0;0;0m\u001b[38;2;255;255;255metc. \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mall \u001b[48;2;0;0;258m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;186m\u001b[38;2;255;255;255mthese \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mapproaches \u001b[48;2;0;0;110m\u001b[38;2;255;255;255mrequire \u001b[48;2;215;0;0m\u001b[38;2;255;255;255meither \u001b[48;2;0;0;217m\u001b[38;2;255;255;255ma \u001b[48;2;207;0;0m\u001b[38;2;255;255;255mlarge \u001b[48;2;0;0;46m\u001b[38;2;255;255;255mamount \u001b[48;2;0;0;258m\u001b[38;2;255;255;255mof \u001b[48;2;70;0;0m\u001b[38;2;255;255;255mannotated \u001b[48;2;77;0;0m\u001b[38;2;255;255;255mtraining \u001b[48;2;166;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(for \u001b[48;2;50;0;0m\u001b[38;2;255;255;255msupervised \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtagging) \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mor \u001b[48;2;0;0;217m\u001b[38;2;255;255;255ma \u001b[48;2;467;0;0m\u001b[38;2;255;255;255mlexicon \u001b[48;2;0;0;9m\u001b[38;2;255;255;255mlisting \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mall \u001b[48;2;0;0;81m\u001b[38;2;255;255;255mpossible \u001b[48;2;45;0;0m\u001b[38;2;255;255;255mtags \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;114m\u001b[38;2;255;255;255meach \u001b[48;2;117;0;0m\u001b[38;2;255;255;255mword \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(for \u001b[48;2;0;0;0m\u001b[38;2;255;255;255munsupervised \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtagging).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\x1b[48;2;12;0;0m\\x1b[38;2;255;255;255mMany \\x1b[48;2;0;0;108m\\x1b[38;2;255;255;255mapproaches \\x1b[48;2;0;0;102m\\x1b[38;2;255;255;255mfor \\x1b[48;2;140;0;0m\\x1b[38;2;255;255;255mPOS \\x1b[48;2;103;0;0m\\x1b[38;2;255;255;255mtagging \\x1b[48;2;0;0;60m\\x1b[38;2;255;255;255mhave \\x1b[48;2;22;0;0m\\x1b[38;2;255;255;255mbeen \\x1b[48;2;188;0;0m\\x1b[38;2;255;255;255mdeveloped \\x1b[48;2;0;0;46m\\x1b[38;2;255;255;255min \\x1b[48;2;29;0;0m\\x1b[38;2;255;255;255mthe \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255mpast, \\x1b[48;2;0;0;281m\\x1b[38;2;255;255;255mincluding \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255mrule-based \\x1b[48;2;103;0;0m\\x1b[38;2;255;255;255mtagging \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m(Brill, \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m1995), \\x1b[48;2;9;0;0m\\x1b[38;2;255;255;255mHMM \\x1b[48;2;316;0;0m\\x1b[38;2;255;255;255mtaggers \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m(Brants, \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m2000; \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255mCutting \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255mand \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255mothers, \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m1992), \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255mmaximum-entropy \\x1b[48;2;0;0;41m\\x1b[38;2;255;255;255mmodels \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m(Rathnaparki, \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m1996), \\x1b[48;2;0;0;97m\\x1b[38;2;255;255;255mcyclic \\x1b[48;2;61;0;0m\\x1b[38;2;255;255;255mdependency \\x1b[48;2;0;0;45m\\x1b[38;2;255;255;255mnetworks \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m(Toutanova \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255met \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255mal. \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m, \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m2003), \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255mmemory-based \\x1b[48;2;0;0;84m\\x1b[38;2;255;255;255mlearning \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m(Daelemans \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255met \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255mal. \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m, \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m1996), \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255metc. \\x1b[48;2;0;0;15m\\x1b[38;2;255;255;255mall \\x1b[48;2;0;0;258m\\x1b[38;2;255;255;255mof \\x1b[48;2;0;0;186m\\x1b[38;2;255;255;255mthese \\x1b[48;2;0;0;108m\\x1b[38;2;255;255;255mapproaches \\x1b[48;2;0;0;110m\\x1b[38;2;255;255;255mrequire \\x1b[48;2;215;0;0m\\x1b[38;2;255;255;255meither \\x1b[48;2;0;0;217m\\x1b[38;2;255;255;255ma \\x1b[48;2;207;0;0m\\x1b[38;2;255;255;255mlarge \\x1b[48;2;0;0;46m\\x1b[38;2;255;255;255mamount \\x1b[48;2;0;0;258m\\x1b[38;2;255;255;255mof \\x1b[48;2;70;0;0m\\x1b[38;2;255;255;255mannotated \\x1b[48;2;77;0;0m\\x1b[38;2;255;255;255mtraining \\x1b[48;2;166;0;0m\\x1b[38;2;255;255;255mdata \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m(for \\x1b[48;2;50;0;0m\\x1b[38;2;255;255;255msupervised \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255mtagging) \\x1b[48;2;0;0;93m\\x1b[38;2;255;255;255mor \\x1b[48;2;0;0;217m\\x1b[38;2;255;255;255ma \\x1b[48;2;467;0;0m\\x1b[38;2;255;255;255mlexicon \\x1b[48;2;0;0;9m\\x1b[38;2;255;255;255mlisting \\x1b[48;2;0;0;15m\\x1b[38;2;255;255;255mall \\x1b[48;2;0;0;81m\\x1b[38;2;255;255;255mpossible \\x1b[48;2;45;0;0m\\x1b[38;2;255;255;255mtags \\x1b[48;2;0;0;102m\\x1b[38;2;255;255;255mfor \\x1b[48;2;0;0;114m\\x1b[38;2;255;255;255meach \\x1b[48;2;117;0;0m\\x1b[38;2;255;255;255mword \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255m(for \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255munsupervised \\x1b[48;2;0;0;0m\\x1b[38;2;255;255;255mtagging).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('test')"
      ],
      "metadata": {
        "id": "r3D3FipbOOxP",
        "outputId": "5219b975-d5f8-4f54-f452-087293d2d57d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF text extratction\n"
      ],
      "metadata": {
        "id": "TD_FQ6ioGFGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_pdf_to_string(file_path):\n",
        "\toutput_string = StringIO()\n",
        "\twith open(file_path, 'rb') as in_file:\n",
        "\t    parser = PDFParser(in_file)\n",
        "\t    doc = PDFDocument(parser)\n",
        "\t    rsrcmgr = PDFResourceManager()\n",
        "\t    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
        "\t    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "\t    for page in PDFPage.create_pages(doc):\n",
        "\t        interpreter.process_page(page)\n",
        "\n",
        "\treturn(output_string.getvalue())\n",
        " \n",
        "def sent_extract(sample):\n",
        "\tdelims=re.findall('\\. [A-Z]',sample)\n",
        "\tsents=re.split('\\. [A-Z]',sample)\n",
        "\n",
        "\tsents[0]=sents[0]+'.'\n",
        "\tfor i,s in enumerate(sents[1:]):\n",
        "\t\tsents[i+1]=delims[i][2]+s+'.'\n",
        "\tfor i,s in enumerate(sents):\n",
        "\t\tsents[i]=re.sub('\\d+https(\\w|\\:|\\/|\\.|\\?|\\=|\\-|\\&)+','',s)\n",
        "\t\t\n",
        "\treturn sents\n",
        "\n",
        "def pdf_text_extract(path):\n",
        "\ttext=convert_pdf_to_string(path)\n",
        "\ttext1 = text.replace('\\x0c','')\n",
        "\ttext2 = text1.split('.\\n\\n')\n",
        "\tprint(text2)\n",
        "\trefine=[t.replace('\\n',' ') for t in text2]\n",
        "\tr=[]\n",
        "\tfor t in refine:\n",
        "\t\tr+=sent_extract(t)\n",
        "\treturn r\n",
        "\n",
        "path='/content/drive/MyDrive/Text-ML/phocus.pdf'\n",
        "text=pdf_text_extract(path)\n",
        "#text"
      ],
      "metadata": {
        "id": "HkUe38wlJSov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dddf6796-c740-4b11-c997-23e6b3d95704"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2\\n2\\n0\\n2\\n\\nn\\na\\nJ\\n\\n4\\n1\\n\\n]\\nL\\nD\\n.\\ns\\nc\\n[\\n\\n2\\nv\\n5\\n1\\n9\\n2\\n0\\n.\\n1\\n0\\n2\\n2\\n:\\nv\\ni\\nX\\nr\\na\\n\\nPhocus: Picking Valuable Research from a Sea of Citations\\n\\nXinrong Zhang\\nzxr19@mails.tsinghua.edu.cn\\nTsinghua University\\nBeijing, China\\n\\nZihou Renâˆ—\\nrzh20@mails.tsinghua.edu.cn\\nTsinghua University\\nBeijing, China\\n\\nShuqi Liuâˆ—\\nliu-sq19@mails.tsinghua.edu.cn\\nTsinghua University\\nBeijing, China\\n\\nYunlong Dengâˆ—\\ndengyl20@mails.tsinghua.edu.cn\\nTsinghua University\\nBeijing, China\\n\\nXi Liâˆ—\\nlixi19@mails.tsinghua.edu.cn\\nTsinghua University\\nBeijing, China\\n\\nYadi Xiaoâˆ—\\nxyd18@mails.tsinghua.edu.cn\\nTsinghua University\\nBeijing, China\\n\\nYuxing Hanâˆ—\\nyuxinghan@tsinghua-sz.org\\nTsinghua Shenzhen International\\nGraduate School\\nShenzhen, China\\n\\nJiangtao Wenâ€ \\njtwen@tsinghua.edu.cn\\nTsinghua University\\nBeijing, China\\n\\nABSTRACT\\nThe deluge of new papers has significantly blocked the develop-\\nment of academics, which is mainly caused by author-level and\\npublication-level evaluation metrics that only focus on quantity.\\nThose metrics have resulted in several severe problems that trou-\\nble scholars focusing on the important research direction for a\\nlong time and even promote an impetuous academic atmosphere.\\nTo solve those problems, we propose Phocus, a novel academic\\nevaluation mechanism for authors and papers. Phocus analyzes\\nthe sentence containing a citation and its contexts to predict the\\nsentiment towards the corresponding reference. Combining others\\nfactors, Phocus classifies citations coarsely, ranks all references\\nwithin a paper, and utilizes the results of the classifier and the rank-\\ning model to get the local influential factor of a reference to the\\nciting paper. The global influential factor of the reference to the\\nciting paper is the product of the local influential factor and the\\ntotal influential factor of the citing paper. Consequently, an authorâ€™s\\nacademic influential factor is the sum of oneâ€™s contributions to each\\npaper one co-authors', 'KEYWORDS\\ncitation classification, sentiment analysis, academic influential fac-\\ntor, data mining\\n\\nFigure 1: the number of new publications on IEEE Xplore\\neach year from 2000 to 2021', '1 INTRODUCTION\\nThe number of papers published each year has grown greatly. For\\nexample, as shown in Figure 1, the number of new papers on IEEE\\nXplore1 increases sharply over the decade', 'Paper boom in academic fields results in many severe problems.\\nCortes et al. [10] examine 2014 NeurIPS and find that it is not able\\nto pick out excellent researches, and could identify terrible papers.\\nChu et al. [8] reveal that too many papers published each year in a\\nfield hinder its development. They state this opinion in two aspects.\\nFirst, researchers are busy coping with a lot of papers, but donâ€™t\\nhave enough time to fully learn novel ideas; Second, the focused\\nattention on a promising idea might be broken up by the deluge of\\nnew ideas', 'âˆ—Authors contributed equally to this research.\\nâ€ Corresponding author\\n1https://ieeexplore.ieee.org/Xplore/home.jsp\\n\\nReference Format:\\nXinrong Zhang, Zihou Ren, Xi Li, Shuqi Liu, Yunlong Deng, Yadi Xiao,\\nYuxing Han, and Jiangtao Wen. 2022. Phocus: Picking Valuable Research\\nfrom a Sea of Citations. In Proceedings of . , 7 pages', ', ,\\nÂ© 2022 ', ' \\n \\n \\n \\n \\n \\n, ,\\n\\nZhang and Wen et al', 'The reason for the sharp increase in papers is that evaluation\\nmetrics for researchers and scholars focus on the number of papers.\\nFrom the scientific output, research funding, to the evaluation of\\nprofessional rank, papers play a very important role, and the more\\npapers, the better. However, It is time to make changes. Quantitative\\nmetrics could not evaluate the real academic impact of a scholar\\nor a paper. They ignore the essential differences between citations,\\nwhich is a fatal error. Seglen expresses strong opposition to im-\\npact factors that measure the academic influence of journals for\\ncommittees seldom have the specialistâ€™ insights to assess primary\\nresearches[31]', 'We propose Phocus, a novel evaluation mechanism for scholars\\nand publications. Phocus analyzes the sentence containing a citation\\nand its contexts to predict the sentiment polarity towards the corre-\\nsponding reference. Besides, Phocus also considers the total number\\nof citations, the number of citations per sentence, author overlap,\\nand the number of references, similar to [35]. Given those factors\\nabove, Phocus uses Naive Bayesian Classifier to divide citations\\ncoarsely into 4 categories and utilizes the LambdaMART model to\\nsort all references within a paper. Combining the categories and\\nthe ranking results, every reference gets its local influential factor\\nwithin [âˆ’1, 1], related to the citing paper. The global influential\\nfactor of the reference to the citing paper is the product of the local\\ninfluential factor and the total influential factor of the citing paper.\\nConsequently, an authorâ€™s academic influential factor is the sum of\\nhis contributions to each paper he co-authors', '2 RELATED WORK\\nOur work involves citation classification, aspect-based sentiment\\nanalysis, ranking model and evaluation metrics for academics,\\nwhich will be introduced in subsections below respectively', '2.1 Citation Classification\\nIn fact, there are already many kinds of research that have focused\\non citation classification. For example, Teufel et al. [33] classify\\ncitation intents into 12 classes, using simple regular match to ex-\\ntract features. Valenzuela et al. [35] divide citations into 4 classes:\\nhighly influential, background, method and results citations, using\\nSVM with an RBF kernel and random forests, taking 13 features into\\nconsideration: total number of direct citations, number of direct cita-\\ntions per section, the total number of indirect citations and number\\nof indirect citations per section, author overlap, is considered help-\\nful, citation appears in table and caption, 1/number of references,\\nnumber of paper citations/all citations, the similarity between ab-\\nstracts, PageRank[28], number of total citing papers after transitive\\nclosure, and field of the cited paper. While Jurgens et al. [20] define 7\\nclasses of citation intents: background, motivation, uses, extension,\\ncontinuation, comparison or contrast, and future, with a Random\\nForest classifier trained using 4 types of features: structural fea-\\ntures, lexical, morphological and grammatical features, field, and\\nusage. Cohan et al. [9] propose a multitask model using BiLSTM\\nand attention mechanism to classify citation intents that is the\\nprimary task and predict the section where the citation occurs and\\nwhere a sentence needs a citation that is auxiliary tasks and is used\\nto assist the primary task2. They categorize intents into 3 classes:\\n\\nbackground information, method, and result comparison. Besides,\\nCohan builds a citation intent dataset SciCite. Those works sim-\\nply classify citations according to intents but ignore the sentiment\\nciting paper towards references, which is vital', 'Butt et al. [6] utilize Naive-Bayes Classifier to predict the senti-\\nment polarity of a sentence containing a citation and its contexts.\\nWhereas Liu et al. [23] use averaged word embeddings to represent\\nsentence vectors and to classify sentiment polarities. However, this\\nmethod generates the overall sentiment of text, rather than the\\nprecise sentiment towards the cited paper, which is unable to apply\\ndirectly', '2.2 Aspect-based Sentiment Analysis\\nAspect-based sentiment analysis (ABSA) is proposed to define such\\na task. Usually, ABSA consists of two stages: locating aspects and\\nanalyzing sentiment. Some works solve this problem also in a two-\\nstage way, while some jointly', 'To detect citation span in Wikipedia, Fetahu et al. [13] propose a\\nsequence classification method using a linear chain CRF to decide\\nwhich text fragments are covered by a citation at the sub-sentence\\nlevel. Whereas Kaplan et al. [22] detect non-explicit citing sentences\\nthat surround an explicit citing sentence, utilizing relational, entity,\\nlexical, and grammatical coherence between them. [25][39]even try\\nto find the most relative sentences in reference paper with the citing\\nsentences. Qazvinian and Radev [29] proposed a method based on\\nprobabilistic inference to extract non-explicit citing sentences by\\nmodelling the sentences in an article and their lexical similarities\\nas a Markov Random Field tuned to detect the patterns that context\\ndata create and employ a Belief Propagation mechanism to detect\\nlikely context sentences. Abu-Jbara and Radev [1] determine the\\ncitation block by first segmenting the sentences and then classifying\\neach word in the sentence as being inside or outside the citation\\nblock. Finally, they aggregate the labels of all the words contained\\nin a segment to assign a label to the whole segment using three\\ndifferent label aggregation rules(majority label of the words, at least\\none of the words, or all of them). Kaplan et al. [21] proposed a new\\nmethod based on coreference-chains for extracting citation blocks\\nfrom research papers', 'Given aspects, Sun et al. [32] construct an auxiliary sentence\\nfrom a aspect, and feed the sentence-pair into BERT-based model.\\nGao et al. [14] utilize three target-dependent variations of the\\nðµð¸ð‘…ð‘‡ð‘ð‘Žð‘ ð‘’ model. Bai et al. [2] propose a novel relational graph\\nattention network3, which integrates typed syntactic dependency\\ninformation', 'As the errors are cumulated in the pipeline, some researchers\\nexplore solutions that detect aspects and classify sentiment jointly.\\nWang et al. [37] propose a latent aspect rating analysis problem\\nthat aims at analyzing reviewersâ€™ latent opinions on an entity from\\nseveral aspects. For a certain entity, they define a set of keywords\\nof aspects and segment reviews into the aspect level. Given as-\\npect segmentation results, they use a novel latent rating regression\\nmodel to calculate aspect ratings and corresponding weights. How-\\never, Wang et al. ignore the inter-dependencies between words and\\nsentences, which causes great information loss. This class prob-\\nlem is also called aspect-based sentiment analysis (ABSA). Ruder\\n\\n2https://github.com/allenai/scicite\\n\\n3https://github.com/muyeby/RGAT-ABSA\\n\\nPhocus: Picking Valuable Research from a Sea of Citations\\n\\n, ,\\n\\net al. [30] proposes a hierarchical bidirectional LSTM to model\\nthe inter-dependencies of sentences within a review. The aspect is\\nrepresented by the average of its entity and attribute embeddings.\\nHoang et al. [18] propose to use a sentence pair classifier model\\nfrom BERT[11] to solve ABSA at sentence and text levels. Hu et al.\\n[19] propose a span-based extract-then-classify framework based\\non BERT4. Xu et al. [38] build a dataset, ReviewRC5, and extend\\nBERT with an extra tasking-specific layer to tune each task. Wal-\\nlaart et al. [36] propose a two-stage algorithm to solve the ABSA\\nfor restaurant reviews: predicting the sentiment with a lexicalized\\ndomain ontology, and using a neural network with a rotatory at-\\ntention mechanism (LCR-Rot) as a backup algorithm. The order\\nof rotatory attention mechanism operation is changed and the ro-\\ntatory attention mechanism is iterated multiple times. Trusca et\\nal. extend [36] with deep contextual word embeddings and add an\\nextra attention layer to its high-level representations[34]. To ad-\\ndress the imbalance issue and utilize the interaction between aspect\\nterms, Luo et al. [24] propose a gradient harmonized and cascaded\\nlabelling model based on BERT. Chen et al. [7] utilize directional\\ngraph convolutional networks to perform end-to-end ABSA task', '2.3 Ranking Model\\nThe ranking model is based on LambdaMART, which is the boosted\\ntree version of LambdaRank[5]. This algorithm solves the gradients\\nof non-smooth cost functions used in ranking models. Burges et al.\\n[4] give a review on RankNet, LambdaRank, and LambdaMART', 'To illustrate the ranking network, we use ð‘ð‘– ð‘— to denote the ð‘—-th ci-\\ntation of the ð‘–-th reference paper. Our ranking network receives an\\nmatrix of shape ((cid:205)ð‘– ð‘›_ð‘ð‘–ð‘¡ð‘–, 4), where 4 stands for the feature quater-\\nnion of (au_overlap, n_cit, cit_word, sen_label). Among which\\ncit_word is calculated as the total number of words in ð‘ð‘œð‘›ð‘¡ð‘’ð‘¥ð‘¡_ð‘Ž +\\nð‘ ð‘’ð‘›ð‘¡ð‘’ð‘›ð‘ð‘’ + ð‘ð‘œð‘›ð‘¡ð‘’ð‘¥ð‘¡_ð‘. The network calculate a score ð‘ ð‘– ð‘— on each\\ntime of citation ð‘ð‘– ð‘— individually, averaging on duplicate citations to\\n(cid:205)ð‘— ð‘ ð‘– ð‘— . Then ð‘ ð‘– is\\nget the score of each reference paper ð‘ ð‘– =\\nused to rank all the reference paper, outputting ð‘Ÿð‘– ', '1\\nð‘›_ð‘ð‘–ð‘¡ð‘–\\n\\n2.4 Evaluation Metrics\\nIn the academic field, there are journal-level, author-level and paper-\\nlevel metrics that measure their impacts', 'The Impact Factor (IF)[26] and CiteScore6 are used to measure\\nthe impact of a journal based on the number of times articles cited\\nduring a fixed period published by the journal. Besides, Journal Cita-\\ntion Reports (JCR) give ranking for journals7, Eigenfactor scores[3]\\nmeasure how likely a journal is to be used, and SCImago Journal\\nRank (SJR)[15] regards the citations issued by more import jour-\\nnals as more important than those issued by less important ones.\\nWhereas Source Normalized Impact per Paper (SNIP)[27] indicates\\nthat a single citation is much more important in subject areas where\\ncitations are less, and vice versa', 'Author-level metrics include h-index, g-index, i10-index and so\\non. H-index also called index â„Ž, is proposed by Jorge E. Hirsch[17],\\nand its definition is the number of papers with citation numbers\\n\\n4https://github.com/huminghao16/SpanABSA\\n5https://howardhsu.github.io/dataset/\\n6https://service.elsevier.com/app/answers/detail/a_id/14880/supporthub/scopus/\\n7https://jcr.clarivate.com/jcr/home\\n\\nFigure 2: the overview of Phocus', 'higher or equal to â„Ž. The g-index is defined as the largest number\\nsuch that the top ð‘” articles received together at least ð‘”2 citations[12].\\nGoogle Scholar proposes the i10-index that is the number of a\\npublication with at least 10 citations. Those metrics are derived\\nfrom citations and do not reveal the truth among citations', 'Paper-level metrics are usually the number of citations. Espe-\\ncially, Semantic Scholar makes the first step towards citation classi-\\nfication. It divided citations into 4 classes: highly influential, back-\\nground, method and results citations[35], using SVM with an RBF\\nkernel and random forests. The features Semantic Scholar use are\\nthe total number of direct citations, number of direct citations\\nper section, the total number of indirect citations and number of\\nindirect citations per section, author overlap, is considered help-\\nful, citation appears in table and caption, 1/number of references,\\nnumber of paper citations/all citations, the similarity between ab-\\nstracts, PageRank[28], number of total citing papers after transitive\\nclosure, and field of the cited paper', '3 METHODOLOGY\\nAs shown in Figure ??, our algorithm consists of 4 stages: pre-\\nprocessing, calculating factors, evaluating contribution, and prop-\\nagating influential factors. In pre-processing stage, we clean raw\\ndata, and obtain simple factors. Complex factors, like sentiment\\npolarity are calculated in second stage. When get all factors needed,\\nwe classify citations into four classes and rank all references, and\\nfigure out the local contribution factor of each reference. We ini-\\ntialize all new paper to the database with an academic influential\\nfactor 1.0, and propagate its impact on references iteratively. The\\nfactors extracted from papers are listed out in Table 1\\n\\n3.1 Pre-processing\\nGiven a paper of string format, a series of steps process the raw data\\nfor the next stage: parsing, segmentation, and matching. Paring is\\naimed at dividing the input text into title, authors, sections, and\\nreferences. We utilize flari8 to parse the title, authors and publish\\nyear of the input paper and its references. We segment the input\\npaper into two-level: section level and sentence level. Section seg-\\nmentation is based on keywords matching and classified into three\\n\\n8https://pypi.org/project/flair/\\n\\nTable 1: factor list\\n\\nTable 2: the classifying standards of Phocus', 'Definition\\n\\nRanges\\n\\nLabel\\n\\nDescription\\n\\nZhang and Wen et al', ', ,\\n\\nName\\n\\ncit_id\\n\\ncit_title\\ncit_author\\ncit_year\\n\\nau_overlap\\n\\nsent_id\\n\\nreference number of a\\npaper in the reference list\\ntitle of a reference\\nauthors of cit_title\\npublish year of cit_title\\n\\noverlap between authors\\nof cit_title and citing paper\\nid of a sentence\\n\\nsec_id\\n\\nsection id of a sentence\\n\\nn_cit\\n\\ncit_text\\n\\ncontext_a\\n\\ncontext_b\\n\\nsen_label\\n\\ntime of cit_id cited\\nin citing paper\\n\\ntext of the sentence that\\ncontains the cit_id\\nrelated sentences previous\\nto cit_text\\nrelated sentences behind\\nto cit_text\\n\\nthe sentiment citing paper\\ntowards cit_ id\\n\\npositive integer\\n\\nstring\\nlist of authors\\nyear\\n\\n[0, 1]\\n\\nnatural number\\n0: related work\\nintroduction\\n1: main body\\n2: conclusion\\n\\nnatural number\\n\\nstring\\n\\nstring\\n\\nstring\\n\\n-1: negative\\n0: neutral\\n1: positive\\n\\n3\\n2\\n1\\n0\\n\\nextending the work; highly influenced by the work\\nusing the work\\nrelated work\\nnegative sentiment towards the work\\n\\nFigure 3: the propagation rules of influential factors\\n\\ncategories: 0 representing related work, introduction or other back-\\nground citation; 1 representing main body including methodology,\\nexperiments and so on; 2 representing conclusion and other parts.\\nSentences are segmented using regular expression matching and\\nare then labelled by their ID according to their appearing order.\\nReference parsing generates title, authors, publish year and even\\ntheir citation markers in the paper. Given that information, we\\nlocate citations in each sentence and match citation markers with\\ntheir corresponding reference papers. Then we could easily get the\\nfactor n_cit and cit_text. Factor au_overlap is calculated according\\nto the following equation:\\n\\nð‘Žð‘¢_ð‘œð‘£ð‘’ð‘Ÿð‘™ð‘Žð‘ = 2 Ã— ð´âˆ©ðµ\\n|ð´ |+|ðµ |\\n\\n(1)\\n\\nwhere A is the author set of citing paper, and B is the author set of\\nreference paper', '3.2 Calculating Factors\\nThere are still three factors unsolved: context_a, context_b, and\\nsen_label. We obtain context_a, context_b with BERT, and propose a\\nnovel aspect-based sentiment analysis algorithm to classify citation\\nsentiment', 'We fine-tune BERT on a manually annotated dataset contain-\\ning over 1,000 sentence pairs labelled as \"related\" or \"irrelevant\".\\nEach sentence pair is generated from a single academic paper', 'We get an accuracy of 94.5% on the evaluation dataset. To ob-\\ntain the context of cit_context, we apply the above classifier it-\\neratively on sentence pair (ð‘† [ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘ âˆ’ ð‘–], ð‘† [ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘]) (ð‘† represent-\\ning the list of all sentences in the paper) where ð‘– increases from\\n1. Once an \"irrelevant\" pair is reported, the iteration is aborted\\nand we take ð‘† [ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘ âˆ’ ð‘– : ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘] as context_a. Another stop-\\nping criterion is that ð‘† [ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘ âˆ’ ð‘–] should always be in the same\\nparagraph with ð‘† [ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘]. A similar procedure is performed on\\n(ð‘† [ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘ + ð‘–], ð‘† [ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘]) to get context_b', '3.3 Evaluating Contribution\\nAfter gathering all needed factors, we train a classifier to categorize\\ncitation into 4 classes: very important, important, neutral, and\\nterrible. And we also train a ranking model to predict the related\\norder of references in terms of their contributions to the paper. First,\\nwe classify citations into four categories with a Naive Bayesian\\nclassifier. The classifying standards are shown in Table 2, and a\\nlarger number of labels represents more contributions', 'The ranking model is based on LambdaMART, which is the\\nboosted tree version of LambdaRank[5]. This algorithm solves the\\ngradients of non-smooth cost functions used in ranking models.\\nBurges et al. [4] give a review on RankNet, LambdaRank, and Lamb-\\ndaMART', 'Based on the classes and order of references, we project them\\n\\ninto [0, 1] to get their influential factors', 'Phocus: Picking Valuable Research from a Sea of Citations\\n\\n, ,\\n\\n3.4 Propagating Influential Factors\\nGiven a list of references and their influential factors of the citing\\npaper, we design some rules to propagate their influence. The main\\nidea is shown in Figure 3', 'ð´ denote a citing paper with academic influential factor ð´ð¹ð´\\ninitialized as 1, set ð‘…ð´, ð¼ ð¹ ð‘™\\nð´ denote all references of ð´, and their\\ncorresponding local contribution to ð´, and ð¼ ð¹ ð‘™\\nð´ð‘– âˆˆ [âˆ’1, 1] is the\\nlocal contribution of reference i to ð´. ð¶ð´ is the set of all papers that\\ncite ð´, and for ð‘— âˆˆ ð¶ð´, ð¼ ð¹ ð‘™\\nð‘—ð´ âˆˆ [âˆ’1, 1] is Aâ€™s local contribution to ð‘—.\\nThen, the academic influential factor of ð´ is:\\n\\nð´ð¹ð´ =\\n\\nâˆ‘ï¸\\n\\nð´ð¹ ð‘— ð¼ ð¹ ð‘™\\nð‘—ð´\\n\\n(2)\\n\\nð‘— âˆˆð¶ð´\\nFor author ð‘Ž who publishes a set of papers ð‘ƒð‘Ž, and his contribution\\nto paper ð‘– âˆˆ ð‘ƒð‘Ž is ð¶ð‘–ð‘Ž âˆˆ [0, 1], his academic influential factor is:\\nâˆ‘ï¸\\n\\nð´ð¹ð‘Ž =\\n\\nð¶ð‘–ð‘Žð´ð¹ð‘–\\n\\n(3)\\n\\nð‘– âˆˆð‘ƒð‘Ž\\nFor paper ð´, and its ð‘ authors, (cid:205)ð‘\\nð‘– ð¶ð´ð‘– â‰¡ 1. There are two problems\\nto prove to ensure that our method is logical. The first one is margin\\neffects. And the second one the propagation rules', '4 EXPERIMENTS\\nWe conduct several experiments to demonstrate our new metrics\\nthat measure the influential factors of an individual scientist or\\nscholar and the citation impact of the publications', 'As the influential factor of a paper is the weighted sum of all\\npapers that cite it and its corresponding contribution to them, the\\nfinal and full network of paper and network should be constructed.\\nHowever, we cannot complete this job yet out of no access to some\\ndatabases, not enough time or computational resources. We will\\nselect some scholars and their publications as targets, and utilize\\nprimary citation and secondary citation relationships. Besides, we\\nalso compare our modules to other state-of-art algorithms to show\\nthe improvement we achieve', '4.1 Peer Comparison\\nScholar and their publications. Let Scholar Y denote some scholar.\\nWe will show the difference between Scholar Y and the Turing\\nAward winner Pat. Hanrahan9. As we emphasize, Pat. Hanrahan\\nis much more influential than scholar Y is not only for that he\\nwins Turing Award, but also is based on solid statistics of citations.\\nFor example, He et al. [16] take one paper of scholar Y as a base-\\nline that performs only better than one baseline among eleven.\\nTable 4 shows evaluation results of scholar Y and Pat. Hanrahan\\non Aminer10, Google Scholar11, Semantic Scholar12 and Phocus.\\nTable 3 lists the number of publications and citations of scholar Y\\nand Pat. Hanrahan. Itâ€™s obviously that scholar Y is more produc-\\ntive than Pat. Hanrahan. However, those numbers covers up some\\nsignificant truths that not all papers are equal influential and not\\nall citations mean agreement with the cited ones. where h repre-\\nsents h-index, g represents g-index, i10 means i10-index, and HIC\\n\\n9https://scholar.google.com/citations?hl=zh-CN&user=RzEnQmgAAAAJ\\n10https://www.aminer.cn/\\n11https://scholar.google.com/\\n12https://www.semanticscholar.org/\\n\\nTable 3: statistics of Y and Hanrahan\\n\\nScholar\\n\\nAminer\\n\\nGoogle Scholar\\n\\npublications citations citations\\n\\nY\\n\\n1146\\n\\n77903\\n\\n78663\\n\\nHanrahan 381\\n\\n52214\\n\\n50568\\n\\nSemantic Scholar\\npublications citations\\n\\n771\\n\\n315\\n\\n59679\\n\\n56383\\n\\nTable 4: evaluation results from several platforms\\n\\nScholar\\n\\nAminer\\n\\nGoogle Scholar\\n\\nSemantic Scholar\\n\\nh\\n\\n131\\n\\nY\\n\\nHanrahan 97\\n\\ng\\n\\n258\\n\\n228\\n\\nh\\n\\n123\\n\\n93\\n\\ni10\\n\\n723\\n\\n200\\n\\nh\\n\\nHIC\\n\\n119\\n\\n5843\\n\\n88\\n\\n3741\\n\\nPhocus\\n(Primary)\\n\\n0.40\\n\\n0.52\\n\\nFigure 4: for paper A, paper B and C cite it directly, called\\nprimary citations, D to A is secondary and E to A is tertiary', 'is the number of highly influential citations. H-index, also called\\nindex â„Ž, is proposed by Jorge E. Hirsch[17], and its definition is the\\nnumber of papers with citation number higher or equal to â„Ž . The\\ng-index is defined as the largest number such that the top ð‘” articles\\nreceived together at least ð‘”2 citations[12]. Google Scholar proposes\\ni10-index that is the number of a publication with at least 10 cita-\\ntions. Those metrics are derived from citations and do not reveal\\nthe truth among citations. Semantic Scholar makes the first step\\ntowards citation classification. It divided citations into 4 classes:\\nhighly influential, background, method and results citations[35], us-\\ning SVM with a RBF kernel and random forests. The features Seman-\\ntic Scholar use are total number of direct citations, number of direct\\ncitations per section, total number of indirect citations and number\\nof indirect citations per section, author overlap, is considered help-\\nful, citation appears in table and caption, 1/number of references,\\nnumber of paper citations/all citations, similarity between abstracts,\\nPageRank[28], number of total citing papers after transitive closure,\\nand field of the cited paper. We collect XX papers that cite scholar Y\\nfrom 78663, and XX papers that cite Patrick Hanrahan from 56383.\\nOnly utilizing primary citations, we get the global academic influ-\\nential factors of scholar Y and Patrick Hanrahan is 0.40 and 0.52\\nrespectively. Figure 4\\n\\n4.2 Mathematical Invariance\\nTo verify the model, we conduct a series of experiments to prove\\nitâ€™s reasonable', 'First, given a set of references within a paper, removing anyone\\nreference from the set wonâ€™t change the related order of left refer-\\nences. And when removing a reference at a time, the left references\\nalso keep related orders', ', ,\\n\\nZhang and Wen et al', 'Table 5: features used for citation span\\n\\nFeature\\n\\nDescription\\n\\ndistance\\n\\nposition\\n\\nsegment\\n\\nThe distance (in words) between the word\\nand the target citaion', 'This feature takes the value 1 if the word\\ncomes before the target citation, and 0 otherwise', 'After splitting the sentence into segments\\nby punctuation and coordination conjunctions,\\nthis feature takes the value 1 if the word occurs\\nin the same segment with the target reference,\\nand 0 otherwise', 'pos_tag\\n\\nThe part of speech tag of the word, the word\\nbefore, and the word after', 'dTreeDistance\\n\\nLength of the shortest dependency path (in\\nthe dependency parse tree) that connects the\\nword to the target reference or its representative', 'lca\\n\\nThe type of the node in the dependency parse\\ntree that is the least common ancestor of the\\nword and the target reference', 'Table 6: results for three different models for citation span\\n\\nModel Precision Recall\\n\\nF1\\n\\nSVM\\nLR\\nCRF\\n\\n0.78\\n0.68\\n0.65\\n\\n0.56\\n0.67\\n0.64\\n\\n0.65\\n0.67\\n0.64\\n\\nAlso, the final score should be stable and insensitive to propa-\\ngating order under a certain paper pool. Our strategy starts from\\na default influential factor 1.0, traversing through each paper and\\nupdating the influential factor successively. It is proven through\\nexperiments that regardless of the updating order, the final score\\nof each paper remains the same', '4.3 Citation Span\\nWe conduct some experiments guided by [1] as our baseline. We\\nannotate the citation span for about 345 citing sentences as our\\ndata set to train and test the baseline model', 'First, we use the tokenizer tool that SpaCy13 provides to segment\\nthe text of each citing sentence into tokens, and use tagger and\\nparser tool to assign part-of-speech-tags and dependency labels to\\neach token', 'Then, we extract features listed in Table 5. as the input of the\\nbaseline model. The training is performed using SVM, Logistic\\nRegression, and CRF, respectively. We use 10-fold cross-validation\\nfor training and testing', 'Table 6 lists the precision, recall, and F1 for the three model', '13https://spacy.io/\\n\\n5 RESULTS\\nAs shown in Table 4, Phocus figures out that the global academic\\ninfluential factors of scholar Y and Patrick Hanrahan are 0.40 and\\n0.52 respectively, and Patrick Hanrahan is 30% higher than scholar\\nY. Itâ€™s the results that only utilize primary citation data. While the\\nevaluation results from Aminer, Google Scholar and even Semantic\\nScholar shows that scholar Y is more productive and influential\\nthan Patrick Hanrahan', '6 CONCLUSION\\nIn this paper, we come up with Phocus, a novel set of academic\\nevaluation metrics for authors and publications based on citation\\njudgements that utilize aspect-based sentiment analysis. To verify\\nour evaluation mechanism, peer comparison and ablation studies\\nhave been conducted. The results show that our metrics are able\\nto identify the truly worthiness of a paper or a scholar, which is\\ndifficult to citation times based metrics, like h-index, g-index and\\nothers', 'Phocus still need improvements. As shown in Section Exper-\\niments, we only use primary citation data, which is not enough\\nto fully prove the reliability of Phocus. Besides, using more data\\nsuch as secondary and tertiary citations could further reflect the\\ngaps between scholars and between metrics. There are still many\\nproblems unsolved, such as â€œcitation circlesâ€ (groups of researchers\\nwho cite one anotherâ€™s work), and self-citation', 'REFERENCES\\n[1] Amjad Abu-Jbara and Dragomir Radev. 2012. Reference scope identification\\nin citing sentences. In Proceedings of the 2012 Conference of the North Ameri-\\ncan Chapter of the Association for Computational Linguistics: Human Language\\nTechnologies. 80â€“90', '[2] Xuefeng Bai, Pengbo Liu, and Yue Zhang. 2021. Investigating Typed Syntac-\\ntic Dependencies for Targeted Sentiment Classification Using Graph Attention\\nNeural Network. IEEE/ACM Trans. Audio, Speech and Lang. Proc. 29 (jan 2021),\\n503â€“514. https://doi.org/10.1109/TASLP.2020.3042009\\n\\n[3] Carl T. Bergstrom. 2007. Eigenfactor Measuring the value and prestige of scholarly\\n\\njournals. College & Research Libraries News 68 (2007), 314â€“316', '[4] Christopher J. C. Burges. 2010. From RankNet to LambdaRank to LambdaMART:\\n\\nAn Overview', '[5] Christopher J. C. Burges, Robert J. Ragno, and Quoc V. Le. 2006. Learning to\\n\\nRank with Nonsmooth Cost Functions. In NIPS', '[6] Bilal Hayat Butt, Muhammad Rafi, Arsal Jamal, Raja Sami Ur Rehman, Syed\\nMuhammad Zubair Alam, and Muhammad Bilal Alam. 2015. Classification of\\nResearch Citations (CRC). In CLBib@ISSI', '[7] Guimin Chen, Yuanhe Tian, and Yan Song. 2020. Joint Aspect Extraction and Sen-\\ntiment Analysis with Directional Graph Convolutional Networks. In Proceedings\\nof the 28th International Conference on Computational Linguistics. International\\nCommittee on Computational Linguistics, Barcelona, Spain (Online), 272â€“279.\\nhttps://doi.org/10.18653/v1/2020.coling-main.24\\n\\n[8] Johan S. G. Chu and James A. Evans. 2021. Slowed canonical progress in large\\nfields of science. Proceedings of the National Academy of Sciences of the United\\nStates of America 118 (2021)', '[9] Arman Cohan, Waleed Ammar, Madeleine van Zuylen, and Field Cady. 2019.\\nStructural Scaffolds for Citation Intent Classification in Scientific Publications.\\nArXiv abs/1904.01608 (2019)', '[10] Corinna Cortes and Neil Lawrence. 2021', 'Inconsistency in Conference Peer\\nReview: Revisiting the 2014 NeurIPS Experiment. ArXiv abs/2109.09774 (2021).\\n[11] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:\\nPre-training of Deep Bidirectional Transformers for Language Understanding.\\nArXiv abs/1810.04805 (2019)', '[12] Leo Egghe. 2006. Theory and practise of the g-index. Scientometrics 69 (2006),\\n\\n131â€“152', '[13] Besnik Fetahu, Katja Markert, and Avishek Anand. 2017. Fine Grained Citation\\nSpan for References in Wikipedia. In Proceedings of the 2017 Conference on Em-\\npirical Methods in Natural Language Processing. Association for Computational\\nLinguistics, Copenhagen, Denmark, 1990â€“1999. https://doi.org/10.18653/v1/D17-\\n1212\\n\\nPhocus: Picking Valuable Research from a Sea of Citations\\n\\n, ,\\n\\n[14] Zhengjie Gao, Ao Feng, Xinyu Song, and Xi Wu. 2019. Target-Dependent Senti-\\n\\nProcessing and Management 16 (1980)', 'ment Classification With BERT. IEEE Access 7 (2019), 154290â€“154299', '[15] Borja Gonzalez-Pereira, Vicente Guerrero-Bote, and Felix Moya-Anegon.\\n2009. The SJR indicator: A new indicator of journalsâ€™ scientific prestige.\\narXiv:0912.4141 [cs.DL]\\n\\n[16] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Deep Residual\\n\\nLearning for Image Recognition. arXiv:1512.03385 [cs.CV]\\n\\n[17] Jorge E. Hirsch. 2005. An index to quantify an individualâ€™s scientific research\\n\\noutput. Proc. Natl. Acad. Sci. USA 102 (2005), 16569â€“16572', '[18] Mickel Hoang, Oskar Alija Bihorac, and Jacobo Rouces. 2019. Aspect-Based\\n\\nSentiment Analysis using BERT. In NODALIDA', '[19] Minghao Hu, Yuxing Peng, Zhen Huang, Dongsheng Li, and Yiwei Lv. 2019.\\nOpen-Domain Targeted Sentiment Analysis via Span-Based Extraction and Clas-\\nsification. In Proceedings of the 57th Annual Meeting of the Association for Compu-\\ntational Linguistics. Association for Computational Linguistics, Florence, Italy,\\n537â€“546. https://doi.org/10.18653/v1/P19-1051\\n\\n[20] David Jurgens, Srijan Kumar, Raine Hoover, Daniel A. McFarland, and Dan\\nJurafsky. 2016. Citation Classification for Behavioral Analysis of a Scientific Field.\\nArXiv abs/1609.00435 (2016)', '[21] Dain Kaplan, Ryu Iida, and Takenobu Tokunaga. 2009. Automatic extraction of\\ncitation contexts for research paper summarization: A coreference-chain based\\napproach. In Proceedings of the 2009 Workshop on Text and Citation Analysis for\\nScholarly Digital Libraries (NLPIR4DL). 88â€“95', '[22] Dain Kaplan, Takenobu Tokunaga, and Simone Teufel. 2016. Citation Block\\nDetermination Using Textual Coherence. Journal of Information Processing 24, 3\\n(2016), 540â€“553. https://doi.org/10.2197/ipsjjip.24.540\\n\\n[23] Haixia Liu. 2017. Sentiment Analysis of Citations Using Word2vec. ArXiv\\n\\nabs/1704.00177 (2017)', '[24] Huaishao Luo, Lei Ji, Tianrui Li, Daxin Jiang, and Nan Duan. 2020. GRACE:\\nGradient Harmonized and Cascaded Labeling for Aspect-based Sentiment Anal-\\nysis. In Findings of the Association for Computational Linguistics: EMNLP 2020.\\nAssociation for Computational Linguistics, Online, 54â€“64. https://doi.org/10.\\n18653/v1/2020.findings-emnlp.6\\n\\n[25] Shutian Ma, Jin Xu, and Chengzhi Zhang. 2018. Automatic Identification of Cited\\nText Spans: A Multi-Classifier Approach over Imbalanced Dataset. Scientometrics\\n116, 2 (aug 2018), 1303â€“1330. https://doi.org/10.1007/s11192-018-2754-2\\n[26] Jessica L. Milstead. 1980. Citation Indexingâ€”Its Theory and Application in Science,\\nInformation\\n\\nTechnology and Humanities. Wiley, Oxford (1979), 274, $15.95', '[27] Henk F. Moed. 2010. Measuring contextual citation impact of scientific journals.\\nJournal of Informetrics 4, 3 (2010), 265â€“277. https://doi.org/10.1016/j.joi.2010.01.\\n002\\n\\n[28] Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The\\nPageRank Citation Ranking: Bringing Order to the Web. Technical Report 1999-\\n66. Stanford InfoLab. http://ilpubs.stanford.edu:8090/422/ Previous number =\\nSIDL-WP-1999-0120', '[29] Vahed Qazvinian and Dragomir Radev. 2010. Identifying Non-Explicit Citing\\nSentences for Citation-Based Summarization.. In Proceedings of the 48th annual\\nmeeting of the association for computational linguistics. 555â€“564', '[30] Sebastian Ruder, Parsa Ghaffari, and John G. Breslin. 2016. A Hierarchical Model\\n\\nof Reviews for Aspect-based Sentiment Analysis. In EMNLP', '[31] Per O. Seglen. 1997. Why the impact factor of journals should not be used for\\n\\nevaluating research. BMJ 314 (1997), 497', '[32] Chi Sun, Luyao Huang, and Xipeng Qiu. 2019. Utilizing BERT for Aspect-Based\\n\\nSentiment Analysis via Constructing Auxiliary Sentence. In NAACL', '[33] Simone Teufel, Advaith Siddharthan, and Dan Tidhar. 2006. Automatic classifica-\\n\\ntion of citation function. In EMNLP', '[34] Maria Mihaela Trusca, Daan Wassenberg, Flavius Frasincar, and Rommert Dekker.\\n2020. A Hybrid Approach for Aspect-Based Sentiment Analysis Using Deep\\nContextual Word Embeddings and Hierarchical Attention. In ICWE', '[35] Marco Valenzuela, Vu A. Ha, and Oren Etzioni. 2015. Identifying Meaningful\\n\\nCitations. In AAAI Workshop: Scholarly Big Data', '[36] Olaf Wallaart and Flavius Frasincar. 2019. A Hybrid Approach for Aspect-Based\\nSentiment Analysis Using a Lexicalized Domain Ontology and Attentional Neural\\nModels. In ESWC', '[37] Hongning Wang, Yue Lu, and ChengXiang Zhai. 2010. Latent aspect rating\\nanalysis on review text data: a rating regression approach. Proceedings of the 16th\\nACM SIGKDD international conference on Knowledge discovery and data mining\\n(2010)', '[38] Hu Xu, Bing Liu, Lei Shu, and Philip S. Yu. 2019. BERT Post-Training for Review\\nReading Comprehension and Aspect-based Sentiment Analysis. In NAACL.\\n[39] Chrysoula Zerva, Minh quoc Nghiem, Nhung T. H. Nguyen, and Sophia Anani-\\nadou. 2020. Cited text span identification for scientific summarisation using pre-\\ntrained encoders. Scientometrics (7 May 2020). https://doi.org/10.1007/s11192-\\n020-03455-z\\n\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abs_end=0\n",
        "ref_start=len(text)-1\n",
        "while '1 INTRODUCTION' not in text[abs_end]: #start at the intro\n",
        "  abs_end+=1\n",
        "end_first=abs_end\n",
        "while 'âˆ—' not in text[end_first]: #start at the intro\n",
        "  end_first+=1\n",
        "copy_mark=end_first\n",
        "while 'Â©' not in text[copy_mark]: #start at the intro\n",
        "  copy_mark+=1\n",
        "while 'REFERENCES' not in text[ref_start]: \n",
        "  ref_start-=1\n",
        "content=text[abs_end:end_first]+text[copy_mark+1:ref_start]"
      ],
      "metadata": {
        "id": "O9lsV2ij-2vn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1530db-cf91-4884-cc5b-47e753292cfb"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "185"
            ]
          },
          "metadata": {},
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_class(text,model,d=3):\n",
        "  codes=tf.constant([[-1.0,0.0,1.0]])\n",
        "  pred=model.predict(text)[0]\n",
        "  i=tf.argmax(pred)\n",
        "  res=codes*pred\n",
        "  def roundDown(n, d=2):\n",
        "    d = int('1' + ('0' * d))\n",
        "    return np.floor(np.array(n) * d) / d\n",
        "  pred=roundDown(pred,d)\n",
        "  score=tf.math.reduce_mean(res,-1)[0].numpy()\n",
        "  classification=roundDown(codes[0,i].numpy(),d)\n",
        "  max_confidence=pred[i]\n",
        "  return classification,max_confidence,roundDown(score,d),list(pred)"
      ],
      "metadata": {
        "id": "Uc5Sg-uKYigY"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coloring of a PDF"
      ],
      "metadata": {
        "id": "_Td1mswaCOFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errs=[]\n",
        "dfs=[]\n",
        "cols=['sentence','class','confidence','net score','neg','neu','pos','text','colored']\n",
        "for i,t in enumerate(content):\n",
        "  try:\n",
        "    c,conf,sc,raw=text_class([t],classifier_model)\n",
        "    colored=color_by_attn(t,tokenizer,preprocesser_model,encoder_model)\n",
        "    df_t = pd.DataFrame([[i,c,conf,sc,raw[0],raw[1],raw[2],t,colored]],columns=cols)\n",
        "    print(i,c,conf,sc,colored)\n",
        "    dfs.append(df_t)\n",
        "    \n",
        "  except Exception:\n",
        "    errs.append(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcFhtVjoCRTh",
        "outputId": "09e38eb1-308f-4368-eacb-09929971a44a"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.0 0.792 0.258 \u001b[48;2;0;0;134m\u001b[38;2;255;255;255m1 \u001b[48;2;48;0;0m\u001b[38;2;255;255;255mINTRODUCTION \u001b[48;2;56;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;224m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mpapers \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mpublished \u001b[48;2;0;0;145m\u001b[38;2;255;255;255meach \u001b[48;2;225;0;0m\u001b[38;2;255;255;255myear \u001b[48;2;53;0;0m\u001b[38;2;255;255;255mhas \u001b[48;2;166;0;0m\u001b[38;2;255;255;255mgrown \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mgreatly.\n",
            "1 1.0 0.678 0.142 \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mFor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mexample, \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mshown \u001b[48;2;0;0;256m\u001b[38;2;255;255;255min \u001b[48;2;208;0;0m\u001b[38;2;255;255;255mFigure \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1, \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mthe \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;103m\u001b[38;2;255;255;255mof \u001b[48;2;89;0;0m\u001b[38;2;255;255;255mnew \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mpapers \u001b[48;2;0;0;155m\u001b[38;2;255;255;255mon \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mIEEE \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mXplore1 \u001b[48;2;192;0;0m\u001b[38;2;255;255;255mincreases \u001b[48;2;137;0;0m\u001b[38;2;255;255;255msharply \u001b[48;2;77;0;0m\u001b[38;2;255;255;255mover \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdecade.\n",
            "2 1.0 0.795 0.215 \u001b[48;2;61;0;0m\u001b[38;2;255;255;255mPaper \u001b[48;2;242;0;0m\u001b[38;2;255;255;255mboom \u001b[48;2;0;0;69m\u001b[38;2;255;255;255min \u001b[48;2;17;0;0m\u001b[38;2;255;255;255macademic \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mfields \u001b[48;2;164;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;69m\u001b[38;2;255;255;255min \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mmany \u001b[48;2;0;0;159m\u001b[38;2;255;255;255msevere \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mproblems.\n",
            "3 0.0 0.809 0.053 \u001b[48;2;104;0;0m\u001b[38;2;255;255;255mCortes \u001b[48;2;0;0;145m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[10] \u001b[48;2;0;0;253m\u001b[38;2;255;255;255mexamine \u001b[48;2;102;0;0m\u001b[38;2;255;255;255m2014 \u001b[48;2;483;0;0m\u001b[38;2;255;255;255mNeurIPS \u001b[48;2;0;0;77m\u001b[38;2;255;255;255mand \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mfind \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;4m\u001b[38;2;255;255;255mit \u001b[48;2;0;0;42m\u001b[38;2;255;255;255mis \u001b[48;2;170;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;0;0;59m\u001b[38;2;255;255;255mable \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;30;0;0m\u001b[38;2;255;255;255mpick \u001b[48;2;140;0;0m\u001b[38;2;255;255;255mout \u001b[48;2;0;0;134m\u001b[38;2;255;255;255mexcellent \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mresearches, \u001b[48;2;0;0;77m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;44m\u001b[38;2;255;255;255mcould \u001b[48;2;0;0;75m\u001b[38;2;255;255;255midentify \u001b[48;2;0;0;184m\u001b[38;2;255;255;255mterrible \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpapers.\n",
            "4 1.0 0.519 0.137 \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mChu \u001b[48;2;0;0;101m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[8] \u001b[48;2;0;0;137m\u001b[38;2;255;255;255mreveal \u001b[48;2;0;0;107m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;41m\u001b[38;2;255;255;255mtoo \u001b[48;2;204;0;0m\u001b[38;2;255;255;255mmany \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mpapers \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mpublished \u001b[48;2;0;0;29m\u001b[38;2;255;255;255meach \u001b[48;2;222;0;0m\u001b[38;2;255;255;255myear \u001b[48;2;0;0;192m\u001b[38;2;255;255;255min \u001b[48;2;0;0;90m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;49m\u001b[38;2;255;255;255mfield \u001b[48;2;421;0;0m\u001b[38;2;255;255;255mhinder \u001b[48;2;149;0;0m\u001b[38;2;255;255;255mits \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdevelopment.\n",
            "5 -1.0 0.631 -0.153 \u001b[48;2;0;0;39m\u001b[38;2;255;255;255mThey \u001b[48;2;201;0;0m\u001b[38;2;255;255;255mstate \u001b[48;2;115;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mopinion \u001b[48;2;0;0;239m\u001b[38;2;255;255;255min \u001b[48;2;0;0;20m\u001b[38;2;255;255;255mtwo \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maspects.\n",
            "6 0.0 0.733 0.014 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFirst, \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mresearchers \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mare \u001b[48;2;128;0;0m\u001b[38;2;255;255;255mbusy \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mcoping \u001b[48;2;0;0;248m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;30m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;23m\u001b[38;2;255;255;255mlot \u001b[48;2;0;0;300m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpapers, \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mbut \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdonâ€™t \u001b[48;2;0;0;143m\u001b[38;2;255;255;255mhave \u001b[48;2;0;0;29m\u001b[38;2;255;255;255menough \u001b[48;2;56;0;0m\u001b[38;2;255;255;255mtime \u001b[48;2;0;0;103m\u001b[38;2;255;255;255mto \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mfully \u001b[48;2;0;0;70m\u001b[38;2;255;255;255mlearn \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mnovel \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mideas; \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mSecond, \u001b[48;2;0;0;120m\u001b[38;2;255;255;255mthe \u001b[48;2;167;0;0m\u001b[38;2;255;255;255mfocused \u001b[48;2;43;0;0m\u001b[38;2;255;255;255mattention \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;30m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;39m\u001b[38;2;255;255;255mpromising \u001b[48;2;72;0;0m\u001b[38;2;255;255;255midea \u001b[48;2;143;0;0m\u001b[38;2;255;255;255mmight \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mbe \u001b[48;2;175;0;0m\u001b[38;2;255;255;255mbroken \u001b[48;2;329;0;0m\u001b[38;2;255;255;255mup \u001b[48;2;139;0;0m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;120m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mdeluge \u001b[48;2;0;0;300m\u001b[38;2;255;255;255mof \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mnew \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mideas.\n",
            "7 0.0 0.854 0.045 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;147;0;0m\u001b[38;2;255;255;255mZhang \u001b[48;2;67;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;50;0;0m\u001b[38;2;255;255;255mWen \u001b[48;2;0;0;225m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal.\n",
            "8 1.0 0.79 0.241 \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mreason \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;9;0;0m\u001b[38;2;255;255;255msharp \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mincrease \u001b[48;2;0;0;192m\u001b[38;2;255;255;255min \u001b[48;2;0;0;114m\u001b[38;2;255;255;255mpapers \u001b[48;2;34;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;224m\u001b[38;2;255;255;255mthat \u001b[48;2;113;0;0m\u001b[38;2;255;255;255mevaluation \u001b[48;2;22;0;0m\u001b[38;2;255;255;255mmetrics \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;141;0;0m\u001b[38;2;255;255;255mresearchers \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mand \u001b[48;2;45;0;0m\u001b[38;2;255;255;255mscholars \u001b[48;2;288;0;0m\u001b[38;2;255;255;255mfocus \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mon \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;230m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpapers.\n",
            "9 1.0 0.661 0.219 \u001b[48;2;0;0;87m\u001b[38;2;255;255;255mFrom \u001b[48;2;0;0;73m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mscientific \u001b[48;2;0;0;0m\u001b[38;2;255;255;255moutput, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mresearch \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfunding, \u001b[48;2;139;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;73m\u001b[38;2;255;255;255mthe \u001b[48;2;238;0;0m\u001b[38;2;255;255;255mevaluation \u001b[48;2;0;0;222m\u001b[38;2;255;255;255mof \u001b[48;2;141;0;0m\u001b[38;2;255;255;255mprofessional \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrank, \u001b[48;2;0;0;157m\u001b[38;2;255;255;255mpapers \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mplay \u001b[48;2;0;0;180m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;187m\u001b[38;2;255;255;255mvery \u001b[48;2;0;0;39m\u001b[38;2;255;255;255mimportant \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrole, \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;73m\u001b[38;2;255;255;255mthe \u001b[48;2;49;0;0m\u001b[38;2;255;255;255mmore \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpapers, \u001b[48;2;0;0;73m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mbetter.\n",
            "10 0.0 0.355 -0.014 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHowever, \u001b[48;2;0;0;121m\u001b[38;2;255;255;255mIt \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mis \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mtime \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;178m\u001b[38;2;255;255;255mmake \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mchanges.\n",
            "11 -1.0 0.764 -0.226 \u001b[48;2;0;0;89m\u001b[38;2;255;255;255mQuantitative \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mmetrics \u001b[48;2;0;0;128m\u001b[38;2;255;255;255mcould \u001b[48;2;279;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;247;0;0m\u001b[38;2;255;255;255mevaluate \u001b[48;2;0;0;52m\u001b[38;2;255;255;255mthe \u001b[48;2;48;0;0m\u001b[38;2;255;255;255mreal \u001b[48;2;14;0;0m\u001b[38;2;255;255;255macademic \u001b[48;2;139;0;0m\u001b[38;2;255;255;255mimpact \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;188m\u001b[38;2;255;255;255ma \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mscholar \u001b[48;2;0;0;99m\u001b[38;2;255;255;255mor \u001b[48;2;0;0;188m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper.\n",
            "12 -1.0 0.614 -0.144 \u001b[48;2;27;0;0m\u001b[38;2;255;255;255mThey \u001b[48;2;43;0;0m\u001b[38;2;255;255;255mignore \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mthe \u001b[48;2;8;0;0m\u001b[38;2;255;255;255messential \u001b[48;2;216;0;0m\u001b[38;2;255;255;255mdifferences \u001b[48;2;149;0;0m\u001b[38;2;255;255;255mbetween \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations, \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;189m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mfatal \u001b[48;2;0;0;0m\u001b[38;2;255;255;255merror.\n",
            "13 1.0 0.498 0.139 \u001b[48;2;632;0;0m\u001b[38;2;255;255;255mSeglen \u001b[48;2;0;0;110m\u001b[38;2;255;255;255mexpresses \u001b[48;2;23;0;0m\u001b[38;2;255;255;255mstrong \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mopposition \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mim- \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mpact \u001b[48;2;0;0;56m\u001b[38;2;255;255;255mfactors \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mthat \u001b[48;2;65;0;0m\u001b[38;2;255;255;255mmeasure \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mthe \u001b[48;2;66;0;0m\u001b[38;2;255;255;255macademic \u001b[48;2;114;0;0m\u001b[38;2;255;255;255minfluence \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mof \u001b[48;2;86;0;0m\u001b[38;2;255;255;255mjournals \u001b[48;2;0;0;7m\u001b[38;2;255;255;255mfor \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mcommittees \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mseldom \u001b[48;2;0;0;101m\u001b[38;2;255;255;255mhave \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mspecialistâ€™ \u001b[48;2;78;0;0m\u001b[38;2;255;255;255minsights \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;79m\u001b[38;2;255;255;255massess \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mprimary \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mresearches[31].\n",
            "14 1.0 0.875 0.29 \u001b[48;2;253;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mpropose \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPhocus, \u001b[48;2;0;0;164m\u001b[38;2;255;255;255ma \u001b[48;2;141;0;0m\u001b[38;2;255;255;255mnovel \u001b[48;2;140;0;0m\u001b[38;2;255;255;255mevaluation \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mmechanism \u001b[48;2;0;0;2m\u001b[38;2;255;255;255mfor \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mscholars \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpublications.\n",
            "15 0.0 0.912 0.027 \u001b[48;2;326;0;0m\u001b[38;2;255;255;255mPhocus \u001b[48;2;201;0;0m\u001b[38;2;255;255;255manalyzes \u001b[48;2;0;0;99m\u001b[38;2;255;255;255mthe \u001b[48;2;71;0;0m\u001b[38;2;255;255;255msentence \u001b[48;2;59;0;0m\u001b[38;2;255;255;255mcontaining \u001b[48;2;0;0;70m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mcitation \u001b[48;2;192;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;70m\u001b[38;2;255;255;255mits \u001b[48;2;30;0;0m\u001b[38;2;255;255;255mcontexts \u001b[48;2;0;0;142m\u001b[38;2;255;255;255mto \u001b[48;2;185;0;0m\u001b[38;2;255;255;255mpredict \u001b[48;2;0;0;99m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;195m\u001b[38;2;255;255;255msentiment \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mpolarity \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mtowards \u001b[48;2;0;0;99m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcorre- \u001b[48;2;0;0;178m\u001b[38;2;255;255;255msponding \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreference.\n",
            "16 0.0 0.978 0.002 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBesides, \u001b[48;2;53;0;0m\u001b[38;2;255;255;255mPhocus \u001b[48;2;40;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;220;0;0m\u001b[38;2;255;255;255mconsiders \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;202;0;0m\u001b[38;2;255;255;255mtotal \u001b[48;2;0;0;118m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;216m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations, \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;118m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;216m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mcitations \u001b[48;2;144;0;0m\u001b[38;2;255;255;255mper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msentence, \u001b[48;2;56;0;0m\u001b[38;2;255;255;255mauthor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255moverlap, \u001b[48;2;147;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;118m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;216m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreferences, \u001b[48;2;35;0;0m\u001b[38;2;255;255;255msimilar \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[35].\n",
            "17 0.0 0.991 0.002 \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mGiven \u001b[48;2;0;0;112m\u001b[38;2;255;255;255mthose \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mfactors \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mabove, \u001b[48;2;128;0;0m\u001b[38;2;255;255;255mPhocus \u001b[48;2;0;0;104m\u001b[38;2;255;255;255muses \u001b[48;2;25;0;0m\u001b[38;2;255;255;255mNaive \u001b[48;2;454;0;0m\u001b[38;2;255;255;255mBayesian \u001b[48;2;77;0;0m\u001b[38;2;255;255;255mClassifier \u001b[48;2;0;0;134m\u001b[38;2;255;255;255mto \u001b[48;2;14;0;0m\u001b[38;2;255;255;255mdivide \u001b[48;2;16;0;0m\u001b[38;2;255;255;255mcitations \u001b[48;2;295;0;0m\u001b[38;2;255;255;255mcoarsely \u001b[48;2;39;0;0m\u001b[38;2;255;255;255minto \u001b[48;2;140;0;0m\u001b[38;2;255;255;255m4 \u001b[48;2;40;0;0m\u001b[38;2;255;255;255mcategories \u001b[48;2;28;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mutilizes \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;280m\u001b[38;2;255;255;255mLambdaMART \u001b[48;2;0;0;121m\u001b[38;2;255;255;255mmodel \u001b[48;2;0;0;134m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;74m\u001b[38;2;255;255;255msort \u001b[48;2;33;0;0m\u001b[38;2;255;255;255mall \u001b[48;2;0;0;9m\u001b[38;2;255;255;255mreferences \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mwithin \u001b[48;2;0;0;239m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper.\n",
            "18 0.0 0.929 0.022 \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mCombining \u001b[48;2;0;0;173m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mcategories \u001b[48;2;0;0;84m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;173m\u001b[38;2;255;255;255mthe \u001b[48;2;68;0;0m\u001b[38;2;255;255;255mranking \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mresults, \u001b[48;2;0;0;33m\u001b[38;2;255;255;255mevery \u001b[48;2;226;0;0m\u001b[38;2;255;255;255mreference \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mgets \u001b[48;2;98;0;0m\u001b[38;2;255;255;255mits \u001b[48;2;225;0;0m\u001b[38;2;255;255;255mlocal \u001b[48;2;120;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;206;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;16;0;0m\u001b[38;2;255;255;255mwithin \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[âˆ’1, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1], \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mrelated \u001b[48;2;0;0;142m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;173m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper.\n",
            "19 1.0 0.878 0.289 \u001b[48;2;0;0;61m\u001b[38;2;255;255;255mthe \u001b[48;2;129;0;0m\u001b[38;2;255;255;255mglobal \u001b[48;2;64;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;214;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;0;0;164m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;61m\u001b[38;2;255;255;255mthe \u001b[48;2;45;0;0m\u001b[38;2;255;255;255mreference \u001b[48;2;0;0;30m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;61m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;99m\u001b[38;2;255;255;255mpaper \u001b[48;2;133;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;61m\u001b[38;2;255;255;255mthe \u001b[48;2;202;0;0m\u001b[38;2;255;255;255mproduct \u001b[48;2;0;0;164m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;61m\u001b[38;2;255;255;255mthe \u001b[48;2;141;0;0m\u001b[38;2;255;255;255mlocal \u001b[48;2;64;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;214;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;107;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;61m\u001b[38;2;255;255;255mthe \u001b[48;2;196;0;0m\u001b[38;2;255;255;255mtotal \u001b[48;2;64;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;214;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;0;0;164m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;61m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper.\n",
            "20 1.0 0.877 0.288 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mConsequently, \u001b[48;2;0;0;185m\u001b[38;2;255;255;255man \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mauthorâ€™s \u001b[48;2;45;0;0m\u001b[38;2;255;255;255macademic \u001b[48;2;72;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;292;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;124;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;14m\u001b[38;2;255;255;255msum \u001b[48;2;0;0;227m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mhis \u001b[48;2;0;0;139m\u001b[38;2;255;255;255mcontributions \u001b[48;2;0;0;128m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;155m\u001b[38;2;255;255;255meach \u001b[48;2;5;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;185;0;0m\u001b[38;2;255;255;255mhe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mco-authors.\n",
            "21 0.0 0.941 0.019 \u001b[48;2;0;0;48m\u001b[38;2;255;255;255m2 \u001b[48;2;0;0;92m\u001b[38;2;255;255;255mRELATED \u001b[48;2;178;0;0m\u001b[38;2;255;255;255mwork \u001b[48;2;0;0;80m\u001b[38;2;255;255;255mOur \u001b[48;2;178;0;0m\u001b[38;2;255;255;255mwork \u001b[48;2;0;0;88m\u001b[38;2;255;255;255minvolves \u001b[48;2;181;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclassification, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maspect-based \u001b[48;2;0;0;10m\u001b[38;2;255;255;255msentiment \u001b[48;2;0;0;0m\u001b[38;2;255;255;255manalysis, \u001b[48;2;75;0;0m\u001b[38;2;255;255;255mranking \u001b[48;2;0;0;31m\u001b[38;2;255;255;255mmodel \u001b[48;2;24;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;124;0;0m\u001b[38;2;255;255;255mevaluation \u001b[48;2;155;0;0m\u001b[38;2;255;255;255mmetrics \u001b[48;2;28;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255macademics, \u001b[48;2;0;0;160m\u001b[38;2;255;255;255mwhich \u001b[48;2;22;0;0m\u001b[38;2;255;255;255mwill \u001b[48;2;0;0;137m\u001b[38;2;255;255;255mbe \u001b[48;2;52;0;0m\u001b[38;2;255;255;255mintroduced \u001b[48;2;0;0;275m\u001b[38;2;255;255;255min \u001b[48;2;0;0;371m\u001b[38;2;255;255;255msubsections \u001b[48;2;0;0;161m\u001b[38;2;255;255;255mbelow \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrespectively.\n",
            "22 1.0 0.641 0.212 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2.1 \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mClassification \u001b[48;2;0;0;233m\u001b[38;2;255;255;255mIn \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfact, \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mthere \u001b[48;2;61;0;0m\u001b[38;2;255;255;255mare \u001b[48;2;261;0;0m\u001b[38;2;255;255;255malready \u001b[48;2;216;0;0m\u001b[38;2;255;255;255mmany \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mkinds \u001b[48;2;0;0;240m\u001b[38;2;255;255;255mof \u001b[48;2;14;0;0m\u001b[38;2;255;255;255mresearch \u001b[48;2;0;0;129m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;65m\u001b[38;2;255;255;255mhave \u001b[48;2;130;0;0m\u001b[38;2;255;255;255mfocused \u001b[48;2;55;0;0m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclassification.\n",
            "23 0.0 0.972 0.008 \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mFor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mexample, \u001b[48;2;618;0;0m\u001b[38;2;255;255;255mTeufel \u001b[48;2;0;0;187m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[33] \u001b[48;2;0;0;1m\u001b[38;2;255;255;255mclassify \u001b[48;2;40;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;13m\u001b[38;2;255;255;255mintents \u001b[48;2;15;0;0m\u001b[38;2;255;255;255minto \u001b[48;2;195;0;0m\u001b[38;2;255;255;255m12 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclasses, \u001b[48;2;0;0;200m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;57m\u001b[38;2;255;255;255msimple \u001b[48;2;0;0;156m\u001b[38;2;255;255;255mregular \u001b[48;2;0;0;45m\u001b[38;2;255;255;255mmatch \u001b[48;2;0;0;9m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mex- \u001b[48;2;112;0;0m\u001b[38;2;255;255;255mtract \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfeatures.\n",
            "24 1.0 0.565 0.18 \u001b[48;2;222;0;0m\u001b[38;2;255;255;255mValenzuela \u001b[48;2;0;0;138m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[35] \u001b[48;2;65;0;0m\u001b[38;2;255;255;255mdivide \u001b[48;2;0;0;162m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;6m\u001b[38;2;255;255;255minto \u001b[48;2;260;0;0m\u001b[38;2;255;255;255m4 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclasses: \u001b[48;2;128;0;0m\u001b[38;2;255;255;255mhighly \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minfluential, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mbackground, \u001b[48;2;109;0;0m\u001b[38;2;255;255;255mmethod \u001b[48;2;0;0;104m\u001b[38;2;255;255;255mand \u001b[48;2;106;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations, \u001b[48;2;0;0;5m\u001b[38;2;255;255;255musing \u001b[48;2;203;0;0m\u001b[38;2;255;255;255mSVM \u001b[48;2;0;0;289m\u001b[38;2;255;255;255mwith \u001b[48;2;173;0;0m\u001b[38;2;255;255;255man \u001b[48;2;208;0;0m\u001b[38;2;255;255;255mRBF \u001b[48;2;137;0;0m\u001b[38;2;255;255;255mkernel \u001b[48;2;0;0;104m\u001b[38;2;255;255;255mand \u001b[48;2;128;0;0m\u001b[38;2;255;255;255mrandom \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mforests, \u001b[48;2;158;0;0m\u001b[38;2;255;255;255mtaking \u001b[48;2;126;0;0m\u001b[38;2;255;255;255m13 \u001b[48;2;0;0;38m\u001b[38;2;255;255;255mfeatures \u001b[48;2;0;0;6m\u001b[38;2;255;255;255minto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mconsideration: \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mtotal \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;59m\u001b[38;2;255;255;255mdirect \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations, \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;59m\u001b[38;2;255;255;255mdirect \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcita- \u001b[48;2;157;0;0m\u001b[38;2;255;255;255mtions \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msection, \u001b[48;2;0;0;68m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mtotal \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;30m\u001b[38;2;255;255;255mindirect \u001b[48;2;0;0;162m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;104m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;30m\u001b[38;2;255;255;255mindirect \u001b[48;2;0;0;162m\u001b[38;2;255;255;255mcitations \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msection, \u001b[48;2;8;0;0m\u001b[38;2;255;255;255mauthor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255moverlap, \u001b[48;2;107;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;180;0;0m\u001b[38;2;255;255;255mconsidered \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhelp- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mful, \u001b[48;2;0;0;88m\u001b[38;2;255;255;255mcitation \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mappears \u001b[48;2;0;0;96m\u001b[38;2;255;255;255min \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mtable \u001b[48;2;0;0;104m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcaption, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1/number \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreferences, \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;45m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations/all \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations, \u001b[48;2;0;0;68m\u001b[38;2;255;255;255mthe \u001b[48;2;46;0;0m\u001b[38;2;255;255;255msimilarity \u001b[48;2;145;0;0m\u001b[38;2;255;255;255mbetween \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mab- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstracts, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPageRank[28], \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mtotal \u001b[48;2;0;0;195m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;92m\u001b[38;2;255;255;255mpapers \u001b[48;2;0;0;23m\u001b[38;2;255;255;255mafter \u001b[48;2;0;0;456m\u001b[38;2;255;255;255mtransitive \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclosure, \u001b[48;2;0;0;104m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfield \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;68m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcited \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper.\n",
            "25 0.0 0.991 0.002 \u001b[48;2;62;0;0m\u001b[38;2;255;255;255mWhile \u001b[48;2;0;0;332m\u001b[38;2;255;255;255mJurgens \u001b[48;2;0;0;226m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[20] \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mdefine \u001b[48;2;96;0;0m\u001b[38;2;255;255;255m7 \u001b[48;2;51;0;0m\u001b[38;2;255;255;255mclasses \u001b[48;2;0;0;222m\u001b[38;2;255;255;255mof \u001b[48;2;70;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mintents: \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mbackground, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmotivation, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255muses, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mextension, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcontinuation, \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mcomparison \u001b[48;2;0;0;94m\u001b[38;2;255;255;255mor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcontrast, \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfuture, \u001b[48;2;0;0;184m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;60m\u001b[38;2;255;255;255ma \u001b[48;2;116;0;0m\u001b[38;2;255;255;255mRandom \u001b[48;2;294;0;0m\u001b[38;2;255;255;255mForest \u001b[48;2;40;0;0m\u001b[38;2;255;255;255mclassifier \u001b[48;2;242;0;0m\u001b[38;2;255;255;255mtrained \u001b[48;2;0;0;68m\u001b[38;2;255;255;255musing \u001b[48;2;102;0;0m\u001b[38;2;255;255;255m4 \u001b[48;2;7;0;0m\u001b[38;2;255;255;255mtypes \u001b[48;2;0;0;222m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfeatures: \u001b[48;2;0;0;30m\u001b[38;2;255;255;255mstructural \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfea- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtures, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mlexical, \u001b[48;2;39;0;0m\u001b[38;2;255;255;255mmorphological \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mand \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mgrammatical \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfeatures, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfield, \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255musage.\n",
            "26 0.0 0.942 0.019 \u001b[48;2;90;0;0m\u001b[38;2;255;255;255mCohan \u001b[48;2;0;0;283m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[9] \u001b[48;2;0;0;175m\u001b[38;2;255;255;255mpropose \u001b[48;2;0;0;107m\u001b[38;2;255;255;255ma \u001b[48;2;728;0;0m\u001b[38;2;255;255;255mmultitask \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mmodel \u001b[48;2;0;0;99m\u001b[38;2;255;255;255musing \u001b[48;2;388;0;0m\u001b[38;2;255;255;255mBiLSTM \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mand \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mattention \u001b[48;2;118;0;0m\u001b[38;2;255;255;255mmechanism \u001b[48;2;0;0;92m\u001b[38;2;255;255;255mto \u001b[48;2;115;0;0m\u001b[38;2;255;255;255mclassify \u001b[48;2;0;0;80m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;220m\u001b[38;2;255;255;255mintents \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;214m\u001b[38;2;255;255;255mis \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;166;0;0m\u001b[38;2;255;255;255mprimary \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mtask \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mand \u001b[48;2;84;0;0m\u001b[38;2;255;255;255mpredict \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;53m\u001b[38;2;255;255;255msection \u001b[48;2;51;0;0m\u001b[38;2;255;255;255mwhere \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;80m\u001b[38;2;255;255;255mcitation \u001b[48;2;11;0;0m\u001b[38;2;255;255;255moccurs \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mand \u001b[48;2;51;0;0m\u001b[38;2;255;255;255mwhere \u001b[48;2;0;0;107m\u001b[38;2;255;255;255ma \u001b[48;2;3;0;0m\u001b[38;2;255;255;255msentence \u001b[48;2;204;0;0m\u001b[38;2;255;255;255mneeds \u001b[48;2;0;0;107m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;80m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;214m\u001b[38;2;255;255;255mis \u001b[48;2;154;0;0m\u001b[38;2;255;255;255mauxiliary \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mtasks \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;214m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;59m\u001b[38;2;255;255;255mused \u001b[48;2;0;0;92m\u001b[38;2;255;255;255mto \u001b[48;2;125;0;0m\u001b[38;2;255;255;255massist \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;166;0;0m\u001b[38;2;255;255;255mprimary \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtask2.\n",
            "27 0.0 0.81 0.059 \u001b[48;2;23;0;0m\u001b[38;2;255;255;255mThey \u001b[48;2;35;0;0m\u001b[38;2;255;255;255mcategorize \u001b[48;2;0;0;277m\u001b[38;2;255;255;255mintents \u001b[48;2;0;0;225m\u001b[38;2;255;255;255minto \u001b[48;2;0;0;114m\u001b[38;2;255;255;255m3 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclasses: \u001b[48;2;155;0;0m\u001b[38;2;255;255;255mbackground \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minformation, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmethod, \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mand \u001b[48;2;24;0;0m\u001b[38;2;255;255;255mresult \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcomparison.\n",
            "28 1.0 0.818 0.272 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBesides, \u001b[48;2;0;0;197m\u001b[38;2;255;255;255mCohan \u001b[48;2;0;0;121m\u001b[38;2;255;255;255mbuilds \u001b[48;2;0;0;72m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mintent \u001b[48;2;435;0;0m\u001b[38;2;255;255;255mdataset \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mSciCite.\n",
            "29 0.0 0.403 0.055 \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mThose \u001b[48;2;0;0;30m\u001b[38;2;255;255;255mworks \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msim- \u001b[48;2;448;0;0m\u001b[38;2;255;255;255mply \u001b[48;2;0;0;96m\u001b[38;2;255;255;255mclassify \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;113m\u001b[38;2;255;255;255maccording \u001b[48;2;0;0;4m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mintents \u001b[48;2;212;0;0m\u001b[38;2;255;255;255mbut \u001b[48;2;103;0;0m\u001b[38;2;255;255;255mignore \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;17m\u001b[38;2;255;255;255msentiment \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mciting \u001b[48;2;91;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;74m\u001b[38;2;255;255;255mtowards \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreferences, \u001b[48;2;0;0;279m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;142m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mvital.\n",
            "30 0.0 0.962 0.011 \u001b[48;2;0;0;7m\u001b[38;2;255;255;255mButt \u001b[48;2;0;0;189m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[6] \u001b[48;2;0;0;280m\u001b[38;2;255;255;255mutilize \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mNaive-Bayes \u001b[48;2;0;0;107m\u001b[38;2;255;255;255mClassifier \u001b[48;2;0;0;162m\u001b[38;2;255;255;255mto \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mpredict \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msenti- \u001b[48;2;150;0;0m\u001b[38;2;255;255;255mment \u001b[48;2;0;0;110m\u001b[38;2;255;255;255mpolarity \u001b[48;2;0;0;92m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;62m\u001b[38;2;255;255;255ma \u001b[48;2;137;0;0m\u001b[38;2;255;255;255msentence \u001b[48;2;73;0;0m\u001b[38;2;255;255;255mcontaining \u001b[48;2;0;0;62m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;236;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;17;0;0m\u001b[38;2;255;255;255mits \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcontexts.\n",
            "31 0.0 0.694 0.095 \u001b[48;2;220;0;0m\u001b[38;2;255;255;255mWhereas \u001b[48;2;39;0;0m\u001b[38;2;255;255;255mLiu \u001b[48;2;0;0;197m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[23] \u001b[48;2;0;0;256m\u001b[38;2;255;255;255muse \u001b[48;2;0;0;29m\u001b[38;2;255;255;255maveraged \u001b[48;2;159;0;0m\u001b[38;2;255;255;255mword \u001b[48;2;178;0;0m\u001b[38;2;255;255;255membeddings \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mto \u001b[48;2;44;0;0m\u001b[38;2;255;255;255mrepresent \u001b[48;2;70;0;0m\u001b[38;2;255;255;255msentence \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mvectors \u001b[48;2;0;0;13m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;90m\u001b[38;2;255;255;255mclassify \u001b[48;2;0;0;93m\u001b[38;2;255;255;255msentiment \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpolarities.\n",
            "32 -1.0 0.924 -0.305 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHowever, \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mmethod \u001b[48;2;212;0;0m\u001b[38;2;255;255;255mgenerates \u001b[48;2;21;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;266;0;0m\u001b[38;2;255;255;255moverall \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msentiment \u001b[48;2;0;0;121m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtext, \u001b[48;2;179;0;0m\u001b[38;2;255;255;255mrather \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mthan \u001b[48;2;21;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mprecise \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msentiment \u001b[48;2;121;0;0m\u001b[38;2;255;255;255mtowards \u001b[48;2;21;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mcited \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper, \u001b[48;2;0;0;137m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;124m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;37m\u001b[38;2;255;255;255munable \u001b[48;2;0;0;112m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mapply \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdirectly.\n",
            "33 1.0 0.743 0.247 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2.2 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAspect-based \u001b[48;2;172;0;0m\u001b[38;2;255;255;255msentiment \u001b[48;2;0;0;120m\u001b[38;2;255;255;255manalysis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAspect-based \u001b[48;2;172;0;0m\u001b[38;2;255;255;255msentiment \u001b[48;2;0;0;120m\u001b[38;2;255;255;255manalysis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(ABSA) \u001b[48;2;0;0;175m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mproposed \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;55;0;0m\u001b[38;2;255;255;255mdefine \u001b[48;2;5;0;0m\u001b[38;2;255;255;255msuch \u001b[48;2;0;0;285m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtask.\n",
            "34 0.0 0.588 0.134 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mUsually, \u001b[48;2;132;0;0m\u001b[38;2;255;255;255mABSA \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mconsists \u001b[48;2;0;0;166m\u001b[38;2;255;255;255mof \u001b[48;2;93;0;0m\u001b[38;2;255;255;255mtwo \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstages: \u001b[48;2;0;0;202m\u001b[38;2;255;255;255mlocating \u001b[48;2;16;0;0m\u001b[38;2;255;255;255maspects \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;89m\u001b[38;2;255;255;255manalyzing \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msentiment.\n",
            "35 1.0 0.878 0.273 \u001b[48;2;96;0;0m\u001b[38;2;255;255;255msome \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mworks \u001b[48;2;155;0;0m\u001b[38;2;255;255;255msolve \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mthis \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mproblem \u001b[48;2;39;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;0;0;252m\u001b[38;2;255;255;255min \u001b[48;2;0;0;194m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtwo- \u001b[48;2;170;0;0m\u001b[38;2;255;255;255mstage \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mway, \u001b[48;2;45;0;0m\u001b[38;2;255;255;255mwhile \u001b[48;2;96;0;0m\u001b[38;2;255;255;255msome \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mjointly.\n",
            "36 0.0 0.986 0.004 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;52m\u001b[38;2;255;255;255mdetect \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mcitation \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mspan \u001b[48;2;0;0;222m\u001b[38;2;255;255;255min \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mWikipedia, \u001b[48;2;352;0;0m\u001b[38;2;255;255;255mFetahu \u001b[48;2;0;0;63m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[13] \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mpropose \u001b[48;2;0;0;182m\u001b[38;2;255;255;255ma \u001b[48;2;109;0;0m\u001b[38;2;255;255;255msequence \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mclassification \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mmethod \u001b[48;2;0;0;252m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;182m\u001b[38;2;255;255;255ma \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mlinear \u001b[48;2;34;0;0m\u001b[38;2;255;255;255mchain \u001b[48;2;5;0;0m\u001b[38;2;255;255;255mCRF \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;184;0;0m\u001b[38;2;255;255;255mdecide \u001b[48;2;28;0;0m\u001b[38;2;255;255;255mwhich \u001b[48;2;115;0;0m\u001b[38;2;255;255;255mtext \u001b[48;2;137;0;0m\u001b[38;2;255;255;255mfragments \u001b[48;2;0;0;74m\u001b[38;2;255;255;255mare \u001b[48;2;237;0;0m\u001b[38;2;255;255;255mcovered \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;182m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mat \u001b[48;2;98;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msub-sentence \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mlevel.\n",
            "37 0.0 0.926 0.008 \u001b[48;2;109;0;0m\u001b[38;2;255;255;255mWhereas \u001b[48;2;0;0;1m\u001b[38;2;255;255;255mKaplan \u001b[48;2;0;0;168m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[22] \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mdetect \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mnon-explicit \u001b[48;2;134;0;0m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;177m\u001b[38;2;255;255;255msentences \u001b[48;2;0;0;136m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;77m\u001b[38;2;255;255;255msurround \u001b[48;2;80;0;0m\u001b[38;2;255;255;255man \u001b[48;2;145;0;0m\u001b[38;2;255;255;255mexplicit \u001b[48;2;134;0;0m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msentence, \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mutilizing \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrelational, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mentity, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mlexical, \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mand \u001b[48;2;107;0;0m\u001b[38;2;255;255;255mgrammatical \u001b[48;2;217;0;0m\u001b[38;2;255;255;255mcoherence \u001b[48;2;220;0;0m\u001b[38;2;255;255;255mbetween \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mthem. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[25][39]even \u001b[48;2;101;0;0m\u001b[38;2;255;255;255mtry \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;106;0;0m\u001b[38;2;255;255;255mfind \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;114m\u001b[38;2;255;255;255mmost \u001b[48;2;0;0;20m\u001b[38;2;255;255;255mrelative \u001b[48;2;0;0;177m\u001b[38;2;255;255;255msentences \u001b[48;2;0;0;206m\u001b[38;2;255;255;255min \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mreference \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;239m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mthe \u001b[48;2;134;0;0m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msentences.\n",
            "38 0.0 0.963 0.011 \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mQazvinian \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;13m\u001b[38;2;255;255;255mRadev \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[29] \u001b[48;2;0;0;231m\u001b[38;2;255;255;255mproposed \u001b[48;2;0;0;308m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mmethod \u001b[48;2;114;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mon \u001b[48;2;638;0;0m\u001b[38;2;255;255;255mprobabilistic \u001b[48;2;0;0;36m\u001b[38;2;255;255;255minference \u001b[48;2;0;0;86m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mextract \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mnon-explicit \u001b[48;2;0;0;70m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;93m\u001b[38;2;255;255;255msentences \u001b[48;2;0;0;49m\u001b[38;2;255;255;255mby \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mmodelling \u001b[48;2;0;0;137m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;93m\u001b[38;2;255;255;255msentences \u001b[48;2;0;0;196m\u001b[38;2;255;255;255min \u001b[48;2;0;0;74m\u001b[38;2;255;255;255man \u001b[48;2;63;0;0m\u001b[38;2;255;255;255marticle \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mtheir \u001b[48;2;492;0;0m\u001b[38;2;255;255;255mlexical \u001b[48;2;86;0;0m\u001b[38;2;255;255;255msimilarities \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;308m\u001b[38;2;255;255;255ma \u001b[48;2;16;0;0m\u001b[38;2;255;255;255mMarkov \u001b[48;2;137;0;0m\u001b[38;2;255;255;255mRandom \u001b[48;2;62;0;0m\u001b[38;2;255;255;255mField \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mtuned \u001b[48;2;0;0;86m\u001b[38;2;255;255;255mto \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mdetect \u001b[48;2;0;0;137m\u001b[38;2;255;255;255mthe \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mpatterns \u001b[48;2;0;0;174m\u001b[38;2;255;255;255mthat \u001b[48;2;87;0;0m\u001b[38;2;255;255;255mcontext \u001b[48;2;347;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;198;0;0m\u001b[38;2;255;255;255mcreate \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;203m\u001b[38;2;255;255;255memploy \u001b[48;2;0;0;308m\u001b[38;2;255;255;255ma \u001b[48;2;91;0;0m\u001b[38;2;255;255;255mBelief \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mPropagation \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mmechanism \u001b[48;2;0;0;86m\u001b[38;2;255;255;255mto \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mdetect \u001b[48;2;0;0;14m\u001b[38;2;255;255;255mlikely \u001b[48;2;87;0;0m\u001b[38;2;255;255;255mcontext \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msentences.\n",
            "39 0.0 0.996 0.0 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAbu-Jbara \u001b[48;2;0;0;33m\u001b[38;2;255;255;255mand \u001b[48;2;209;0;0m\u001b[38;2;255;255;255mRadev \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[1] \u001b[48;2;209;0;0m\u001b[38;2;255;255;255mdetermine \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mthe \u001b[48;2;71;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;55;0;0m\u001b[38;2;255;255;255mblock \u001b[48;2;0;0;162m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;4m\u001b[38;2;255;255;255mfirst \u001b[48;2;249;0;0m\u001b[38;2;255;255;255msegmenting \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mthe \u001b[48;2;11;0;0m\u001b[38;2;255;255;255msentences \u001b[48;2;0;0;33m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mthen \u001b[48;2;0;0;140m\u001b[38;2;255;255;255mclassifying \u001b[48;2;0;0;70m\u001b[38;2;255;255;255meach \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mword \u001b[48;2;0;0;237m\u001b[38;2;255;255;255min \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mthe \u001b[48;2;263;0;0m\u001b[38;2;255;255;255msentence \u001b[48;2;0;0;323m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;10m\u001b[38;2;255;255;255mbeing \u001b[48;2;0;0;84m\u001b[38;2;255;255;255minside \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mor \u001b[48;2;0;0;93m\u001b[38;2;255;255;255moutside \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mthe \u001b[48;2;71;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mblock.\n",
            "40 0.0 0.997 0.0 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFinally, \u001b[48;2;0;0;110m\u001b[38;2;255;255;255mthey \u001b[48;2;0;0;2m\u001b[38;2;255;255;255maggregate \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;96m\u001b[38;2;255;255;255mlabels \u001b[48;2;0;0;218m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mall \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mwords \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mcontained \u001b[48;2;0;0;109m\u001b[38;2;255;255;255min \u001b[48;2;0;0;0m\u001b[38;2;255;255;255ma \u001b[48;2;165;0;0m\u001b[38;2;255;255;255msegment \u001b[48;2;17;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;21;0;0m\u001b[38;2;255;255;255massign \u001b[48;2;0;0;0m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mlabel \u001b[48;2;17;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mthe \u001b[48;2;127;0;0m\u001b[38;2;255;255;255mwhole \u001b[48;2;165;0;0m\u001b[38;2;255;255;255msegment \u001b[48;2;1;0;0m\u001b[38;2;255;255;255musing \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mthree \u001b[48;2;65;0;0m\u001b[38;2;255;255;255mdifferent \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mlabel \u001b[48;2;0;0;7m\u001b[38;2;255;255;255maggregation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrules(majority \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mlabel \u001b[48;2;0;0;218m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwords, \u001b[48;2;0;0;133m\u001b[38;2;255;255;255mat \u001b[48;2;170;0;0m\u001b[38;2;255;255;255mleast \u001b[48;2;0;0;98m\u001b[38;2;255;255;255mone \u001b[48;2;0;0;218m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwords, \u001b[48;2;27;0;0m\u001b[38;2;255;255;255mor \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mall \u001b[48;2;0;0;218m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mthem).\n",
            "41 0.0 0.727 0.089 \u001b[48;2;0;0;25m\u001b[38;2;255;255;255mKaplan \u001b[48;2;0;0;230m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[21] \u001b[48;2;0;0;193m\u001b[38;2;255;255;255mproposed \u001b[48;2;0;0;88m\u001b[38;2;255;255;255ma \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mnew \u001b[48;2;0;0;115m\u001b[38;2;255;255;255mmethod \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcoreference-chains \u001b[48;2;0;0;65m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;9m\u001b[38;2;255;255;255mextracting \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;103;0;0m\u001b[38;2;255;255;255mblocks \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mfrom \u001b[48;2;165;0;0m\u001b[38;2;255;255;255mresearch \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpapers.\n",
            "42 0.0 0.974 0.007 \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mGiven \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maspects, \u001b[48;2;0;0;171m\u001b[38;2;255;255;255mSun \u001b[48;2;0;0;236m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[32] \u001b[48;2;24;0;0m\u001b[38;2;255;255;255mconstruct \u001b[48;2;5;0;0m\u001b[38;2;255;255;255man \u001b[48;2;141;0;0m\u001b[38;2;255;255;255mauxiliary \u001b[48;2;99;0;0m\u001b[38;2;255;255;255msentence \u001b[48;2;0;0;114m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;10m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maspect, \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mand \u001b[48;2;115;0;0m\u001b[38;2;255;255;255mfeed \u001b[48;2;171;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msentence-pair \u001b[48;2;21;0;0m\u001b[38;2;255;255;255minto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBERT-based \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodel.\n",
            "43 0.0 0.854 0.027 \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mGao \u001b[48;2;0;0;203m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[14] \u001b[48;2;0;0;103m\u001b[38;2;255;255;255mutilize \u001b[48;2;23;0;0m\u001b[38;2;255;255;255mthree \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtarget-dependent \u001b[48;2;145;0;0m\u001b[38;2;255;255;255mvariations \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;39m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mðµð¸ð‘…ð‘‡ð‘ð‘Žð‘ ð‘’ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodel.\n",
            "44 0.0 0.597 0.133 \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mBai \u001b[48;2;0;0;188m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[2] \u001b[48;2;0;0;220m\u001b[38;2;255;255;255mpropose \u001b[48;2;0;0;73m\u001b[38;2;255;255;255ma \u001b[48;2;174;0;0m\u001b[38;2;255;255;255mnovel \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mrelational \u001b[48;2;20;0;0m\u001b[38;2;255;255;255mgraph \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mattention \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mnetwork3, \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mwhich \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mintegrates \u001b[48;2;95;0;0m\u001b[38;2;255;255;255mtyped \u001b[48;2;406;0;0m\u001b[38;2;255;255;255msyntactic \u001b[48;2;240;0;0m\u001b[38;2;255;255;255mdependency \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minformation.\n",
            "45 1.0 0.635 0.193 \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mAs \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mthe \u001b[48;2;120;0;0m\u001b[38;2;255;255;255merrors \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mare \u001b[48;2;362;0;0m\u001b[38;2;255;255;255mcumulated \u001b[48;2;0;0;134m\u001b[38;2;255;255;255min \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpipeline, \u001b[48;2;65;0;0m\u001b[38;2;255;255;255msome \u001b[48;2;237;0;0m\u001b[38;2;255;255;255mresearchers \u001b[48;2;0;0;79m\u001b[38;2;255;255;255mexplore \u001b[48;2;16;0;0m\u001b[38;2;255;255;255msolutions \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mdetect \u001b[48;2;0;0;101m\u001b[38;2;255;255;255maspects \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mclassify \u001b[48;2;0;0;46m\u001b[38;2;255;255;255msentiment \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mjointly.\n",
            "46 0.0 0.706 0.095 \u001b[48;2;0;0;14m\u001b[38;2;255;255;255mWang \u001b[48;2;0;0;315m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[37] \u001b[48;2;0;0;121m\u001b[38;2;255;255;255mpropose \u001b[48;2;0;0;141m\u001b[38;2;255;255;255ma \u001b[48;2;238;0;0m\u001b[38;2;255;255;255mlatent \u001b[48;2;0;0;40m\u001b[38;2;255;255;255maspect \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mrating \u001b[48;2;0;0;78m\u001b[38;2;255;255;255manalysis \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mproblem \u001b[48;2;0;0;46m\u001b[38;2;255;255;255mthat \u001b[48;2;113;0;0m\u001b[38;2;255;255;255maims \u001b[48;2;0;0;61m\u001b[38;2;255;255;255mat \u001b[48;2;84;0;0m\u001b[38;2;255;255;255manalyzing \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreviewersâ€™ \u001b[48;2;238;0;0m\u001b[38;2;255;255;255mlatent \u001b[48;2;48;0;0m\u001b[38;2;255;255;255mopinions \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mon \u001b[48;2;92;0;0m\u001b[38;2;255;255;255man \u001b[48;2;226;0;0m\u001b[38;2;255;255;255mentity \u001b[48;2;0;0;89m\u001b[38;2;255;255;255mfrom \u001b[48;2;176;0;0m\u001b[38;2;255;255;255mseveral \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maspects.\n",
            "47 0.0 0.977 0.007 \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mFor \u001b[48;2;0;0;38m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;55m\u001b[38;2;255;255;255mcertain \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mentity, \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mthey \u001b[48;2;61;0;0m\u001b[38;2;255;255;255mdefine \u001b[48;2;0;0;38m\u001b[38;2;255;255;255ma \u001b[48;2;124;0;0m\u001b[38;2;255;255;255mset \u001b[48;2;0;0;259m\u001b[38;2;255;255;255mof \u001b[48;2;380;0;0m\u001b[38;2;255;255;255mkeywords \u001b[48;2;0;0;259m\u001b[38;2;255;255;255mof \u001b[48;2;55;0;0m\u001b[38;2;255;255;255maspects \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;114m\u001b[38;2;255;255;255msegment \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mreviews \u001b[48;2;112;0;0m\u001b[38;2;255;255;255minto \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mthe \u001b[48;2;175;0;0m\u001b[38;2;255;255;255maspect \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mlevel.\n",
            "48 0.0 0.772 0.074 \u001b[48;2;58;0;0m\u001b[38;2;255;255;255mGiven \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mas- \u001b[48;2;212;0;0m\u001b[38;2;255;255;255mpect \u001b[48;2;0;0;266m\u001b[38;2;255;255;255msegmentation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mresults, \u001b[48;2;145;0;0m\u001b[38;2;255;255;255mthey \u001b[48;2;0;0;87m\u001b[38;2;255;255;255muse \u001b[48;2;0;0;199m\u001b[38;2;255;255;255ma \u001b[48;2;152;0;0m\u001b[38;2;255;255;255mnovel \u001b[48;2;226;0;0m\u001b[38;2;255;255;255mlatent \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mrating \u001b[48;2;88;0;0m\u001b[38;2;255;255;255mregression \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mmodel \u001b[48;2;0;0;10m\u001b[38;2;255;255;255mto \u001b[48;2;69;0;0m\u001b[38;2;255;255;255mcalculate \u001b[48;2;0;0;7m\u001b[38;2;255;255;255maspect \u001b[48;2;0;0;68m\u001b[38;2;255;255;255mratings \u001b[48;2;0;0;85m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;125m\u001b[38;2;255;255;255mcorresponding \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mweights.\n",
            "49 1.0 0.645 0.202 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHow- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mever, \u001b[48;2;0;0;95m\u001b[38;2;255;255;255mWang \u001b[48;2;0;0;129m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;156m\u001b[38;2;255;255;255mignore \u001b[48;2;0;0;130m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minter-dependencies \u001b[48;2;174;0;0m\u001b[38;2;255;255;255mbetween \u001b[48;2;100;0;0m\u001b[38;2;255;255;255mwords \u001b[48;2;164;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msentences, \u001b[48;2;0;0;234m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;33m\u001b[38;2;255;255;255mcauses \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mgreat \u001b[48;2;173;0;0m\u001b[38;2;255;255;255minformation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mloss.\n",
            "50 1.0 0.869 0.288 \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mThis \u001b[48;2;0;0;221m\u001b[38;2;255;255;255mclass \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mprob- \u001b[48;2;419;0;0m\u001b[38;2;255;255;255mlem \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mis \u001b[48;2;68;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mcalled \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maspect-based \u001b[48;2;27;0;0m\u001b[38;2;255;255;255msentiment \u001b[48;2;0;0;30m\u001b[38;2;255;255;255manalysis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(ABSA).\n",
            "51 0.0 0.966 0.01 \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mRuder \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPhocus: \u001b[48;2;0;0;133m\u001b[38;2;255;255;255mPicking \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mValuable \u001b[48;2;59;0;0m\u001b[38;2;255;255;255mResearch \u001b[48;2;0;0;22m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;45m\u001b[38;2;255;255;255ma \u001b[48;2;137;0;0m\u001b[38;2;255;255;255mSea \u001b[48;2;0;0;147m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mCitations \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;0;0;150m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[30] \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mproposes \u001b[48;2;0;0;45m\u001b[38;2;255;255;255ma \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mhierarchical \u001b[48;2;468;0;0m\u001b[38;2;255;255;255mbidirectional \u001b[48;2;0;0;241m\u001b[38;2;255;255;255mLSTM \u001b[48;2;0;0;52m\u001b[38;2;255;255;255mto \u001b[48;2;93;0;0m\u001b[38;2;255;255;255mmodel \u001b[48;2;87;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minter-dependencies \u001b[48;2;0;0;147m\u001b[38;2;255;255;255mof \u001b[48;2;158;0;0m\u001b[38;2;255;255;255msentences \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mwithin \u001b[48;2;0;0;45m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreview.\n",
            "52 1.0 0.639 0.208 \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mthe \u001b[48;2;188;0;0m\u001b[38;2;255;255;255maspect \u001b[48;2;0;0;41m\u001b[38;2;255;255;255mis \u001b[48;2;147;0;0m\u001b[38;2;255;255;255mrepresented \u001b[48;2;0;0;20m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mthe \u001b[48;2;250;0;0m\u001b[38;2;255;255;255maverage \u001b[48;2;0;0;199m\u001b[38;2;255;255;255mof \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mits \u001b[48;2;14;0;0m\u001b[38;2;255;255;255mentity \u001b[48;2;0;0;192m\u001b[38;2;255;255;255mand \u001b[48;2;18;0;0m\u001b[38;2;255;255;255mattribute \u001b[48;2;0;0;0m\u001b[38;2;255;255;255membeddings.\n",
            "53 0.0 0.98 0.006 \u001b[48;2;399;0;0m\u001b[38;2;255;255;255mHoang \u001b[48;2;0;0;207m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[18] \u001b[48;2;0;0;254m\u001b[38;2;255;255;255mpropose \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;43m\u001b[38;2;255;255;255muse \u001b[48;2;0;0;146m\u001b[38;2;255;255;255ma \u001b[48;2;126;0;0m\u001b[38;2;255;255;255msentence \u001b[48;2;154;0;0m\u001b[38;2;255;255;255mpair \u001b[48;2;2;0;0m\u001b[38;2;255;255;255mclassifier \u001b[48;2;92;0;0m\u001b[38;2;255;255;255mmodel \u001b[48;2;0;0;43m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBERT[11] \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mto \u001b[48;2;7;0;0m\u001b[38;2;255;255;255msolve \u001b[48;2;0;0;193m\u001b[38;2;255;255;255mABSA \u001b[48;2;0;0;33m\u001b[38;2;255;255;255mat \u001b[48;2;126;0;0m\u001b[38;2;255;255;255msentence \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;114;0;0m\u001b[38;2;255;255;255mtext \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mlevels.\n",
            "54 0.0 0.6 0.131 \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mHu \u001b[48;2;0;0;184m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[19] \u001b[48;2;0;0;239m\u001b[38;2;255;255;255mpropose \u001b[48;2;0;0;60m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mspan-based \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mextract-then-classify \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mframework \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBERT4.\n",
            "55 0.0 0.899 0.033 \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mXu \u001b[48;2;0;0;194m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[38] \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mbuild \u001b[48;2;0;0;60m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdataset, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mReviewRC5, \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mextend \u001b[48;2;8;0;0m\u001b[38;2;255;255;255mBERT \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;66m\u001b[38;2;255;255;255man \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mextra \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtasking-specific \u001b[48;2;186;0;0m\u001b[38;2;255;255;255mlayer \u001b[48;2;0;0;148m\u001b[38;2;255;255;255mto \u001b[48;2;88;0;0m\u001b[38;2;255;255;255mtune \u001b[48;2;43;0;0m\u001b[38;2;255;255;255meach \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtask.\n",
            "56 0.0 0.92 0.026 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mWal- \u001b[48;2;318;0;0m\u001b[38;2;255;255;255mlaart \u001b[48;2;0;0;150m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[36] \u001b[48;2;0;0;44m\u001b[38;2;255;255;255mpropose \u001b[48;2;0;0;48m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtwo-stage \u001b[48;2;0;0;19m\u001b[38;2;255;255;255malgorithm \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;114;0;0m\u001b[38;2;255;255;255msolve \u001b[48;2;0;0;140m\u001b[38;2;255;255;255mthe \u001b[48;2;107;0;0m\u001b[38;2;255;255;255mABSA \u001b[48;2;0;0;113m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrestaurant \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreviews: \u001b[48;2;38;0;0m\u001b[38;2;255;255;255mpredicting \u001b[48;2;0;0;140m\u001b[38;2;255;255;255mthe \u001b[48;2;18;0;0m\u001b[38;2;255;255;255msentiment \u001b[48;2;0;0;254m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;48m\u001b[38;2;255;255;255ma \u001b[48;2;775;0;0m\u001b[38;2;255;255;255mlexicalized \u001b[48;2;117;0;0m\u001b[38;2;255;255;255mdomain \u001b[48;2;0;0;0m\u001b[38;2;255;255;255montology, \u001b[48;2;0;0;22m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;88m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;48m\u001b[38;2;255;255;255ma \u001b[48;2;229;0;0m\u001b[38;2;255;255;255mneural \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mnetwork \u001b[48;2;0;0;254m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;48m\u001b[38;2;255;255;255ma \u001b[48;2;20;0;0m\u001b[38;2;255;255;255mrotatory \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mat- \u001b[48;2;21;0;0m\u001b[38;2;255;255;255mtention \u001b[48;2;0;0;76m\u001b[38;2;255;255;255mmechanism \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(LCR-Rot) \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;48m\u001b[38;2;255;255;255ma \u001b[48;2;53;0;0m\u001b[38;2;255;255;255mbackup \u001b[48;2;0;0;0m\u001b[38;2;255;255;255malgorithm.\n",
            "57 0.0 0.897 0.031 \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mthe \u001b[48;2;112;0;0m\u001b[38;2;255;255;255morder \u001b[48;2;0;0;337m\u001b[38;2;255;255;255mof \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mrotatory \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mattention \u001b[48;2;0;0;57m\u001b[38;2;255;255;255mmechanism \u001b[48;2;0;0;217m\u001b[38;2;255;255;255moperation \u001b[48;2;0;0;1m\u001b[38;2;255;255;255mis \u001b[48;2;246;0;0m\u001b[38;2;255;255;255mchanged \u001b[48;2;56;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mro- \u001b[48;2;87;0;0m\u001b[38;2;255;255;255mtatory \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mattention \u001b[48;2;0;0;57m\u001b[38;2;255;255;255mmechanism \u001b[48;2;0;0;1m\u001b[38;2;255;255;255mis \u001b[48;2;219;0;0m\u001b[38;2;255;255;255miterated \u001b[48;2;21;0;0m\u001b[38;2;255;255;255mmultiple \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtimes.\n",
            "58 0.0 0.969 0.009 \u001b[48;2;168;0;0m\u001b[38;2;255;255;255mTrusca \u001b[48;2;0;0;212m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;184m\u001b[38;2;255;255;255mextend \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[36] \u001b[48;2;0;0;196m\u001b[38;2;255;255;255mwith \u001b[48;2;163;0;0m\u001b[38;2;255;255;255mdeep \u001b[48;2;52;0;0m\u001b[38;2;255;255;255mcontextual \u001b[48;2;136;0;0m\u001b[38;2;255;255;255mword \u001b[48;2;175;0;0m\u001b[38;2;255;255;255membeddings \u001b[48;2;0;0;10m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;163m\u001b[38;2;255;255;255madd \u001b[48;2;1;0;0m\u001b[38;2;255;255;255man \u001b[48;2;54;0;0m\u001b[38;2;255;255;255mextra \u001b[48;2;0;0;42m\u001b[38;2;255;255;255mattention \u001b[48;2;158;0;0m\u001b[38;2;255;255;255mlayer \u001b[48;2;109;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;89;0;0m\u001b[38;2;255;255;255mits \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhigh-level \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrepresentations[34].\n",
            "59 0.0 0.724 0.091 \u001b[48;2;181;0;0m\u001b[38;2;255;255;255mTo \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mad- \u001b[48;2;231;0;0m\u001b[38;2;255;255;255mdress \u001b[48;2;0;0;44m\u001b[38;2;255;255;255mthe \u001b[48;2;263;0;0m\u001b[38;2;255;255;255mimbalance \u001b[48;2;93;0;0m\u001b[38;2;255;255;255missue \u001b[48;2;20;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;165m\u001b[38;2;255;255;255mutilize \u001b[48;2;0;0;44m\u001b[38;2;255;255;255mthe \u001b[48;2;152;0;0m\u001b[38;2;255;255;255minteraction \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mbetween \u001b[48;2;6;0;0m\u001b[38;2;255;255;255maspect \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mterms, \u001b[48;2;0;0;7m\u001b[38;2;255;255;255mLuo \u001b[48;2;0;0;203m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[24] \u001b[48;2;0;0;209m\u001b[38;2;255;255;255mpropose \u001b[48;2;0;0;220m\u001b[38;2;255;255;255ma \u001b[48;2;212;0;0m\u001b[38;2;255;255;255mgradient \u001b[48;2;146;0;0m\u001b[38;2;255;255;255mharmonized \u001b[48;2;20;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;72m\u001b[38;2;255;255;255mcascaded \u001b[48;2;0;0;218m\u001b[38;2;255;255;255mlabelling \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mmodel \u001b[48;2;34;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;233m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBERT.\n",
            "60 0.0 0.669 0.109 \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mChen \u001b[48;2;0;0;235m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[7] \u001b[48;2;0;0;186m\u001b[38;2;255;255;255mutilize \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mdirectional \u001b[48;2;51;0;0m\u001b[38;2;255;255;255mgraph \u001b[48;2;601;0;0m\u001b[38;2;255;255;255mconvolutional \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mnetworks \u001b[48;2;54;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;119m\u001b[38;2;255;255;255mperform \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mend-to-end \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mABSA \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtask.\n",
            "61 0.0 0.805 0.062 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2.3 \u001b[48;2;216;0;0m\u001b[38;2;255;255;255mranking \u001b[48;2;0;0;73m\u001b[38;2;255;255;255mmodel \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;216;0;0m\u001b[38;2;255;255;255mranking \u001b[48;2;0;0;73m\u001b[38;2;255;255;255mmodel \u001b[48;2;0;0;14m\u001b[38;2;255;255;255mis \u001b[48;2;262;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mLambdaMART, \u001b[48;2;0;0;164m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;14m\u001b[38;2;255;255;255mis \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mboosted \u001b[48;2;226;0;0m\u001b[38;2;255;255;255mtree \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mversion \u001b[48;2;0;0;209m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mLambdaRank[5].\n",
            "62 0.0 0.58 0.125 \u001b[48;2;49;0;0m\u001b[38;2;255;255;255mThis \u001b[48;2;0;0;26m\u001b[38;2;255;255;255malgorithm \u001b[48;2;275;0;0m\u001b[38;2;255;255;255msolves \u001b[48;2;28;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mgradients \u001b[48;2;0;0;250m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mnon-smooth \u001b[48;2;103;0;0m\u001b[38;2;255;255;255mcost \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mfunctions \u001b[48;2;0;0;136m\u001b[38;2;255;255;255mused \u001b[48;2;0;0;174m\u001b[38;2;255;255;255min \u001b[48;2;243;0;0m\u001b[38;2;255;255;255mranking \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels.\n",
            "63 0.0 0.889 0.031 \u001b[48;2;112;0;0m\u001b[38;2;255;255;255mBurges \u001b[48;2;0;0;199m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[4] \u001b[48;2;62;0;0m\u001b[38;2;255;255;255mgive \u001b[48;2;83;0;0m\u001b[38;2;255;255;255ma \u001b[48;2;197;0;0m\u001b[38;2;255;255;255mreview \u001b[48;2;37;0;0m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mRankNet, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mLambdaRank, \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mLambdaMART.\n",
            "64 0.0 0.968 0.01 \u001b[48;2;0;0;98m\u001b[38;2;255;255;255mto \u001b[48;2;26;0;0m\u001b[38;2;255;255;255millustrate \u001b[48;2;0;0;38m\u001b[38;2;255;255;255mthe \u001b[48;2;158;0;0m\u001b[38;2;255;255;255mranking \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mnetwork, \u001b[48;2;219;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;0;22m\u001b[38;2;255;255;255muse \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘ð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘— \u001b[48;2;0;0;98m\u001b[38;2;255;255;255mto \u001b[48;2;146;0;0m\u001b[38;2;255;255;255mdenote \u001b[48;2;0;0;38m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘—-th \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mci- \u001b[48;2;105;0;0m\u001b[38;2;255;255;255mtation \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;38m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘–-th \u001b[48;2;68;0;0m\u001b[38;2;255;255;255mreference \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper.\n",
            "65 0.0 0.971 0.008 \u001b[48;2;158;0;0m\u001b[38;2;255;255;255mOur \u001b[48;2;244;0;0m\u001b[38;2;255;255;255mranking \u001b[48;2;75;0;0m\u001b[38;2;255;255;255mnetwork \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mreceives \u001b[48;2;164;0;0m\u001b[38;2;255;255;255man \u001b[48;2;208;0;0m\u001b[38;2;255;255;255mmatrix \u001b[48;2;65;0;0m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mshape \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m((cid:205)ð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘›_ð‘ð‘–ð‘¡ð‘–, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m4), \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mwhere \u001b[48;2;0;0;75m\u001b[38;2;255;255;255m4 \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mstands \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;35;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;70;0;0m\u001b[38;2;255;255;255mfeature \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mquater- \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mnion \u001b[48;2;65;0;0m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(au_overlap, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mn_cit, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcit_word, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msen_label).\n",
            "66 0.0 0.959 0.009 \u001b[48;2;0;0;87m\u001b[38;2;255;255;255mAmong \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcit_word \u001b[48;2;0;0;120m\u001b[38;2;255;255;255mis \u001b[48;2;247;0;0m\u001b[38;2;255;255;255mcalculated \u001b[48;2;91;0;0m\u001b[38;2;255;255;255mas \u001b[48;2;24;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;174;0;0m\u001b[38;2;255;255;255mtotal \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;230m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;10m\u001b[38;2;255;255;255mwords \u001b[48;2;0;0;238m\u001b[38;2;255;255;255min \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘ð‘œð‘›ð‘¡ð‘’ð‘¥ð‘¡_ð‘Ž \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m+ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘ ð‘’ð‘›ð‘¡ð‘’ð‘›ð‘ð‘’ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m+ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘ð‘œð‘›ð‘¡ð‘’ð‘¥ð‘¡_ð‘.\n",
            "67 0.0 0.978 0.006 \u001b[48;2;93;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;195;0;0m\u001b[38;2;255;255;255mnetwork \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mcalculate \u001b[48;2;0;0;98m\u001b[38;2;255;255;255ma \u001b[48;2;19;0;0m\u001b[38;2;255;255;255mscore \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘ ð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘— \u001b[48;2;0;0;223m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;82m\u001b[38;2;255;255;255meach \u001b[48;2;25;0;0m\u001b[38;2;255;255;255mtime \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mof \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘ð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘— \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mindividually, \u001b[48;2;135;0;0m\u001b[38;2;255;255;255maveraging \u001b[48;2;0;0;223m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;67m\u001b[38;2;255;255;255mduplicate \u001b[48;2;0;0;214m\u001b[38;2;255;255;255mcitations \u001b[48;2;86;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(cid:205)ð‘— \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘ ð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘— \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m.\n",
            "68 0.0 0.981 0.005 \u001b[48;2;131;0;0m\u001b[38;2;255;255;255mThen \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘ ð‘– \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;146;0;0m\u001b[38;2;255;255;255mget \u001b[48;2;0;0;215m\u001b[38;2;255;255;255mthe \u001b[48;2;275;0;0m\u001b[38;2;255;255;255mscore \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;123m\u001b[38;2;255;255;255meach \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mreference \u001b[48;2;0;0;123m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘ ð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m= \u001b[48;2;58;0;0m\u001b[38;2;255;255;255mused \u001b[48;2;0;0;173m\u001b[38;2;255;255;255mto \u001b[48;2;95;0;0m\u001b[38;2;255;255;255mrank \u001b[48;2;18;0;0m\u001b[38;2;255;255;255mall \u001b[48;2;0;0;215m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mreference \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper, \u001b[48;2;33;0;0m\u001b[38;2;255;255;255moutputting \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘Ÿð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m.\n",
            "69 0.0 0.748 0.082 \u001b[48;2;0;0;158m\u001b[38;2;255;255;255m1 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘›_ð‘ð‘–ð‘¡ð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2.4 \u001b[48;2;0;0;104m\u001b[38;2;255;255;255mEvaluation \u001b[48;2;51;0;0m\u001b[38;2;255;255;255mmetrics \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mIn \u001b[48;2;0;0;90m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;28m\u001b[38;2;255;255;255macademic \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfield, \u001b[48;2;7;0;0m\u001b[38;2;255;255;255mthere \u001b[48;2;0;0;90m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mjournal-level, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mauthor-level \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper- \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mlevel \u001b[48;2;51;0;0m\u001b[38;2;255;255;255mmetrics \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;147m\u001b[38;2;255;255;255mmeasure \u001b[48;2;92;0;0m\u001b[38;2;255;255;255mtheir \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mimpacts.\n",
            "70 0.0 0.968 0.01 \u001b[48;2;146;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;116;0;0m\u001b[38;2;255;255;255mimpact \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mFactor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(IF)[26] \u001b[48;2;22;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;150m\u001b[38;2;255;255;255mCiteScore6 \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;30m\u001b[38;2;255;255;255mused \u001b[48;2;0;0;92m\u001b[38;2;255;255;255mto \u001b[48;2;188;0;0m\u001b[38;2;255;255;255mmeasure \u001b[48;2;146;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;116;0;0m\u001b[38;2;255;255;255mimpact \u001b[48;2;0;0;207m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;193m\u001b[38;2;255;255;255ma \u001b[48;2;136;0;0m\u001b[38;2;255;255;255mjournal \u001b[48;2;148;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mon \u001b[48;2;146;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;135m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;207m\u001b[38;2;255;255;255mof \u001b[48;2;112;0;0m\u001b[38;2;255;255;255mtimes \u001b[48;2;0;0;144m\u001b[38;2;255;255;255marticles \u001b[48;2;0;0;99m\u001b[38;2;255;255;255mcited \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mduring \u001b[48;2;0;0;193m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mfixed \u001b[48;2;73;0;0m\u001b[38;2;255;255;255mperiod \u001b[48;2;0;0;82m\u001b[38;2;255;255;255mpublished \u001b[48;2;0;0;81m\u001b[38;2;255;255;255mby \u001b[48;2;146;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mjournal.\n",
            "71 0.0 0.766 0.05 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBesides, \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mJournal \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mCita- \u001b[48;2;363;0;0m\u001b[38;2;255;255;255mtion \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mReports \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(JCR) \u001b[48;2;23;0;0m\u001b[38;2;255;255;255mgive \u001b[48;2;67;0;0m\u001b[38;2;255;255;255mranking \u001b[48;2;0;0;74m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mjournals7, \u001b[48;2;734;0;0m\u001b[38;2;255;255;255mEigenfactor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mscores[3] \u001b[48;2;258;0;0m\u001b[38;2;255;255;255mmeasure \u001b[48;2;27;0;0m\u001b[38;2;255;255;255mhow \u001b[48;2;92;0;0m\u001b[38;2;255;255;255mlikely \u001b[48;2;0;0;86m\u001b[38;2;255;255;255ma \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mJournal \u001b[48;2;65;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;277;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mbe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mused, \u001b[48;2;71;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mSCImago \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mJournal \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mRank \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(SJR)[15] \u001b[48;2;188;0;0m\u001b[38;2;255;255;255mregards \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;37m\u001b[38;2;255;255;255missued \u001b[48;2;0;0;157m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mmore \u001b[48;2;0;0;159m\u001b[38;2;255;255;255mimport \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mjour- \u001b[48;2;122;0;0m\u001b[38;2;255;255;255mnals \u001b[48;2;0;0;293m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mmore \u001b[48;2;0;0;25m\u001b[38;2;255;255;255mimportant \u001b[48;2;0;0;45m\u001b[38;2;255;255;255mthan \u001b[48;2;0;0;181m\u001b[38;2;255;255;255mthose \u001b[48;2;0;0;37m\u001b[38;2;255;255;255missued \u001b[48;2;0;0;157m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mless \u001b[48;2;0;0;25m\u001b[38;2;255;255;255mimportant \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mones.\n",
            "72 0.0 0.725 -0.045 \u001b[48;2;28;0;0m\u001b[38;2;255;255;255mWhereas \u001b[48;2;0;0;95m\u001b[38;2;255;255;255mSource \u001b[48;2;0;0;335m\u001b[38;2;255;255;255mNormalized \u001b[48;2;0;0;73m\u001b[38;2;255;255;255mImpact \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mper \u001b[48;2;138;0;0m\u001b[38;2;255;255;255mPaper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(SNIP)[27] \u001b[48;2;80;0;0m\u001b[38;2;255;255;255mindicates \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;72m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;11m\u001b[38;2;255;255;255msingle \u001b[48;2;132;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;114;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;174;0;0m\u001b[38;2;255;255;255mmuch \u001b[48;2;224;0;0m\u001b[38;2;255;255;255mmore \u001b[48;2;222;0;0m\u001b[38;2;255;255;255mimportant \u001b[48;2;0;0;212m\u001b[38;2;255;255;255min \u001b[48;2;0;0;31m\u001b[38;2;255;255;255msubject \u001b[48;2;0;0;44m\u001b[38;2;255;255;255mareas \u001b[48;2;0;0;136m\u001b[38;2;255;255;255mwhere \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;119m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mless, \u001b[48;2;35;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mvice \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mversa.\n",
            "73 1.0 0.734 0.241 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAuthor-level \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mmetrics \u001b[48;2;0;0;104m\u001b[38;2;255;255;255minclude \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mh-index, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mg-index, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mi10-index \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mand \u001b[48;2;189;0;0m\u001b[38;2;255;255;255mso \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mon.\n",
            "74 1.0 0.745 0.248 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mH-index \u001b[48;2;0;0;49m\u001b[38;2;255;255;255malso \u001b[48;2;17;0;0m\u001b[38;2;255;255;255mcalled \u001b[48;2;127;0;0m\u001b[38;2;255;255;255mindex \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâ„Ž, \u001b[48;2;0;0;185m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;129m\u001b[38;2;255;255;255mproposed \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mby \u001b[48;2;92;0;0m\u001b[38;2;255;255;255mJorge \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mE.\n",
            "75 0.0 0.941 0.018 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHirsch[17], \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;210m\u001b[38;2;255;255;255mits \u001b[48;2;0;0;72m\u001b[38;2;255;255;255mdefinition \u001b[48;2;65;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mthe \u001b[48;2;65;0;0m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;175m\u001b[38;2;255;255;255mof \u001b[48;2;100;0;0m\u001b[38;2;255;255;255mpapers \u001b[48;2;0;0;249m\u001b[38;2;255;255;255mwith \u001b[48;2;137;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;91;0;0m\u001b[38;2;255;255;255mnumbers \u001b[48;2;251;0;0m\u001b[38;2;255;255;255mFigure \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2: \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mthe \u001b[48;2;90;0;0m\u001b[38;2;255;255;255moverview \u001b[48;2;0;0;175m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPhocus.\n",
            "76 0.0 0.599 0.055 \u001b[48;2;199;0;0m\u001b[38;2;255;255;255mhigher \u001b[48;2;0;0;119m\u001b[38;2;255;255;255mor \u001b[48;2;0;0;57m\u001b[38;2;255;255;255mequal \u001b[48;2;0;0;119m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâ„Ž.\n",
            "77 1.0 0.467 0.133 \u001b[48;2;0;0;244m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mg-index \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mis \u001b[48;2;227;0;0m\u001b[38;2;255;255;255mdefined \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;244m\u001b[38;2;255;255;255mthe \u001b[48;2;217;0;0m\u001b[38;2;255;255;255mlargest \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mnumber \u001b[48;2;38;0;0m\u001b[38;2;255;255;255msuch \u001b[48;2;0;0;175m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;244m\u001b[38;2;255;255;255mthe \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mtop \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘” \u001b[48;2;0;0;99m\u001b[38;2;255;255;255marticles \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreceived \u001b[48;2;206;0;0m\u001b[38;2;255;255;255mtogether \u001b[48;2;0;0;205m\u001b[38;2;255;255;255mat \u001b[48;2;90;0;0m\u001b[38;2;255;255;255mleast \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘”2 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations[12].\n",
            "78 1.0 0.644 0.193 \u001b[48;2;107;0;0m\u001b[38;2;255;255;255mGoogle \u001b[48;2;21;0;0m\u001b[38;2;255;255;255mScholar \u001b[48;2;0;0;33m\u001b[38;2;255;255;255mproposes \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mi10-index \u001b[48;2;0;0;186m\u001b[38;2;255;255;255mthat \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;70;0;0m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;229m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;91m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;4m\u001b[38;2;255;255;255mpublication \u001b[48;2;0;0;227m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mat \u001b[48;2;165;0;0m\u001b[38;2;255;255;255mleast \u001b[48;2;109;0;0m\u001b[38;2;255;255;255m10 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations.\n",
            "79 -1.0 0.597 -0.192 \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mThose \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mmetrics \u001b[48;2;0;0;189m\u001b[38;2;255;255;255mare \u001b[48;2;276;0;0m\u001b[38;2;255;255;255mderived \u001b[48;2;0;0;127m\u001b[38;2;255;255;255mfrom \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mcitations \u001b[48;2;8;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;55;0;0m\u001b[38;2;255;255;255mdo \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mreveal \u001b[48;2;0;0;233m\u001b[38;2;255;255;255mthe \u001b[48;2;37;0;0m\u001b[38;2;255;255;255mtruth \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mamong \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations.\n",
            "80 1.0 0.674 0.216 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPaper-level \u001b[48;2;0;0;112m\u001b[38;2;255;255;255mmetrics \u001b[48;2;0;0;31m\u001b[38;2;255;255;255mare \u001b[48;2;214;0;0m\u001b[38;2;255;255;255musually \u001b[48;2;24;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;216m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations.\n",
            "81 1.0 0.96 0.311 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mEspe- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcially, \u001b[48;2;0;0;99m\u001b[38;2;255;255;255mSemantic \u001b[48;2;0;0;10m\u001b[38;2;255;255;255mScholar \u001b[48;2;86;0;0m\u001b[38;2;255;255;255mmakes \u001b[48;2;0;0;10m\u001b[38;2;255;255;255mthe \u001b[48;2;5;0;0m\u001b[38;2;255;255;255mfirst \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mstep \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mtowards \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclassi- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfication.\n",
            "82 0.0 0.721 0.092 \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mIt \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mdivided \u001b[48;2;0;0;99m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;28m\u001b[38;2;255;255;255minto \u001b[48;2;144;0;0m\u001b[38;2;255;255;255m4 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclasses: \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mhighly \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minfluential, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mback- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mground, \u001b[48;2;0;0;136m\u001b[38;2;255;255;255mmethod \u001b[48;2;14;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations[35], \u001b[48;2;0;0;85m\u001b[38;2;255;255;255musing \u001b[48;2;129;0;0m\u001b[38;2;255;255;255mSVM \u001b[48;2;0;0;344m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;27m\u001b[38;2;255;255;255man \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mRBF \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mkernel \u001b[48;2;14;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;42;0;0m\u001b[38;2;255;255;255mrandom \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mforests.\n",
            "83 0.0 0.935 0.015 \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mfeatures \u001b[48;2;0;0;25m\u001b[38;2;255;255;255mSemantic \u001b[48;2;294;0;0m\u001b[38;2;255;255;255mScholar \u001b[48;2;0;0;90m\u001b[38;2;255;255;255muse \u001b[48;2;51;0;0m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mtotal \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;257m\u001b[38;2;255;255;255mof \u001b[48;2;44;0;0m\u001b[38;2;255;255;255mdirect \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations, \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;257m\u001b[38;2;255;255;255mof \u001b[48;2;44;0;0m\u001b[38;2;255;255;255mdirect \u001b[48;2;0;0;133m\u001b[38;2;255;255;255mcitations \u001b[48;2;112;0;0m\u001b[38;2;255;255;255mper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msection, \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mtotal \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;257m\u001b[38;2;255;255;255mof \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mindirect \u001b[48;2;0;0;133m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;107m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;257m\u001b[38;2;255;255;255mof \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mindirect \u001b[48;2;0;0;133m\u001b[38;2;255;255;255mcitations \u001b[48;2;112;0;0m\u001b[38;2;255;255;255mper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msection, \u001b[48;2;120;0;0m\u001b[38;2;255;255;255mauthor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255moverlap, \u001b[48;2;102;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;216;0;0m\u001b[38;2;255;255;255mconsidered \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhelp- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mful, \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mcitation \u001b[48;2;140;0;0m\u001b[38;2;255;255;255mappears \u001b[48;2;0;0;143m\u001b[38;2;255;255;255min \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mtable \u001b[48;2;0;0;107m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcaption, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1/number \u001b[48;2;0;0;257m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreferences, \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;257m\u001b[38;2;255;255;255mof \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations/all \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations, \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mthe \u001b[48;2;31;0;0m\u001b[38;2;255;255;255msimilarity \u001b[48;2;98;0;0m\u001b[38;2;255;255;255mbetween \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mab- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstracts, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPageRank[28], \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;257m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mtotal \u001b[48;2;0;0;152m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;70m\u001b[38;2;255;255;255mpapers \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mafter \u001b[48;2;0;0;368m\u001b[38;2;255;255;255mtransitive \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclosure, \u001b[48;2;0;0;107m\u001b[38;2;255;255;255mand \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mfield \u001b[48;2;0;0;257m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcited \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper.\n",
            "84 0.0 0.882 0.038 \u001b[48;2;0;0;85m\u001b[38;2;255;255;255m3 \u001b[48;2;0;0;159m\u001b[38;2;255;255;255mMETHODOLOGY \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mAs \u001b[48;2;0;0;103m\u001b[38;2;255;255;255mshown \u001b[48;2;0;0;283m\u001b[38;2;255;255;255min \u001b[48;2;91;0;0m\u001b[38;2;255;255;255mFigure \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m??, \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;109;0;0m\u001b[38;2;255;255;255malgorithm \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mconsists \u001b[48;2;0;0;198m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;63m\u001b[38;2;255;255;255m4 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstages: \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpre- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mprocessing, \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mcalculating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfactors, \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mevaluating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcontribution, \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mprop- \u001b[48;2;395;0;0m\u001b[38;2;255;255;255magating \u001b[48;2;0;0;79m\u001b[38;2;255;255;255minfluential \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfactors.\n",
            "85 1.0 0.709 0.233 \u001b[48;2;0;0;194m\u001b[38;2;255;255;255mIn \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpre-processing \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstage, \u001b[48;2;166;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mclean \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mraw \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdata, \u001b[48;2;5;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mobtain \u001b[48;2;0;0;91m\u001b[38;2;255;255;255msimple \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfactors.\n",
            "86 1.0 0.808 0.259 \u001b[48;2;0;0;7m\u001b[38;2;255;255;255mComplex \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfactors, \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mlike \u001b[48;2;0;0;203m\u001b[38;2;255;255;255msentiment \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mpolarity \u001b[48;2;0;0;136m\u001b[38;2;255;255;255mare \u001b[48;2;231;0;0m\u001b[38;2;255;255;255mcalculated \u001b[48;2;0;0;76m\u001b[38;2;255;255;255min \u001b[48;2;72;0;0m\u001b[38;2;255;255;255msecond \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstage.\n",
            "87 0.0 0.965 0.008 \u001b[48;2;187;0;0m\u001b[38;2;255;255;255mWhen \u001b[48;2;0;0;113m\u001b[38;2;255;255;255mget \u001b[48;2;0;0;175m\u001b[38;2;255;255;255mall \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mfactors \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mneeded, \u001b[48;2;135;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;14;0;0m\u001b[38;2;255;255;255mclassify \u001b[48;2;0;0;101m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;108m\u001b[38;2;255;255;255minto \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mfour \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mclasses \u001b[48;2;38;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;52m\u001b[38;2;255;255;255mrank \u001b[48;2;0;0;175m\u001b[38;2;255;255;255mall \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreferences, \u001b[48;2;38;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;148;0;0m\u001b[38;2;255;255;255mfigure \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mout \u001b[48;2;0;0;222m\u001b[38;2;255;255;255mthe \u001b[48;2;183;0;0m\u001b[38;2;255;255;255mlocal \u001b[48;2;53;0;0m\u001b[38;2;255;255;255mcontribution \u001b[48;2;129;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;0;0;183m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;75m\u001b[38;2;255;255;255meach \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreference.\n",
            "88 1.0 0.682 0.22 \u001b[48;2;226;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mini- \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mtialize \u001b[48;2;0;0;171m\u001b[38;2;255;255;255mall \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mnew \u001b[48;2;0;0;123m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;139m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;46m\u001b[38;2;255;255;255mthe \u001b[48;2;107;0;0m\u001b[38;2;255;255;255mdatabase \u001b[48;2;0;0;329m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;56m\u001b[38;2;255;255;255man \u001b[48;2;121;0;0m\u001b[38;2;255;255;255macademic \u001b[48;2;132;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;145;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1.0, \u001b[48;2;42;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;313;0;0m\u001b[38;2;255;255;255mpropagate \u001b[48;2;0;0;155m\u001b[38;2;255;255;255mits \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mimpact \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mreferences \u001b[48;2;0;0;0m\u001b[38;2;255;255;255miteratively.\n",
            "89 0.0 0.994 0.001 \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mthe \u001b[48;2;134;0;0m\u001b[38;2;255;255;255mfactors \u001b[48;2;143;0;0m\u001b[38;2;255;255;255mextracted \u001b[48;2;0;0;207m\u001b[38;2;255;255;255mfrom \u001b[48;2;121;0;0m\u001b[38;2;255;255;255mpapers \u001b[48;2;0;0;90m\u001b[38;2;255;255;255mare \u001b[48;2;162;0;0m\u001b[38;2;255;255;255mlisted \u001b[48;2;45;0;0m\u001b[38;2;255;255;255mout \u001b[48;2;0;0;74m\u001b[38;2;255;255;255min \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;169m\u001b[38;2;255;255;255m1 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m3.1 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPre-processing \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mGiven \u001b[48;2;0;0;107m\u001b[38;2;255;255;255ma \u001b[48;2;73;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;311m\u001b[38;2;255;255;255mof \u001b[48;2;201;0;0m\u001b[38;2;255;255;255mstring \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mformat, \u001b[48;2;0;0;107m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mseries \u001b[48;2;0;0;311m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msteps \u001b[48;2;108;0;0m\u001b[38;2;255;255;255mprocess \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mthe \u001b[48;2;218;0;0m\u001b[38;2;255;255;255mraw \u001b[48;2;179;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;19;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;25m\u001b[38;2;255;255;255mnext \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstage: \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mparsing, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msegmentation, \u001b[48;2;0;0;43m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmatching.\n",
            "90 0.0 0.753 0.078 \u001b[48;2;118;0;0m\u001b[38;2;255;255;255mParing \u001b[48;2;0;0;296m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;56m\u001b[38;2;255;255;255maimed \u001b[48;2;0;0;261m\u001b[38;2;255;255;255mat \u001b[48;2;91;0;0m\u001b[38;2;255;255;255mdividing \u001b[48;2;52;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;153;0;0m\u001b[38;2;255;255;255minput \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mtext \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtitle, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mauthors, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msections, \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreferences.\n",
            "91 0.0 0.842 0.049 \u001b[48;2;265;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mutilize \u001b[48;2;7;0;0m\u001b[38;2;255;255;255mflari8 \u001b[48;2;0;0;48m\u001b[38;2;255;255;255mto \u001b[48;2;395;0;0m\u001b[38;2;255;255;255mparse \u001b[48;2;0;0;97m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtitle, \u001b[48;2;0;0;45m\u001b[38;2;255;255;255mauthors \u001b[48;2;0;0;81m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mpublish \u001b[48;2;78;0;0m\u001b[38;2;255;255;255myear \u001b[48;2;0;0;201m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;97m\u001b[38;2;255;255;255mthe \u001b[48;2;108;0;0m\u001b[38;2;255;255;255minput \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;81m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;215m\u001b[38;2;255;255;255mits \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreferences.\n",
            "92 0.0 0.945 0.013 \u001b[48;2;205;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;77;0;0m\u001b[38;2;255;255;255msegment \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mthe \u001b[48;2;222;0;0m\u001b[38;2;255;255;255minput \u001b[48;2;0;0;13m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;32m\u001b[38;2;255;255;255minto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtwo-level: \u001b[48;2;0;0;94m\u001b[38;2;255;255;255msection \u001b[48;2;0;0;1m\u001b[38;2;255;255;255mlevel \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mand \u001b[48;2;77;0;0m\u001b[38;2;255;255;255msentence \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mlevel.\n",
            "93 0.0 0.978 0.006 \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mSection \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mseg- \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mmentation \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mis \u001b[48;2;159;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mkeywords \u001b[48;2;0;0;212m\u001b[38;2;255;255;255mmatching \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mand \u001b[48;2;174;0;0m\u001b[38;2;255;255;255mclassified \u001b[48;2;0;0;64m\u001b[38;2;255;255;255minto \u001b[48;2;119;0;0m\u001b[38;2;255;255;255mthree \u001b[48;2;0;0;170m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1: \u001b[48;2;162;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;107;0;0m\u001b[38;2;255;255;255mlist \u001b[48;2;0;0;170m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2: \u001b[48;2;49;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;54;0;0m\u001b[38;2;255;255;255mclassifying \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mstandards \u001b[48;2;0;0;141m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPhocus.\n",
            "94 0.0 0.978 0.003 \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mDefinition \u001b[48;2;38;0;0m\u001b[38;2;255;255;255mRanges \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mLabel \u001b[48;2;0;0;56m\u001b[38;2;255;255;255mDescription \u001b[48;2;93;0;0m\u001b[38;2;255;255;255mZhang \u001b[48;2;121;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;231;0;0m\u001b[38;2;255;255;255mWen \u001b[48;2;0;0;212m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal.\n",
            "96 0.0 0.989 0.002 \u001b[48;2;260;0;0m\u001b[38;2;255;255;255mSentences \u001b[48;2;0;0;107m\u001b[38;2;255;255;255mare \u001b[48;2;122;0;0m\u001b[38;2;255;255;255msegmented \u001b[48;2;0;0;231m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mregular \u001b[48;2;24;0;0m\u001b[38;2;255;255;255mexpression \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mmatching \u001b[48;2;0;0;114m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;107m\u001b[38;2;255;255;255mare \u001b[48;2;88;0;0m\u001b[38;2;255;255;255mthen \u001b[48;2;135;0;0m\u001b[38;2;255;255;255mlabelled \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mby \u001b[48;2;5;0;0m\u001b[38;2;255;255;255mtheir \u001b[48;2;244;0;0m\u001b[38;2;255;255;255mID \u001b[48;2;43;0;0m\u001b[38;2;255;255;255maccording \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mto \u001b[48;2;5;0;0m\u001b[38;2;255;255;255mtheir \u001b[48;2;0;0;23m\u001b[38;2;255;255;255mappearing \u001b[48;2;0;0;0m\u001b[38;2;255;255;255morder.\n",
            "97 0.0 0.792 0.065 \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mReference \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mparsing \u001b[48;2;0;0;188m\u001b[38;2;255;255;255mgenerates \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtitle, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mauthors, \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mpublish \u001b[48;2;0;0;14m\u001b[38;2;255;255;255myear \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mand \u001b[48;2;80;0;0m\u001b[38;2;255;255;255meven \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mtheir \u001b[48;2;0;0;89m\u001b[38;2;255;255;255mcitation \u001b[48;2;39;0;0m\u001b[38;2;255;255;255mmarkers \u001b[48;2;0;0;185m\u001b[38;2;255;255;255min \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper.\n",
            "98 0.0 0.969 0.007 \u001b[48;2;95;0;0m\u001b[38;2;255;255;255mGiven \u001b[48;2;0;0;253m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minformation, \u001b[48;2;320;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mlocate \u001b[48;2;77;0;0m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;51m\u001b[38;2;255;255;255min \u001b[48;2;0;0;34m\u001b[38;2;255;255;255meach \u001b[48;2;0;0;48m\u001b[38;2;255;255;255msentence \u001b[48;2;21;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;44;0;0m\u001b[38;2;255;255;255mmatch \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mcitation \u001b[48;2;30;0;0m\u001b[38;2;255;255;255mmarkers \u001b[48;2;0;0;273m\u001b[38;2;255;255;255mwith \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mtheir \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mcorresponding \u001b[48;2;106;0;0m\u001b[38;2;255;255;255mreference \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpapers.\n",
            "99 1.0 0.714 0.214 \u001b[48;2;233;0;0m\u001b[38;2;255;255;255mThen \u001b[48;2;126;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;2;0;0m\u001b[38;2;255;255;255mcould \u001b[48;2;182;0;0m\u001b[38;2;255;255;255measily \u001b[48;2;183;0;0m\u001b[38;2;255;255;255mget \u001b[48;2;0;0;140m\u001b[38;2;255;255;255mthe \u001b[48;2;38;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mn_cit \u001b[48;2;0;0;82m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcit_text.\n",
            "100 0.0 0.993 0.002 \u001b[48;2;120;0;0m\u001b[38;2;255;255;255mFactor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mau_overlap \u001b[48;2;121;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;344;0;0m\u001b[38;2;255;255;255mcalculated \u001b[48;2;278;0;0m\u001b[38;2;255;255;255maccording \u001b[48;2;0;0;2m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mthe \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mfollowing \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mequation: \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘Žð‘¢_ð‘œð‘£ð‘’ð‘Ÿð‘™ð‘Žð‘ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m= \u001b[48;2;0;0;201m\u001b[38;2;255;255;255m2 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mÃ— \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´âˆ©ðµ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m|ð´ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m|+|ðµ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m| \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(1) \u001b[48;2;18;0;0m\u001b[38;2;255;255;255mwhere \u001b[48;2;0;0;121m\u001b[38;2;255;255;255mA \u001b[48;2;121;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mthe \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mauthor \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mset \u001b[48;2;0;0;183m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;45m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper, \u001b[48;2;105;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;39m\u001b[38;2;255;255;255mB \u001b[48;2;121;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mthe \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mauthor \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mset \u001b[48;2;0;0;183m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreference \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper.\n",
            "101 0.0 0.889 0.028 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m3.2 \u001b[48;2;0;0;177m\u001b[38;2;255;255;255mCalculating \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mfactors \u001b[48;2;0;0;121m\u001b[38;2;255;255;255mThere \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mare \u001b[48;2;309;0;0m\u001b[38;2;255;255;255mstill \u001b[48;2;0;0;124m\u001b[38;2;255;255;255mthree \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mfactors \u001b[48;2;0;0;0m\u001b[38;2;255;255;255munsolved: \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcontext_a, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcontext_b, \u001b[48;2;102;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msen_label.\n",
            "102 0.0 0.77 0.074 \u001b[48;2;215;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;0;0;41m\u001b[38;2;255;255;255mobtain \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcontext_a, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcontext_b \u001b[48;2;0;0;318m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBERT, \u001b[48;2;43;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;147m\u001b[38;2;255;255;255mpropose \u001b[48;2;0;0;170m\u001b[38;2;255;255;255ma \u001b[48;2;145;0;0m\u001b[38;2;255;255;255mnovel \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maspect-based \u001b[48;2;123;0;0m\u001b[38;2;255;255;255msentiment \u001b[48;2;0;0;153m\u001b[38;2;255;255;255manalysis \u001b[48;2;0;0;65m\u001b[38;2;255;255;255malgorithm \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;41m\u001b[38;2;255;255;255mclassify \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msentiment.\n",
            "103 0.0 0.683 0.102 \u001b[48;2;202;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfine-tune \u001b[48;2;50;0;0m\u001b[38;2;255;255;255mBERT \u001b[48;2;0;0;169m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;82m\u001b[38;2;255;255;255ma \u001b[48;2;91;0;0m\u001b[38;2;255;255;255mmanually \u001b[48;2;0;0;72m\u001b[38;2;255;255;255mannotated \u001b[48;2;368;0;0m\u001b[38;2;255;255;255mdataset \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcontain- \u001b[48;2;182;0;0m\u001b[38;2;255;255;255ming \u001b[48;2;137;0;0m\u001b[38;2;255;255;255mover \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1,000 \u001b[48;2;0;0;123m\u001b[38;2;255;255;255msentence \u001b[48;2;0;0;140m\u001b[38;2;255;255;255mpairs \u001b[48;2;5;0;0m\u001b[38;2;255;255;255mlabelled \u001b[48;2;0;0;298m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m\"related\" \u001b[48;2;0;0;122m\u001b[38;2;255;255;255mor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m\"irrelevant\".\n",
            "104 0.0 0.811 0.059 \u001b[48;2;0;0;114m\u001b[38;2;255;255;255mEach \u001b[48;2;0;0;12m\u001b[38;2;255;255;255msentence \u001b[48;2;42;0;0m\u001b[38;2;255;255;255mpair \u001b[48;2;0;0;202m\u001b[38;2;255;255;255mis \u001b[48;2;227;0;0m\u001b[38;2;255;255;255mgenerated \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;79m\u001b[38;2;255;255;255ma \u001b[48;2;26;0;0m\u001b[38;2;255;255;255msingle \u001b[48;2;140;0;0m\u001b[38;2;255;255;255macademic \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper.\n",
            "105 1.0 0.722 0.233 \u001b[48;2;302;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;2;0;0m\u001b[38;2;255;255;255mget \u001b[48;2;0;0;28m\u001b[38;2;255;255;255man \u001b[48;2;13;0;0m\u001b[38;2;255;255;255maccuracy \u001b[48;2;0;0;96m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m94.5% \u001b[48;2;0;0;208m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;95m\u001b[38;2;255;255;255mthe \u001b[48;2;132;0;0m\u001b[38;2;255;255;255mevaluation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdataset.\n",
            "106 0.0 0.987 0.001 \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mTo \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mob- \u001b[48;2;323;0;0m\u001b[38;2;255;255;255mtain \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mthe \u001b[48;2;106;0;0m\u001b[38;2;255;255;255mcontext \u001b[48;2;0;0;368m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcit_context, \u001b[48;2;130;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;0;80m\u001b[38;2;255;255;255mapply \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mthe \u001b[48;2;128;0;0m\u001b[38;2;255;255;255mabove \u001b[48;2;0;0;119m\u001b[38;2;255;255;255mclassifier \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mit- \u001b[48;2;0;0;126m\u001b[38;2;255;255;255meratively \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;66m\u001b[38;2;255;255;255msentence \u001b[48;2;0;0;104m\u001b[38;2;255;255;255mpair \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(ð‘† \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâˆ’ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘–], \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘† \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘]) \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(ð‘† \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrepresent- \u001b[48;2;207;0;0m\u001b[38;2;255;255;255ming \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mthe \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mlist \u001b[48;2;0;0;368m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;76m\u001b[38;2;255;255;255mall \u001b[48;2;0;0;135m\u001b[38;2;255;255;255msentences \u001b[48;2;0;0;200m\u001b[38;2;255;255;255min \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper) \u001b[48;2;71;0;0m\u001b[38;2;255;255;255mwhere \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mincreases \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1.\n",
            "107 0.0 0.99 0.0 \u001b[48;2;217;0;0m\u001b[38;2;255;255;255mOnce \u001b[48;2;0;0;155m\u001b[38;2;255;255;255man \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m\"irrelevant\" \u001b[48;2;0;0;80m\u001b[38;2;255;255;255mpair \u001b[48;2;0;0;218m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreported, \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mthe \u001b[48;2;15;0;0m\u001b[38;2;255;255;255miteration \u001b[48;2;0;0;218m\u001b[38;2;255;255;255mis \u001b[48;2;16;0;0m\u001b[38;2;255;255;255maborted \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;88;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;0;104m\u001b[38;2;255;255;255mtake \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘† \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâˆ’ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m: \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘] \u001b[48;2;0;0;200m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcontext_a.\n",
            "108 0.0 0.864 0.037 \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mAnother \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstop- \u001b[48;2;147;0;0m\u001b[38;2;255;255;255mping \u001b[48;2;0;0;150m\u001b[38;2;255;255;255mcriterion \u001b[48;2;0;0;81m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;85m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘† \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâˆ’ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘–] \u001b[48;2;93;0;0m\u001b[38;2;255;255;255mshould \u001b[48;2;252;0;0m\u001b[38;2;255;255;255malways \u001b[48;2;22;0;0m\u001b[38;2;255;255;255mbe \u001b[48;2;8;0;0m\u001b[38;2;255;255;255min \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;108m\u001b[38;2;255;255;255msame \u001b[48;2;0;0;41m\u001b[38;2;255;255;255mparagraph \u001b[48;2;0;0;246m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘† \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘].\n",
            "109 0.0 0.942 0.018 \u001b[48;2;0;0;183m\u001b[38;2;255;255;255mA \u001b[48;2;0;0;118m\u001b[38;2;255;255;255msimilar \u001b[48;2;0;0;202m\u001b[38;2;255;255;255mprocedure \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;56m\u001b[38;2;255;255;255mperformed \u001b[48;2;0;0;104m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(ð‘† \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m+ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘–], \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘† \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[ð‘ ð‘’ð‘›ð‘¡_ð‘–ð‘‘]) \u001b[48;2;0;0;48m\u001b[38;2;255;255;255mto \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mget \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcontext_b.\n",
            "110 1.0 0.52 0.173 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m3.3 \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mEvaluating \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mContribution \u001b[48;2;21;0;0m\u001b[38;2;255;255;255mAfter \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mgathering \u001b[48;2;2;0;0m\u001b[38;2;255;255;255mall \u001b[48;2;87;0;0m\u001b[38;2;255;255;255mneeded \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfactors, \u001b[48;2;190;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;102;0;0m\u001b[38;2;255;255;255mtrain \u001b[48;2;76;0;0m\u001b[38;2;255;255;255ma \u001b[48;2;113;0;0m\u001b[38;2;255;255;255mclassifier \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;40;0;0m\u001b[38;2;255;255;255mcategorize \u001b[48;2;0;0;274m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;293m\u001b[38;2;255;255;255minto \u001b[48;2;30;0;0m\u001b[38;2;255;255;255m4 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclasses: \u001b[48;2;0;0;68m\u001b[38;2;255;255;255mvery \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mimportant, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mimportant, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mneutral, \u001b[48;2;0;0;92m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mterrible.\n",
            "111 0.0 0.72 0.09 \u001b[48;2;175;0;0m\u001b[38;2;255;255;255mAnd \u001b[48;2;166;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;33;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;112;0;0m\u001b[38;2;255;255;255mtrain \u001b[48;2;0;0;11m\u001b[38;2;255;255;255ma \u001b[48;2;201;0;0m\u001b[38;2;255;255;255mranking \u001b[48;2;105;0;0m\u001b[38;2;255;255;255mmodel \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;101;0;0m\u001b[38;2;255;255;255mpredict \u001b[48;2;0;0;52m\u001b[38;2;255;255;255mthe \u001b[48;2;62;0;0m\u001b[38;2;255;255;255mrelated \u001b[48;2;0;0;44m\u001b[38;2;255;255;255morder \u001b[48;2;0;0;215m\u001b[38;2;255;255;255mof \u001b[48;2;134;0;0m\u001b[38;2;255;255;255mreferences \u001b[48;2;0;0;199m\u001b[38;2;255;255;255min \u001b[48;2;0;0;52m\u001b[38;2;255;255;255mterms \u001b[48;2;0;0;215m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;96m\u001b[38;2;255;255;255mtheir \u001b[48;2;0;0;59m\u001b[38;2;255;255;255mcontributions \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;52m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper.\n",
            "112 0.0 0.896 0.031 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFirst, \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mclassify \u001b[48;2;0;0;115m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;63m\u001b[38;2;255;255;255minto \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mfour \u001b[48;2;25;0;0m\u001b[38;2;255;255;255mcategories \u001b[48;2;0;0;187m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;162m\u001b[38;2;255;255;255ma \u001b[48;2;104;0;0m\u001b[38;2;255;255;255mNaive \u001b[48;2;341;0;0m\u001b[38;2;255;255;255mBayesian \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclassifier.\n",
            "113 1.0 0.753 0.245 \u001b[48;2;14;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mclassifying \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mstandards \u001b[48;2;0;0;188m\u001b[38;2;255;255;255mare \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mshown \u001b[48;2;0;0;112m\u001b[38;2;255;255;255min \u001b[48;2;68;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2, \u001b[48;2;48;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;39;0;0m\u001b[38;2;255;255;255ma \u001b[48;2;273;0;0m\u001b[38;2;255;255;255mlarger \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;207m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mlabels \u001b[48;2;20;0;0m\u001b[38;2;255;255;255mrepresents \u001b[48;2;174;0;0m\u001b[38;2;255;255;255mmore \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcontributions.\n",
            "114 0.0 0.666 0.108 \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;216;0;0m\u001b[38;2;255;255;255mranking \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mmodel \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mis \u001b[48;2;217;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;96m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mLambdaMART, \u001b[48;2;0;0;147m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mis \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mboosted \u001b[48;2;228;0;0m\u001b[38;2;255;255;255mtree \u001b[48;2;39;0;0m\u001b[38;2;255;255;255mversion \u001b[48;2;0;0;216m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mLambdaRank[5].\n",
            "115 0.0 0.58 0.125 \u001b[48;2;49;0;0m\u001b[38;2;255;255;255mThis \u001b[48;2;0;0;26m\u001b[38;2;255;255;255malgorithm \u001b[48;2;275;0;0m\u001b[38;2;255;255;255msolves \u001b[48;2;28;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mgradients \u001b[48;2;0;0;250m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mnon-smooth \u001b[48;2;103;0;0m\u001b[38;2;255;255;255mcost \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mfunctions \u001b[48;2;0;0;136m\u001b[38;2;255;255;255mused \u001b[48;2;0;0;174m\u001b[38;2;255;255;255min \u001b[48;2;243;0;0m\u001b[38;2;255;255;255mranking \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels.\n",
            "116 0.0 0.826 0.051 \u001b[48;2;0;0;22m\u001b[38;2;255;255;255mBurges \u001b[48;2;0;0;199m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[4] \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mgive \u001b[48;2;6;0;0m\u001b[38;2;255;255;255ma \u001b[48;2;50;0;0m\u001b[38;2;255;255;255mreview \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mRankNet, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mLambdaRank, \u001b[48;2;0;0;74m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mLamb- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdaMART.\n",
            "117 1.0 0.629 0.196 \u001b[48;2;231;0;0m\u001b[38;2;255;255;255mBased \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;220m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;74m\u001b[38;2;255;255;255mclasses \u001b[48;2;0;0;70m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;26m\u001b[38;2;255;255;255morder \u001b[48;2;0;0;270m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreferences, \u001b[48;2;159;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mproject \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mthem \u001b[48;2;0;0;54m\u001b[38;2;255;255;255minto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[0, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1] \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;175;0;0m\u001b[38;2;255;255;255mget \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mtheir \u001b[48;2;34;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfactors.\n",
            "118 0.0 0.925 0.024 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPhocus: \u001b[48;2;0;0;74m\u001b[38;2;255;255;255mPicking \u001b[48;2;14;0;0m\u001b[38;2;255;255;255mValuable \u001b[48;2;114;0;0m\u001b[38;2;255;255;255mResearch \u001b[48;2;0;0;33m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;8m\u001b[38;2;255;255;255ma \u001b[48;2;109;0;0m\u001b[38;2;255;255;255mSea \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mCitations \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m3.4 \u001b[48;2;312;0;0m\u001b[38;2;255;255;255mPropagating \u001b[48;2;0;0;73m\u001b[38;2;255;255;255minfluential \u001b[48;2;193;0;0m\u001b[38;2;255;255;255mfactors \u001b[48;2;250;0;0m\u001b[38;2;255;255;255mGiven \u001b[48;2;0;0;8m\u001b[38;2;255;255;255ma \u001b[48;2;124;0;0m\u001b[38;2;255;255;255mlist \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mreferences \u001b[48;2;75;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;168m\u001b[38;2;255;255;255mtheir \u001b[48;2;0;0;73m\u001b[38;2;255;255;255minfluential \u001b[48;2;193;0;0m\u001b[38;2;255;255;255mfactors \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mof \u001b[48;2;45;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;127m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper, \u001b[48;2;93;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;0;48m\u001b[38;2;255;255;255mdesign \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msome \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mrules \u001b[48;2;0;0;103m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mpropagate \u001b[48;2;0;0;168m\u001b[38;2;255;255;255mtheir \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minfluence.\n",
            "119 1.0 0.907 0.299 \u001b[48;2;0;0;85m\u001b[38;2;255;255;255mThe \u001b[48;2;112;0;0m\u001b[38;2;255;255;255mmain \u001b[48;2;0;0;55m\u001b[38;2;255;255;255midea \u001b[48;2;0;0;84m\u001b[38;2;255;255;255mis \u001b[48;2;181;0;0m\u001b[38;2;255;255;255mshown \u001b[48;2;0;0;125m\u001b[38;2;255;255;255min \u001b[48;2;186;0;0m\u001b[38;2;255;255;255mFigure \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m3.\n",
            "120 0.0 0.94 0.019 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´ \u001b[48;2;24;0;0m\u001b[38;2;255;255;255mdenote \u001b[48;2;0;0;53m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;181m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;298m\u001b[38;2;255;255;255mwith \u001b[48;2;197;0;0m\u001b[38;2;255;255;255macademic \u001b[48;2;147;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;141;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´ð¹ð´ \u001b[48;2;319;0;0m\u001b[38;2;255;255;255minitialized \u001b[48;2;108;0;0m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1, \u001b[48;2;58;0;0m\u001b[38;2;255;255;255mset \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘…ð´, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð¼ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð¹ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘™ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´ \u001b[48;2;24;0;0m\u001b[38;2;255;255;255mdenote \u001b[48;2;0;0;308m\u001b[38;2;255;255;255mall \u001b[48;2;27;0;0m\u001b[38;2;255;255;255mreferences \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´, \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mand \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mtheir \u001b[48;2;0;0;129m\u001b[38;2;255;255;255mcorresponding \u001b[48;2;0;0;88m\u001b[38;2;255;255;255mlocal \u001b[48;2;193;0;0m\u001b[38;2;255;255;255mcontribution \u001b[48;2;159;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´, \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð¼ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð¹ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘™ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´ð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâˆˆ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[âˆ’1, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1] \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;188;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;88m\u001b[38;2;255;255;255mlocal \u001b[48;2;193;0;0m\u001b[38;2;255;255;255mcontribution \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;380m\u001b[38;2;255;255;255mreference \u001b[48;2;131;0;0m\u001b[38;2;255;255;255mi \u001b[48;2;159;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð¶ð´ \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;188;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;58;0;0m\u001b[38;2;255;255;255mset \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;308m\u001b[38;2;255;255;255mall \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mpapers \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mcite \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´, \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘— \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâˆˆ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð¶ð´, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð¼ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð¹ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘™ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘—ð´ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâˆˆ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[âˆ’1, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1] \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAâ€™s \u001b[48;2;0;0;88m\u001b[38;2;255;255;255mlocal \u001b[48;2;193;0;0m\u001b[38;2;255;255;255mcontribution \u001b[48;2;159;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘—.\n",
            "121 0.0 0.533 0.154 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mThen, \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;47;0;0m\u001b[38;2;255;255;255macademic \u001b[48;2;138;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;0;0;1m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mis: \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´ð¹ð´ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m= \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâˆ‘ï¸ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´ð¹ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘— \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð¼ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð¹ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘™ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘—ð´ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(2) \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘— \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâˆˆð¶ð´ \u001b[48;2;58;0;0m\u001b[38;2;255;255;255mFor \u001b[48;2;0;0;88m\u001b[38;2;255;255;255mauthor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘Ž \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mwho \u001b[48;2;137;0;0m\u001b[38;2;255;255;255mpublishes \u001b[48;2;0;0;45m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mset \u001b[48;2;0;0;1m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;253m\u001b[38;2;255;255;255mpapers \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘ƒð‘Ž, \u001b[48;2;92;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;154m\u001b[38;2;255;255;255mhis \u001b[48;2;0;0;109m\u001b[38;2;255;255;255mcontribution \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâˆˆ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘ƒð‘Ž \u001b[48;2;94;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð¶ð‘–ð‘Ž \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâˆˆ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[0, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1], \u001b[48;2;0;0;154m\u001b[38;2;255;255;255mhis \u001b[48;2;47;0;0m\u001b[38;2;255;255;255macademic \u001b[48;2;138;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mis: \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâˆ‘ï¸ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´ð¹ð‘Ž \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m= \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð¶ð‘–ð‘Žð´ð¹ð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(3) \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâˆˆð‘ƒð‘Ž \u001b[48;2;58;0;0m\u001b[38;2;255;255;255mFor \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´, \u001b[48;2;92;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mits \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mauthors, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(cid:205)ð‘ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð¶ð´ð‘– \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâ‰¡ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1.\n",
            "122 0.0 0.349 -0.009 \u001b[48;2;0;0;119m\u001b[38;2;255;255;255mThere \u001b[48;2;0;0;159m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mtwo \u001b[48;2;5;0;0m\u001b[38;2;255;255;255mproblems \u001b[48;2;43;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;92;0;0m\u001b[38;2;255;255;255mprove \u001b[48;2;43;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mensure \u001b[48;2;0;0;161m\u001b[38;2;255;255;255mthat \u001b[48;2;39;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mmethod \u001b[48;2;0;0;151m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mlogical.\n",
            "123 1.0 0.733 0.237 \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;212;0;0m\u001b[38;2;255;255;255mfirst \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mone \u001b[48;2;0;0;14m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;201m\u001b[38;2;255;255;255mmargin \u001b[48;2;0;0;0m\u001b[38;2;255;255;255meffects.\n",
            "124 0.0 0.833 0.044 \u001b[48;2;213;0;0m\u001b[38;2;255;255;255mAnd \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mthe \u001b[48;2;39;0;0m\u001b[38;2;255;255;255msecond \u001b[48;2;0;0;202m\u001b[38;2;255;255;255mone \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mthe \u001b[48;2;101;0;0m\u001b[38;2;255;255;255mpropagation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrules.\n",
            "125 0.0 0.818 0.058 \u001b[48;2;0;0;110m\u001b[38;2;255;255;255m4 \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mexperiments \u001b[48;2;64;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;0;0;283m\u001b[38;2;255;255;255mconduct \u001b[48;2;0;0;73m\u001b[38;2;255;255;255mseveral \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mexperiments \u001b[48;2;0;0;150m\u001b[38;2;255;255;255mto \u001b[48;2;30;0;0m\u001b[38;2;255;255;255mdemonstrate \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;156;0;0m\u001b[38;2;255;255;255mnew \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mmetrics \u001b[48;2;0;0;260m\u001b[38;2;255;255;255mthat \u001b[48;2;158;0;0m\u001b[38;2;255;255;255mmeasure \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mthe \u001b[48;2;172;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;265;0;0m\u001b[38;2;255;255;255mfactors \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;31m\u001b[38;2;255;255;255man \u001b[48;2;158;0;0m\u001b[38;2;255;255;255mindividual \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mscientist \u001b[48;2;16;0;0m\u001b[38;2;255;255;255mor \u001b[48;2;98;0;0m\u001b[38;2;255;255;255mscholar \u001b[48;2;99;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mthe \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;73;0;0m\u001b[38;2;255;255;255mimpact \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpublications.\n",
            "126 0.0 0.597 0.132 \u001b[48;2;23;0;0m\u001b[38;2;255;255;255mAs \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mthe \u001b[48;2;141;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;231;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;0;0;252m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;81m\u001b[38;2;255;255;255ma \u001b[48;2;38;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mthe \u001b[48;2;345;0;0m\u001b[38;2;255;255;255mweighted \u001b[48;2;92;0;0m\u001b[38;2;255;255;255msum \u001b[48;2;0;0;252m\u001b[38;2;255;255;255mof \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mall \u001b[48;2;23;0;0m\u001b[38;2;255;255;255mpapers \u001b[48;2;0;0;43m\u001b[38;2;255;255;255mthat \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mcite \u001b[48;2;0;0;68m\u001b[38;2;255;255;255mit \u001b[48;2;0;0;56m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;185m\u001b[38;2;255;255;255mits \u001b[48;2;0;0;58m\u001b[38;2;255;255;255mcorresponding \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mcontribution \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mthem, \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mthe \u001b[48;2;206;0;0m\u001b[38;2;255;255;255mfinal \u001b[48;2;0;0;56m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;161m\u001b[38;2;255;255;255mfull \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mnetwork \u001b[48;2;0;0;252m\u001b[38;2;255;255;255mof \u001b[48;2;38;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;56m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mnetwork \u001b[48;2;67;0;0m\u001b[38;2;255;255;255mshould \u001b[48;2;0;0;174m\u001b[38;2;255;255;255mbe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mconstructed.\n",
            "127 -1.0 0.917 -0.297 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHowever, \u001b[48;2;86;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;106;0;0m\u001b[38;2;255;255;255mcannot \u001b[48;2;0;0;245m\u001b[38;2;255;255;255mcomplete \u001b[48;2;0;0;74m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mjob \u001b[48;2;90;0;0m\u001b[38;2;255;255;255myet \u001b[48;2;0;0;20m\u001b[38;2;255;255;255mout \u001b[48;2;0;0;207m\u001b[38;2;255;255;255mof \u001b[48;2;64;0;0m\u001b[38;2;255;255;255mno \u001b[48;2;0;0;114m\u001b[38;2;255;255;255maccess \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;49m\u001b[38;2;255;255;255msome \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdatabases, \u001b[48;2;215;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;0;0;156m\u001b[38;2;255;255;255menough \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mtime \u001b[48;2;185;0;0m\u001b[38;2;255;255;255mor \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mcomputational \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mresources.\n",
            "128 0.0 0.773 0.066 \u001b[48;2;263;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;209;0;0m\u001b[38;2;255;255;255mwill \u001b[48;2;117;0;0m\u001b[38;2;255;255;255mselect \u001b[48;2;3;0;0m\u001b[38;2;255;255;255msome \u001b[48;2;85;0;0m\u001b[38;2;255;255;255mscholars \u001b[48;2;0;0;133m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mtheir \u001b[48;2;24;0;0m\u001b[38;2;255;255;255mpublications \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtargets, \u001b[48;2;0;0;133m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;205m\u001b[38;2;255;255;255mutilize \u001b[48;2;158;0;0m\u001b[38;2;255;255;255mprimary \u001b[48;2;0;0;94m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;133m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;13m\u001b[38;2;255;255;255msecondary \u001b[48;2;0;0;94m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrelationships.\n",
            "129 1.0 0.915 0.303 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBesides, \u001b[48;2;148;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;80;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mcompare \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;0;0;44m\u001b[38;2;255;255;255mmodules \u001b[48;2;0;0;156m\u001b[38;2;255;255;255mto \u001b[48;2;50;0;0m\u001b[38;2;255;255;255mother \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstate-of-art \u001b[48;2;0;0;245m\u001b[38;2;255;255;255malgorithms \u001b[48;2;0;0;156m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;9m\u001b[38;2;255;255;255mshow \u001b[48;2;0;0;156m\u001b[38;2;255;255;255mthe \u001b[48;2;85;0;0m\u001b[38;2;255;255;255mimprovement \u001b[48;2;148;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255machieve.\n",
            "130 0.0 0.719 0.088 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m4.1 \u001b[48;2;112;0;0m\u001b[38;2;255;255;255mPeer \u001b[48;2;84;0;0m\u001b[38;2;255;255;255mComparison \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mScholar \u001b[48;2;0;0;90m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;243m\u001b[38;2;255;255;255mtheir \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpublications.\n",
            "131 0.0 0.72 0.075 \u001b[48;2;91;0;0m\u001b[38;2;255;255;255mLet \u001b[48;2;64;0;0m\u001b[38;2;255;255;255mScholar \u001b[48;2;183;0;0m\u001b[38;2;255;255;255mY \u001b[48;2;0;0;43m\u001b[38;2;255;255;255mdenote \u001b[48;2;0;0;94m\u001b[38;2;255;255;255msome \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mscholar.\n",
            "132 1.0 0.769 0.226 \u001b[48;2;155;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;68;0;0m\u001b[38;2;255;255;255mwill \u001b[48;2;176;0;0m\u001b[38;2;255;255;255mshow \u001b[48;2;0;0;195m\u001b[38;2;255;255;255mthe \u001b[48;2;166;0;0m\u001b[38;2;255;255;255mdifference \u001b[48;2;0;0;10m\u001b[38;2;255;255;255mbetween \u001b[48;2;0;0;65m\u001b[38;2;255;255;255mScholar \u001b[48;2;25;0;0m\u001b[38;2;255;255;255mY \u001b[48;2;0;0;125m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;195m\u001b[38;2;255;255;255mthe \u001b[48;2;105;0;0m\u001b[38;2;255;255;255mTuring \u001b[48;2;0;0;52m\u001b[38;2;255;255;255mAward \u001b[48;2;0;0;185m\u001b[38;2;255;255;255mwinner \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPat.\n",
            "133 0.0 0.688 0.022 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHanrahan9.\n",
            "134 -1.0 0.437 -0.011 \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mAs \u001b[48;2;0;0;205m\u001b[38;2;255;255;255mwe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255memphasize, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPat.\n",
            "135 1.0 0.699 0.152 \u001b[48;2;293;0;0m\u001b[38;2;255;255;255mHanrahan \u001b[48;2;0;0;177m\u001b[38;2;255;255;255mis \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mmuch \u001b[48;2;86;0;0m\u001b[38;2;255;255;255mmore \u001b[48;2;48;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;0;0;92m\u001b[38;2;255;255;255mthan \u001b[48;2;0;0;68m\u001b[38;2;255;255;255mscholar \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mY \u001b[48;2;0;0;177m\u001b[38;2;255;255;255mis \u001b[48;2;273;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;172;0;0m\u001b[38;2;255;255;255monly \u001b[48;2;0;0;77m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;287m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mhe \u001b[48;2;20;0;0m\u001b[38;2;255;255;255mwins \u001b[48;2;157;0;0m\u001b[38;2;255;255;255mTuring \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAward, \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mbut \u001b[48;2;0;0;136m\u001b[38;2;255;255;255malso \u001b[48;2;0;0;177m\u001b[38;2;255;255;255mis \u001b[48;2;106;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;141m\u001b[38;2;255;255;255mon \u001b[48;2;84;0;0m\u001b[38;2;255;255;255msolid \u001b[48;2;35;0;0m\u001b[38;2;255;255;255mstatistics \u001b[48;2;0;0;265m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations.\n",
            "136 0.0 0.607 0.102 \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mFor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mexample, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHe \u001b[48;2;0;0;122m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[16] \u001b[48;2;0;0;82m\u001b[38;2;255;255;255mtake \u001b[48;2;0;0;272m\u001b[38;2;255;255;255mone \u001b[48;2;49;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;251m\u001b[38;2;255;255;255mof \u001b[48;2;116;0;0m\u001b[38;2;255;255;255mscholar \u001b[48;2;184;0;0m\u001b[38;2;255;255;255mY \u001b[48;2;0;0;49m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;22m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mbase- \u001b[48;2;154;0;0m\u001b[38;2;255;255;255mline \u001b[48;2;0;0;120m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;142m\u001b[38;2;255;255;255mperforms \u001b[48;2;40;0;0m\u001b[38;2;255;255;255monly \u001b[48;2;0;0;23m\u001b[38;2;255;255;255mbetter \u001b[48;2;50;0;0m\u001b[38;2;255;255;255mthan \u001b[48;2;0;0;272m\u001b[38;2;255;255;255mone \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mbaseline \u001b[48;2;0;0;79m\u001b[38;2;255;255;255mamong \u001b[48;2;0;0;0m\u001b[38;2;255;255;255meleven.\n",
            "137 0.0 0.509 0.159 \u001b[48;2;240;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;76m\u001b[38;2;255;255;255m4 \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mshows \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mevaluation \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;120m\u001b[38;2;255;255;255mof \u001b[48;2;237;0;0m\u001b[38;2;255;255;255mscholar \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mY \u001b[48;2;0;0;48m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPat.\n",
            "138 0.0 0.833 0.054 \u001b[48;2;537;0;0m\u001b[38;2;255;255;255mHanrahan \u001b[48;2;0;0;175m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAminer10, \u001b[48;2;14;0;0m\u001b[38;2;255;255;255mGoogle \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mScholar11, \u001b[48;2;0;0;89m\u001b[38;2;255;255;255mSemantic \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mScholar12 \u001b[48;2;0;0;2m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPhocus.\n",
            "139 0.0 0.685 0.095 \u001b[48;2;185;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;42m\u001b[38;2;255;255;255m3 \u001b[48;2;204;0;0m\u001b[38;2;255;255;255mlists \u001b[48;2;90;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;18m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;216m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mpublications \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;213m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;216m\u001b[38;2;255;255;255mof \u001b[48;2;138;0;0m\u001b[38;2;255;255;255mscholar \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mY \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPat.\n",
            "140 0.0 0.671 0.065 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHanrahan.\n",
            "141 1.0 0.792 0.211 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mItâ€™s \u001b[48;2;0;0;87m\u001b[38;2;255;255;255mobviously \u001b[48;2;0;0;269m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;135m\u001b[38;2;255;255;255mscholar \u001b[48;2;95;0;0m\u001b[38;2;255;255;255mY \u001b[48;2;0;0;30m\u001b[38;2;255;255;255mis \u001b[48;2;38;0;0m\u001b[38;2;255;255;255mmore \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mproduc- \u001b[48;2;303;0;0m\u001b[38;2;255;255;255mtive \u001b[48;2;0;0;107m\u001b[38;2;255;255;255mthan \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPat.\n",
            "142 0.0 0.671 0.065 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHanrahan.\n",
            "144 1.0 0.9 0.272 \u001b[48;2;163;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;205;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;96m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;76m\u001b[38;2;255;255;255mhighly \u001b[48;2;0;0;149m\u001b[38;2;255;255;255minfluential \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations.\n",
            "145 1.0 0.718 0.239 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mH-index, \u001b[48;2;0;0;31m\u001b[38;2;255;255;255malso \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mcalled \u001b[48;2;189;0;0m\u001b[38;2;255;255;255mindex \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâ„Ž, \u001b[48;2;0;0;214m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;95m\u001b[38;2;255;255;255mproposed \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mby \u001b[48;2;115;0;0m\u001b[38;2;255;255;255mJorge \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mE.\n",
            "146 0.0 0.901 0.018 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHirsch[17], \u001b[48;2;0;0;87m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;237m\u001b[38;2;255;255;255mits \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mdefinition \u001b[48;2;20;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;71;0;0m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;124m\u001b[38;2;255;255;255mof \u001b[48;2;120;0;0m\u001b[38;2;255;255;255mpapers \u001b[48;2;0;0;251m\u001b[38;2;255;255;255mwith \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;71;0;0m\u001b[38;2;255;255;255mnumber \u001b[48;2;246;0;0m\u001b[38;2;255;255;255mhigher \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mor \u001b[48;2;91;0;0m\u001b[38;2;255;255;255mequal \u001b[48;2;103;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâ„Ž \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m.\n",
            "147 1.0 0.467 0.133 \u001b[48;2;0;0;244m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mg-index \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mis \u001b[48;2;227;0;0m\u001b[38;2;255;255;255mdefined \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;244m\u001b[38;2;255;255;255mthe \u001b[48;2;217;0;0m\u001b[38;2;255;255;255mlargest \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mnumber \u001b[48;2;38;0;0m\u001b[38;2;255;255;255msuch \u001b[48;2;0;0;175m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;244m\u001b[38;2;255;255;255mthe \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mtop \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘” \u001b[48;2;0;0;99m\u001b[38;2;255;255;255marticles \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreceived \u001b[48;2;206;0;0m\u001b[38;2;255;255;255mtogether \u001b[48;2;0;0;205m\u001b[38;2;255;255;255mat \u001b[48;2;90;0;0m\u001b[38;2;255;255;255mleast \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð‘”2 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations[12].\n",
            "148 1.0 0.589 0.183 \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mGoogle \u001b[48;2;0;0;31m\u001b[38;2;255;255;255mScholar \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mproposes \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mi10-index \u001b[48;2;0;0;185m\u001b[38;2;255;255;255mthat \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;40;0;0m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;217m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;138m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;68m\u001b[38;2;255;255;255mpublication \u001b[48;2;0;0;232m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mat \u001b[48;2;158;0;0m\u001b[38;2;255;255;255mleast \u001b[48;2;76;0;0m\u001b[38;2;255;255;255m10 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcita- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtions.\n",
            "149 -1.0 0.597 -0.192 \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mThose \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mmetrics \u001b[48;2;0;0;189m\u001b[38;2;255;255;255mare \u001b[48;2;276;0;0m\u001b[38;2;255;255;255mderived \u001b[48;2;0;0;127m\u001b[38;2;255;255;255mfrom \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mcitations \u001b[48;2;8;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;55;0;0m\u001b[38;2;255;255;255mdo \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mreveal \u001b[48;2;0;0;233m\u001b[38;2;255;255;255mthe \u001b[48;2;37;0;0m\u001b[38;2;255;255;255mtruth \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mamong \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations.\n",
            "150 1.0 0.934 0.303 \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mSemantic \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mScholar \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mmakes \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mthe \u001b[48;2;7;0;0m\u001b[38;2;255;255;255mfirst \u001b[48;2;0;0;322m\u001b[38;2;255;255;255mstep \u001b[48;2;28;0;0m\u001b[38;2;255;255;255mtowards \u001b[48;2;94;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclassification.\n",
            "151 0.0 0.75 0.082 \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mIt \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mdivided \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;2m\u001b[38;2;255;255;255minto \u001b[48;2;206;0;0m\u001b[38;2;255;255;255m4 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclasses: \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mhighly \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minfluential, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mbackground, \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mmethod \u001b[48;2;43;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;90;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations[35], \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mus- \u001b[48;2;270;0;0m\u001b[38;2;255;255;255ming \u001b[48;2;148;0;0m\u001b[38;2;255;255;255mSVM \u001b[48;2;0;0;399m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;223m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mRBF \u001b[48;2;7;0;0m\u001b[38;2;255;255;255mkernel \u001b[48;2;43;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;16;0;0m\u001b[38;2;255;255;255mrandom \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mforests.\n",
            "152 0.0 0.94 0.012 \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;67m\u001b[38;2;255;255;255mfeatures \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mSeman- \u001b[48;2;411;0;0m\u001b[38;2;255;255;255mtic \u001b[48;2;118;0;0m\u001b[38;2;255;255;255mScholar \u001b[48;2;0;0;66m\u001b[38;2;255;255;255muse \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mtotal \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;231m\u001b[38;2;255;255;255mof \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mdirect \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations, \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;231m\u001b[38;2;255;255;255mof \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mdirect \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mcitations \u001b[48;2;51;0;0m\u001b[38;2;255;255;255mper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msection, \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mtotal \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;231m\u001b[38;2;255;255;255mof \u001b[48;2;37;0;0m\u001b[38;2;255;255;255mindirect \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;110m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;231m\u001b[38;2;255;255;255mof \u001b[48;2;37;0;0m\u001b[38;2;255;255;255mindirect \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mcitations \u001b[48;2;51;0;0m\u001b[38;2;255;255;255mper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msection, \u001b[48;2;56;0;0m\u001b[38;2;255;255;255mauthor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255moverlap, \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;173;0;0m\u001b[38;2;255;255;255mconsidered \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhelp- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mful, \u001b[48;2;0;0;42m\u001b[38;2;255;255;255mcitation \u001b[48;2;98;0;0m\u001b[38;2;255;255;255mappears \u001b[48;2;0;0;147m\u001b[38;2;255;255;255min \u001b[48;2;84;0;0m\u001b[38;2;255;255;255mtable \u001b[48;2;0;0;110m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcaption, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1/number \u001b[48;2;0;0;231m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreferences, \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;231m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations/all \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations, \u001b[48;2;11;0;0m\u001b[38;2;255;255;255msimilarity \u001b[48;2;33;0;0m\u001b[38;2;255;255;255mbetween \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mabstracts, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPageRank[28], \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mnumber \u001b[48;2;0;0;231m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mtotal \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;97m\u001b[38;2;255;255;255mpapers \u001b[48;2;19;0;0m\u001b[38;2;255;255;255mafter \u001b[48;2;0;0;318m\u001b[38;2;255;255;255mtransitive \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclosure, \u001b[48;2;0;0;110m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mfield \u001b[48;2;0;0;231m\u001b[38;2;255;255;255mof \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcited \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper.\n",
            "153 0.0 0.932 0.014 \u001b[48;2;360;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mcollect \u001b[48;2;51;0;0m\u001b[38;2;255;255;255mXX \u001b[48;2;0;0;84m\u001b[38;2;255;255;255mpapers \u001b[48;2;0;0;141m\u001b[38;2;255;255;255mthat \u001b[48;2;42;0;0m\u001b[38;2;255;255;255mcite \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mscholar \u001b[48;2;149;0;0m\u001b[38;2;255;255;255mY \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m78663, \u001b[48;2;156;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;51;0;0m\u001b[38;2;255;255;255mXX \u001b[48;2;0;0;84m\u001b[38;2;255;255;255mpapers \u001b[48;2;0;0;141m\u001b[38;2;255;255;255mthat \u001b[48;2;42;0;0m\u001b[38;2;255;255;255mcite \u001b[48;2;0;0;10m\u001b[38;2;255;255;255mPatrick \u001b[48;2;194;0;0m\u001b[38;2;255;255;255mHanrahan \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m56383.\n",
            "154 1.0 0.428 0.069 \u001b[48;2;38;0;0m\u001b[38;2;255;255;255mOnly \u001b[48;2;0;0;257m\u001b[38;2;255;255;255mutilizing \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mprimary \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations, \u001b[48;2;185;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;116;0;0m\u001b[38;2;255;255;255mget \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mthe \u001b[48;2;67;0;0m\u001b[38;2;255;255;255mglobal \u001b[48;2;57;0;0m\u001b[38;2;255;255;255macademic \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minflu- \u001b[48;2;197;0;0m\u001b[38;2;255;255;255mential \u001b[48;2;23;0;0m\u001b[38;2;255;255;255mfactors \u001b[48;2;0;0;224m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;2m\u001b[38;2;255;255;255mscholar \u001b[48;2;0;0;20m\u001b[38;2;255;255;255mY \u001b[48;2;86;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mPatrick \u001b[48;2;124;0;0m\u001b[38;2;255;255;255mHanrahan \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0.40 \u001b[48;2;86;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0.52 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrespectively.\n",
            "155 0.0 0.756 0.078 \u001b[48;2;178;0;0m\u001b[38;2;255;255;255mFigure \u001b[48;2;0;0;210m\u001b[38;2;255;255;255m4 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m4.2 \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mMathematical \u001b[48;2;245;0;0m\u001b[38;2;255;255;255mInvariance \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;24;0;0m\u001b[38;2;255;255;255mverify \u001b[48;2;0;0;121m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodel, \u001b[48;2;228;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mconduct \u001b[48;2;0;0;76m\u001b[38;2;255;255;255ma \u001b[48;2;112;0;0m\u001b[38;2;255;255;255mseries \u001b[48;2;0;0;266m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mexperiments \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;100;0;0m\u001b[38;2;255;255;255mprove \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mitâ€™s \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreasonable.\n",
            "156 0.0 0.977 0.004 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFirst, \u001b[48;2;80;0;0m\u001b[38;2;255;255;255mgiven \u001b[48;2;0;0;129m\u001b[38;2;255;255;255ma \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mset \u001b[48;2;0;0;296m\u001b[38;2;255;255;255mof \u001b[48;2;5;0;0m\u001b[38;2;255;255;255mreferences \u001b[48;2;0;0;97m\u001b[38;2;255;255;255mwithin \u001b[48;2;0;0;129m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper, \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mremoving \u001b[48;2;17;0;0m\u001b[38;2;255;255;255manyone \u001b[48;2;71;0;0m\u001b[38;2;255;255;255mreference \u001b[48;2;0;0;138m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mthe \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mset \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwonâ€™t \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mchange \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mthe \u001b[48;2;120;0;0m\u001b[38;2;255;255;255mrelated \u001b[48;2;0;0;110m\u001b[38;2;255;255;255morder \u001b[48;2;0;0;296m\u001b[38;2;255;255;255mof \u001b[48;2;119;0;0m\u001b[38;2;255;255;255mleft \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrefer- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mences.\n",
            "157 0.0 0.946 0.011 \u001b[48;2;64;0;0m\u001b[38;2;255;255;255mAnd \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mwhen \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mremoving \u001b[48;2;0;0;66m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mreference \u001b[48;2;0;0;147m\u001b[38;2;255;255;255mat \u001b[48;2;0;0;66m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtime, \u001b[48;2;164;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;89;0;0m\u001b[38;2;255;255;255mleft \u001b[48;2;121;0;0m\u001b[38;2;255;255;255mreferences \u001b[48;2;132;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;99;0;0m\u001b[38;2;255;255;255mkeep \u001b[48;2;49;0;0m\u001b[38;2;255;255;255mrelated \u001b[48;2;0;0;0m\u001b[38;2;255;255;255morders.\n",
            "158 0.0 0.854 0.045 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;147;0;0m\u001b[38;2;255;255;255mZhang \u001b[48;2;67;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;50;0;0m\u001b[38;2;255;255;255mWen \u001b[48;2;0;0;225m\u001b[38;2;255;255;255met \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mal.\n",
            "159 0.0 0.97 0.008 \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m5: \u001b[48;2;0;0;230m\u001b[38;2;255;255;255mfeatures \u001b[48;2;0;0;232m\u001b[38;2;255;255;255mused \u001b[48;2;0;0;142m\u001b[38;2;255;255;255mfor \u001b[48;2;2;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mspan \u001b[48;2;0;0;134m\u001b[38;2;255;255;255mFeature \u001b[48;2;0;0;39m\u001b[38;2;255;255;255mDescription \u001b[48;2;140;0;0m\u001b[38;2;255;255;255mdistance \u001b[48;2;22;0;0m\u001b[38;2;255;255;255mposition \u001b[48;2;118;0;0m\u001b[38;2;255;255;255msegment \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mthe \u001b[48;2;140;0;0m\u001b[38;2;255;255;255mdistance \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(in \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwords) \u001b[48;2;129;0;0m\u001b[38;2;255;255;255mbetween \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mthe \u001b[48;2;221;0;0m\u001b[38;2;255;255;255mword \u001b[48;2;73;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mthe \u001b[48;2;143;0;0m\u001b[38;2;255;255;255mtarget \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitaion.\n",
            "160 0.0 0.93 0.017 \u001b[48;2;0;0;200m\u001b[38;2;255;255;255mThis \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mfeature \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mtakes \u001b[48;2;0;0;70m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;59m\u001b[38;2;255;255;255mvalue \u001b[48;2;0;0;68m\u001b[38;2;255;255;255m1 \u001b[48;2;40;0;0m\u001b[38;2;255;255;255mif \u001b[48;2;0;0;70m\u001b[38;2;255;255;255mthe \u001b[48;2;236;0;0m\u001b[38;2;255;255;255mword \u001b[48;2;0;0;42m\u001b[38;2;255;255;255mcomes \u001b[48;2;265;0;0m\u001b[38;2;255;255;255mbefore \u001b[48;2;0;0;70m\u001b[38;2;255;255;255mthe \u001b[48;2;188;0;0m\u001b[38;2;255;255;255mtarget \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitation, \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;47;0;0m\u001b[38;2;255;255;255m0 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255motherwise.\n",
            "161 0.0 0.993 0.0 \u001b[48;2;59;0;0m\u001b[38;2;255;255;255mAfter \u001b[48;2;37;0;0m\u001b[38;2;255;255;255msplitting \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mthe \u001b[48;2;171;0;0m\u001b[38;2;255;255;255msentence \u001b[48;2;10;0;0m\u001b[38;2;255;255;255minto \u001b[48;2;301;0;0m\u001b[38;2;255;255;255msegments \u001b[48;2;0;0;101m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;155m\u001b[38;2;255;255;255mpunctuation \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;211m\u001b[38;2;255;255;255mcoordination \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mconjunctions, \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;182;0;0m\u001b[38;2;255;255;255mfeature \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mtakes \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mthe \u001b[48;2;101;0;0m\u001b[38;2;255;255;255mvalue \u001b[48;2;70;0;0m\u001b[38;2;255;255;255m1 \u001b[48;2;112;0;0m\u001b[38;2;255;255;255mif \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mthe \u001b[48;2;181;0;0m\u001b[38;2;255;255;255mword \u001b[48;2;0;0;40m\u001b[38;2;255;255;255moccurs \u001b[48;2;0;0;138m\u001b[38;2;255;255;255min \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mthe \u001b[48;2;58;0;0m\u001b[38;2;255;255;255msame \u001b[48;2;108;0;0m\u001b[38;2;255;255;255msegment \u001b[48;2;0;0;206m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mthe \u001b[48;2;216;0;0m\u001b[38;2;255;255;255mtarget \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreference, \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mand \u001b[48;2;28;0;0m\u001b[38;2;255;255;255m0 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255motherwise.\n",
            "162 0.0 0.968 0.008 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpos_tag \u001b[48;2;0;0;213m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mpart \u001b[48;2;0;0;150m\u001b[38;2;255;255;255mof \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mspeech \u001b[48;2;121;0;0m\u001b[38;2;255;255;255mtag \u001b[48;2;0;0;150m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;213m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mword, \u001b[48;2;0;0;213m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mword \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mbefore, \u001b[48;2;122;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;213m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mword \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mafter.\n",
            "163 0.0 0.956 0.002 \u001b[48;2;0;0;179m\u001b[38;2;255;255;255mdTreeDistance \u001b[48;2;124;0;0m\u001b[38;2;255;255;255mLength \u001b[48;2;0;0;103m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mshortest \u001b[48;2;182;0;0m\u001b[38;2;255;255;255mdependency \u001b[48;2;0;0;22m\u001b[38;2;255;255;255mpath \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(in \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mthe \u001b[48;2;182;0;0m\u001b[38;2;255;255;255mdependency \u001b[48;2;154;0;0m\u001b[38;2;255;255;255mparse \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtree) \u001b[48;2;0;0;204m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;96m\u001b[38;2;255;255;255mconnects \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mthe \u001b[48;2;295;0;0m\u001b[38;2;255;255;255mword \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mthe \u001b[48;2;177;0;0m\u001b[38;2;255;255;255mtarget \u001b[48;2;0;0;1m\u001b[38;2;255;255;255mreference \u001b[48;2;62;0;0m\u001b[38;2;255;255;255mor \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mits \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrepresentative.\n",
            "164 0.0 0.943 0.015 \u001b[48;2;0;0;97m\u001b[38;2;255;255;255mlca \u001b[48;2;0;0;235m\u001b[38;2;255;255;255mthe \u001b[48;2;114;0;0m\u001b[38;2;255;255;255mtype \u001b[48;2;0;0;232m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;235m\u001b[38;2;255;255;255mthe \u001b[48;2;194;0;0m\u001b[38;2;255;255;255mnode \u001b[48;2;0;0;63m\u001b[38;2;255;255;255min \u001b[48;2;0;0;235m\u001b[38;2;255;255;255mthe \u001b[48;2;193;0;0m\u001b[38;2;255;255;255mdependency \u001b[48;2;263;0;0m\u001b[38;2;255;255;255mparse \u001b[48;2;159;0;0m\u001b[38;2;255;255;255mtree \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;235m\u001b[38;2;255;255;255mthe \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mleast \u001b[48;2;0;0;42m\u001b[38;2;255;255;255mcommon \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mancestor \u001b[48;2;0;0;232m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;235m\u001b[38;2;255;255;255mthe \u001b[48;2;220;0;0m\u001b[38;2;255;255;255mword \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;235m\u001b[38;2;255;255;255mthe \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mtarget \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreference.\n",
            "165 0.0 0.765 0.061 \u001b[48;2;195;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m6: \u001b[48;2;70;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mfor \u001b[48;2;102;0;0m\u001b[38;2;255;255;255mthree \u001b[48;2;243;0;0m\u001b[38;2;255;255;255mdifferent \u001b[48;2;124;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mcitation \u001b[48;2;22;0;0m\u001b[38;2;255;255;255mspan \u001b[48;2;22;0;0m\u001b[38;2;255;255;255mModel \u001b[48;2;0;0;183m\u001b[38;2;255;255;255mPrecision \u001b[48;2;0;0;129m\u001b[38;2;255;255;255mRecall \u001b[48;2;0;0;2m\u001b[38;2;255;255;255mF1 \u001b[48;2;189;0;0m\u001b[38;2;255;255;255mSVM \u001b[48;2;105;0;0m\u001b[38;2;255;255;255mLR \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mCRF \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0.78 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0.68 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0.65 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0.56 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0.67 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0.64 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0.65 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0.67 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0.64 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAlso, \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mthe \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mfinal \u001b[48;2;0;0;235m\u001b[38;2;255;255;255mscore \u001b[48;2;114;0;0m\u001b[38;2;255;255;255mshould \u001b[48;2;0;0;101m\u001b[38;2;255;255;255mbe \u001b[48;2;128;0;0m\u001b[38;2;255;255;255mstable \u001b[48;2;0;0;139m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;248m\u001b[38;2;255;255;255minsensitive \u001b[48;2;0;0;216m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpropa- \u001b[48;2;158;0;0m\u001b[38;2;255;255;255mgating \u001b[48;2;0;0;143m\u001b[38;2;255;255;255morder \u001b[48;2;0;0;226m\u001b[38;2;255;255;255munder \u001b[48;2;0;0;230m\u001b[38;2;255;255;255ma \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mcertain \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpool.\n",
            "166 0.0 0.643 0.101 \u001b[48;2;127;0;0m\u001b[38;2;255;255;255mOur \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mstrategy \u001b[48;2;186;0;0m\u001b[38;2;255;255;255mstarts \u001b[48;2;0;0;87m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;161m\u001b[38;2;255;255;255ma \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mdefault \u001b[48;2;43;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;75;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1.0, \u001b[48;2;0;0;208m\u001b[38;2;255;255;255mtraversing \u001b[48;2;0;0;181m\u001b[38;2;255;255;255mthrough \u001b[48;2;0;0;136m\u001b[38;2;255;255;255meach \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mand \u001b[48;2;335;0;0m\u001b[38;2;255;255;255mupdating \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mthe \u001b[48;2;43;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;75;0;0m\u001b[38;2;255;255;255mfactor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msuccessively.\n",
            "167 1.0 0.737 0.217 \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mIt \u001b[48;2;0;0;166m\u001b[38;2;255;255;255mis \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mproven \u001b[48;2;0;0;186m\u001b[38;2;255;255;255mthrough \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mexperiments \u001b[48;2;0;0;157m\u001b[38;2;255;255;255mthat \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mregardless \u001b[48;2;0;0;151m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;161m\u001b[38;2;255;255;255mthe \u001b[48;2;300;0;0m\u001b[38;2;255;255;255mupdating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255morder, \u001b[48;2;0;0;161m\u001b[38;2;255;255;255mthe \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mfinal \u001b[48;2;82;0;0m\u001b[38;2;255;255;255mscore \u001b[48;2;0;0;151m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;23m\u001b[38;2;255;255;255meach \u001b[48;2;173;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;237;0;0m\u001b[38;2;255;255;255mremains \u001b[48;2;0;0;161m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msame.\n",
            "168 0.0 0.655 0.111 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m4.3 \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mCitation \u001b[48;2;19;0;0m\u001b[38;2;255;255;255mSpan \u001b[48;2;260;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;0;0;244m\u001b[38;2;255;255;255mconduct \u001b[48;2;162;0;0m\u001b[38;2;255;255;255msome \u001b[48;2;0;0;87m\u001b[38;2;255;255;255mexperiments \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mguided \u001b[48;2;0;0;58m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[1] \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mas \u001b[48;2;86;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mbaseline.\n",
            "169 0.0 0.934 -0.004 \u001b[48;2;144;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;149;0;0m\u001b[38;2;255;255;255mannotate \u001b[48;2;0;0;162m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mcitation \u001b[48;2;43;0;0m\u001b[38;2;255;255;255mspan \u001b[48;2;0;0;174m\u001b[38;2;255;255;255mfor \u001b[48;2;61;0;0m\u001b[38;2;255;255;255mabout \u001b[48;2;0;0;246m\u001b[38;2;255;255;255m345 \u001b[48;2;0;0;188m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;18m\u001b[38;2;255;255;255msentences \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mas \u001b[48;2;145;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;236;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;178;0;0m\u001b[38;2;255;255;255mset \u001b[48;2;58;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;89;0;0m\u001b[38;2;255;255;255mtrain \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mand \u001b[48;2;27;0;0m\u001b[38;2;255;255;255mtest \u001b[48;2;0;0;162m\u001b[38;2;255;255;255mthe \u001b[48;2;85;0;0m\u001b[38;2;255;255;255mbaseline \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodel.\n",
            "170 0.0 0.969 0.009 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFirst, \u001b[48;2;171;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;0;137m\u001b[38;2;255;255;255muse \u001b[48;2;25;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;122;0;0m\u001b[38;2;255;255;255mtokenizer \u001b[48;2;0;0;143m\u001b[38;2;255;255;255mtool \u001b[48;2;0;0;169m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mSpaCy13 \u001b[48;2;142;0;0m\u001b[38;2;255;255;255mprovides \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mto \u001b[48;2;253;0;0m\u001b[38;2;255;255;255msegment \u001b[48;2;25;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;157;0;0m\u001b[38;2;255;255;255mtext \u001b[48;2;0;0;163m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;114m\u001b[38;2;255;255;255meach \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mciting \u001b[48;2;0;0;1m\u001b[38;2;255;255;255msentence \u001b[48;2;51;0;0m\u001b[38;2;255;255;255minto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtokens, \u001b[48;2;0;0;185m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;137m\u001b[38;2;255;255;255muse \u001b[48;2;194;0;0m\u001b[38;2;255;255;255mtagger \u001b[48;2;0;0;185m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;233m\u001b[38;2;255;255;255mparser \u001b[48;2;0;0;143m\u001b[38;2;255;255;255mtool \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;66m\u001b[38;2;255;255;255massign \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpart-of-speech-tags \u001b[48;2;0;0;185m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mdependency \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mlabels \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;114m\u001b[38;2;255;255;255meach \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtoken.\n",
            "171 0.0 0.953 0.013 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mThen, \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;77;0;0m\u001b[38;2;255;255;255mextract \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mfeatures \u001b[48;2;145;0;0m\u001b[38;2;255;255;255mlisted \u001b[48;2;0;0;109m\u001b[38;2;255;255;255min \u001b[48;2;24;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m5. \u001b[48;2;0;0;140m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;67m\u001b[38;2;255;255;255mthe \u001b[48;2;145;0;0m\u001b[38;2;255;255;255minput \u001b[48;2;0;0;110m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;67m\u001b[38;2;255;255;255mthe \u001b[48;2;178;0;0m\u001b[38;2;255;255;255mbaseline \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodel.\n",
            "172 0.0 0.803 0.062 \u001b[48;2;77;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;264;0;0m\u001b[38;2;255;255;255mtraining \u001b[48;2;0;0;114m\u001b[38;2;255;255;255mis \u001b[48;2;94;0;0m\u001b[38;2;255;255;255mperformed \u001b[48;2;0;0;113m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mSVM, \u001b[48;2;156;0;0m\u001b[38;2;255;255;255mLogistic \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mRegression, \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mCRF, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrespectively.\n",
            "173 1.0 0.659 0.214 \u001b[48;2;283;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;14;0;0m\u001b[38;2;255;255;255muse \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m10-fold \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcross-validation \u001b[48;2;0;0;107m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;4m\u001b[38;2;255;255;255mtraining \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtesting.\n",
            "174 0.0 0.776 0.039 \u001b[48;2;207;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;39;0;0m\u001b[38;2;255;255;255m6 \u001b[48;2;199;0;0m\u001b[38;2;255;255;255mlists \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mprecision, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrecall, \u001b[48;2;0;0;104m\u001b[38;2;255;255;255mand \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mF1 \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;13m\u001b[38;2;255;255;255mthree \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodel.\n",
            "175 -1.0 0.493 -0.105 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m5 \u001b[48;2;0;0;2m\u001b[38;2;255;255;255mRESULTS \u001b[48;2;0;0;164m\u001b[38;2;255;255;255mAs \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mshown \u001b[48;2;0;0;156m\u001b[38;2;255;255;255min \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m4, \u001b[48;2;311;0;0m\u001b[38;2;255;255;255mPhocus \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mfigures \u001b[48;2;0;0;45m\u001b[38;2;255;255;255mout \u001b[48;2;0;0;168m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mthe \u001b[48;2;136;0;0m\u001b[38;2;255;255;255mglobal \u001b[48;2;0;0;20m\u001b[38;2;255;255;255macademic \u001b[48;2;107;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;257;0;0m\u001b[38;2;255;255;255mfactors \u001b[48;2;0;0;195m\u001b[38;2;255;255;255mof \u001b[48;2;53;0;0m\u001b[38;2;255;255;255mscholar \u001b[48;2;0;0;20m\u001b[38;2;255;255;255mY \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;96m\u001b[38;2;255;255;255mPatrick \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mHanrahan \u001b[48;2;0;0;57m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0.40 \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0.52 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrespectively, \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;96m\u001b[38;2;255;255;255mPatrick \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mHanrahan \u001b[48;2;77;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m30% \u001b[48;2;400;0;0m\u001b[38;2;255;255;255mhigher \u001b[48;2;0;0;85m\u001b[38;2;255;255;255mthan \u001b[48;2;53;0;0m\u001b[38;2;255;255;255mscholar \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mY.\n",
            "176 -1.0 0.616 -0.094 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mItâ€™s \u001b[48;2;0;0;154m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;44m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;167m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;14m\u001b[38;2;255;255;255monly \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mutilize \u001b[48;2;174;0;0m\u001b[38;2;255;255;255mprimary \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdata.\n",
            "177 -1.0 0.653 -0.113 \u001b[48;2;336;0;0m\u001b[38;2;255;255;255mWhile \u001b[48;2;0;0;109m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mevaluation \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;155m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAminer, \u001b[48;2;0;0;139m\u001b[38;2;255;255;255mGoogle \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mscholar \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;14;0;0m\u001b[38;2;255;255;255meven \u001b[48;2;0;0;96m\u001b[38;2;255;255;255mSemantic \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mscholar \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mshows \u001b[48;2;0;0;264m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mscholar \u001b[48;2;55;0;0m\u001b[38;2;255;255;255mY \u001b[48;2;139;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;176;0;0m\u001b[38;2;255;255;255mmore \u001b[48;2;211;0;0m\u001b[38;2;255;255;255mproductive \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;78;0;0m\u001b[38;2;255;255;255minfluential \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mthan \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mPatrick \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHanrahan.\n",
            "178 0.0 0.921 0.025 \u001b[48;2;0;0;90m\u001b[38;2;255;255;255m6 \u001b[48;2;0;0;130m\u001b[38;2;255;255;255mCONCLUSION \u001b[48;2;0;0;194m\u001b[38;2;255;255;255mIn \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpaper, \u001b[48;2;230;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;184;0;0m\u001b[38;2;255;255;255mcome \u001b[48;2;294;0;0m\u001b[38;2;255;255;255mup \u001b[48;2;0;0;181m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPhocus, \u001b[48;2;0;0;99m\u001b[38;2;255;255;255ma \u001b[48;2;334;0;0m\u001b[38;2;255;255;255mnovel \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mset \u001b[48;2;0;0;194m\u001b[38;2;255;255;255mof \u001b[48;2;81;0;0m\u001b[38;2;255;255;255macademic \u001b[48;2;134;0;0m\u001b[38;2;255;255;255mevaluation \u001b[48;2;18;0;0m\u001b[38;2;255;255;255mmetrics \u001b[48;2;0;0;67m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mauthors \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mpublications \u001b[48;2;0;0;10m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;88m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;85m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;127m\u001b[38;2;255;255;255mjudgements \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;200m\u001b[38;2;255;255;255mutilize \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maspect-based \u001b[48;2;36;0;0m\u001b[38;2;255;255;255msentiment \u001b[48;2;0;0;0m\u001b[38;2;255;255;255manalysis.\n",
            "179 1.0 0.813 0.27 \u001b[48;2;156;0;0m\u001b[38;2;255;255;255mTo \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mverify \u001b[48;2;169;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mevaluation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmechanism, \u001b[48;2;140;0;0m\u001b[38;2;255;255;255mpeer \u001b[48;2;0;0;120m\u001b[38;2;255;255;255mcomparison \u001b[48;2;0;0;101m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;288m\u001b[38;2;255;255;255mablation \u001b[48;2;0;0;81m\u001b[38;2;255;255;255mstudies \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mhave \u001b[48;2;179;0;0m\u001b[38;2;255;255;255mbeen \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mconducted.\n",
            "180 0.0 0.561 0.131 \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mthe \u001b[48;2;122;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;74m\u001b[38;2;255;255;255mshow \u001b[48;2;0;0;94m\u001b[38;2;255;255;255mthat \u001b[48;2;109;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mmetrics \u001b[48;2;0;0;49m\u001b[38;2;255;255;255mare \u001b[48;2;64;0;0m\u001b[38;2;255;255;255mable \u001b[48;2;0;0;95m\u001b[38;2;255;255;255mto \u001b[48;2;140;0;0m\u001b[38;2;255;255;255midentify \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mthe \u001b[48;2;251;0;0m\u001b[38;2;255;255;255mtruly \u001b[48;2;391;0;0m\u001b[38;2;255;255;255mworthiness \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;203m\u001b[38;2;255;255;255ma \u001b[48;2;70;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mor \u001b[48;2;0;0;203m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mscholar, \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;109m\u001b[38;2;255;255;255mis \u001b[48;2;35;0;0m\u001b[38;2;255;255;255mdifficult \u001b[48;2;0;0;95m\u001b[38;2;255;255;255mto \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mcitation \u001b[48;2;128;0;0m\u001b[38;2;255;255;255mtimes \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmetrics, \u001b[48;2;0;0;165m\u001b[38;2;255;255;255mlike \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mh-index, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mg-index \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mothers.\n",
            "181 1.0 0.829 0.248 \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mPhocus \u001b[48;2;108;0;0m\u001b[38;2;255;255;255mstill \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mneed \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mimprovements.\n",
            "182 -1.0 0.574 -0.168 \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mAs \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mshown \u001b[48;2;0;0;263m\u001b[38;2;255;255;255min \u001b[48;2;0;0;114m\u001b[38;2;255;255;255mSection \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mExper- \u001b[48;2;0;0;0m\u001b[38;2;255;255;255miments, \u001b[48;2;183;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;215;0;0m\u001b[38;2;255;255;255monly \u001b[48;2;0;0;166m\u001b[38;2;255;255;255muse \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mprimary \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mcitation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdata, \u001b[48;2;0;0;143m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mis \u001b[48;2;201;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;16;0;0m\u001b[38;2;255;255;255menough \u001b[48;2;0;0;159m\u001b[38;2;255;255;255mto \u001b[48;2;52;0;0m\u001b[38;2;255;255;255mfully \u001b[48;2;226;0;0m\u001b[38;2;255;255;255mprove \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;82m\u001b[38;2;255;255;255mreliability \u001b[48;2;0;0;134m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPhocus.\n",
            "183 1.0 0.514 0.161 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBesides, \u001b[48;2;0;0;250m\u001b[38;2;255;255;255musing \u001b[48;2;5;0;0m\u001b[38;2;255;255;255mmore \u001b[48;2;131;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;151;0;0m\u001b[38;2;255;255;255msuch \u001b[48;2;0;0;235m\u001b[38;2;255;255;255mas \u001b[48;2;44;0;0m\u001b[38;2;255;255;255msecondary \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mand \u001b[48;2;2;0;0m\u001b[38;2;255;255;255mtertiary \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mcitations \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mcould \u001b[48;2;166;0;0m\u001b[38;2;255;255;255mfurther \u001b[48;2;128;0;0m\u001b[38;2;255;255;255mreflect \u001b[48;2;0;0;98m\u001b[38;2;255;255;255mthe \u001b[48;2;168;0;0m\u001b[38;2;255;255;255mgaps \u001b[48;2;154;0;0m\u001b[38;2;255;255;255mbetween \u001b[48;2;59;0;0m\u001b[38;2;255;255;255mscholars \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mand \u001b[48;2;154;0;0m\u001b[38;2;255;255;255mbetween \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmetrics.\n",
            "184 1.0 0.486 0.145 \u001b[48;2;0;0;137m\u001b[38;2;255;255;255mThere \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mare \u001b[48;2;295;0;0m\u001b[38;2;255;255;255mstill \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mmany \u001b[48;2;55;0;0m\u001b[38;2;255;255;255mproblems \u001b[48;2;0;0;0m\u001b[38;2;255;255;255munsolved, \u001b[48;2;0;0;2m\u001b[38;2;255;255;255msuch \u001b[48;2;0;0;237m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mâ€œcitation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcirclesâ€ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(groups \u001b[48;2;0;0;173m\u001b[38;2;255;255;255mof \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mresearchers \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mwho \u001b[48;2;0;0;77m\u001b[38;2;255;255;255mcite \u001b[48;2;58;0;0m\u001b[38;2;255;255;255mone \u001b[48;2;0;0;0m\u001b[38;2;255;255;255manotherâ€™s \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwork), \u001b[48;2;0;0;44m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mself-citation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_phocus=pd.concat(dfs)"
      ],
      "metadata": {
        "id": "fcWMHFQ4iMeP"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_paper_sentiment=np.mean(df_phocus['net score'])\n",
        "overall_paper_sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e786wcE1nYsZ",
        "outputId": "d9f7f885-3a26-4221-9085-5a0ce4692c1e"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09324489795918367"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_phocus.sort_values(by=['net score'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mPGTjJnCnr1k",
        "outputId": "b2be03fd-97ec-4798-a97c-8652c2b52b7f"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sentence  class  confidence  net score    neg    neu    pos  \\\n",
              "0        47   -1.0       0.510     -0.072  0.510  0.192  0.297   \n",
              "0        38    0.0       0.993      0.000  0.002  0.993  0.004   \n",
              "0        40    0.0       0.956      0.002  0.017  0.956  0.025   \n",
              "0        20    0.0       0.978      0.003  0.005  0.978  0.015   \n",
              "0        34    0.0       0.977      0.004  0.004  0.977  0.018   \n",
              "0         9    0.0       0.984      0.005  0.000  0.984  0.015   \n",
              "0        42    0.0       0.972      0.007  0.002  0.972  0.024   \n",
              "0        39    0.0       0.968      0.008  0.003  0.968  0.027   \n",
              "0        10    0.0       0.973      0.008  0.001  0.973  0.025   \n",
              "0        13    0.0       0.968      0.010  0.000  0.968  0.031   \n",
              "0        45    0.0       0.963      0.010  0.002  0.963  0.034   \n",
              "0        44    0.0       0.966      0.010  0.000  0.966  0.032   \n",
              "0         7    0.0       0.962      0.011  0.001  0.962  0.035   \n",
              "0        15    0.0       0.965      0.011  0.000  0.965  0.033   \n",
              "0        41    0.0       0.943      0.015  0.004  0.943  0.052   \n",
              "0        37    0.0       0.930      0.017  0.008  0.930  0.060   \n",
              "0        36    0.0       0.941      0.017  0.002  0.941  0.055   \n",
              "0         5    0.0       0.941      0.019  0.000  0.941  0.057   \n",
              "0        29    0.0       0.940      0.019  0.000  0.940  0.058   \n",
              "0        48    0.0       0.921      0.025  0.000  0.921  0.078   \n",
              "0        19    0.0       0.882      0.038  0.001  0.882  0.115   \n",
              "0        46    0.0       0.776      0.039  0.053  0.776  0.170   \n",
              "0        22    0.0       0.799      0.040  0.039  0.799  0.161   \n",
              "0        35    0.0       0.854      0.045  0.005  0.854  0.140   \n",
              "0         2    0.0       0.854      0.045  0.005  0.854  0.140   \n",
              "0        28    0.0       0.831      0.054  0.001  0.831  0.166   \n",
              "0        17    0.0       0.599      0.055  0.116  0.599  0.283   \n",
              "0        30    0.0       0.818      0.058  0.003  0.818  0.178   \n",
              "0        23    0.0       0.772      0.073  0.003  0.772  0.223   \n",
              "0        12    0.0       0.751      0.079  0.005  0.751  0.243   \n",
              "0        43    0.0       0.680      0.102  0.005  0.680  0.314   \n",
              "0        26    0.0       0.666      0.108  0.004  0.666  0.328   \n",
              "0        14    0.0       0.656      0.112  0.003  0.656  0.340   \n",
              "0        31    0.0       0.597      0.132  0.002  0.597  0.399   \n",
              "0        32    0.0       0.540      0.144  0.012  0.540  0.447   \n",
              "0         6    1.0       0.582      0.192  0.006  0.411  0.582   \n",
              "0        11    1.0       0.635      0.193  0.054  0.309  0.635   \n",
              "0        27    1.0       0.629      0.196  0.039  0.330  0.629   \n",
              "0         1    1.0       0.795      0.215  0.149  0.054  0.795   \n",
              "0        25    1.0       0.649      0.215  0.002  0.347  0.649   \n",
              "0        18    1.0       0.674      0.216  0.025  0.300  0.674   \n",
              "0         3    1.0       0.790      0.241  0.067  0.141  0.790   \n",
              "0        49    1.0       0.829      0.248  0.083  0.086  0.829   \n",
              "0         8    1.0       0.755      0.251  0.002  0.241  0.755   \n",
              "0         0    1.0       0.792      0.258  0.018  0.188  0.792   \n",
              "0        16    1.0       0.799      0.263  0.010  0.189  0.799   \n",
              "0        24    1.0       0.822      0.266  0.023  0.154  0.822   \n",
              "0        33    1.0       0.900      0.272  0.081  0.018  0.900   \n",
              "0         4    1.0       0.875      0.290  0.003  0.121  0.875   \n",
              "\n",
              "                                                text  \\\n",
              "0    5 RESULTS As shown in Table 4, Phocus figure...   \n",
              "0  After splitting the sentence into segments by ...   \n",
              "0  dTreeDistance  Length of the shortest dependen...   \n",
              "0  Definition  Ranges  Label  Description  Zhang ...   \n",
              "0  First, given a set of references within a pape...   \n",
              "0  To detect citation span in Wikipedia, Fetahu e...   \n",
              "0  Table  results for three different models for ...   \n",
              "0  pos_tag  The part of speech tag of the word, t...   \n",
              "0  Given aspects, Sun et al. [] construct an auxi...   \n",
              "0  To illustrate the ranking network, we use ð‘ð‘– ð‘—...   \n",
              "0  Then, we extract features listed in Table  as ...   \n",
              "0  First, we use the tokenizer tool that SpaCy pr...   \n",
              "0  Butt et al. [6] utilize Naive-Bayes Classifier...   \n",
              "0  The Impact Factor (IF)[] and CiteScore6 are us...   \n",
              "0  lca  The type of the node in the dependency pa...   \n",
              "0  This feature takes the value 1 if the word com...   \n",
              "0  Table  features used for citation span  Featur...   \n",
              "0  2 RELATED WORK Our work involves citation clas...   \n",
              "0  ð´ denote a citing paper with academic influent...   \n",
              "0  6 CONCLUSION In this paper, we come up with Ph...   \n",
              "0  3 METHODOLOGY As shown in Figure ??, our algor...   \n",
              "0  Table 6 lists the precision, recall, and F1 fo...   \n",
              "0   Calculating Factors There are still three fac...   \n",
              "0                          , ,  Zhang and Wen et al.   \n",
              "0                          , ,  Zhang and Wen et al.   \n",
              "0  Phocus: Picking Valuable Research from a Sea o...   \n",
              "0                              higher or equal to â„Ž.   \n",
              "0  4 EXPERIMENTS We conduct several experiments t...   \n",
              "0  We fine-tune BERT on a manually annotated data...   \n",
              "0   Ranking Model The ranking model is based on L...   \n",
              "0   Citation Span We conduct some experiments gui...   \n",
              "0  The ranking model is based on LambdaMART, whic...   \n",
              "0  1 ð‘›_ð‘ð‘–ð‘¡ð‘–   Evaluation Metrics In the academic ...   \n",
              "0  As the influential factor of a paper is the we...   \n",
              "0    Peer Comparison Scholar and their publications.   \n",
              "0   Citation Classification In fact, there are al...   \n",
              "0  As the errors are cumulated in the pipeline, s...   \n",
              "0  Based on the classes and order of references, ...   \n",
              "0  Paper boom in academic fields results in many ...   \n",
              "0   Evaluating Contribution After gathering all n...   \n",
              "0  Paper-level metrics are usually the number of ...   \n",
              "0  The reason for the sharp increase in papers is...   \n",
              "0                    Phocus still need improvements.   \n",
              "0   Aspect-based Sentiment Analysis Aspect-based ...   \n",
              "0  1 INTRODUCTION The number of papers published ...   \n",
              "0  Author-level metrics include h-index, g-index,...   \n",
              "0  We get an accuracy of % on the evaluation data...   \n",
              "0     is the number of highly influential citations.   \n",
              "0  We propose Phocus, a novel evaluation mechanis...   \n",
              "\n",
              "                                             colored  \n",
              "0  \u001b[48;2;0;0;25m\u001b[38;2;255;255;255m5 \u001b[48;2;0;0;...  \n",
              "0  \u001b[48;2;59;0;0m\u001b[38;2;255;255;255mAfter \u001b[48;2;...  \n",
              "0  \u001b[48;2;0;0;179m\u001b[38;2;255;255;255mdTreeDistanc...  \n",
              "0  \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mDefinition \u001b[...  \n",
              "0  \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFirst, \u001b[48;2;...  \n",
              "0  \u001b[48;2;0;0;20m\u001b[38;2;255;255;255mto \u001b[48;2;0;0...  \n",
              "0  \u001b[48;2;62;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;...  \n",
              "0  \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpos_tag \u001b[48;2...  \n",
              "0  \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mGiven \u001b[48;2;...  \n",
              "0  \u001b[48;2;0;0;98m\u001b[38;2;255;255;255mto \u001b[48;2;26;...  \n",
              "0  \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mThen, \u001b[48;2;0...  \n",
              "0  \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFirst, \u001b[48;2;...  \n",
              "0  \u001b[48;2;0;0;7m\u001b[38;2;255;255;255mButt \u001b[48;2;0;...  \n",
              "0  \u001b[48;2;151;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;1...  \n",
              "0  \u001b[48;2;0;0;97m\u001b[38;2;255;255;255mlca \u001b[48;2;0;...  \n",
              "0  \u001b[48;2;0;0;200m\u001b[38;2;255;255;255mThis \u001b[48;2;...  \n",
              "0  \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mTable \u001b[48;2;...  \n",
              "0  \u001b[48;2;0;0;48m\u001b[38;2;255;255;255m2 \u001b[48;2;0;0;...  \n",
              "0  \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´ \u001b[48;2;24;0;...  \n",
              "0  \u001b[48;2;0;0;90m\u001b[38;2;255;255;255m6 \u001b[48;2;0;0;...  \n",
              "0  \u001b[48;2;0;0;85m\u001b[38;2;255;255;255m3 \u001b[48;2;0;0;...  \n",
              "0  \u001b[48;2;207;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2...  \n",
              "0  \u001b[48;2;0;0;198m\u001b[38;2;255;255;255mCalculating ...  \n",
              "0  \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;0;0;0...  \n",
              "0  \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;0;0;0...  \n",
              "0  \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPhocus: \u001b[48;2...  \n",
              "0  \u001b[48;2;199;0;0m\u001b[38;2;255;255;255mhigher \u001b[48;...  \n",
              "0  \u001b[48;2;0;0;110m\u001b[38;2;255;255;255m4 \u001b[48;2;0;0...  \n",
              "0  \u001b[48;2;201;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;0;...  \n",
              "0  \u001b[48;2;220;0;0m\u001b[38;2;255;255;255mranking \u001b[48...  \n",
              "0  \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mCitation \u001b[4...  \n",
              "0  \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;21...  \n",
              "0  \u001b[48;2;0;0;240m\u001b[38;2;255;255;255m1 \u001b[48;2;0;0...  \n",
              "0  \u001b[48;2;23;0;0m\u001b[38;2;255;255;255mAs \u001b[48;2;0;0...  \n",
              "0  \u001b[48;2;205;0;0m\u001b[38;2;255;255;255mPeer \u001b[48;2;...  \n",
              "0  \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mcitation \u001b[48...  \n",
              "0  \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mAs \u001b[48;2;0;0...  \n",
              "0  \u001b[48;2;231;0;0m\u001b[38;2;255;255;255mBased \u001b[48;2...  \n",
              "0  \u001b[48;2;61;0;0m\u001b[38;2;255;255;255mPaper \u001b[48;2;...  \n",
              "0  \u001b[48;2;0;0;76m\u001b[38;2;255;255;255mEvaluating \u001b[...  \n",
              "0  \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPaper-level \u001b[...  \n",
              "0  \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;10...  \n",
              "0  \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mPhocus \u001b[48;...  \n",
              "0  \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAspect-based \u001b...  \n",
              "0  \u001b[48;2;0;0;134m\u001b[38;2;255;255;255m1 \u001b[48;2;48;...  \n",
              "0  \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAuthor-level \u001b...  \n",
              "0  \u001b[48;2;298;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;0;...  \n",
              "0  \u001b[48;2;163;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;20...  \n",
              "0  \u001b[48;2;253;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;0;...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3ef33ce-fb97-46e8-bb8b-6d63c83408d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>class</th>\n",
              "      <th>confidence</th>\n",
              "      <th>net score</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>text</th>\n",
              "      <th>colored</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>47</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.510</td>\n",
              "      <td>-0.072</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.192</td>\n",
              "      <td>0.297</td>\n",
              "      <td>5 RESULTS As shown in Table 4, Phocus figure...</td>\n",
              "      <td>\u001b[48;2;0;0;25m\u001b[38;2;255;255;255m5 \u001b[48;2;0;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.993</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.993</td>\n",
              "      <td>0.004</td>\n",
              "      <td>After splitting the sentence into segments by ...</td>\n",
              "      <td>\u001b[48;2;59;0;0m\u001b[38;2;255;255;255mAfter \u001b[48;2;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.956</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.956</td>\n",
              "      <td>0.025</td>\n",
              "      <td>dTreeDistance  Length of the shortest dependen...</td>\n",
              "      <td>\u001b[48;2;0;0;179m\u001b[38;2;255;255;255mdTreeDistanc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.015</td>\n",
              "      <td>Definition  Ranges  Label  Description  Zhang ...</td>\n",
              "      <td>\u001b[48;2;0;0;19m\u001b[38;2;255;255;255mDefinition \u001b[...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.977</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.977</td>\n",
              "      <td>0.018</td>\n",
              "      <td>First, given a set of references within a pape...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFirst, \u001b[48;2;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.984</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.984</td>\n",
              "      <td>0.015</td>\n",
              "      <td>To detect citation span in Wikipedia, Fetahu e...</td>\n",
              "      <td>\u001b[48;2;0;0;20m\u001b[38;2;255;255;255mto \u001b[48;2;0;0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.972</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.972</td>\n",
              "      <td>0.024</td>\n",
              "      <td>Table  results for three different models for ...</td>\n",
              "      <td>\u001b[48;2;62;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.968</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.968</td>\n",
              "      <td>0.027</td>\n",
              "      <td>pos_tag  The part of speech tag of the word, t...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpos_tag \u001b[48;2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.973</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.973</td>\n",
              "      <td>0.025</td>\n",
              "      <td>Given aspects, Sun et al. [] construct an auxi...</td>\n",
              "      <td>\u001b[48;2;0;0;28m\u001b[38;2;255;255;255mGiven \u001b[48;2;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.968</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.968</td>\n",
              "      <td>0.031</td>\n",
              "      <td>To illustrate the ranking network, we use ð‘ð‘– ð‘—...</td>\n",
              "      <td>\u001b[48;2;0;0;98m\u001b[38;2;255;255;255mto \u001b[48;2;26;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.963</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.963</td>\n",
              "      <td>0.034</td>\n",
              "      <td>Then, we extract features listed in Table  as ...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mThen, \u001b[48;2;0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.966</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.966</td>\n",
              "      <td>0.032</td>\n",
              "      <td>First, we use the tokenizer tool that SpaCy pr...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFirst, \u001b[48;2;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.962</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.962</td>\n",
              "      <td>0.035</td>\n",
              "      <td>Butt et al. [6] utilize Naive-Bayes Classifier...</td>\n",
              "      <td>\u001b[48;2;0;0;7m\u001b[38;2;255;255;255mButt \u001b[48;2;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.965</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.965</td>\n",
              "      <td>0.033</td>\n",
              "      <td>The Impact Factor (IF)[] and CiteScore6 are us...</td>\n",
              "      <td>\u001b[48;2;151;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.943</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.943</td>\n",
              "      <td>0.052</td>\n",
              "      <td>lca  The type of the node in the dependency pa...</td>\n",
              "      <td>\u001b[48;2;0;0;97m\u001b[38;2;255;255;255mlca \u001b[48;2;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.930</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.930</td>\n",
              "      <td>0.060</td>\n",
              "      <td>This feature takes the value 1 if the word com...</td>\n",
              "      <td>\u001b[48;2;0;0;200m\u001b[38;2;255;255;255mThis \u001b[48;2;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.941</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.941</td>\n",
              "      <td>0.055</td>\n",
              "      <td>Table  features used for citation span  Featur...</td>\n",
              "      <td>\u001b[48;2;0;0;16m\u001b[38;2;255;255;255mTable \u001b[48;2;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.941</td>\n",
              "      <td>0.019</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.941</td>\n",
              "      <td>0.057</td>\n",
              "      <td>2 RELATED WORK Our work involves citation clas...</td>\n",
              "      <td>\u001b[48;2;0;0;48m\u001b[38;2;255;255;255m2 \u001b[48;2;0;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.019</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.058</td>\n",
              "      <td>ð´ denote a citing paper with academic influent...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´ \u001b[48;2;24;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.921</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.921</td>\n",
              "      <td>0.078</td>\n",
              "      <td>6 CONCLUSION In this paper, we come up with Ph...</td>\n",
              "      <td>\u001b[48;2;0;0;90m\u001b[38;2;255;255;255m6 \u001b[48;2;0;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.882</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.882</td>\n",
              "      <td>0.115</td>\n",
              "      <td>3 METHODOLOGY As shown in Figure ??, our algor...</td>\n",
              "      <td>\u001b[48;2;0;0;85m\u001b[38;2;255;255;255m3 \u001b[48;2;0;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.776</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.053</td>\n",
              "      <td>0.776</td>\n",
              "      <td>0.170</td>\n",
              "      <td>Table 6 lists the precision, recall, and F1 fo...</td>\n",
              "      <td>\u001b[48;2;207;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.799</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.799</td>\n",
              "      <td>0.161</td>\n",
              "      <td>Calculating Factors There are still three fac...</td>\n",
              "      <td>\u001b[48;2;0;0;198m\u001b[38;2;255;255;255mCalculating ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.045</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.140</td>\n",
              "      <td>, ,  Zhang and Wen et al.</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;0;0;0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.045</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.140</td>\n",
              "      <td>, ,  Zhang and Wen et al.</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255m, \u001b[48;2;0;0;0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.831</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.831</td>\n",
              "      <td>0.166</td>\n",
              "      <td>Phocus: Picking Valuable Research from a Sea o...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPhocus: \u001b[48;2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.599</td>\n",
              "      <td>0.055</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.599</td>\n",
              "      <td>0.283</td>\n",
              "      <td>higher or equal to â„Ž.</td>\n",
              "      <td>\u001b[48;2;199;0;0m\u001b[38;2;255;255;255mhigher \u001b[48;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.818</td>\n",
              "      <td>0.058</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.818</td>\n",
              "      <td>0.178</td>\n",
              "      <td>4 EXPERIMENTS We conduct several experiments t...</td>\n",
              "      <td>\u001b[48;2;0;0;110m\u001b[38;2;255;255;255m4 \u001b[48;2;0;0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.772</td>\n",
              "      <td>0.073</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.772</td>\n",
              "      <td>0.223</td>\n",
              "      <td>We fine-tune BERT on a manually annotated data...</td>\n",
              "      <td>\u001b[48;2;201;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.751</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.751</td>\n",
              "      <td>0.243</td>\n",
              "      <td>Ranking Model The ranking model is based on L...</td>\n",
              "      <td>\u001b[48;2;220;0;0m\u001b[38;2;255;255;255mranking \u001b[48...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.314</td>\n",
              "      <td>Citation Span We conduct some experiments gui...</td>\n",
              "      <td>\u001b[48;2;0;0;117m\u001b[38;2;255;255;255mCitation \u001b[4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.666</td>\n",
              "      <td>0.328</td>\n",
              "      <td>The ranking model is based on LambdaMART, whic...</td>\n",
              "      <td>\u001b[48;2;81;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.656</td>\n",
              "      <td>0.112</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.656</td>\n",
              "      <td>0.340</td>\n",
              "      <td>1 ð‘›_ð‘ð‘–ð‘¡ð‘–   Evaluation Metrics In the academic ...</td>\n",
              "      <td>\u001b[48;2;0;0;240m\u001b[38;2;255;255;255m1 \u001b[48;2;0;0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.597</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.597</td>\n",
              "      <td>0.399</td>\n",
              "      <td>As the influential factor of a paper is the we...</td>\n",
              "      <td>\u001b[48;2;23;0;0m\u001b[38;2;255;255;255mAs \u001b[48;2;0;0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.144</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.447</td>\n",
              "      <td>Peer Comparison Scholar and their publications.</td>\n",
              "      <td>\u001b[48;2;205;0;0m\u001b[38;2;255;255;255mPeer \u001b[48;2;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.192</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.411</td>\n",
              "      <td>0.582</td>\n",
              "      <td>Citation Classification In fact, there are al...</td>\n",
              "      <td>\u001b[48;2;0;0;11m\u001b[38;2;255;255;255mcitation \u001b[48...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.635</td>\n",
              "      <td>0.193</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.309</td>\n",
              "      <td>0.635</td>\n",
              "      <td>As the errors are cumulated in the pipeline, s...</td>\n",
              "      <td>\u001b[48;2;32;0;0m\u001b[38;2;255;255;255mAs \u001b[48;2;0;0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.629</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.330</td>\n",
              "      <td>0.629</td>\n",
              "      <td>Based on the classes and order of references, ...</td>\n",
              "      <td>\u001b[48;2;231;0;0m\u001b[38;2;255;255;255mBased \u001b[48;2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.795</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.149</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.795</td>\n",
              "      <td>Paper boom in academic fields results in many ...</td>\n",
              "      <td>\u001b[48;2;61;0;0m\u001b[38;2;255;255;255mPaper \u001b[48;2;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.649</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.347</td>\n",
              "      <td>0.649</td>\n",
              "      <td>Evaluating Contribution After gathering all n...</td>\n",
              "      <td>\u001b[48;2;0;0;76m\u001b[38;2;255;255;255mEvaluating \u001b[...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.674</td>\n",
              "      <td>0.216</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.674</td>\n",
              "      <td>Paper-level metrics are usually the number of ...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPaper-level \u001b[...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.790</td>\n",
              "      <td>0.241</td>\n",
              "      <td>0.067</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.790</td>\n",
              "      <td>The reason for the sharp increase in papers is...</td>\n",
              "      <td>\u001b[48;2;78;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.248</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.086</td>\n",
              "      <td>0.829</td>\n",
              "      <td>Phocus still need improvements.</td>\n",
              "      <td>\u001b[48;2;0;0;182m\u001b[38;2;255;255;255mPhocus \u001b[48;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.755</td>\n",
              "      <td>0.251</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.241</td>\n",
              "      <td>0.755</td>\n",
              "      <td>Aspect-based Sentiment Analysis Aspect-based ...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAspect-based \u001b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.792</td>\n",
              "      <td>0.258</td>\n",
              "      <td>0.018</td>\n",
              "      <td>0.188</td>\n",
              "      <td>0.792</td>\n",
              "      <td>1 INTRODUCTION The number of papers published ...</td>\n",
              "      <td>\u001b[48;2;0;0;134m\u001b[38;2;255;255;255m1 \u001b[48;2;48;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.799</td>\n",
              "      <td>0.263</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.189</td>\n",
              "      <td>0.799</td>\n",
              "      <td>Author-level metrics include h-index, g-index,...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAuthor-level \u001b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.822</td>\n",
              "      <td>0.266</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.154</td>\n",
              "      <td>0.822</td>\n",
              "      <td>We get an accuracy of % on the evaluation data...</td>\n",
              "      <td>\u001b[48;2;298;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.272</td>\n",
              "      <td>0.081</td>\n",
              "      <td>0.018</td>\n",
              "      <td>0.900</td>\n",
              "      <td>is the number of highly influential citations.</td>\n",
              "      <td>\u001b[48;2;163;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.290</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.121</td>\n",
              "      <td>0.875</td>\n",
              "      <td>We propose Phocus, a novel evaluation mechanis...</td>\n",
              "      <td>\u001b[48;2;253;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;0;...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3ef33ce-fb97-46e8-bb8b-6d63c83408d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3ef33ce-fb97-46e8-bb8b-6d63c83408d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3ef33ce-fb97-46e8-bb8b-6d63c83408d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errs"
      ],
      "metadata": {
        "id": "sfr8lMzYMJNq",
        "outputId": "f834427e-da88-489d-f39e-8dd61a276ad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[95, 143]"
            ]
          },
          "metadata": {},
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(content[143])"
      ],
      "metadata": {
        "id": "edgSHcYCuS7U",
        "outputId": "49961340-8f96-4923-f1dd-dbb61fe91870",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "However, those numbers covers up some significant truths that not all papers are equal influential and not all citations mean agreement with the cited ones. where h repre- sents h-index, g represents g-index, i10 means i10-index, and HIC  9https://scholar.google.com/citations?hl=zh-CN&user=RzEnQmgAAAAJ 10https://www.aminer.cn/ 11https://scholar.google.com/ 12https://www.semanticscholar.org/  Table 3: statistics of Y and Hanrahan  Scholar  Aminer  Google Scholar  publications citations citations  Y  1146  77903  78663  Hanrahan 381  52214  50568  Semantic Scholar publications citations  771  315  59679  56383  Table 4: evaluation results from several platforms  Scholar  Aminer  Google Scholar  Semantic Scholar  h  131  Y  Hanrahan 97  g  258  228  h  123  93  i10  723  200  h  HIC  119  5843  88  3741  Phocus (Primary)  0.40  0.52  Figure 4: for paper A, paper B and C cite it directly, called primary citations, D to A is secondary and E to A is tertiary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(color_by_attn(content[86],tokenizer,preprocesser_model,encoder_model))"
      ],
      "metadata": {
        "id": "5W-uSOK4MKgk",
        "outputId": "47509aa2-4ec2-40a6-d5b2-d187fd5e516d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-9a638c6f8473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_by_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m86\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocesser_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-0f6592054b79>\u001b[0m in \u001b[0;36mcolor_by_attn\u001b[0;34m(text, toker, preper, encoder)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprocessed\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mprocess_for_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_attn_for_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocesser_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_bytes_strs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-3ba09b0bc540>\u001b[0m in \u001b[0;36mget_attn_for_words\u001b[0;34m(context, tokenizer, prep, encoder)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindicies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mattn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mfull_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 131 is out of bounds for axis 0 with size 125"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content[134]"
      ],
      "metadata": {
        "id": "igoZJhU3MWaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.split('\\d{1,}https:',content[134]) #remove subscripts"
      ],
      "metadata": {
        "id": "_BQ6mWooOfj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.split('Table \\d{1,}:',content[134]) #remove tables"
      ],
      "metadata": {
        "id": "mwEOZ1WSPiAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.split('Figure \\d{1,}:',content[134]) #remove tables"
      ],
      "metadata": {
        "id": "YtulqK88P_wX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "input.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}