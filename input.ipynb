{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h7Lr7k5d1jd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ENEE439d-TEXTML/TextML/blob/master/input.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/ENEE439d-TEXTML/TextML/blob/master/input.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPiicLOUd1jj"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U \"tensorflow-text==2.8.*\" # A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q tf-models-official==2.7.0 # For adamW\n",
        "!pip install focal-loss # focal loss implmnetion for tf\n",
        "!pip install pdfminer.six #pdf text extratction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52FpqTzrPr-t",
        "outputId": "7bffe4bc-dda5-4a06-ecbc-2623a0cd2692"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: focal-loss in /usr/local/lib/python3.7/dist-packages (0.0.7)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal-loss) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (4.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.0.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (14.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.44.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.25.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal-loss) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2->focal-loss) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.2.0)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.7/dist-packages (20220506)\n",
            "Requirement already satisfied: cryptography~=36.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (36.0.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (2.0.12)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography~=36.0.0->pdfminer.six) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography~=36.0.0->pdfminer.six) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "BPnv0Vlcd3KI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #basic imports\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split # https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization, bert  # to create AdamW optimizer\n",
        "from focal_loss import SparseCategoricalFocalLoss\n",
        "import official.nlp.bert.tokenization"
      ],
      "metadata": {
        "id": "dkxbtcKbP4AU"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import StringIO\n",
        "\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfdocument import PDFDocument\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.pdfparser import PDFParser"
      ],
      "metadata": {
        "id": "Xx7DXy_KYgAE"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns; sns.set_theme()"
      ],
      "metadata": {
        "id": "C8Bp4YVOR8JZ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data read in"
      ],
      "metadata": {
        "id": "Q-Dc1EsOuQA0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "465BADPxeNII",
        "outputId": "f90b7cbd-ce9b-4872-f510-2861ce483e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Sk1zTIA6eOM5",
        "outputId": "538c5a1a-85e2-4f45-8bb8-83a771bdb50b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  cited_paper  label                                               text\n",
              "0    A00-2024      0  We analyzed a set of articles and identified s...\n",
              "1    A00-2024      0  Table 3: Example compressions Compression AvgL...\n",
              "2    A00-2024      0  5.3 Related works and discussion Our two-step ...\n",
              "3    A00-2024      0  (1999) proposed a summarization system based o...\n",
              "4    A00-2024      0  We found that the deletion of lead parts did n..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f61e96f-e1b8-4e24-b35a-d49254ec39b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f61e96f-e1b8-4e24-b35a-d49254ec39b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f61e96f-e1b8-4e24-b35a-d49254ec39b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f61e96f-e1b8-4e24-b35a-d49254ec39b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "filepath = '/content/drive/MyDrive/Text-ML/full_sentiment_dataset.csv' #'data.csv'\n",
        "df= pd.read_csv(filepath)\n",
        "df1=df.drop(['no','paper','context_a','context_b'],axis=1)\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImSOYF6Py2J8",
        "outputId": "d45cbc00-08b2-430f-932e-9ddbf96bc1ae"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    7627\n",
              " 1     829\n",
              "-1     280\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filtering by regex"
      ],
      "metadata": {
        "id": "FHIvNaLfuUoe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytc03_FI-b5L",
        "outputId": "5bc3e17f-daf8-4273-a68f-8b60ac652a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\[*\\]|\\(\\d{4}\\)|\\(?((\\(?((\\w+, )*(\\w+ )+)((and|&) ((\\w+ *))?)?,? \\(?\\d{4}\\)?|((\\w+, )*(\\w+ )+)et al\\. ?,? \\(?\\d{4}\\)?\\)?)((; )|( (and|&) ))*)+\n"
          ]
        }
      ],
      "source": [
        "context=df1['text']\n",
        "\n",
        "re1= \"\\(((([A-Za-z]+ *)+(, \\d+))+(; )*)+\\)\" # matches author and author, year\n",
        "re_year=\",? \\(?\\d{4}\\)?\" # match , {4 digits} which may be wrapped in () \n",
        "re_and=\"(and|&) \"\n",
        "re_auth=\"((\\w+, )*(\\w+ )+)\"\n",
        "re_et= re_auth+\"et al\\. ?\"+re_year # matches author et al. , year\n",
        "re_2a= re_auth+\"(\"+re_and+\"((\\w+ *))?)?\"+re_year # matches author and author, year\n",
        "re_sep=\"((; )|( \"+re_and+\"))*\"# match the '; ' gap or ' and ' gap\n",
        "re_para_year=\"\\(\\d{4}\\)\"\n",
        "re_in_brack=\"\\[*\\]\"\n",
        "re_apa =re_in_brack+\"|\"+re_para_year+\"|\"+\"\\(?(\"+\"(\\(?\"+re_2a+\"|\"+re_et+\"\\)?)\"+re_sep+\")+\"\n",
        "print(re_apa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "NEZIAWQtykDg"
      },
      "outputs": [],
      "source": [
        "def remove_matches(text,regex=re_apa):\n",
        "  text1=text\n",
        "  rem_len=0\n",
        "  pattern= re.compile(regex)\n",
        "  while True:\n",
        "    matches=pattern.search(text1)\n",
        "    #print(matches)\n",
        "    if matches == None:\n",
        "      break\n",
        "\n",
        "    spn=matches.span()\n",
        "    text1=text1[0:spn[0]]+text1[spn[1]:-1]\n",
        "    cit_len=spn[1]-spn[0]\n",
        "    rem_len+=cit_len\n",
        "  \n",
        "  if len(text) >0:\n",
        "    percent_removed=rem_len/len(text)\n",
        "  else:\n",
        "    percent_removed=1\n",
        "  return text1,percent_removed \n",
        "\n",
        "# print(context[5])\n",
        "# remove_citation(context[5],regex=re_apa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "TmjjH1gp9A6T"
      },
      "outputs": [],
      "source": [
        "output=df1['text'].apply(lambda x: remove_matches(text=x,regex=re_apa)) #df['col1'] = df.apply(lambda x: complex_function(x['col1']), axis=1)\n",
        "df_o = pd.DataFrame(list(output), columns =['clean','p_rem'])\n",
        "output_1=df_o['clean'].apply(lambda x: remove_matches(text=x,regex='[^\\w_0-9 ]+')) \n",
        "df_o_1 = pd.DataFrame(list(output_1), columns =['clean','p_rem'])\n",
        "#df_o.head()\n",
        "\n",
        "df1['text_clean']=df_o_1['clean']\n",
        "df1['text_clean_len']=df_o_1['clean'].apply(len)\n",
        "df1['p_rem']=df_o['p_rem']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OVt3NtaJDDrx",
        "outputId": "284f4f0d-d5cd-4bc2-e074-617563693737"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cited_paper  label                                               text  \\\n",
              "0       A00-2024      0  We analyzed a set of articles and identified s...   \n",
              "1       A00-2024      0  Table 3: Example compressions Compression AvgL...   \n",
              "2       A00-2024      0  5.3 Related works and discussion Our two-step ...   \n",
              "3       A00-2024      0  (1999) proposed a summarization system based o...   \n",
              "4       A00-2024      0  We found that the deletion of lead parts did n...   \n",
              "...          ...    ...                                                ...   \n",
              "8731    W96-0213      1  He has achieved state-of-the art results by ap...   \n",
              "8732    W96-0213      0  B = (Brill and Wu, 1998); M = (Magerman, 1995)...   \n",
              "8733    W96-0213      0  The model we use is similar to that of (Ratnap...   \n",
              "8734    W96-0213      1  Our model exploits the same kind of tag-n-gram...   \n",
              "8735    W96-0213      0  In that table, TBL stands for Brill's transfor...   \n",
              "\n",
              "                                             text_clean  text_clean_len  \\\n",
              "0     We analyzed a set of articles and identified s...             425   \n",
              "1     Table 3 Example compressions Compression AvgLe...             229   \n",
              "2     53 Related works and discussion Our twostep mo...             105   \n",
              "3      proposed a summarization system based on the ...             321   \n",
              "4     We found that the deletion of lead parts did n...              73   \n",
              "...                                                 ...             ...   \n",
              "8731  He has achieved stateofthe art results by appl...             139   \n",
              "8732   B  M  Magerman 1995 O  our data R  Ratnaparkhi 1              48   \n",
              "8733  The model we use is similar to that of Ratnapa...              55   \n",
              "8734  Our model exploits the same kind of tagngram i...             157   \n",
              "8735  In that table TBL stands for Brills transforma...             288   \n",
              "\n",
              "         p_rem  \n",
              "0     0.098765  \n",
              "1     0.260745  \n",
              "2     0.308176  \n",
              "3     0.078804  \n",
              "4     0.408000  \n",
              "...        ...  \n",
              "8731  0.151515  \n",
              "8732  0.421488  \n",
              "8733  0.000000  \n",
              "8734  0.000000  \n",
              "8735  0.000000  \n",
              "\n",
              "[8736 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-604cb39d-63bb-4e8b-8453-458046b0a2ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_clean_len</th>\n",
              "      <th>p_rem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "      <td>425</td>\n",
              "      <td>0.098765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "      <td>Table 3 Example compressions Compression AvgLe...</td>\n",
              "      <td>229</td>\n",
              "      <td>0.260745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "      <td>53 Related works and discussion Our twostep mo...</td>\n",
              "      <td>105</td>\n",
              "      <td>0.308176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "      <td>proposed a summarization system based on the ...</td>\n",
              "      <td>321</td>\n",
              "      <td>0.078804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "      <td>73</td>\n",
              "      <td>0.408000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>1</td>\n",
              "      <td>He has achieved state-of-the art results by ap...</td>\n",
              "      <td>He has achieved stateofthe art results by appl...</td>\n",
              "      <td>139</td>\n",
              "      <td>0.151515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8732</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>B = (Brill and Wu, 1998); M = (Magerman, 1995)...</td>\n",
              "      <td>B  M  Magerman 1995 O  our data R  Ratnaparkhi 1</td>\n",
              "      <td>48</td>\n",
              "      <td>0.421488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8733</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>The model we use is similar to that of (Ratnap...</td>\n",
              "      <td>The model we use is similar to that of Ratnapa...</td>\n",
              "      <td>55</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8734</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>1</td>\n",
              "      <td>Our model exploits the same kind of tag-n-gram...</td>\n",
              "      <td>Our model exploits the same kind of tagngram i...</td>\n",
              "      <td>157</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8735</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>In that table, TBL stands for Brill's transfor...</td>\n",
              "      <td>In that table TBL stands for Brills transforma...</td>\n",
              "      <td>288</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8736 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-604cb39d-63bb-4e8b-8453-458046b0a2ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-604cb39d-63bb-4e8b-8453-458046b0a2ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-604cb39d-63bb-4e8b-8453-458046b0a2ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove under and over sized samples\n",
        "large samples appear to be poorly written"
      ],
      "metadata": {
        "id": "pkNPWqAHKLxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getMidLen(data,label,labelKey='label',lenKey='text_clean_len',lowMod=1,highMod=1):\n",
        "  df1 =data.loc[data[labelKey] == label]\n",
        "  neu_mean=np.mean(list(df1[lenKey]))\n",
        "  neu_std=np.std(list(df1[lenKey]))\n",
        "  df1_no_high = df1.loc[df1[lenKey] < highMod*(neu_mean +neu_std)]\n",
        "  # print(neu_mean)\n",
        "  # print(neu_std)\n",
        "\n",
        "  while neu_std > neu_mean:\n",
        "    neu_mean=np.mean(list(df1_no_high['text_clean_len']))\n",
        "    neu_std=np.std(list(df1_no_high['text_clean_len']))\n",
        "    # print(neu_mean)\n",
        "    # print(neu_std)\n",
        "    df1_no_high = df1.loc[df1['text_clean_len'] < highMod*(neu_mean +neu_std)]\n",
        "\n",
        "  df1_mid = df1_no_high.loc[df1_no_high['text_clean_len'] > lowMod*(neu_mean -neu_std)]\n",
        "\n",
        "  return df1_mid\n",
        "\n",
        "df2 = df1.loc[df1['p_rem'] < .5] #keep sampels with less than half of it are citation\n",
        "\n",
        "df_neu=getMidLen(df2,0,lowMod=2)\n",
        "df_pos=getMidLen(df2,1,lowMod=1,highMod=2)\n",
        "df_neg=getMidLen(df2,-1,lowMod=1,highMod=2)\n",
        "df3= pd.concat([df_neg,df_neu,df_pos])\n",
        "df3['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq-BsMfleXID",
        "outputId": "f6971ec9-6bed-4a61-c3e6-aecabdcb4566"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    2524\n",
              " 1     746\n",
              "-1     246\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def catagorize(data,labelKey='label'):\n",
        "  rows=len(data.index)\n",
        "  onehots=np.zeros((rows,3),dtype=int)\n",
        "  for i,lab in enumerate(data[labelKey]):\n",
        "    onehots[i][lab+1]=1\n",
        "  return onehots\n",
        "\n",
        "hots=catagorize(df3)\n",
        "df3['label_onehot']=list(hots)\n",
        "df3['label_index']=df3['label']+1"
      ],
      "metadata": {
        "id": "VnsKnaB0AU4i"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq= np.array(list(df3['label_index'].value_counts(normalize=True,sort=False)))\n",
        "print(freq)\n",
        "class_ratio= 1/freq\n",
        "class_ratio"
      ],
      "metadata": {
        "id": "Mbn2dX1C2Ixs",
        "outputId": "cb3a8be5-46b5-4e1f-aa7a-9d7fd3180fac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06996587 0.71786121 0.21217292]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14.29268293,  1.39302694,  4.71313673])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Model"
      ],
      "metadata": {
        "id": "QtrXZF4_unOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(list(df3['text_clean']), list(df3['label_index']), test_size=0.2, random_state=42)\n",
        "X_train= [[s] for s in X_train]\n",
        "X_test= [[s] for s in X_test]\n",
        "y_train=[[s] for s in list(y_train)]\n",
        "y_test=[[s] for s in list(y_test)]"
      ],
      "metadata": {
        "id": "kKtJq5Baj1Wl"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose a BERT model to fine-tune (Taken from tutorial)\n",
        "\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "metadata": {
        "id": "9WK-J5dQpprm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e70fa8-8720-4bbb-a3b3-02a3f597322c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check model passes"
      ],
      "metadata": {
        "id": "91uobQaIu-iE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "metadata": {
        "id": "YINTv-Uu8HP5"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = X_train[1]\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGAgJwGg08-j",
        "outputId": "bc61c4c7-9a9e-428a-b8e0-0521f5aea241"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_word_ids', 'input_type_ids', 'input_mask']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [  101  1999  5688 11416  6024  4275  2024  4738  2000 25845  1996  4101]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "metadata": {
        "id": "U2o1JW9b9MHu"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW0iEt6Z9PKt",
        "outputId": "b400717b-887e-4d81-f0ca-2b687b1d0bb6"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.99835694 -0.7678578  -0.21300124  0.08411987 -0.08593949  0.98550844\n",
            "  0.9732349  -0.8306031  -0.55687106 -0.95725054 -0.3960305  -0.94115573]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[ 3.8915187e-01  2.3267061e-01  6.1780311e-02 ... -9.2866874e-01\n",
            "   4.3027106e-01  8.3279318e-01]\n",
            " [ 4.5310837e-01  7.2308904e-01 -3.2866317e-01 ... -1.1163950e-04\n",
            "  -3.3482751e-01  5.7274055e-01]\n",
            " [-2.5876865e-01  1.4199525e+00 -4.2525381e-01 ...  4.9038833e-01\n",
            "   1.4491324e-01  5.7048750e-01]\n",
            " ...\n",
            " [ 2.6529512e-01 -2.3668993e-01  8.4921330e-02 ...  2.0211086e-02\n",
            "   3.9103544e-01  8.9449620e-01]\n",
            " [ 2.9499257e-01  5.8424294e-01 -6.7344594e-01 ... -1.6148384e+00\n",
            "   1.3211843e+00 -6.0517174e-01]\n",
            " [-1.8697177e-01  5.2527428e-01  9.2377967e-01 ... -5.6088662e-01\n",
            "   1.0293359e+00 -7.8856331e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## full model setup"
      ],
      "metadata": {
        "id": "GSyS6XhXvGXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(3, activation='softmax', name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "XWtmKUBu_3kJ"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = build_classifier_model()"
      ],
      "metadata": {
        "id": "Z17Cu4Awc3jA"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check loss function"
      ],
      "metadata": {
        "id": "KgOUUHifvD3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(bert_raw_result)\n",
        "\n",
        "l =  SparseCategoricalFocalLoss(gamma=2,class_weight=class_ratio)\n",
        "test =tf.convert_to_tensor([1.0])\n",
        "l(test,bert_raw_result)"
      ],
      "metadata": {
        "id": "jHqpunBDTKym",
        "outputId": "163d1b08-54ad-4f74-c295-5ee7b028f75c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.1488465 0.2751187 0.5760347]], shape=(1, 3), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.9446458>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Save and Log"
      ],
      "metadata": {
        "id": "hTEGlj9RvLg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "steps_per_epoch = 200 #tf.data.experimental.cardinality(X_train).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 2e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n",
        "\n",
        "# def auc_wrapper(y_true,y_pred):\n",
        "#   print(y_true,y_pred)\n",
        "\n",
        "#   y_true=tf.reshape(y_true,[1])\n",
        "#   print(y_true)\n",
        "#   y_true= tf.cast(y_true, tf.int32)\n",
        "#   print(y_true)\n",
        "#   y_true=tf.one_hot(y_true,depth=3)\n",
        "#   print(y_true)\n",
        "#   return tf.keras.metrics.AUC(multi_label=True)(y_true,y_pred)\n",
        "\n",
        "\n",
        "loss =  SparseCategoricalFocalLoss(gamma=2,class_weight=class_ratio) #tf.keras.losses.MeanSquaredError()\n",
        "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]#, auc_wrapper]#, tf.keras.metrics.AUC(multi_label=True)]\n",
        "\n",
        "\n",
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"citation_BERT_{epoch}\",\n",
        "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
        "        monitor=\"val_sparse_categorical_accuracy\",\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n",
        "]\n"
      ],
      "metadata": {
        "id": "MB9Af5RMCuqP"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Training model with {tfhub_handle_encoder}')\n",
        "# history = classifier_model.fit(x=X_train,y=y_train, validation_data=(X_test,y_test),epochs=epochs,callbacks= callbacks, verbose=True)"
      ],
      "metadata": {
        "id": "89v_3XqEE3HN"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier_model.save_weights(''/content/drive/MyDrive/Text-ML/checkpoint1')"
      ],
      "metadata": {
        "id": "Pox0n2xZjdtX"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect model"
      ],
      "metadata": {
        "id": "Z_fseNCGvY4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "00eGEQhDdMUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017c83e9-ffed-4efb-cffc-1af71865c8f9"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorboard --logdir=logs"
      ],
      "metadata": {
        "id": "Gszh9ZNBbQXe"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.load_weights('/content/drive/MyDrive/Text-ML/checkpoint')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMRXTmWvmBNn",
        "outputId": "9dc583b1-fc08-42c2-e8d1-fab4a2371ed0"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f28fb9c16d0>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preds=classifier_model.predict(X_train,verbose=1)"
      ],
      "metadata": {
        "id": "vCgZJCYsvdMe"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preds_t=classifier_model.predict(X_test,verbose=1)"
      ],
      "metadata": {
        "id": "Wu5a35I1wlOi"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c_mat=tf.math.confusion_matrix(np.argmax(preds,-1),y_train)\n",
        "# ax = sns.heatmap(c_mat,annot=True,linewidths=.5)"
      ],
      "metadata": {
        "id": "_5R4bXyzxoql"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c_mat=tf.math.confusion_matrix(np.argmax(preds_t,-1),y_test)\n",
        "# ax = sns.heatmap(c_mat,annot=True,linewidths=.5)"
      ],
      "metadata": {
        "id": "RPkpGRdDyCz6"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get attention colorings"
      ],
      "metadata": {
        "id": "ZRca_y_Kvq86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1\n"
      ],
      "metadata": {
        "id": "aSNvnkyoJdqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.layers"
      ],
      "metadata": {
        "id": "PR_gDYEQofck",
        "outputId": "931b02d6-c22d-4b3b-ee8e-a1913451d1d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f28e777bd90>,\n",
              " <tensorflow_hub.keras_layer.KerasLayer at 0x7f28e77c58d0>,\n",
              " <tensorflow_hub.keras_layer.KerasLayer at 0x7f28f4fe8a90>,\n",
              " <keras.layers.core.dropout.Dropout at 0x7f28e722e3d0>,\n",
              " <keras.layers.core.dense.Dense at 0x7f28e7160b10>]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from official.nlp import bert \n",
        "import official.nlp.bert.tokenization"
      ],
      "metadata": {
        "id": "bC2uW7zrx7VR"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = bert.tokenization.FullTokenizer(vocab_file='/content/drive/MyDrive/Text-ML/vocab.txt')\n",
        "preprocesser_model = keras.Model(inputs=classifier_model.input,outputs=classifier_model.get_layer('preprocessing').output)\n",
        "encoder_model = keras.Model(inputs=classifier_model.input,outputs=classifier_model.get_layer('BERT_encoder').output)"
      ],
      "metadata": {
        "id": "Lnb_ie7zxpbc"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocab size:\", len(tokenizer.vocab))"
      ],
      "metadata": {
        "id": "mjgJ0WAwRjYb",
        "outputId": "8e21bbb7-8b64-4870-e912-65bed4f7049d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 30522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attnetion token mapping"
      ],
      "metadata": {
        "id": "z7DPKDmPI9yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attn(context,prep,encoder): # assume stirng array input\n",
        "  t_context=tf.convert_to_tensor(context)\n",
        "\n",
        "  p_out=prep(t_context)\n",
        "  #print(p_out)\n",
        "  stop_index=0\n",
        "  while(stop_index< p_out[\"input_mask\"].shape[1] and p_out[\"input_mask\"][0][stop_index] == 1):\n",
        "    stop_index+=1\n",
        "  \n",
        "  if stop_index >= 128:\n",
        "    stop_index=127\n",
        "\n",
        "  output = encoder(t_context)\n",
        "  #print(output[\"sequence_output\"].shape)\n",
        "  valid_entries=output[\"sequence_output\"][:,1:stop_index-1,:]\n",
        "  a=tf.math.reduce_mean(valid_entries,-1)\n",
        "  mean=tf.math.reduce_mean(a,-1,keepdims=True)\n",
        "  std=tf.math.reduce_std(a,-1,keepdims=True)\n",
        "  a1=(a-mean)/std\n",
        "\n",
        "  return a1"
      ],
      "metadata": {
        "id": "NC_Cyexu9TQI"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attn_for_words(context,tokenizer,prep,encoder):\n",
        "  attn = get_attn(context,prep,encoder).numpy()\n",
        "  tokens = tokenizer.tokenize(context[0]) \n",
        "\n",
        "  indicies=np.ones((len(tokens)),dtype=int)\n",
        "  for i,tok in enumerate(tokens):\n",
        "    if '##' in tok:\n",
        "      indicies[i]=0\n",
        "\n",
        "  full_words=tokens.copy()\n",
        "  ix=-1\n",
        "  for i,tok in enumerate(tokens):\n",
        "    if not indicies[i]:\n",
        "      attn[0][ix]+=attn[0][i]\n",
        "      full_words[ix]+=tok[2:]\n",
        "    else:\n",
        "      ix=i\n",
        "\n",
        "  t_f=tf.convert_to_tensor(full_words) #stores as byte string...\n",
        "  masked_f=tf.boolean_mask(t_f,indicies)\n",
        "  t_a=tf.convert_to_tensor(attn)[0]\n",
        "  masked_a=tf.boolean_mask(t_a[:len(indicies)],indicies)\n",
        "  \n",
        "\n",
        "  return masked_f.numpy(),masked_a.numpy()\n",
        "\n",
        "#words, at=get_attn_for_words(processed,tokenizer,preprocesser_model,encoder_model)"
      ],
      "metadata": {
        "id": "iyhKVIiY121W"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## converters and annotation"
      ],
      "metadata": {
        "id": "kj_6JUFQIvG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_for_input(raw_context):\n",
        "  c1,_ =remove_matches(text=raw_context,regex=re_apa)\n",
        "  c2,_ =remove_matches(text=c1,regex='[^\\w_\\-0-9 ]+')\n",
        "  return [c2]\n",
        "\n",
        "#process_for_input(example)"
      ],
      "metadata": {
        "id": "PTVxz5uFJZyI"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_bytes_strs(words):\n",
        "  return [w.decode('UTF-8') for w in list(words)]"
      ],
      "metadata": {
        "id": "uFUPhtLDH5SS"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_to_color(attn): #blue pos red neg\n",
        "  rgbs = np.zeros((len(attn),3),dtype=int)\n",
        "  for i,score in enumerate(attn):\n",
        "    if score < 0:\n",
        "      rgbs[i][0]=-255*score//2\n",
        "    else:\n",
        "      rgbs[i][2]=255*score//2\n",
        "  \n",
        "  return rgbs"
      ],
      "metadata": {
        "id": "yDhvZkOFMFJ3"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coloring(text,fore=None,back=None):\n",
        "    txt=text\n",
        "    if fore != None and fore[0] != -1:\n",
        "      txt = \"\\033[38;2;{};{};{}m\".format(fore[0], fore[1], fore[2])+txt\n",
        "    if back != None and back[0] != -1:\n",
        "      txt = \"\\033[48;2;{};{};{}m\".format(back[0], back[1], back[2])+txt\n",
        "    return txt\n",
        "\n",
        "#print(coloring('Hello',back=[500,0,0]) + coloring('Hello', back=(0,0,255)))"
      ],
      "metadata": {
        "id": "X8GvqhLvOR8H"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_class(text,model,d=3):\n",
        "  codes=tf.constant([[-1.0,0.0,1.0]])\n",
        "  pred=model.predict(text)[0]\n",
        "  i=tf.argmax(pred)\n",
        "  res=codes*pred\n",
        "  def roundDown(n, d=2):\n",
        "    d = int('1' + ('0' * d))\n",
        "    return np.floor(np.array(n) * d) / d\n",
        "  pred=roundDown(pred,d)\n",
        "  score=tf.math.reduce_mean(res,-1)[0].numpy()\n",
        "  classification=roundDown(codes[0,i].numpy(),d)\n",
        "  max_confidence=pred[i]\n",
        "  return classification,max_confidence,roundDown(score,d),list(pred)"
      ],
      "metadata": {
        "id": "Uc5Sg-uKYigY"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## full pipeline"
      ],
      "metadata": {
        "id": "spUdAeqoI0Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def color_by_attn(text,toker,preper,encoder):\n",
        "  all_words_original=text.split()\n",
        "  all_words=text.lower().split()\n",
        "  processed= process_for_input(text)\n",
        "\n",
        "  words, at=get_attn_for_words(processed,tokenizer,preprocesser_model,encoder_model)\n",
        "\n",
        "  total_at_abs=np.sum(np.absolute(at))\n",
        "\n",
        "  ws=conv_bytes_strs(words)\n",
        "  conv=conv_to_color(at)\n",
        "  mapping=dict(zip(ws,conv))\n",
        "  orig_mapping=dict(zip(all_words,all_words_original))\n",
        "\n",
        "  for i,w in enumerate(all_words):\n",
        "    if w not in mapping:\n",
        "      mapping[w]=[0,0,0] #make black\n",
        "    else:\n",
        "      mapping[w]=list(mapping[w])\n",
        "\n",
        "  colored=[coloring(orig_mapping[word],fore=[255,255,255],back=mapping[word]) for word in all_words]\n",
        "  printed=' '.join(colored)\n",
        "  return printed,total_at_abs"
      ],
      "metadata": {
        "id": "hossOHKtZ1Wn"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF text extratction\n"
      ],
      "metadata": {
        "id": "TD_FQ6ioGFGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_pdf_to_string(file_path):\n",
        "\toutput_string = StringIO()\n",
        "\twith open(file_path, 'rb') as in_file:\n",
        "\t    parser = PDFParser(in_file)\n",
        "\t    doc = PDFDocument(parser)\n",
        "\t    rsrcmgr = PDFResourceManager()\n",
        "\t    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
        "\t    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "\t    for page in PDFPage.create_pages(doc):\n",
        "\t        interpreter.process_page(page)\n",
        "\n",
        "\treturn(output_string.getvalue())\n",
        " \n",
        "def sent_extract(sample):\n",
        "\tdelims=re.findall('\\. +[A-Z]',sample)\n",
        "\tsents=re.split('\\. +[A-Z]',sample)\n",
        "\n",
        "\tsents[0]=sents[0]+'.'\n",
        "\tfor i,s in enumerate(sents[1:]):\n",
        "\t\tsents[i+1]=delims[i][-1]+s+'.'\n",
        "\tfor i,s in enumerate(sents):\n",
        "\t\tsents[i]=re.sub('\\d+https(\\w|\\:|\\/|\\.|\\?|\\=|\\-|\\&)+','',s)\n",
        "\t\n",
        "\treturn sents\n",
        "\n",
        "def pdf_text_extract(path):\n",
        "  text=convert_pdf_to_string(path)\n",
        "  text1 = text.replace('\\x0c','')\n",
        "  text2 = text1.split('.\\n\\n')\n",
        "  refine=[t.replace('\\n',' ') for t in text2]\n",
        "  r=[]\n",
        "  for t in refine:\n",
        "    r+=sent_extract(t)\n",
        "  return r"
      ],
      "metadata": {
        "id": "HkUe38wlJSov"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_content(text):\n",
        "  abs_end=0\n",
        "  ref_start=len(text)-1\n",
        "  while abs_end< len(text) and 'INTRODUCTION' not in text[abs_end]: #start at the intro\n",
        "    abs_end+=1\n",
        "  end_first=abs_end\n",
        "  while  end_first< len(text) and '∗' not in text[end_first]: #start at the intro\n",
        "    end_first+=1\n",
        "  copy_mark=end_first\n",
        "  while  copy_mark< len(text) and '©' not in text[copy_mark]: #start at the intro\n",
        "    copy_mark+=1\n",
        "  while  ref_start> 0 and 'REFERENCES' not in text[ref_start]: \n",
        "    ref_start-=1\n",
        "  \n",
        "  if abs_end == len(text): #fail and return\n",
        "    return text\n",
        "  return text[abs_end:end_first]+text[copy_mark+1:ref_start]"
      ],
      "metadata": {
        "id": "O9lsV2ij-2vn"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coloring of a PDF"
      ],
      "metadata": {
        "id": "_Td1mswaCOFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/Text-ML/phocus.pdf'\n",
        "text=pdf_text_extract(path)"
      ],
      "metadata": {
        "id": "h_EqFHH0E359"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content=get_content(text)"
      ],
      "metadata": {
        "id": "D3RjXhrfE9Ex"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_text(content,p=True,print_err=False):\n",
        "  errs=[]\n",
        "  dfs=[]\n",
        "  sect='Unknown'\n",
        "  cols=['sentence','section','class','confidence','net score','net attention','neg','neu','pos','text','colored']\n",
        "  i=0\n",
        "  for t in content:\n",
        "    try:\n",
        "      if ', ,' in t or len(t) < 20:\n",
        "        continue\n",
        "      match =re.match('^\\d+ [A-Z]+ ?(\\w+)? [A-Z]',t)\n",
        "      sp=1\n",
        "      if match != None:\n",
        "        sp=match.span()[1]-2\n",
        "        if p:\n",
        "          print(t[:sp])\n",
        "        sect=re.split('\\d+ ',t[:sp])[1]\n",
        "        t=t[sp:]\n",
        "\n",
        "      c,conf,sc,raw=text_class([t],classifier_model)\n",
        "      colored,abs_at=color_by_attn(t,tokenizer,preprocesser_model,encoder_model)\n",
        "      df_t = pd.DataFrame([[i,sect,c,conf,sc,abs_at,raw[0],raw[1],raw[2],t,colored]],columns=cols)\n",
        "      if p:\n",
        "        print(i,c,conf,colored)\n",
        "      dfs.append(df_t)\n",
        "      i+=1\n",
        "        \n",
        "    except Exception:\n",
        "      if print_err:\n",
        "        print('err:', t)\n",
        "  \n",
        "  return pd.concat(dfs)"
      ],
      "metadata": {
        "id": "AcFhtVjoCRTh"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_phocus=label_text(content)"
      ],
      "metadata": {
        "id": "HCuOwjdTFXMc"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_phocus"
      ],
      "metadata": {
        "id": "tovj8h9QN3Ft"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full paper labeling pipeline"
      ],
      "metadata": {
        "id": "TUncqdGaHkrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label(path,p=True,print_err=False):\n",
        "  text=pdf_text_extract(path)\n",
        "  content=get_content(text)\n",
        "  return text,content,label_text(content,p,print_err)"
      ],
      "metadata": {
        "id": "6u0N5kqAHqs3"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Click the run button to upload the pdf you want to scan.\n",
        "from google.colab import files\n",
        "! cd \"/content\"\n",
        "uploaded = files.upload()\n",
        "\n",
        "pdf = \"/content/\" + list(uploaded.keys())[0]"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "96qyZyoLCMfb",
        "outputId": "1b34d4f8-4c37-44da-9718-edb6eefb648b"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-394cf884-7679-475b-81a8-dd8f07f33458\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-394cf884-7679-475b-81a8-dd8f07f33458\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bhi-ar-2016.pdf to bhi-ar-2016 (2).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c=label(pdf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7vcuukHRaPp",
        "outputId": "c483ce60-d66b-4437-f350-a1ddf17966c6"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.0 0.659 \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mINTRODUCTION \u001b[48;2;0;0;139m\u001b[38;2;255;255;255mActivity \u001b[48;2;0;0;191m\u001b[38;2;255;255;255mrecognition \u001b[48;2;318;0;0m\u001b[38;2;255;255;255mresearch \u001b[48;2;250;0;0m\u001b[38;2;255;255;255moriginally \u001b[48;2;0;0;227m\u001b[38;2;255;255;255mutilized \u001b[48;2;75;0;0m\u001b[38;2;255;255;255mspecially \u001b[48;2;199;0;0m\u001b[38;2;255;255;255mengineered \u001b[48;2;48;0;0m\u001b[38;2;255;255;255mdevices \u001b[48;2;0;0;45m\u001b[38;2;255;255;255mdistributed \u001b[48;2;0;0;2m\u001b[38;2;255;255;255macross \u001b[48;2;0;0;115m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msubject’s \u001b[48;2;118;0;0m\u001b[38;2;255;255;255mbody \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[2, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m6, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m11] \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;182;0;0m\u001b[38;2;255;255;255midentify \u001b[48;2;0;0;186m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msubject’s \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mphysical \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities, \u001b[48;2;88;0;0m\u001b[38;2;255;255;255mbut \u001b[48;2;0;0;121m\u001b[38;2;255;255;255min \u001b[48;2;80;0;0m\u001b[38;2;255;255;255mrecent \u001b[48;2;0;0;30m\u001b[38;2;255;255;255myears \u001b[48;2;39;0;0m\u001b[38;2;255;255;255mmuch \u001b[48;2;0;0;140m\u001b[38;2;255;255;255mof \u001b[48;2;100;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;318;0;0m\u001b[38;2;255;255;255mresearch \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mbegan \u001b[48;2;0;0;256m\u001b[38;2;255;255;255mutilizing \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mcommercial \u001b[48;2;0;0;53m\u001b[38;2;255;255;255msmartphones \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[7, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m9, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m11, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m14], \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;239m\u001b[38;2;255;255;255minclude \u001b[48;2;0;0;186m\u001b[38;2;255;255;255mthe \u001b[48;2;204;0;0m\u001b[38;2;255;255;255mrequisite \u001b[48;2;0;0;46m\u001b[38;2;255;255;255msensors \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(i.e., \u001b[48;2;0;0;47m\u001b[38;2;255;255;255maccelerometers \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mgyroscopes).\n",
            "1 0.0 0.536 \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;179m\u001b[38;2;255;255;255muse \u001b[48;2;0;0;203m\u001b[38;2;255;255;255mof \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mthese \u001b[48;2;0;0;103m\u001b[38;2;255;255;255mubiquitous \u001b[48;2;23;0;0m\u001b[38;2;255;255;255mcommercial \u001b[48;2;103;0;0m\u001b[38;2;255;255;255mdevices \u001b[48;2;161;0;0m\u001b[38;2;255;255;255mgreatly \u001b[48;2;117;0;0m\u001b[38;2;255;255;255mexpanded \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;8;0;0m\u001b[38;2;255;255;255mapplications \u001b[48;2;0;0;203m\u001b[38;2;255;255;255mof \u001b[48;2;106;0;0m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrecognition, \u001b[48;2;0;0;74m\u001b[38;2;255;255;255mbut \u001b[48;2;0;0;108m\u001b[38;2;255;255;255malso \u001b[48;2;0;0;217m\u001b[38;2;255;255;255mintroduced \u001b[48;2;0;0;42m\u001b[38;2;255;255;255mlimitations \u001b[48;2;0;0;86m\u001b[38;2;255;255;255mdue \u001b[48;2;0;0;41m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mtheir \u001b[48;2;0;0;20m\u001b[38;2;255;255;255mplacement \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;31m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255muser’s \u001b[48;2;243;0;0m\u001b[38;2;255;255;255mbody \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;23;0;0m\u001b[38;2;255;255;255minconsistent \u001b[48;2;0;0;0m\u001b[38;2;255;255;255morientation.\n",
            "2 -1.0 0.636 \u001b[48;2;0;0;192m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mexample, \u001b[48;2;54;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;47;0;0m\u001b[38;2;255;255;255msmartphone \u001b[48;2;0;0;96m\u001b[38;2;255;255;255mcould \u001b[48;2;180;0;0m\u001b[38;2;255;255;255mshift \u001b[48;2;0;0;164m\u001b[38;2;255;255;255min \u001b[48;2;0;0;74m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mperson’s \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mpocket \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;54;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mpocket \u001b[48;2;94;0;0m\u001b[38;2;255;255;255mposition \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(near \u001b[48;2;54;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;171;0;0m\u001b[38;2;255;255;255mupper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mthigh) \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mis \u001b[48;2;85;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;24;0;0m\u001b[38;2;255;255;255mideal \u001b[48;2;0;0;192m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;144m\u001b[38;2;255;255;255mtracking \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhand-based \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities.\n",
            "3 1.0 0.416 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mSmartphone-based \u001b[48;2;0;0;2m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;191m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mespecially \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mlimited \u001b[48;2;0;0;86m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwomen, \u001b[48;2;0;0;156m\u001b[38;2;255;255;255msince \u001b[48;2;0;0;110m\u001b[38;2;255;255;255mthey \u001b[48;2;183;0;0m\u001b[38;2;255;255;255mtypically \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mdo \u001b[48;2;199;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mkeep \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;185;0;0m\u001b[38;2;255;255;255mphone \u001b[48;2;0;0;9m\u001b[38;2;255;255;255min \u001b[48;2;0;0;49m\u001b[38;2;255;255;255mtheir \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpocket.\n",
            "4 1.0 0.929 \u001b[48;2;0;0;121m\u001b[38;2;255;255;255mMost \u001b[48;2;0;0;270m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;204m\u001b[38;2;255;255;255mthese \u001b[48;2;94;0;0m\u001b[38;2;255;255;255mlimitations \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mare \u001b[48;2;165;0;0m\u001b[38;2;255;255;255maddressed \u001b[48;2;0;0;57m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartwatches, \u001b[48;2;0;0;65m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mare \u001b[48;2;189;0;0m\u001b[38;2;255;255;255mworn \u001b[48;2;0;0;135m\u001b[38;2;255;255;255min \u001b[48;2;0;0;67m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;43m\u001b[38;2;255;255;255mconsistent \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mposition \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;65m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mare \u001b[48;2;152;0;0m\u001b[38;2;255;255;255mideally \u001b[48;2;115;0;0m\u001b[38;2;255;255;255msituated \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mtracking \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhand-based \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities.\n",
            "5 1.0 0.863 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFurthermore, \u001b[48;2;0;0;185m\u001b[38;2;255;255;255msince \u001b[48;2;0;0;230m\u001b[38;2;255;255;255mvirtually \u001b[48;2;0;0;125m\u001b[38;2;255;255;255mall \u001b[48;2;299;0;0m\u001b[38;2;255;255;255msmartwatches \u001b[48;2;0;0;43m\u001b[38;2;255;255;255mwork \u001b[48;2;0;0;120m\u001b[38;2;255;255;255min \u001b[48;2;94;0;0m\u001b[38;2;255;255;255mtandem \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartphones, \u001b[48;2;68;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;103;0;0m\u001b[38;2;255;255;255msensor \u001b[48;2;198;0;0m\u001b[38;2;255;255;255minformation \u001b[48;2;17;0;0m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;8m\u001b[38;2;255;255;255mboth \u001b[48;2;175;0;0m\u001b[38;2;255;255;255mdevices \u001b[48;2;28;0;0m\u001b[38;2;255;255;255mcan \u001b[48;2;0;0;119m\u001b[38;2;255;255;255mbe \u001b[48;2;80;0;0m\u001b[38;2;255;255;255mutilized \u001b[48;2;0;0;212m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;115m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrecognition.\n",
            "6 1.0 0.723 \u001b[48;2;84;0;0m\u001b[38;2;255;255;255mThis \u001b[48;2;62;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;164;0;0m\u001b[38;2;255;255;255mexamines \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;134m\u001b[38;2;255;255;255muse \u001b[48;2;0;0;229m\u001b[38;2;255;255;255mof \u001b[48;2;127;0;0m\u001b[38;2;255;255;255msmartphones \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;374;0;0m\u001b[38;2;255;255;255msmartwatches \u001b[48;2;0;0;133m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrecognition.\n",
            "7 1.0 0.906 \u001b[48;2;0;0;59m\u001b[38;2;255;255;255mthe \u001b[48;2;49;0;0m\u001b[38;2;255;255;255mperformance \u001b[48;2;0;0;302m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartphone-based \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;209m\u001b[38;2;255;255;255mrecognition \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;178;0;0m\u001b[38;2;255;255;255mcompared \u001b[48;2;0;0;118m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;59m\u001b[38;2;255;255;255mthe \u001b[48;2;49;0;0m\u001b[38;2;255;255;255mperformance \u001b[48;2;0;0;302m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartwatch-based \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrecognition— \u001b[48;2;0;0;61m\u001b[38;2;255;255;255malthough \u001b[48;2;182;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;0;155m\u001b[38;2;255;255;255mrecognize \u001b[48;2;0;0;87m\u001b[38;2;255;255;255mthat \u001b[48;2;49;0;0m\u001b[38;2;255;255;255multimately \u001b[48;2;0;0;72m\u001b[38;2;255;255;255ma \u001b[48;2;19;0;0m\u001b[38;2;255;255;255mcombination \u001b[48;2;0;0;302m\u001b[38;2;255;255;255mof \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mboth \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mdevices \u001b[48;2;119;0;0m\u001b[38;2;255;255;255mmay \u001b[48;2;103;0;0m\u001b[38;2;255;255;255mwork \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mbest.\n",
            "8 1.0 0.594 \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;38m\u001b[38;2;255;255;255mefficacy \u001b[48;2;0;0;137m\u001b[38;2;255;255;255mof \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;178;0;0m\u001b[38;2;255;255;255msmartwatch \u001b[48;2;460;0;0m\u001b[38;2;255;255;255maccelerometer \u001b[48;2;21;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;108;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;223;0;0m\u001b[38;2;255;255;255mcompared \u001b[48;2;0;0;139m\u001b[38;2;255;255;255mwith \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;38m\u001b[38;2;255;255;255mefficacy \u001b[48;2;0;0;137m\u001b[38;2;255;255;255mof \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;288m\u001b[38;2;255;255;255mperforming \u001b[48;2;0;0;152m\u001b[38;2;255;255;255mactivity \u001b[48;2;178;0;0m\u001b[38;2;255;255;255msmartwatch \u001b[48;2;219;0;0m\u001b[38;2;255;255;255mgyroscope \u001b[48;2;0;0;4m\u001b[38;2;255;255;255msensor \u001b[48;2;0;0;150m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrecognition.\n",
            "9 1.0 0.673 \u001b[48;2;128;0;0m\u001b[38;2;255;255;255mOur \u001b[48;2;90;0;0m\u001b[38;2;255;255;255mprior \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mresearch \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mdemonstrated \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartphone-based \u001b[48;2;22;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;0;0;122m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;195m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels— \u001b[48;2;52;0;0m\u001b[38;2;255;255;255mbuilt \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mwith \u001b[48;2;159;0;0m\u001b[38;2;255;255;255mtraining \u001b[48;2;293;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;86;0;0m\u001b[38;2;255;255;255mfrom \u001b[48;2;115;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;35;0;0m\u001b[38;2;255;255;255mintended \u001b[48;2;0;0;0m\u001b[38;2;255;255;255muser—vastly \u001b[48;2;480;0;0m\u001b[38;2;255;255;255moutperform \u001b[48;2;0;0;120m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels, \u001b[48;2;58;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;214m\u001b[38;2;255;255;255mthis \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mstudy \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mshows \u001b[48;2;0;0;143m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;214m\u001b[38;2;255;255;255mthis \u001b[48;2;75;0;0m\u001b[38;2;255;255;255madvantage \u001b[48;2;0;0;38m\u001b[38;2;255;255;255mextends \u001b[48;2;0;0;124m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartwatch-based \u001b[48;2;0;0;122m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;195m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels.\n",
            "10 0.0 0.75 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFinally, \u001b[48;2;0;0;99m\u001b[38;2;255;255;255mthis \u001b[48;2;67;0;0m\u001b[38;2;255;255;255mstudy \u001b[48;2;120;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;18;0;0m\u001b[38;2;255;255;255mextends \u001b[48;2;101;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;166;0;0m\u001b[38;2;255;255;255mprior \u001b[48;2;0;0;152m\u001b[38;2;255;255;255mwork \u001b[48;2;0;0;143m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;288m\u001b[38;2;255;255;255mrecognizing \u001b[48;2;33;0;0m\u001b[38;2;255;255;255mmany \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mmore \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities, \u001b[48;2;0;0;112m\u001b[38;2;255;255;255mincluding \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhand-based \u001b[48;2;0;0;112m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(e.g., \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mtyping \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwriting).\n",
            "11 0.0 0.905 \u001b[48;2;0;0;213m\u001b[38;2;255;255;255mOf \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mspecial \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mnote, \u001b[48;2;0;0;84m\u001b[38;2;255;255;255mthis \u001b[48;2;134;0;0m\u001b[38;2;255;255;255mstudy \u001b[48;2;0;0;89m\u001b[38;2;255;255;255mincludes \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mmany \u001b[48;2;0;0;0m\u001b[38;2;255;255;255meating-related \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(e.g., \u001b[48;2;0;0;64m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msoup, \u001b[48;2;0;0;64m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;10m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msandwich, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdrinking), \u001b[48;2;0;0;55m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mopens \u001b[48;2;319;0;0m\u001b[38;2;255;255;255mup \u001b[48;2;0;0;42m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mpossibility \u001b[48;2;0;0;57m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mnew \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhealth-related \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mapplications.\n",
            "12 1.0 0.798 \u001b[48;2;0;0;137m\u001b[38;2;255;255;255mthe \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;68m\u001b[38;2;255;255;255min \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;80;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mdemonstrate \u001b[48;2;0;0;139m\u001b[38;2;255;255;255mthat \u001b[48;2;377;0;0m\u001b[38;2;255;255;255msmartwatches \u001b[48;2;0;0;168m\u001b[38;2;255;255;255mhave \u001b[48;2;0;0;137m\u001b[38;2;255;255;255mthe \u001b[48;2;109;0;0m\u001b[38;2;255;255;255mpotential \u001b[48;2;0;0;30m\u001b[38;2;255;255;255mto \u001b[48;2;207;0;0m\u001b[38;2;255;255;255maccurately \u001b[48;2;58;0;0m\u001b[38;2;255;255;255midentify \u001b[48;2;0;0;44m\u001b[38;2;255;255;255ma \u001b[48;2;191;0;0m\u001b[38;2;255;255;255mlarge \u001b[48;2;0;0;48m\u001b[38;2;255;255;255mvariety \u001b[48;2;0;0;319m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities, \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mincluding \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhand-based \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255meating-based \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;139m\u001b[38;2;255;255;255mthat \u001b[48;2;183;0;0m\u001b[38;2;255;255;255mcannot \u001b[48;2;0;0;202m\u001b[38;2;255;255;255mbe \u001b[48;2;59;0;0m\u001b[38;2;255;255;255meffectively \u001b[48;2;20;0;0m\u001b[38;2;255;255;255mrecognized \u001b[48;2;0;0;181m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartphones.\n",
            "13 1.0 0.575 \u001b[48;2;0;0;67m\u001b[38;2;255;255;255mConsistent \u001b[48;2;0;0;308m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;49m\u001b[38;2;255;255;255mour \u001b[48;2;0;0;23m\u001b[38;2;255;255;255mprior \u001b[48;2;143;0;0m\u001b[38;2;255;255;255msmartphone \u001b[48;2;0;0;77m\u001b[38;2;255;255;255mwork \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[7, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m9], \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mclassification \u001b[48;2;0;0;67m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mare \u001b[48;2;161;0;0m\u001b[38;2;255;255;255minduced \u001b[48;2;0;0;61m\u001b[38;2;255;255;255mfrom \u001b[48;2;141;0;0m\u001b[38;2;255;255;255mlabeled \u001b[48;2;109;0;0m\u001b[38;2;255;255;255mtraining \u001b[48;2;222;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;105m\u001b[38;2;255;255;255musing \u001b[48;2;124;0;0m\u001b[38;2;255;255;255mstandard \u001b[48;2;162;0;0m\u001b[38;2;255;255;255mmachine \u001b[48;2;101;0;0m\u001b[38;2;255;255;255mlearning \u001b[48;2;0;0;0m\u001b[38;2;255;255;255malgorithms. \u001b[48;2;62;0;0m\u001b[38;2;255;255;255mrisks \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;110;0;0m\u001b[38;2;255;255;255mhealth \u001b[48;2;275;0;0m\u001b[38;2;255;255;255mSmartwatch \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartphone-based \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;222m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;176m\u001b[38;2;255;255;255mhas \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mmany \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mapplications \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[8].\n",
            "14 0.0 0.916 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mGenerally, \u001b[48;2;0;0;167m\u001b[38;2;255;255;255mthese \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mdevices \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mcan \u001b[48;2;0;0;70m\u001b[38;2;255;255;255moperate \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mmore \u001b[48;2;28;0;0m\u001b[38;2;255;255;255mintelligently \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mif \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mthey \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mare \u001b[48;2;176;0;0m\u001b[38;2;255;255;255maware \u001b[48;2;0;0;166m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;9m\u001b[38;2;255;255;255mwhat \u001b[48;2;0;0;147m\u001b[38;2;255;255;255mtheir \u001b[48;2;125;0;0m\u001b[38;2;255;255;255muser \u001b[48;2;77;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;278;0;0m\u001b[38;2;255;255;255mdoing \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(e.g., \u001b[48;2;0;0;192m\u001b[38;2;255;255;255mforwarding \u001b[48;2;0;0;130m\u001b[38;2;255;255;255ma \u001b[48;2;95;0;0m\u001b[38;2;255;255;255mcall \u001b[48;2;0;0;223m\u001b[38;2;255;255;255mto \u001b[48;2;93;0;0m\u001b[38;2;255;255;255mvoicemail \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mduring \u001b[48;2;0;0;130m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmeal).\n",
            "15 1.0 0.934 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHowever, \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;18m\u001b[38;2;255;255;255mmain \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mapplication \u001b[48;2;0;0;300m\u001b[38;2;255;255;255mof \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;236;0;0m\u001b[38;2;255;255;255mresearch \u001b[48;2;0;0;42m\u001b[38;2;255;255;255mhas \u001b[48;2;0;0;58m\u001b[38;2;255;255;255mbeen \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mto \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mimprove \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpeople’s \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mhealth \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwellbeing.\n",
            "16 1.0 0.884 \u001b[48;2;0;0;174m\u001b[38;2;255;255;255mPhysical \u001b[48;2;0;0;211m\u001b[38;2;255;255;255minactivity \u001b[48;2;0;0;124m\u001b[38;2;255;255;255mand \u001b[48;2;295;0;0m\u001b[38;2;255;255;255munhealthy \u001b[48;2;49;0;0m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;31m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mtwo \u001b[48;2;0;0;169m\u001b[38;2;255;255;255mof \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mmost \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpowerful, \u001b[48;2;513;0;0m\u001b[38;2;255;255;255mmodifiable \u001b[48;2;0;0;2m\u001b[38;2;255;255;255mrisk \u001b[48;2;275;0;0m\u001b[38;2;255;255;255mfactors \u001b[48;2;0;0;94m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdisease.\n",
            "17 1.0 0.456 \u001b[48;2;17;0;0m\u001b[38;2;255;255;255mPerforming \u001b[48;2;101;0;0m\u001b[38;2;255;255;255ma \u001b[48;2;180;0;0m\u001b[38;2;255;255;255msufficient \u001b[48;2;160;0;0m\u001b[38;2;255;255;255mamount \u001b[48;2;0;0;141m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mphysical \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mactivity \u001b[48;2;108;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;220;0;0m\u001b[38;2;255;255;255mimportant \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mbecause \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mphysical \u001b[48;2;294;0;0m\u001b[38;2;255;255;255minactivity \u001b[48;2;195;0;0m\u001b[38;2;255;255;255mdramatically \u001b[48;2;225;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;103m\u001b[38;2;255;255;255mincreases \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mcardiovascular \u001b[48;2;34;0;0m\u001b[38;2;255;255;255mdisease \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[4], \u001b[48;2;0;0;236m\u001b[38;2;255;255;255mcolon \u001b[48;2;44;0;0m\u001b[38;2;255;255;255mcancer \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[5], \u001b[48;2;0;0;46m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;4m\u001b[38;2;255;255;255mmany \u001b[48;2;0;0;203m\u001b[38;2;255;255;255mother \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdiseases—while \u001b[48;2;101;0;0m\u001b[38;2;255;255;255ma \u001b[48;2;221;0;0m\u001b[38;2;255;255;255mhealthy \u001b[48;2;160;0;0m\u001b[38;2;255;255;255mamount \u001b[48;2;0;0;141m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mphysical \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mactivity \u001b[48;2;255;0;0m\u001b[38;2;255;255;255mreduces \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mrisk \u001b[48;2;0;0;141m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mall-cause \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mmortality \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[1] \u001b[48;2;0;0;46m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;76m\u001b[38;2;255;255;255mcould \u001b[48;2;0;0;112m\u001b[38;2;255;255;255mprevent \u001b[48;2;0;0;45m\u001b[38;2;255;255;255mtwo \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mmillion \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mdeaths \u001b[48;2;114;0;0m\u001b[38;2;255;255;255mper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255myear \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[12].\n",
            "18 1.0 0.804 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mSimilarly, \u001b[48;2;0;0;48m\u001b[38;2;255;255;255mthere \u001b[48;2;0;0;9m\u001b[38;2;255;255;255mare \u001b[48;2;117;0;0m\u001b[38;2;255;255;255msignificant \u001b[48;2;0;0;25m\u001b[38;2;255;255;255mhealth \u001b[48;2;148;0;0m\u001b[38;2;255;255;255mrisks \u001b[48;2;56;0;0m\u001b[38;2;255;255;255massociated \u001b[48;2;0;0;294m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;174m\u001b[38;2;255;255;255mexcessive \u001b[48;2;0;0;13m\u001b[38;2;255;255;255mcaloric \u001b[48;2;133;0;0m\u001b[38;2;255;255;255mintake \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[10].\n",
            "19 -1.0 0.822 \u001b[48;2;93;0;0m\u001b[38;2;255;255;255mWhile \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mmany \u001b[48;2;0;0;38m\u001b[38;2;255;255;255mtypes \u001b[48;2;0;0;372m\u001b[38;2;255;255;255mof \u001b[48;2;136;0;0m\u001b[38;2;255;255;255minterventions \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mseek \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mto \u001b[48;2;33;0;0m\u001b[38;2;255;255;255mreduce \u001b[48;2;0;0;7m\u001b[38;2;255;255;255mthe \u001b[48;2;148;0;0m\u001b[38;2;255;255;255mtendency \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mtoward \u001b[48;2;0;0;0m\u001b[38;2;255;255;255movereating, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mlong-term \u001b[48;2;130;0;0m\u001b[38;2;255;255;255mdietary \u001b[48;2;104;0;0m\u001b[38;2;255;255;255madherence \u001b[48;2;73;0;0m\u001b[38;2;255;255;255mremains \u001b[48;2;0;0;73m\u001b[38;2;255;255;255ma \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mmajor \u001b[48;2;148;0;0m\u001b[38;2;255;255;255mchallenge \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[3].\n",
            "20 1.0 0.885 \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mActivity \u001b[48;2;0;0;125m\u001b[38;2;255;255;255mmonitoring \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mcan \u001b[48;2;110;0;0m\u001b[38;2;255;255;255mhelp \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mcombat \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mboth \u001b[48;2;0;0;126m\u001b[38;2;255;255;255minactivity \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;99m\u001b[38;2;255;255;255movereating \u001b[48;2;0;0;197m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;168m\u001b[38;2;255;255;255mproviding \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maccurate, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mreal-time \u001b[48;2;75;0;0m\u001b[38;2;255;255;255minformation \u001b[48;2;45;0;0m\u001b[38;2;255;255;255mabout \u001b[48;2;543;0;0m\u001b[38;2;255;255;255msedentary \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mbehavior, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mexercise, \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mand \u001b[48;2;28;0;0m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mbehavior.\n",
            "21 1.0 0.734 \u001b[48;2;0;0;151m\u001b[38;2;255;255;255mThe \u001b[48;2;254;0;0m\u001b[38;2;255;255;255msmartwatch \u001b[48;2;0;0;133m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;174m\u001b[38;2;255;255;255mperfectly \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mpoised \u001b[48;2;0;0;162m\u001b[38;2;255;255;255mto \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mconvey \u001b[48;2;52;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;121;0;0m\u001b[38;2;255;255;255minformation \u001b[48;2;0;0;6m\u001b[38;2;255;255;255msince \u001b[48;2;0;0;203m\u001b[38;2;255;255;255mit \u001b[48;2;0;0;133m\u001b[38;2;255;255;255mis \u001b[48;2;121;0;0m\u001b[38;2;255;255;255malways \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mreadily \u001b[48;2;182;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;432;0;0m\u001b[38;2;255;255;255munobtrusively \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maccessible—which \u001b[48;2;0;0;137m\u001b[38;2;255;255;255mreason \u001b[48;2;0;0;147m\u001b[38;2;255;255;255mwhy \u001b[48;2;254;0;0m\u001b[38;2;255;255;255msmartwatch \u001b[48;2;0;0;199m\u001b[38;2;255;255;255mmanufacturers \u001b[48;2;166;0;0m\u001b[38;2;255;255;255mtout \u001b[48;2;0;0;110m\u001b[38;2;255;255;255mits \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mpotential \u001b[48;2;0;0;162m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;4m\u001b[38;2;255;255;255mimprove \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhealth.\n",
            "22 1.0 0.729 \u001b[48;2;148;0;0m\u001b[38;2;255;255;255mWhile \u001b[48;2;0;0;208m\u001b[38;2;255;255;255mthere \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mare \u001b[48;2;26;0;0m\u001b[38;2;255;255;255msome \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mbasic \u001b[48;2;0;0;127m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mrecognition \u001b[48;2;153;0;0m\u001b[38;2;255;255;255mapplications \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartwatches, \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;179;0;0m\u001b[38;2;255;255;255mwork \u001b[48;2;4;0;0m\u001b[38;2;255;255;255minvolves \u001b[48;2;150;0;0m\u001b[38;2;255;255;255mmuch \u001b[48;2;127;0;0m\u001b[38;2;255;255;255mmore \u001b[48;2;90;0;0m\u001b[38;2;255;255;255mspecific \u001b[48;2;0;0;46m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(including \u001b[48;2;0;0;198m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;42m\u001b[38;2;255;255;255mvariety \u001b[48;2;0;0;265m\u001b[38;2;255;255;255mof \u001b[48;2;55;0;0m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities).\n",
            "23 0.0 0.713 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mSmartwatch-based \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mapps \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mcapable \u001b[48;2;0;0;261m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mtracking \u001b[48;2;0;0;44m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;171m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mcould \u001b[48;2;194;0;0m\u001b[38;2;255;255;255multimately \u001b[48;2;21;0;0m\u001b[38;2;255;255;255mreplace \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(or \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maugment) \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mthe \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mmanually \u001b[48;2;84;0;0m\u001b[38;2;255;255;255mintensive \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mmethods \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mmaintaining \u001b[48;2;0;0;239m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mfood \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdiary. \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;9m\u001b[38;2;255;255;255mone \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m*This \u001b[48;2;287;0;0m\u001b[38;2;255;255;255mmaterial \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mis \u001b[48;2;286;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mupon \u001b[48;2;75;0;0m\u001b[38;2;255;255;255mwork \u001b[48;2;0;0;49m\u001b[38;2;255;255;255msupported \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mthe \u001b[48;2;158;0;0m\u001b[38;2;255;255;255mNational \u001b[48;2;0;0;22m\u001b[38;2;255;255;255mScience \u001b[48;2;0;0;10m\u001b[38;2;255;255;255mFoundation \u001b[48;2;0;0;186m\u001b[38;2;255;255;255munder \u001b[48;2;0;0;20m\u001b[38;2;255;255;255mGrant \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mNo. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1116124.\n",
            "24 0.0 0.973 \u001b[48;2;0;0;88m\u001b[38;2;255;255;255mAll \u001b[48;2;0;0;73m\u001b[38;2;255;255;255mauthors \u001b[48;2;0;0;43m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;176m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mthe \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mDepartment \u001b[48;2;0;0;183m\u001b[38;2;255;255;255mof \u001b[48;2;100;0;0m\u001b[38;2;255;255;255mComputer \u001b[48;2;113;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;145;0;0m\u001b[38;2;255;255;255mInformation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mScience, \u001b[48;2;0;0;151m\u001b[38;2;255;255;255mFordham \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mUniversity, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBronx, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mNY \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m10458 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mUSA. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(Corresponding \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mauthor: \u001b[48;2;110;0;0m\u001b[38;2;255;255;255mPhone \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m718-817-0785; \u001b[48;2;0;0;0m\u001b[38;2;255;255;255memail: \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mgaweiss@fordham.edu).\n",
            "25 0.0 0.826 \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mThe \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;246m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mtask \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mThe \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;246m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mtask \u001b[48;2;0;0;58m\u001b[38;2;255;255;255minvolves \u001b[48;2;0;0;85m\u001b[38;2;255;255;255mmapping \u001b[48;2;159;0;0m\u001b[38;2;255;255;255mtime \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mseries \u001b[48;2;103;0;0m\u001b[38;2;255;255;255msensor \u001b[48;2;214;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;45m\u001b[38;2;255;255;255ma \u001b[48;2;452;0;0m\u001b[38;2;255;255;255msmartwatch \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mand/or \u001b[48;2;69;0;0m\u001b[38;2;255;255;255msmartphone \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;45m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;40m\u001b[38;2;255;255;255msingle \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivity.\n",
            "26 0.0 0.984 \u001b[48;2;0;0;187m\u001b[38;2;255;255;255mIn \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mour \u001b[48;2;0;0;227m\u001b[38;2;255;255;255mapproach \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mthe \u001b[48;2;141;0;0m\u001b[38;2;255;255;255mtime \u001b[48;2;50;0;0m\u001b[38;2;255;255;255mseries \u001b[48;2;86;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mis \u001b[48;2;460;0;0m\u001b[38;2;255;255;255maggregated \u001b[48;2;26;0;0m\u001b[38;2;255;255;255minto \u001b[48;2;133;0;0m\u001b[38;2;255;255;255mexamples \u001b[48;2;93;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;95m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mnon-overlapping \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m10- \u001b[48;2;63;0;0m\u001b[38;2;255;255;255msecond \u001b[48;2;0;0;46m\u001b[38;2;255;255;255mintervals \u001b[48;2;0;0;261m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdata; \u001b[48;2;96;0;0m\u001b[38;2;255;255;255man \u001b[48;2;0;0;150m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mrecognized \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mcorrectly \u001b[48;2;189;0;0m\u001b[38;2;255;255;255mif \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mthe \u001b[48;2;83;0;0m\u001b[38;2;255;255;255msingle \u001b[48;2;0;0;150m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;173m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;6m\u001b[38;2;255;255;255moccurred \u001b[48;2;77;0;0m\u001b[38;2;255;255;255mduring \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m10-second \u001b[48;2;0;0;72m\u001b[38;2;255;255;255minterval \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mis \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mcorrectly \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclassified.\n",
            "27 0.0 0.746 \u001b[48;2;99;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;128;0;0m\u001b[38;2;255;255;255mI \u001b[48;2;124;0;0m\u001b[38;2;255;255;255mlists \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;38m\u001b[38;2;255;255;255meighteen \u001b[48;2;0;0;88m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;264m\u001b[38;2;255;255;255mincluded \u001b[48;2;0;0;149m\u001b[38;2;255;255;255min \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstudy.\n",
            "28 1.0 0.538 \u001b[48;2;0;0;166m\u001b[38;2;255;255;255mThe \u001b[48;2;142;0;0m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;190m\u001b[38;2;255;255;255mare \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mgrouped \u001b[48;2;5;0;0m\u001b[38;2;255;255;255minto \u001b[48;2;122;0;0m\u001b[38;2;255;255;255mthree \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mgeneral \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcategories.\n",
            "29 0.0 0.975 \u001b[48;2;33;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mdetails \u001b[48;2;8;0;0m\u001b[38;2;255;255;255massociated \u001b[48;2;0;0;168m\u001b[38;2;255;255;255mwith \u001b[48;2;33;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;302;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;196;0;0m\u001b[38;2;255;255;255mcollection \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mprocess \u001b[48;2;0;0;85m\u001b[38;2;255;255;255mare \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mdescribed \u001b[48;2;0;0;120m\u001b[38;2;255;255;255min \u001b[48;2;33;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;89;0;0m\u001b[38;2;255;255;255mnext \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msection.\n",
            "30 0.0 0.639 \u001b[48;2;43;0;0m\u001b[38;2;255;255;255mEIGHTEEN \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mUTILIZED \u001b[48;2;0;0;141m\u001b[38;2;255;255;255mIN \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mTHIS \u001b[48;2;30;0;0m\u001b[38;2;255;255;255mSTUDY \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mGeneral \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(not \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhand-oriented) \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;122m\u001b[38;2;255;255;255mWalking \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;103m\u001b[38;2;255;255;255mJogging \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;159m\u001b[38;2;255;255;255mClimbing \u001b[48;2;0;0;81m\u001b[38;2;255;255;255mStairs \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mSitting \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mStanding \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mKicking \u001b[48;2;0;0;94m\u001b[38;2;255;255;255mSoccer \u001b[48;2;0;0;241m\u001b[38;2;255;255;255mBall \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mGeneral \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(hand-oriented) \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;663;0;0m\u001b[38;2;255;255;255mDribbling \u001b[48;2;0;0;197m\u001b[38;2;255;255;255mBasketball \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mPlaying \u001b[48;2;149;0;0m\u001b[38;2;255;255;255mCatch \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;318m\u001b[38;2;255;255;255mTennis \u001b[48;2;0;0;241m\u001b[38;2;255;255;255mBall \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(two \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpeople) \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;57m\u001b[38;2;255;255;255mTyping \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;120m\u001b[38;2;255;255;255mHandwriting \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;220m\u001b[38;2;255;255;255mClapping \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;232m\u001b[38;2;255;255;255mBrushing \u001b[48;2;0;0;216m\u001b[38;2;255;255;255mTeeth \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;79m\u001b[38;2;255;255;255mFolding \u001b[48;2;39;0;0m\u001b[38;2;255;255;255mClothes \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mEating \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(hand-oriented) \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mEating \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mPasta \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mEating \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mSoup \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mEating \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mSandwich \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mEating \u001b[48;2;43;0;0m\u001b[38;2;255;255;255mChips \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mo \u001b[48;2;58;0;0m\u001b[38;2;255;255;255mDrinking \u001b[48;2;67;0;0m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;9m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mCup \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mIII.\n",
            "31 0.0 0.712 \u001b[48;2;145;0;0m\u001b[38;2;255;255;255mEXPERIMENT \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mmethodology \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mmethodology \u001b[48;2;99;0;0m\u001b[38;2;255;255;255massociated \u001b[48;2;0;0;372m\u001b[38;2;255;255;255mwith \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mgenerating \u001b[48;2;18;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;91;0;0m\u001b[38;2;255;255;255mevaluating \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mthe \u001b[48;2;102;0;0m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mmodels \u001b[48;2;21;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;135;0;0m\u001b[38;2;255;255;255mdiscussed \u001b[48;2;0;0;153m\u001b[38;2;255;255;255min \u001b[48;2;33;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msection.\n",
            "32 0.0 0.844 \u001b[48;2;0;0;59m\u001b[38;2;255;255;255mThis \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mincludes \u001b[48;2;0;0;232m\u001b[38;2;255;255;255mthe \u001b[48;2;195;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;168;0;0m\u001b[38;2;255;255;255mcollection \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mprocedure, \u001b[48;2;0;0;232m\u001b[38;2;255;255;255mthe \u001b[48;2;37;0;0m\u001b[38;2;255;255;255mmethod \u001b[48;2;0;0;129m\u001b[38;2;255;255;255mfor \u001b[48;2;34;0;0m\u001b[38;2;255;255;255mtransforming \u001b[48;2;0;0;232m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mlow-level \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtime-series \u001b[48;2;52;0;0m\u001b[38;2;255;255;255msensor \u001b[48;2;195;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;83m\u001b[38;2;255;255;255minto \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mexamples, \u001b[48;2;44;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;232m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mmodel \u001b[48;2;0;0;98m\u001b[38;2;255;255;255minduction \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mprocess.\n",
            "33 0.0 0.985 \u001b[48;2;23;0;0m\u001b[38;2;255;255;255msome \u001b[48;2;0;0;220m\u001b[38;2;255;255;255mof \u001b[48;2;53;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;181;0;0m\u001b[38;2;255;255;255mmaterial \u001b[48;2;0;0;9m\u001b[38;2;255;255;255mhas \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mbeen \u001b[48;2;107;0;0m\u001b[38;2;255;255;255mpresented \u001b[48;2;0;0;189m\u001b[38;2;255;255;255min \u001b[48;2;186;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;294;0;0m\u001b[38;2;255;255;255mprior \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartphone- \u001b[48;2;158;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;38;0;0m\u001b[38;2;255;255;255mwork \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[7, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m9], \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mso \u001b[48;2;0;0;189m\u001b[38;2;255;255;255min \u001b[48;2;0;0;196m\u001b[38;2;255;255;255mthese \u001b[48;2;0;0;219m\u001b[38;2;255;255;255mcases \u001b[48;2;23;0;0m\u001b[38;2;255;255;255msome \u001b[48;2;40;0;0m\u001b[38;2;255;255;255mdetails \u001b[48;2;77;0;0m\u001b[38;2;255;255;255mmay \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mbe \u001b[48;2;139;0;0m\u001b[38;2;255;255;255momitted \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mand \u001b[48;2;90;0;0m\u001b[38;2;255;255;255mreplaced \u001b[48;2;0;0;107m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mappropriate \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcitations.\n",
            "34 0.0 0.967 \u001b[48;2;201;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mCollection \u001b[48;2;0;0;58m\u001b[38;2;255;255;255mthe \u001b[48;2;201;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;80;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;67;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;140;0;0m\u001b[38;2;255;255;255mstudy \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mwas \u001b[48;2;289;0;0m\u001b[38;2;255;255;255mcollected \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mfrom \u001b[48;2;47;0;0m\u001b[38;2;255;255;255m17 \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mtest \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msubjects, \u001b[48;2;0;0;70m\u001b[38;2;255;255;255meach \u001b[48;2;0;0;298m\u001b[38;2;255;255;255mof \u001b[48;2;107;0;0m\u001b[38;2;255;255;255mwhom \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mwere \u001b[48;2;0;0;12m\u001b[38;2;255;255;255masked \u001b[48;2;0;0;89m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;101m\u001b[38;2;255;255;255mperform \u001b[48;2;0;0;58m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;99m\u001b[38;2;255;255;255m18 \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mactivities \u001b[48;2;142;0;0m\u001b[38;2;255;255;255mlisted \u001b[48;2;0;0;157m\u001b[38;2;255;255;255min \u001b[48;2;0;0;46m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mI.\n",
            "35 0.0 0.925 \u001b[48;2;0;0;99m\u001b[38;2;255;255;255mEach \u001b[48;2;0;0;189m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;208m\u001b[38;2;255;255;255mwas \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mperformed \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mfor \u001b[48;2;37;0;0m\u001b[38;2;255;255;255mtwo \u001b[48;2;203;0;0m\u001b[38;2;255;255;255mminutes \u001b[48;2;251;0;0m\u001b[38;2;255;255;255mwhile \u001b[48;2;0;0;125m\u001b[38;2;255;255;255mthe \u001b[48;2;47;0;0m\u001b[38;2;255;255;255msubject \u001b[48;2;0;0;46m\u001b[38;2;255;255;255mwore \u001b[48;2;0;0;180m\u001b[38;2;255;255;255ma \u001b[48;2;321;0;0m\u001b[38;2;255;255;255msmartwatch \u001b[48;2;0;0;81m\u001b[38;2;255;255;255mon \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mtheir \u001b[48;2;179;0;0m\u001b[38;2;255;255;255mdominant \u001b[48;2;0;0;30m\u001b[38;2;255;255;255mhand \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;180m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;30m\u001b[38;2;255;255;255mpaired \u001b[48;2;120;0;0m\u001b[38;2;255;255;255msmartphone \u001b[48;2;0;0;5m\u001b[38;2;255;255;255min \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mtheir \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfront-right \u001b[48;2;103;0;0m\u001b[38;2;255;255;255mpocket \u001b[48;2;0;0;207m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;125m\u001b[38;2;255;255;255mthe \u001b[48;2;151;0;0m\u001b[38;2;255;255;255mphone \u001b[48;2;108;0;0m\u001b[38;2;255;255;255moriented \u001b[48;2;132;0;0m\u001b[38;2;255;255;255mupright \u001b[48;2;0;0;207m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;125m\u001b[38;2;255;255;255mthe \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mscreen \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mfacing \u001b[48;2;0;0;0m\u001b[38;2;255;255;255moutward.\n",
            "36 0.0 0.923 \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mAll \u001b[48;2;223;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;240m\u001b[38;2;255;255;255mwas \u001b[48;2;323;0;0m\u001b[38;2;255;255;255mcollected \u001b[48;2;0;0;0m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;122m\u001b[38;2;255;255;255mthe \u001b[48;2;64;0;0m\u001b[38;2;255;255;255mLG \u001b[48;2;23;0;0m\u001b[38;2;255;255;255mG \u001b[48;2;0;0;25m\u001b[38;2;255;255;255mWatch \u001b[48;2;223;0;0m\u001b[38;2;255;255;255msmartwatch \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;122m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;74m\u001b[38;2;255;255;255mSamsung \u001b[48;2;86;0;0m\u001b[38;2;255;255;255mGalaxy \u001b[48;2;53;0;0m\u001b[38;2;255;255;255mS4 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartphone, \u001b[48;2;0;0;46m\u001b[38;2;255;255;255mboth \u001b[48;2;0;0;261m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;31m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;211m\u001b[38;2;255;255;255mwere \u001b[48;2;102;0;0m\u001b[38;2;255;255;255mrunning \u001b[48;2;0;0;122m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;20m\u001b[38;2;255;255;255mAndroid \u001b[48;2;8;0;0m\u001b[38;2;255;255;255mWear \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mmobile \u001b[48;2;81;0;0m\u001b[38;2;255;255;255moperating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msystem.\n",
            "37 1.0 0.876 \u001b[48;2;0;0;82m\u001b[38;2;255;255;255mThe \u001b[48;2;244;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mcollection \u001b[48;2;0;0;176m\u001b[38;2;255;255;255mprocess \u001b[48;2;0;0;135m\u001b[38;2;255;255;255mtook \u001b[48;2;16;0;0m\u001b[38;2;255;255;255mapproximately \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mone \u001b[48;2;130;0;0m\u001b[38;2;255;255;255mhour \u001b[48;2;0;0;121m\u001b[38;2;255;255;255mper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mperson.\n",
            "38 0.0 0.87 \u001b[48;2;71;0;0m\u001b[38;2;255;255;255mAll \u001b[48;2;0;0;42m\u001b[38;2;255;255;255mtest \u001b[48;2;0;0;104m\u001b[38;2;255;255;255msubjects \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mprovided \u001b[48;2;130;0;0m\u001b[38;2;255;255;255mwritten \u001b[48;2;54;0;0m\u001b[38;2;255;255;255minformed \u001b[48;2;157;0;0m\u001b[38;2;255;255;255mconsent \u001b[48;2;155;0;0m\u001b[38;2;255;255;255mprior \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mto \u001b[48;2;38;0;0m\u001b[38;2;255;255;255mparticipating \u001b[48;2;0;0;51m\u001b[38;2;255;255;255min \u001b[48;2;100;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstudy, \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;270m\u001b[38;2;255;255;255mwas \u001b[48;2;44;0;0m\u001b[38;2;255;255;255mapproved \u001b[48;2;120;0;0m\u001b[38;2;255;255;255mby \u001b[48;2;114;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;0;0;0m\u001b[38;2;255;255;255muniversity’s \u001b[48;2;34;0;0m\u001b[38;2;255;255;255mInstitutional \u001b[48;2;77;0;0m\u001b[38;2;255;255;255mReview \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBoard.\n",
            "39 1.0 0.835 \u001b[48;2;0;0;73m\u001b[38;2;255;255;255mThe \u001b[48;2;277;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;115;0;0m\u001b[38;2;255;255;255mcollection \u001b[48;2;0;0;142m\u001b[38;2;255;255;255mprocess \u001b[48;2;0;0;101m\u001b[38;2;255;255;255mutilizes \u001b[48;2;129;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mcustom \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mdesigned \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartwatch/smartphone \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mapp.\n",
            "40 0.0 0.975 \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mthe \u001b[48;2;305;0;0m\u001b[38;2;255;255;255mapp \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mcollects \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;70m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;10m\u001b[38;2;255;255;255maccelerometer \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;139m\u001b[38;2;255;255;255mgyroscope \u001b[48;2;0;0;150m\u001b[38;2;255;255;255mon \u001b[48;2;227;0;0m\u001b[38;2;255;255;255mboth \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mthe \u001b[48;2;188;0;0m\u001b[38;2;255;255;255mphone \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mand \u001b[48;2;145;0;0m\u001b[38;2;255;255;255mwatch \u001b[48;2;0;0;274m\u001b[38;2;255;255;255mat \u001b[48;2;0;0;80m\u001b[38;2;255;255;255ma \u001b[48;2;148;0;0m\u001b[38;2;255;255;255mrate \u001b[48;2;0;0;33m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m20Hz, \u001b[48;2;0;0;328m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;80m\u001b[38;2;255;255;255meach \u001b[48;2;142;0;0m\u001b[38;2;255;255;255msensor \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mproviding \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;59;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mthree \u001b[48;2;0;0;133m\u001b[38;2;255;255;255mspatial \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdimensions.\n",
            "41 0.0 0.979 \u001b[48;2;0;0;23m\u001b[38;2;255;255;255mAfter \u001b[48;2;0;0;185m\u001b[38;2;255;255;255mtwo \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mminutes \u001b[48;2;0;0;303m\u001b[38;2;255;255;255mof \u001b[48;2;160;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;139m\u001b[38;2;255;255;255mis \u001b[48;2;209;0;0m\u001b[38;2;255;255;255mcollected \u001b[48;2;0;0;112m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;51m\u001b[38;2;255;255;255man \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivity, \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mthe \u001b[48;2;277;0;0m\u001b[38;2;255;255;255msmartphone \u001b[48;2;169;0;0m\u001b[38;2;255;255;255mautomatically \u001b[48;2;0;0;32m\u001b[38;2;255;255;255msends \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdata, \u001b[48;2;0;0;194m\u001b[38;2;255;255;255min \u001b[48;2;0;0;51m\u001b[38;2;255;255;255man \u001b[48;2;0;0;0m\u001b[38;2;255;255;255memail \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmessage, \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;57m\u001b[38;2;255;255;255ma \u001b[48;2;128;0;0m\u001b[38;2;255;255;255mserver \u001b[48;2;0;0;112m\u001b[38;2;255;255;255mfor \u001b[48;2;39;0;0m\u001b[38;2;255;255;255mstorage \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;20m\u001b[38;2;255;255;255mlater \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mretrieval.\n",
            "42 0.0 0.609 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mUnfortunately, \u001b[48;2;250;0;0m\u001b[38;2;255;255;255munresolved \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;173m\u001b[38;2;255;255;255msporadic \u001b[48;2;135;0;0m\u001b[38;2;255;255;255missues \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mwith \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mphone’s \u001b[48;2;0;0;270m\u001b[38;2;255;255;255mgyroscope \u001b[48;2;0;0;57m\u001b[38;2;255;255;255mprevented \u001b[48;2;0;0;53m\u001b[38;2;255;255;255msufficient \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mphone-gyroscope \u001b[48;2;181;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;200m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;92m\u001b[38;2;255;255;255mbeing \u001b[48;2;330;0;0m\u001b[38;2;255;255;255mcollected \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mand \u001b[48;2;185;0;0m\u001b[38;2;255;255;255mhence \u001b[48;2;49;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;222;0;0m\u001b[38;2;255;255;255msensor \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mis \u001b[48;2;27;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;0;0;49m\u001b[38;2;255;255;255mincorporated \u001b[48;2;0;0;203m\u001b[38;2;255;255;255minto \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;0;0;0m\u001b[38;2;255;255;255manalysis.\n",
            "43 0.0 0.987 \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mthe \u001b[48;2;109;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;194;0;0m\u001b[38;2;255;255;255mreceived \u001b[48;2;69;0;0m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mthe \u001b[48;2;307;0;0m\u001b[38;2;255;255;255mserver \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mwas \u001b[48;2;143;0;0m\u001b[38;2;255;255;255mlater \u001b[48;2;107;0;0m\u001b[38;2;255;255;255mtrimmed \u001b[48;2;0;0;125m\u001b[38;2;255;255;255mto \u001b[48;2;39;0;0m\u001b[38;2;255;255;255mensure \u001b[48;2;0;0;181m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mthe \u001b[48;2;192;0;0m\u001b[38;2;255;255;255mcollected \u001b[48;2;109;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;42;0;0m\u001b[38;2;255;255;255mcorresponded \u001b[48;2;0;0;125m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;70m\u001b[38;2;255;255;255man \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(sometimes \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mtest \u001b[48;2;14;0;0m\u001b[38;2;255;255;255msubjects \u001b[48;2;146;0;0m\u001b[38;2;255;255;255mdelayed \u001b[48;2;0;0;228m\u001b[38;2;255;255;255min \u001b[48;2;0;0;18m\u001b[38;2;255;255;255mstarting \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;124m\u001b[38;2;255;255;255mor \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mended \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mearly).\n",
            "44 0.0 0.521 \u001b[48;2;0;0;212m\u001b[38;2;255;255;255mthe \u001b[48;2;54;0;0m\u001b[38;2;255;255;255mtrimming \u001b[48;2;113;0;0m\u001b[38;2;255;255;255mresulted \u001b[48;2;0;0;120m\u001b[38;2;255;255;255min \u001b[48;2;0;0;52m\u001b[38;2;255;255;255mhaving \u001b[48;2;99;0;0m\u001b[38;2;255;255;255mapproximately \u001b[48;2;114;0;0m\u001b[38;2;255;255;255m100 \u001b[48;2;242;0;0m\u001b[38;2;255;255;255mseconds \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mof \u001b[48;2;193;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;4m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;114m\u001b[38;2;255;255;255meach \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mactivity \u001b[48;2;162;0;0m\u001b[38;2;255;255;255mrather \u001b[48;2;0;0;2m\u001b[38;2;255;255;255mthan \u001b[48;2;0;0;212m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;95m\u001b[38;2;255;255;255mfull \u001b[48;2;0;0;127m\u001b[38;2;255;255;255mtwo \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mminutes.\n",
            "45 0.0 0.925 \u001b[48;2;195;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mTransformation \u001b[48;2;0;0;171m\u001b[38;2;255;255;255mConventional \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mclassification \u001b[48;2;0;0;160m\u001b[38;2;255;255;255malgorithms \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mdo \u001b[48;2;198;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;47;0;0m\u001b[38;2;255;255;255moperate \u001b[48;2;0;0;161m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtime-series \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdata, \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mso \u001b[48;2;0;0;164m\u001b[38;2;255;255;255mthe \u001b[48;2;201;0;0m\u001b[38;2;255;255;255mraw \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mtime \u001b[48;2;0;0;46m\u001b[38;2;255;255;255mseries \u001b[48;2;101;0;0m\u001b[38;2;255;255;255msensor \u001b[48;2;195;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mwas \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mtransformed \u001b[48;2;0;0;196m\u001b[38;2;255;255;255minto \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mexamples \u001b[48;2;0;0;167m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;147m\u001b[38;2;255;255;255mtaking \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m10-second \u001b[48;2;200;0;0m\u001b[38;2;255;255;255mchunks \u001b[48;2;0;0;224m\u001b[38;2;255;255;255mof \u001b[48;2;195;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;77m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;77m\u001b[38;2;255;255;255mgenerating \u001b[48;2;237;0;0m\u001b[38;2;255;255;255mhigher \u001b[48;2;49;0;0m\u001b[38;2;255;255;255mlevel \u001b[48;2;0;0;129m\u001b[38;2;255;255;255mfeatures \u001b[48;2;0;0;197m\u001b[38;2;255;255;255mthat \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mdescribe \u001b[48;2;0;0;164m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mbehavior \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mover \u001b[48;2;0;0;85m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mtime \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mperiod.\n",
            "46 0.0 0.521 \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;21m\u001b[38;2;255;255;255m43 \u001b[48;2;370;0;0m\u001b[38;2;255;255;255mhigher \u001b[48;2;62;0;0m\u001b[38;2;255;255;255mlevel \u001b[48;2;0;0;97m\u001b[38;2;255;255;255mfeatures \u001b[48;2;0;0;138m\u001b[38;2;255;255;255minvolve \u001b[48;2;193;0;0m\u001b[38;2;255;255;255mcomputing \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maverages, \u001b[48;2;8;0;0m\u001b[38;2;255;255;255mstandard \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdeviations, \u001b[48;2;56;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mother \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mmeasures \u001b[48;2;0;0;258m\u001b[38;2;255;255;255mfrom \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mx, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255my, \u001b[48;2;56;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mz \u001b[48;2;0;0;95m\u001b[38;2;255;255;255maxis \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mvalues \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msensor.\n",
            "47 0.0 0.942 \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mdetails \u001b[48;2;0;0;255m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mthe \u001b[48;2;248;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;87;0;0m\u001b[38;2;255;255;255mtransformation \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mprocess, \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mincluding \u001b[48;2;0;0;110m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;101m\u001b[38;2;255;255;255mdescription \u001b[48;2;0;0;255m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mthe \u001b[48;2;283;0;0m\u001b[38;2;255;255;255mhigher \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mlevel \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfeatures, \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mis \u001b[48;2;84;0;0m\u001b[38;2;255;255;255mprovided \u001b[48;2;0;0;14m\u001b[38;2;255;255;255min \u001b[48;2;232;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;153;0;0m\u001b[38;2;255;255;255mprior \u001b[48;2;67;0;0m\u001b[38;2;255;255;255mwork \u001b[48;2;0;0;48m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartphone-based \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;180m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[7, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m9].\n",
            "48 0.0 0.966 \u001b[48;2;84;0;0m\u001b[38;2;255;255;255mNote \u001b[48;2;0;0;155m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;225m\u001b[38;2;255;255;255min \u001b[48;2;0;0;165m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;80m\u001b[38;2;255;255;255mstudy \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mgenerate \u001b[48;2;223;0;0m\u001b[38;2;255;255;255mexamples \u001b[48;2;0;0;120m\u001b[38;2;255;255;255mfrom \u001b[48;2;128;0;0m\u001b[38;2;255;255;255monly \u001b[48;2;0;0;90m\u001b[38;2;255;255;255mone \u001b[48;2;205;0;0m\u001b[38;2;255;255;255msensor \u001b[48;2;0;0;85m\u001b[38;2;255;255;255mat \u001b[48;2;0;0;210m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtime; \u001b[48;2;28;0;0m\u001b[38;2;255;255;255mthus \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mwhen \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mpresent \u001b[48;2;54;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;225m\u001b[38;2;255;255;255min \u001b[48;2;0;0;49m\u001b[38;2;255;255;255mSection \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mIV, \u001b[48;2;54;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;45m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;138m\u001b[38;2;255;255;255mrecognition \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mperformance \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mof \u001b[48;2;28;0;0m\u001b[38;2;255;255;255meach \u001b[48;2;205;0;0m\u001b[38;2;255;255;255msensor \u001b[48;2;0;0;38m\u001b[38;2;255;255;255mis \u001b[48;2;247;0;0m\u001b[38;2;255;255;255mprovided \u001b[48;2;198;0;0m\u001b[38;2;255;255;255mseparately \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(i.e., \u001b[48;2;54;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;273;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;52m\u001b[38;2;255;255;255mutilize \u001b[48;2;0;0;210m\u001b[38;2;255;255;255ma \u001b[48;2;61;0;0m\u001b[38;2;255;255;255msingle \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msensor).\n",
            "49 0.0 0.956 \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mModel \u001b[48;2;0;0;144m\u001b[38;2;255;255;255mInduction \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;13m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;88m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;121m\u001b[38;2;255;255;255mare \u001b[48;2;171;0;0m\u001b[38;2;255;255;255minduced \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mthe \u001b[48;2;194;0;0m\u001b[38;2;255;255;255mlabeled \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mtraining \u001b[48;2;65;0;0m\u001b[38;2;255;255;255mexamples \u001b[48;2;0;0;21m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mthe \u001b[48;2;244;0;0m\u001b[38;2;255;255;255mWEKA \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[13] \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mRandom \u001b[48;2;352;0;0m\u001b[38;2;255;255;255mForest \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(RF) \u001b[48;2;0;0;0m\u001b[38;2;255;255;255malgorithm, \u001b[48;2;0;0;22m\u001b[38;2;255;255;255mJ48 \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mdecision \u001b[48;2;173;0;0m\u001b[38;2;255;255;255mtree \u001b[48;2;0;0;0m\u001b[38;2;255;255;255malgorithm, \u001b[48;2;0;0;112m\u001b[38;2;255;255;255mIB3 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minstance-based \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mlearning \u001b[48;2;0;0;0m\u001b[38;2;255;255;255malgorithm, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mNaïve \u001b[48;2;113;0;0m\u001b[38;2;255;255;255mBayes \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(NB) \u001b[48;2;0;0;0m\u001b[38;2;255;255;255malgorithm, \u001b[48;2;34;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;117m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmulti-layer \u001b[48;2;0;0;211m\u001b[38;2;255;255;255mperceptron \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(MLP) \u001b[48;2;0;0;0m\u001b[38;2;255;255;255malgorithm.\n",
            "50 0.0 0.982 \u001b[48;2;0;0;1m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mdefault \u001b[48;2;53;0;0m\u001b[38;2;255;255;255mparameter \u001b[48;2;6;0;0m\u001b[38;2;255;255;255msettings \u001b[48;2;0;0;154m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;24m\u001b[38;2;255;255;255meach \u001b[48;2;0;0;86m\u001b[38;2;255;255;255malgorithm \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mused, \u001b[48;2;37;0;0m\u001b[38;2;255;255;255mexcept \u001b[48;2;0;0;154m\u001b[38;2;255;255;255mfor \u001b[48;2;137;0;0m\u001b[38;2;255;255;255mNB \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mwhere \u001b[48;2;171;0;0m\u001b[38;2;255;255;255mkernel \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mestimation \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255menabled, \u001b[48;2;164;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;1m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minstance-based \u001b[48;2;110;0;0m\u001b[38;2;255;255;255mlearning \u001b[48;2;0;0;86m\u001b[38;2;255;255;255malgorithm \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mwhere \u001b[48;2;0;0;130m\u001b[38;2;255;255;255m3 \u001b[48;2;0;0;150m\u001b[38;2;255;255;255mnearest \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mneighbors \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mare \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mused \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(there \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mare \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mdozens \u001b[48;2;0;0;314m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mdefault \u001b[48;2;132;0;0m\u001b[38;2;255;255;255mparameters \u001b[48;2;0;0;154m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;1m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;173m\u001b[38;2;255;255;255malgorithms \u001b[48;2;0;0;134m\u001b[38;2;255;255;255memployed \u001b[48;2;0;0;170m\u001b[38;2;255;255;255min \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mpaper \u001b[48;2;65;0;0m\u001b[38;2;255;255;255mso \u001b[48;2;129;0;0m\u001b[38;2;255;255;255mplease \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mrefer \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;309;0;0m\u001b[38;2;255;255;255mWEKA \u001b[48;2;16;0;0m\u001b[38;2;255;255;255monline \u001b[48;2;62;0;0m\u001b[38;2;255;255;255mdocumentation \u001b[48;2;0;0;154m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;68m\u001b[38;2;255;255;255mmore \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdetails).\n",
            "51 1.0 0.85 \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mTwo \u001b[48;2;40;0;0m\u001b[38;2;255;255;255mtypes \u001b[48;2;0;0;221m\u001b[38;2;255;255;255mof \u001b[48;2;113;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;98m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;0m\u001b[38;2;255;255;255minduced.\n",
            "52 0.0 0.956 \u001b[48;2;167;0;0m\u001b[38;2;255;255;255mPersonal \u001b[48;2;0;0;31m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mutilize \u001b[48;2;188;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;115m\u001b[38;2;255;255;255mfrom \u001b[48;2;134;0;0m\u001b[38;2;255;255;255monly \u001b[48;2;0;0;142m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mintended \u001b[48;2;0;0;27m\u001b[38;2;255;255;255muser \u001b[48;2;42;0;0m\u001b[38;2;255;255;255mwhile \u001b[48;2;0;0;143m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;31m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;171m\u001b[38;2;255;255;255mare \u001b[48;2;182;0;0m\u001b[38;2;255;255;255mbuilt \u001b[48;2;0;0;205m\u001b[38;2;255;255;255musing \u001b[48;2;137;0;0m\u001b[38;2;255;255;255mtraining \u001b[48;2;188;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;115m\u001b[38;2;255;255;255mfrom \u001b[48;2;207;0;0m\u001b[38;2;255;255;255meveryone \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mbut \u001b[48;2;0;0;142m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mintended \u001b[48;2;0;0;0m\u001b[38;2;255;255;255muser.\n",
            "53 -1.0 0.824 \u001b[48;2;213;0;0m\u001b[38;2;255;255;255mOur \u001b[48;2;138;0;0m\u001b[38;2;255;255;255mprior \u001b[48;2;85;0;0m\u001b[38;2;255;255;255mresearch \u001b[48;2;0;0;23m\u001b[38;2;255;255;255mhas \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mshown \u001b[48;2;0;0;173m\u001b[38;2;255;255;255mthat \u001b[48;2;175;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;0;0;23m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;144m\u001b[38;2;255;255;255mvastly \u001b[48;2;335;0;0m\u001b[38;2;255;255;255moutperform \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;23m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;199m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;219m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[9], \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mbut \u001b[48;2;0;0;96m\u001b[38;2;255;255;255mat \u001b[48;2;0;0;39m\u001b[38;2;255;255;255mthe \u001b[48;2;126;0;0m\u001b[38;2;255;255;255mcost \u001b[48;2;0;0;65m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;178m\u001b[38;2;255;255;255mrequiring \u001b[48;2;15;0;0m\u001b[38;2;255;255;255meach \u001b[48;2;209;0;0m\u001b[38;2;255;255;255muser \u001b[48;2;52;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mprovide \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mlabeled \u001b[48;2;201;0;0m\u001b[38;2;255;255;255mtraining \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdata.\n",
            "54 0.0 0.946 \u001b[48;2;0;0;235m\u001b[38;2;255;255;255mIn \u001b[48;2;0;0;68m\u001b[38;2;255;255;255morder \u001b[48;2;0;0;10m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mbuild \u001b[48;2;0;0;248m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mevaluate \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;313;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels, \u001b[48;2;239;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;65m\u001b[38;2;255;255;255mfrom \u001b[48;2;74;0;0m\u001b[38;2;255;255;255meach \u001b[48;2;0;0;151m\u001b[38;2;255;255;255mof \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;181;0;0m\u001b[38;2;255;255;255m17 \u001b[48;2;166;0;0m\u001b[38;2;255;255;255msubjects \u001b[48;2;42;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;212;0;0m\u001b[38;2;255;255;255mpartitioned \u001b[48;2;0;0;107m\u001b[38;2;255;255;255minto \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mtraining \u001b[48;2;0;0;248m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;44m\u001b[38;2;255;255;255mtest \u001b[48;2;0;0;46m\u001b[38;2;255;255;255msets \u001b[48;2;0;0;146m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m10-fold \u001b[48;2;25;0;0m\u001b[38;2;255;255;255mcross \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mvalidation.\n",
            "55 1.0 0.623 \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mTherefore \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mthe \u001b[48;2;294;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;48;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;165m\u001b[38;2;255;255;255min \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mthe \u001b[48;2;179;0;0m\u001b[38;2;255;255;255mnext \u001b[48;2;0;0;89m\u001b[38;2;255;255;255msection \u001b[48;2;0;0;90m\u001b[38;2;255;255;255mare \u001b[48;2;255;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;138m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mresults \u001b[48;2;147;0;0m\u001b[38;2;255;255;255maveraged \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mover \u001b[48;2;5;0;0m\u001b[38;2;255;255;255m17 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m×10 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m= \u001b[48;2;0;0;97m\u001b[38;2;255;255;255m170 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels.\n",
            "56 0.0 0.984 \u001b[48;2;0;0;22m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;197m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;76m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;160m\u001b[38;2;255;255;255mare \u001b[48;2;226;0;0m\u001b[38;2;255;255;255mgenerated \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;82m\u001b[38;2;255;255;255mtaking \u001b[48;2;179;0;0m\u001b[38;2;255;255;255mtraining \u001b[48;2;129;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mfrom \u001b[48;2;102;0;0m\u001b[38;2;255;255;255m16 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255musers, \u001b[48;2;145;0;0m\u001b[38;2;255;255;255mbuilding \u001b[48;2;0;0;33m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodel, \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mand \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mthen \u001b[48;2;0;0;9m\u001b[38;2;255;255;255mevaluating \u001b[48;2;0;0;229m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mmodel \u001b[48;2;0;0;84m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;22m\u001b[38;2;255;255;255mthe \u001b[48;2;152;0;0m\u001b[38;2;255;255;255mremaining \u001b[48;2;0;0;0m\u001b[38;2;255;255;255muser; \u001b[48;2;139;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;155m\u001b[38;2;255;255;255mis \u001b[48;2;102;0;0m\u001b[38;2;255;255;255mrepeated \u001b[48;2;0;0;79m\u001b[38;2;255;255;255m17 \u001b[48;2;69;0;0m\u001b[38;2;255;255;255mtimes \u001b[48;2;0;0;84m\u001b[38;2;255;255;255mso \u001b[48;2;0;0;229m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mall \u001b[48;2;117;0;0m\u001b[38;2;255;255;255msubjects \u001b[48;2;0;0;160m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mevaluated.\n",
            "57 -1.0 0.468 \u001b[48;2;0;0;115m\u001b[38;2;255;255;255mIn \u001b[48;2;0;0;273m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mcase \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m10- \u001b[48;2;179;0;0m\u001b[38;2;255;255;255mfold \u001b[48;2;101;0;0m\u001b[38;2;255;255;255mcross \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mvalidation \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mis \u001b[48;2;88;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mused \u001b[48;2;19;0;0m\u001b[38;2;255;255;255msince \u001b[48;2;98;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mhave \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mplenty \u001b[48;2;0;0;89m\u001b[38;2;255;255;255mof \u001b[48;2;100;0;0m\u001b[38;2;255;255;255mtraining \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdata.\n",
            "58 1.0 0.527 \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mresults \u001b[48;2;51;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;10m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mare \u001b[48;2;274;0;0m\u001b[38;2;255;255;255maverages \u001b[48;2;175;0;0m\u001b[38;2;255;255;255mover \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mthe \u001b[48;2;23;0;0m\u001b[38;2;255;255;255m17 \u001b[48;2;0;0;84m\u001b[38;2;255;255;255mgenerated \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels.\n",
            "59 0.0 0.814 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPER-ACTIVITY \u001b[48;2;0;0;118m\u001b[38;2;255;255;255mACCURACY \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mFOR \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mRF \u001b[48;2;134;0;0m\u001b[38;2;255;255;255mMODELS \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;225m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;114m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mare \u001b[48;2;127;0;0m\u001b[38;2;255;255;255mpresented \u001b[48;2;41;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;95m\u001b[38;2;255;255;255manalyzed \u001b[48;2;0;0;216m\u001b[38;2;255;255;255min \u001b[48;2;52;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msection.\n",
            "60 1.0 0.803 \u001b[48;2;73;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;122;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;56;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;73;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;274;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;277m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;191m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;235m\u001b[38;2;255;255;255mrecognition \u001b[48;2;22;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;81m\u001b[38;2;255;255;255mare \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mpresented \u001b[48;2;0;0;9m\u001b[38;2;255;255;255min \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;97m\u001b[38;2;255;255;255mII \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mIII, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrespectively.\n",
            "61 0.0 0.963 \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mResults \u001b[48;2;0;0;160m\u001b[38;2;255;255;255mare \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mmeasured \u001b[48;2;0;0;137m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mclassification \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maccuracy, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;193m\u001b[38;2;255;255;255min \u001b[48;2;0;0;266m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;95m\u001b[38;2;255;255;255mcase \u001b[48;2;52;0;0m\u001b[38;2;255;255;255mcorresponds \u001b[48;2;94;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;191;0;0m\u001b[38;2;255;255;255mpercentage \u001b[48;2;0;0;142m\u001b[38;2;255;255;255mof \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;38;0;0m\u001b[38;2;255;255;255mclassifications \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mthat \u001b[48;2;162;0;0m\u001b[38;2;255;255;255mcorrectly \u001b[48;2;89;0;0m\u001b[38;2;255;255;255midentify \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;39m\u001b[38;2;255;255;255mactivity \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;269;0;0m\u001b[38;2;255;255;255muser \u001b[48;2;153;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mperforming.\n",
            "62 0.0 0.936 \u001b[48;2;78;0;0m\u001b[38;2;255;255;255mEach \u001b[48;2;169;0;0m\u001b[38;2;255;255;255mmodel \u001b[48;2;0;0;148m\u001b[38;2;255;255;255mutilizes \u001b[48;2;0;0;130m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;51m\u001b[38;2;255;255;255msingle \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msensor—models \u001b[48;2;0;0;72m\u001b[38;2;255;255;255musing \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwatch-accelerometer, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mphone-accelerometer, \u001b[48;2;0;0;115m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwatch-gyroscope \u001b[48;2;0;0;205m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;2m\u001b[38;2;255;255;255mall \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mevaluated.\n",
            "63 0.0 0.804 \u001b[48;2;0;0;205m\u001b[38;2;255;255;255mA \u001b[48;2;142;0;0m\u001b[38;2;255;255;255mmodel \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mis \u001b[48;2;14;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;227;0;0m\u001b[38;2;255;255;255mgenerated \u001b[48;2;0;0;47m\u001b[38;2;255;255;255musing \u001b[48;2;7;0;0m\u001b[38;2;255;255;255meach \u001b[48;2;0;0;65m\u001b[38;2;255;255;255mof \u001b[48;2;45;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;77;0;0m\u001b[38;2;255;255;255mfive \u001b[48;2;0;0;55m\u001b[38;2;255;255;255mlearning \u001b[48;2;0;0;202m\u001b[38;2;255;255;255malgorithms \u001b[48;2;0;0;77m\u001b[38;2;255;255;255mdescribed \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mearlier.\n",
            "64 0.0 0.745 \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mAll \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;183m\u001b[38;2;255;255;255min \u001b[48;2;22;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;167m\u001b[38;2;255;255;255mII \u001b[48;2;0;0;94m\u001b[38;2;255;255;255mand \u001b[48;2;5;0;0m\u001b[38;2;255;255;255mIII \u001b[48;2;14;0;0m\u001b[38;2;255;255;255mare \u001b[48;2;357;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;0;0;20m\u001b[38;2;255;255;255mon \u001b[48;2;116;0;0m\u001b[38;2;255;255;255m17 \u001b[48;2;75;0;0m\u001b[38;2;255;255;255mtest \u001b[48;2;15;0;0m\u001b[38;2;255;255;255msubjects \u001b[48;2;52;0;0m\u001b[38;2;255;255;255mwho \u001b[48;2;56;0;0m\u001b[38;2;255;255;255mperformed \u001b[48;2;65;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;107;0;0m\u001b[38;2;255;255;255m18 \u001b[48;2;0;0;162m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;190m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mwere \u001b[48;2;209;0;0m\u001b[38;2;255;255;255mlisted \u001b[48;2;0;0;183m\u001b[38;2;255;255;255min \u001b[48;2;22;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mI.\n",
            "65 0.0 0.85 \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mOVERALL \u001b[48;2;0;0;157m\u001b[38;2;255;255;255mACCURACY \u001b[48;2;0;0;77m\u001b[38;2;255;255;255mFOR \u001b[48;2;226;0;0m\u001b[38;2;255;255;255mPERSONAL \u001b[48;2;23;0;0m\u001b[38;2;255;255;255mMODELS \u001b[48;2;0;0;79m\u001b[38;2;255;255;255mAlgorithm \u001b[48;2;0;0;42m\u001b[38;2;255;255;255mRF \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mJ48 \u001b[48;2;0;0;148m\u001b[38;2;255;255;255mIB3 \u001b[48;2;129;0;0m\u001b[38;2;255;255;255mNB \u001b[48;2;20;0;0m\u001b[38;2;255;255;255mMLP \u001b[48;2;0;0;41m\u001b[38;2;255;255;255mAve \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mPhone \u001b[48;2;39;0;0m\u001b[38;2;255;255;255maccel \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(%) \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m75.5 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m65.5 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m67.7 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m77.1 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m77.0 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m72.6 \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mWatch \u001b[48;2;39;0;0m\u001b[38;2;255;255;255maccel \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(%) \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m93.3 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m86.1 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m93.3 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m92.7 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m94.2 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m91.9 \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mWatch \u001b[48;2;0;0;768m\u001b[38;2;255;255;255mgyroscope \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(%) \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m79.0 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m73.0 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m60.1 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m80.2 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m70.0 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m72.4 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mTABLE \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mIII.\n",
            "66 -1.0 0.912 \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mOVERALL \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mACCURACY \u001b[48;2;0;0;2m\u001b[38;2;255;255;255mFOR \u001b[48;2;0;0;183m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;41m\u001b[38;2;255;255;255mAlgorithm \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mRF \u001b[48;2;93;0;0m\u001b[38;2;255;255;255mJ48 \u001b[48;2;0;0;150m\u001b[38;2;255;255;255mIB3 \u001b[48;2;157;0;0m\u001b[38;2;255;255;255mNB \u001b[48;2;116;0;0m\u001b[38;2;255;255;255mMLP \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mAve \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mPhone \u001b[48;2;76;0;0m\u001b[38;2;255;255;255maccel \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(%) \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m35.1 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m24.1 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m22.5 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m26.2 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m18.9 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m25.3 \u001b[48;2;39;0;0m\u001b[38;2;255;255;255mWatch \u001b[48;2;76;0;0m\u001b[38;2;255;255;255maccel \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(%) \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m70.3 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m59.3 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m62.0 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m63.8 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m64.6 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m64.0 \u001b[48;2;39;0;0m\u001b[38;2;255;255;255mWatch \u001b[48;2;0;0;547m\u001b[38;2;255;255;255mgyroscope \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(%) \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m57.5 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m49.6 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m49.3 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m53.5 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m57.7 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m53.5 \u001b[48;2;0;0;9m\u001b[38;2;255;255;255mThe \u001b[48;2;0;0;90m\u001b[38;2;255;255;255mresults \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mshow \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mthat, \u001b[48;2;0;0;148m\u001b[38;2;255;255;255mconsistent \u001b[48;2;0;0;234m\u001b[38;2;255;255;255mwith \u001b[48;2;17;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;0;0;71m\u001b[38;2;255;255;255mprevious \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartphone-based \u001b[48;2;0;0;114m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;414m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;90m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[9], \u001b[48;2;58;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mmodels \u001b[48;2;433;0;0m\u001b[38;2;255;255;255moutperform \u001b[48;2;0;0;183m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels, \u001b[48;2;0;0;139m\u001b[38;2;255;255;255meven \u001b[48;2;0;0;46m\u001b[38;2;255;255;255mthough \u001b[48;2;0;0;147m\u001b[38;2;255;255;255mthey \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mare \u001b[48;2;159;0;0m\u001b[38;2;255;255;255mbuilt \u001b[48;2;0;0;174m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmuch \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mless \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtraining \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdata.\n",
            "67 -1.0 0.555 \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mthe \u001b[48;2;150;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;126;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mshow \u001b[48;2;0;0;222m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mthe \u001b[48;2;141;0;0m\u001b[38;2;255;255;255mwatch \u001b[48;2;277;0;0m\u001b[38;2;255;255;255maccelerometer \u001b[48;2;0;0;144m\u001b[38;2;255;255;255mprovides \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mmuch \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mbetter \u001b[48;2;150;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;55;0;0m\u001b[38;2;255;255;255mthan \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mthe \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mphone \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maccelerometer, \u001b[48;2;0;0;358m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;168m\u001b[38;2;255;255;255man \u001b[48;2;175;0;0m\u001b[38;2;255;255;255maverage \u001b[48;2;0;0;80m\u001b[38;2;255;255;255maccuracy \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m91.9% \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mversus \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m72.6% \u001b[48;2;0;0;141m\u001b[38;2;255;255;255mfor \u001b[48;2;290;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;70;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;158;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m64.0% \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mversus \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m25.3% \u001b[48;2;0;0;141m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels.\n",
            "68 -1.0 0.524 \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mThese \u001b[48;2;224;0;0m\u001b[38;2;255;255;255mdifferences \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mare \u001b[48;2;62;0;0m\u001b[38;2;255;255;255mlargely \u001b[48;2;137;0;0m\u001b[38;2;255;255;255mdue \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mto \u001b[48;2;42;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhand-based \u001b[48;2;0;0;118m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;233m\u001b[38;2;255;255;255mincluded \u001b[48;2;0;0;159m\u001b[38;2;255;255;255min \u001b[48;2;5;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstudy.\n",
            "69 -1.0 0.779 \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mwatch \u001b[48;2;0;0;233m\u001b[38;2;255;255;255mgyroscope \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mperforms \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mmuch \u001b[48;2;122;0;0m\u001b[38;2;255;255;255mmore \u001b[48;2;0;0;77m\u001b[38;2;255;255;255mpoorly \u001b[48;2;56;0;0m\u001b[38;2;255;255;255mthan \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mwatch \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maccelerometer, \u001b[48;2;0;0;294m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;160m\u001b[38;2;255;255;255man \u001b[48;2;178;0;0m\u001b[38;2;255;255;255maverage \u001b[48;2;0;0;81m\u001b[38;2;255;255;255maccuracy \u001b[48;2;128;0;0m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m72.4% \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mversus \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m91.9% \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mfor \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;364;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;0;0;94m\u001b[38;2;255;255;255mmodels \u001b[48;2;162;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m53.5% \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mversus \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m64.0% \u001b[48;2;0;0;69m\u001b[38;2;255;255;255mfor \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;206m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;94m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(as \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mmentioned \u001b[48;2;235;0;0m\u001b[38;2;255;255;255mearlier \u001b[48;2;0;0;82m\u001b[38;2;255;255;255mthere \u001b[48;2;0;0;161m\u001b[38;2;255;255;255mwere \u001b[48;2;0;0;40m\u001b[38;2;255;255;255mtechnical \u001b[48;2;186;0;0m\u001b[38;2;255;255;255mdifficulties \u001b[48;2;0;0;15m\u001b[38;2;255;255;255min \u001b[48;2;85;0;0m\u001b[38;2;255;255;255mcapturing \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mphone \u001b[48;2;0;0;233m\u001b[38;2;255;255;255mgyroscope \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdata).\n",
            "70 0.0 0.588 \u001b[48;2;71;0;0m\u001b[38;2;255;255;255mWhile \u001b[48;2;0;0;183m\u001b[38;2;255;255;255mit \u001b[48;2;0;0;136m\u001b[38;2;255;255;255mmakes \u001b[48;2;0;0;248m\u001b[38;2;255;255;255msense \u001b[48;2;0;0;97m\u001b[38;2;255;255;255mto \u001b[48;2;43;0;0m\u001b[38;2;255;255;255mgenerate \u001b[48;2;126;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;104m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mthe \u001b[48;2;85;0;0m\u001b[38;2;255;255;255mfusion \u001b[48;2;0;0;299m\u001b[38;2;255;255;255mof \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mmultiple \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msensors, \u001b[48;2;119;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mis \u001b[48;2;95;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mdone \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mbecause \u001b[48;2;0;0;299m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;9m\u001b[38;2;255;255;255missues \u001b[48;2;218;0;0m\u001b[38;2;255;255;255msynchronizing \u001b[48;2;0;0;15m\u001b[38;2;255;255;255mthe \u001b[48;2;174;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;99m\u001b[38;2;255;255;255mfrom \u001b[48;2;101;0;0m\u001b[38;2;255;255;255mdifferent \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msensors—possibly \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mrunning \u001b[48;2;0;0;192m\u001b[38;2;255;255;255mon \u001b[48;2;101;0;0m\u001b[38;2;255;255;255mdifferent \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdevices.\n",
            "71 1.0 0.495 \u001b[48;2;92;0;0m\u001b[38;2;255;255;255mSince \u001b[48;2;0;0;84m\u001b[38;2;255;255;255mthe \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mwatch \u001b[48;2;350;0;0m\u001b[38;2;255;255;255maccelerometer \u001b[48;2;8;0;0m\u001b[38;2;255;255;255myields \u001b[48;2;0;0;84m\u001b[38;2;255;255;255mthe \u001b[48;2;21;0;0m\u001b[38;2;255;255;255mbest \u001b[48;2;0;0;81m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;203m\u001b[38;2;255;255;255mfor \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mboth \u001b[48;2;139;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;0;0;52m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;190m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels, \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;249;0;0m\u001b[38;2;255;255;255mfocus \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mmost \u001b[48;2;0;0;243m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mour \u001b[48;2;107;0;0m\u001b[38;2;255;255;255mattention \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;58m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msensor.\n",
            "72 1.0 0.846 \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mIt \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mis \u001b[48;2;215;0;0m\u001b[38;2;255;255;255mworth \u001b[48;2;214;0;0m\u001b[38;2;255;255;255memphasizing \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;188m\u001b[38;2;255;255;255mthe \u001b[48;2;16;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;151;0;0m\u001b[38;2;255;255;255msensor \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mare \u001b[48;2;13;0;0m\u001b[38;2;255;255;255mquite \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mimpressive, \u001b[48;2;167;0;0m\u001b[38;2;255;255;255mgiven \u001b[48;2;0;0;188m\u001b[38;2;255;255;255mthe \u001b[48;2;186;0;0m\u001b[38;2;255;255;255mdiversity \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mof \u001b[48;2;35;0;0m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mare \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtracked, \u001b[48;2;0;0;188m\u001b[38;2;255;255;255mthe \u001b[48;2;89;0;0m\u001b[38;2;255;255;255mgranularity \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;188m\u001b[38;2;255;255;255mthe \u001b[48;2;35;0;0m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(i.e., \u001b[48;2;134;0;0m\u001b[38;2;255;255;255meating \u001b[48;2;35;0;0m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mare \u001b[48;2;134;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mall \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mgrouped \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtogether), \u001b[48;2;55;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;188m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mfact \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;210m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mstrategy \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mof \u001b[48;2;44;0;0m\u001b[38;2;255;255;255mguessing \u001b[48;2;0;0;188m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;143m\u001b[38;2;255;255;255mmost \u001b[48;2;0;0;137m\u001b[38;2;255;255;255mcommon \u001b[48;2;0;0;222m\u001b[38;2;255;255;255mactivity \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mwould \u001b[48;2;0;0;21m\u001b[38;2;255;255;255myield \u001b[48;2;72;0;0m\u001b[38;2;255;255;255man \u001b[48;2;106;0;0m\u001b[38;2;255;255;255maccuracy \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mof \u001b[48;2;141;0;0m\u001b[38;2;255;255;255monly \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mabout \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m5% \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(i.e., \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mabout \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255min \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m18).\n",
            "73 0.0 0.604 \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mDue \u001b[48;2;0;0;122m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;81m\u001b[38;2;255;255;255mspace \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mlimitations, \u001b[48;2;193;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;215;0;0m\u001b[38;2;255;255;255mfocus \u001b[48;2;213;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;249;0;0m\u001b[38;2;255;255;255manalysis \u001b[48;2;45;0;0m\u001b[38;2;255;255;255mon \u001b[48;2;38;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;54m\u001b[38;2;255;255;255minduced \u001b[48;2;0;0;139m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;33m\u001b[38;2;255;255;255mthe \u001b[48;2;59;0;0m\u001b[38;2;255;255;255mRandom \u001b[48;2;244;0;0m\u001b[38;2;255;255;255mForest \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(RF) \u001b[48;2;0;0;0m\u001b[38;2;255;255;255malgorithm, \u001b[48;2;0;0;33m\u001b[38;2;255;255;255msince \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mthis \u001b[48;2;28;0;0m\u001b[38;2;255;255;255malgorithm \u001b[48;2;0;0;1m\u001b[38;2;255;255;255mperforms \u001b[48;2;17;0;0m\u001b[38;2;255;255;255mwell \u001b[48;2;115;0;0m\u001b[38;2;255;255;255mover \u001b[48;2;0;0;33m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;85m\u001b[38;2;255;255;255m6 \u001b[48;2;0;0;200m\u001b[38;2;255;255;255mconfigurations \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(3 \u001b[48;2;0;0;13m\u001b[38;2;255;255;255msensors \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;59m\u001b[38;2;255;255;255m2 \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mtypes \u001b[48;2;0;0;270m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels).\n",
            "74 1.0 0.926 \u001b[48;2;0;0;55m\u001b[38;2;255;255;255mthe \u001b[48;2;497;0;0m\u001b[38;2;255;255;255maccuracies \u001b[48;2;0;0;236m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;55m\u001b[38;2;255;255;255mthe \u001b[48;2;6;0;0m\u001b[38;2;255;255;255mRF \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels, \u001b[48;2;89;0;0m\u001b[38;2;255;255;255mover \u001b[48;2;0;0;55m\u001b[38;2;255;255;255mthe \u001b[48;2;125;0;0m\u001b[38;2;255;255;255m18 \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;123m\u001b[38;2;255;255;255mfor \u001b[48;2;35;0;0m\u001b[38;2;255;255;255mboth \u001b[48;2;189;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;0;0;49m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;129m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mare \u001b[48;2;161;0;0m\u001b[38;2;255;255;255mshown \u001b[48;2;0;0;121m\u001b[38;2;255;255;255min \u001b[48;2;98;0;0m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mIV.\n",
            "75 1.0 0.743 \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mThese \u001b[48;2;84;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;31m\u001b[38;2;255;255;255mindicate \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;160m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;39m\u001b[38;2;255;255;255maccuracy \u001b[48;2;0;0;21m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;160m\u001b[38;2;255;255;255mthe \u001b[48;2;164;0;0m\u001b[38;2;255;255;255mactivities \u001b[48;2;170;0;0m\u001b[38;2;255;255;255mvaries \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwidely.\n",
            "76 -1.0 0.593 \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;73;0;0m\u001b[38;2;255;255;255mlast \u001b[48;2;0;0;57m\u001b[38;2;255;255;255mgroup \u001b[48;2;0;0;373m\u001b[38;2;255;255;255mof \u001b[48;2;94;0;0m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(i.e., \u001b[48;2;183;0;0m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities) \u001b[48;2;122;0;0m\u001b[38;2;255;255;255mseems \u001b[48;2;0;0;33m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;205m\u001b[38;2;255;255;255mhave \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;52;0;0m\u001b[38;2;255;255;255mlowest \u001b[48;2;0;0;8m\u001b[38;2;255;255;255maccuracy \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mwhen \u001b[48;2;193;0;0m\u001b[38;2;255;255;255mcompared \u001b[48;2;0;0;33m\u001b[38;2;255;255;255mto \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;149;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;16;0;0m\u001b[38;2;255;255;255mother \u001b[48;2;37;0;0m\u001b[38;2;255;255;255mtwo \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mgroupings.\n",
            "77 1.0 0.564 \u001b[48;2;19;0;0m\u001b[38;2;255;255;255mThis \u001b[48;2;115;0;0m\u001b[38;2;255;255;255msuggests \u001b[48;2;92;0;0m\u001b[38;2;255;255;255mperhaps \u001b[48;2;0;0;119m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mthe \u001b[48;2;48;0;0m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;180m\u001b[38;2;255;255;255mactivities \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mmay \u001b[48;2;0;0;179m\u001b[38;2;255;255;255mbe \u001b[48;2;0;0;34m\u001b[38;2;255;255;255msimilar \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mand \u001b[48;2;10;0;0m\u001b[38;2;255;255;255mmay \u001b[48;2;0;0;179m\u001b[38;2;255;255;255mbe \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mgetting \u001b[48;2;321;0;0m\u001b[38;2;255;255;255mconfused \u001b[48;2;0;0;87m\u001b[38;2;255;255;255mwith \u001b[48;2;102;0;0m\u001b[38;2;255;255;255mone \u001b[48;2;0;0;0m\u001b[38;2;255;255;255manother.\n",
            "78 -1.0 0.579 \u001b[48;2;267;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;327;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;93;0;0m\u001b[38;2;255;255;255msee \u001b[48;2;0;0;113m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mthe \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mphone \u001b[48;2;111;0;0m\u001b[38;2;255;255;255msensor \u001b[48;2;0;0;222m\u001b[38;2;255;255;255mperforms \u001b[48;2;0;0;80m\u001b[38;2;255;255;255mmuch \u001b[48;2;61;0;0m\u001b[38;2;255;255;255mworse \u001b[48;2;85;0;0m\u001b[38;2;255;255;255mthan \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;177m\u001b[38;2;255;255;255mtwo \u001b[48;2;0;0;104m\u001b[38;2;255;255;255mwatch \u001b[48;2;27;0;0m\u001b[38;2;255;255;255msensors \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;37m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivity, \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;228;0;0m\u001b[38;2;255;255;255mboth \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;303m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;8;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;144;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels—but \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mespecially \u001b[48;2;36;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;303m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels.\n",
            "79 0.0 0.617 \u001b[48;2;0;0;73m\u001b[38;2;255;255;255mThis \u001b[48;2;23;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mmost \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mlikely \u001b[48;2;0;0;20m\u001b[38;2;255;255;255mdue \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;109m\u001b[38;2;255;255;255mfact \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mthat \u001b[48;2;40;0;0m\u001b[38;2;255;255;255mmany \u001b[48;2;0;0;228m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;72m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhand-based \u001b[48;2;0;0;30m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;109m\u001b[38;2;255;255;255min \u001b[48;2;0;0;72m\u001b[38;2;255;255;255mthe \u001b[48;2;185;0;0m\u001b[38;2;255;255;255msecond \u001b[48;2;234;0;0m\u001b[38;2;255;255;255mgrouping \u001b[48;2;0;0;11m\u001b[38;2;255;255;255malso \u001b[48;2;0;0;140m\u001b[38;2;255;255;255minvolve \u001b[48;2;0;0;14m\u001b[38;2;255;255;255msignificant \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mbody \u001b[48;2;0;0;46m\u001b[38;2;255;255;255mmotion \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(e.g., \u001b[48;2;458;0;0m\u001b[38;2;255;255;255mdribbling \u001b[48;2;0;0;88m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;172m\u001b[38;2;255;255;255mfolding \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclothes).\n",
            "80 -1.0 0.695 \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mIt \u001b[48;2;0;0;188m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;61m\u001b[38;2;255;255;255minteresting \u001b[48;2;0;0;173m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;199m\u001b[38;2;255;255;255ma \u001b[48;2;152;0;0m\u001b[38;2;255;255;255mphone \u001b[48;2;0;0;39m\u001b[38;2;255;255;255min \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mone’s \u001b[48;2;286;0;0m\u001b[38;2;255;255;255mpocket \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mcan \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mbe \u001b[48;2;0;0;5m\u001b[38;2;255;255;255meffective \u001b[48;2;0;0;98m\u001b[38;2;255;255;255mat \u001b[48;2;0;0;37m\u001b[38;2;255;255;255midentifying \u001b[48;2;33;0;0m\u001b[38;2;255;255;255mmany \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhand-based \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities, \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mbut \u001b[48;2;0;0;188m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mineffective \u001b[48;2;0;0;98m\u001b[38;2;255;255;255mat \u001b[48;2;0;0;37m\u001b[38;2;255;255;255midentifying \u001b[48;2;0;0;89m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities.\n",
            "81 -1.0 0.885 \u001b[48;2;186;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mhad \u001b[48;2;138;0;0m\u001b[38;2;255;255;255mpreviously \u001b[48;2;39;0;0m\u001b[38;2;255;255;255mseen \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mthat \u001b[48;2;127;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;30;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;547;0;0m\u001b[38;2;255;255;255moutperform \u001b[48;2;0;0;13m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels, \u001b[48;2;0;0;36m\u001b[38;2;255;255;255mbut \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mthe \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mthat \u001b[48;2;127;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;30;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;213m\u001b[38;2;255;255;255mare \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;64m\u001b[38;2;255;255;255mparticularly \u001b[48;2;44;0;0m\u001b[38;2;255;255;255meffective \u001b[48;2;0;0;74m\u001b[38;2;255;255;255mat \u001b[48;2;409;0;0m\u001b[38;2;255;255;255mboosting \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mthe \u001b[48;2;162;0;0m\u001b[38;2;255;255;255mperformance \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mthe \u001b[48;2;61;0;0m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities—perhaps \u001b[48;2;33;0;0m\u001b[38;2;255;255;255msuggesting \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;166m\u001b[38;2;255;255;255mthere \u001b[48;2;0;0;44m\u001b[38;2;255;255;255mis \u001b[48;2;80;0;0m\u001b[38;2;255;255;255mwide \u001b[48;2;230;0;0m\u001b[38;2;255;255;255mvariance \u001b[48;2;0;0;234m\u001b[38;2;255;255;255min \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mhow \u001b[48;2;166;0;0m\u001b[38;2;255;255;255mpeople \u001b[48;2;0;0;0m\u001b[38;2;255;255;255meat. \u001b[48;2;0;0;234m\u001b[38;2;255;255;255min \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;129m\u001b[38;2;255;255;255mIV \u001b[48;2;0;0;22m\u001b[38;2;255;255;255mshow \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mthe \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;0;0;234m\u001b[38;2;255;255;255min \u001b[48;2;0;0;75m\u001b[38;2;255;255;255mTable \u001b[48;2;0;0;129m\u001b[38;2;255;255;255mIV \u001b[48;2;0;0;23m\u001b[38;2;255;255;255mdo \u001b[48;2;175;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;188;0;0m\u001b[38;2;255;255;255mtell \u001b[48;2;85;0;0m\u001b[38;2;255;255;255mus \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mhow \u001b[48;2;0;0;166m\u001b[38;2;255;255;255mthere \u001b[48;2;0;0;52m\u001b[38;2;255;255;255merrors \u001b[48;2;0;0;213m\u001b[38;2;255;255;255mare \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mdistributed \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mor—more \u001b[48;2;0;0;8m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;111m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpoint—which \u001b[48;2;0;0;112m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;213m\u001b[38;2;255;255;255mare \u001b[48;2;44;0;0m\u001b[38;2;255;255;255mconfused \u001b[48;2;0;0;171m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;119m\u001b[38;2;255;255;255mone \u001b[48;2;0;0;0m\u001b[38;2;255;255;255manother.\n",
            "82 -1.0 0.936 \u001b[48;2;0;0;286m\u001b[38;2;255;255;255mA \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodel’s \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mconfusion \u001b[48;2;99;0;0m\u001b[38;2;255;255;255mmatrix \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mcan \u001b[48;2;175;0;0m\u001b[38;2;255;255;255manswer \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mthis, \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mbut \u001b[48;2;35;0;0m\u001b[38;2;255;255;255msince \u001b[48;2;0;0;69m\u001b[38;2;255;255;255meach \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mconfusion \u001b[48;2;99;0;0m\u001b[38;2;255;255;255mmatrix \u001b[48;2;0;0;173m\u001b[38;2;255;255;255mhas \u001b[48;2;126;0;0m\u001b[38;2;255;255;255mdimensions \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m18×18, \u001b[48;2;70;0;0m\u001b[38;2;255;255;255mit \u001b[48;2;0;0;85m\u001b[38;2;255;255;255mis \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;0;0;239m\u001b[38;2;255;255;255mpractical \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mdisplay \u001b[48;2;0;0;185m\u001b[38;2;255;255;255mthem \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mhere.\n",
            "83 -1.0 0.49 \u001b[48;2;127;0;0m\u001b[38;2;255;255;255mBut \u001b[48;2;226;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;121;0;0m\u001b[38;2;255;255;255mcan \u001b[48;2;62;0;0m\u001b[38;2;255;255;255manalyze \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mthese \u001b[48;2;51;0;0m\u001b[38;2;255;255;255mmatrices \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;67m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;163m\u001b[38;2;255;255;255mmost \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mproblematic \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcases.\n",
            "84 1.0 0.516 \u001b[48;2;73;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mexample, \u001b[48;2;120;0;0m\u001b[38;2;255;255;255mif \u001b[48;2;195;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mlook \u001b[48;2;0;0;18m\u001b[38;2;255;255;255mat \u001b[48;2;0;0;204m\u001b[38;2;255;255;255mthe \u001b[48;2;110;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;73;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;204m\u001b[38;2;255;255;255mthe \u001b[48;2;132;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mRF \u001b[48;2;171;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;263;0;0m\u001b[38;2;255;255;255mbuilt \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mfrom \u001b[48;2;0;0;204m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwatch-accelerometer \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msensor, \u001b[48;2;195;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;0;2m\u001b[38;2;255;255;255msee \u001b[48;2;0;0;147m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;204m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mhardest \u001b[48;2;0;0;155m\u001b[38;2;255;255;255mactivity \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;160m\u001b[38;2;255;255;255mrecognize \u001b[48;2;0;0;66m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“eating \u001b[48;2;0;0;182m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msandwich,” \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mwhich \u001b[48;2;0;0;173m\u001b[38;2;255;255;255mhas \u001b[48;2;0;0;182m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m68.9% \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maccuracy.\n",
            "85 0.0 0.696 \u001b[48;2;34;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;260;0;0m\u001b[38;2;255;255;255mconfusion \u001b[48;2;185;0;0m\u001b[38;2;255;255;255mmatrix \u001b[48;2;166;0;0m\u001b[38;2;255;255;255mindicates \u001b[48;2;0;0;159m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwalking, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mjogging, \u001b[48;2;0;0;25m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;59m\u001b[38;2;255;255;255mstair \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mclimbing—but \u001b[48;2;90;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;80m\u001b[38;2;255;255;255mmay \u001b[48;2;135;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;0;0;2m\u001b[38;2;255;255;255mbe \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mappropriate \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;120m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;159m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;80m\u001b[38;2;255;255;255mmay \u001b[48;2;135;0;0m\u001b[38;2;255;255;255mnot \u001b[48;2;16;0;0m\u001b[38;2;255;255;255mrepeat \u001b[48;2;0;0;243m\u001b[38;2;255;255;255min \u001b[48;2;0;0;125m\u001b[38;2;255;255;255msuch \u001b[48;2;0;0;150m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mshort \u001b[48;2;0;0;115m\u001b[38;2;255;255;255mtime \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mframe.\n",
            "86 1.0 0.525 \u001b[48;2;300;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;85;0;0m\u001b[38;2;255;255;255mplan \u001b[48;2;2;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mexplore \u001b[48;2;101;0;0m\u001b[38;2;255;255;255malternative \u001b[48;2;0;0;82m\u001b[38;2;255;255;255mstrategies \u001b[48;2;0;0;56m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mhandling \u001b[48;2;3;0;0m\u001b[38;2;255;255;255msuch \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities.\n",
            "87 0.0 0.885 \u001b[48;2;127;0;0m\u001b[38;2;255;255;255mREFERENCES \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[1] \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mS.\n",
            "88 0.0 0.944 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mGibbons, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“Physical \u001b[48;2;0;0;235m\u001b[38;2;255;255;255mfitness \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mall-cause \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmortality: \u001b[48;2;18;0;0m\u001b[38;2;255;255;255mA \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mprospective \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mstudy \u001b[48;2;0;0;198m\u001b[38;2;255;255;255mof \u001b[48;2;145;0;0m\u001b[38;2;255;255;255mhealthy \u001b[48;2;195;0;0m\u001b[38;2;255;255;255mmen \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwomen,” \u001b[48;2;0;0;14m\u001b[38;2;255;255;255mJournal \u001b[48;2;0;0;198m\u001b[38;2;255;255;255mof \u001b[48;2;30;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;325;0;0m\u001b[38;2;255;255;255mAmerican \u001b[48;2;119;0;0m\u001b[38;2;255;255;255mMedical \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAssociation, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mvol. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m262, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpp. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2395-2401, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1989. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[2] \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mY.\n",
            "89 0.0 0.949 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mNam, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mY-J \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mChoi, \u001b[48;2;58;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mW-D \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mCho, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“SmartBuckle: \u001b[48;2;0;0;89m\u001b[38;2;255;255;255mhuman \u001b[48;2;0;0;166m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;180m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;175m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;143m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m3-axis \u001b[48;2;580;0;0m\u001b[38;2;255;255;255maccelerometer \u001b[48;2;58;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;143m\u001b[38;2;255;255;255ma \u001b[48;2;103;0;0m\u001b[38;2;255;255;255mwearable \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcamera,” \u001b[48;2;0;0;104m\u001b[38;2;255;255;255min \u001b[48;2;98;0;0m\u001b[38;2;255;255;255mHealthNet \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m’08 \u001b[48;2;0;0;129m\u001b[38;2;255;255;255mProceedings \u001b[48;2;0;0;239m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2nd \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mInt.\n",
            "90 0.0 0.706 \u001b[48;2;163;0;0m\u001b[38;2;255;255;255mWorkshop \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;8m\u001b[38;2;255;255;255mSystems \u001b[48;2;0;0;169m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;44m\u001b[38;2;255;255;255mNetworking \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mSupport \u001b[48;2;0;0;39m\u001b[38;2;255;255;255mfor \u001b[48;2;130;0;0m\u001b[38;2;255;255;255mHealth \u001b[48;2;245;0;0m\u001b[38;2;255;255;255mCare \u001b[48;2;0;0;169m\u001b[38;2;255;255;255mand \u001b[48;2;90;0;0m\u001b[38;2;255;255;255mAssisted \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mLiving \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mEnvironments. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[3] \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mK.\n",
            "91 0.0 0.947 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mCheskin, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“Self-efficacy, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mattendance, \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mand \u001b[48;2;85;0;0m\u001b[38;2;255;255;255mweight \u001b[48;2;127;0;0m\u001b[38;2;255;255;255mloss \u001b[48;2;0;0;27m\u001b[38;2;255;255;255min \u001b[48;2;14;0;0m\u001b[38;2;255;255;255mobesity \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtreatment,” \u001b[48;2;0;0;130m\u001b[38;2;255;255;255mAddict \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBehav, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mvol. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m22, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpp. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m567–70, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1997. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[4] \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mS.\n",
            "92 0.0 0.97 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mL., \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“Physical \u001b[48;2;0;0;230m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;115m\u001b[38;2;255;255;255mthe \u001b[48;2;27;0;0m\u001b[38;2;255;255;255mprevention \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;120m\u001b[38;2;255;255;255mcoronary \u001b[48;2;0;0;41m\u001b[38;2;255;255;255mheart \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdisease,” \u001b[48;2;167;0;0m\u001b[38;2;255;255;255mAnnals \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mof \u001b[48;2;107;0;0m\u001b[38;2;255;255;255mClinical \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mResearch, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mvol. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m3, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpp. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m404-432, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1971. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[5] \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mM.\n",
            "93 0.0 0.98 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAhlbom, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mA, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“Sedentary \u001b[48;2;0;0;100m\u001b[38;2;255;255;255mjobs \u001b[48;2;0;0;57m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mcolon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mcancer,” \u001b[48;2;160;0;0m\u001b[38;2;255;255;255mAmerican \u001b[48;2;7;0;0m\u001b[38;2;255;255;255mJournal \u001b[48;2;0;0;225m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mEpidemiology, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mvol. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m123, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpp. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m775-780, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1986. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[6] \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mN.\n",
            "94 0.0 0.952 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHomanyi, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“An \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;8m\u001b[38;2;255;255;255msystem \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mfor \u001b[48;2;220;0;0m\u001b[38;2;255;255;255mMobile \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mphones,” \u001b[48;2;0;0;215m\u001b[38;2;255;255;255min \u001b[48;2;220;0;0m\u001b[38;2;255;255;255mMobile \u001b[48;2;0;0;88m\u001b[38;2;255;255;255mNetworks \u001b[48;2;0;0;116m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mApplications, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mvol. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m14, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mno. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpp. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m82-91, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2008. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[7] \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mJ.\n",
            "95 0.0 0.953 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mMoore, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“Activity \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;150m\u001b[38;2;255;255;255musing \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mcell \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mphone \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maccelerometers,” \u001b[48;2;42;0;0m\u001b[38;2;255;255;255mACM \u001b[48;2;720;0;0m\u001b[38;2;255;255;255mSIGKDD \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mExplorations, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mvol. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m12, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mno. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpp. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m74–82, \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mDecember \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2010. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[8] \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mJ.\n",
            "96 0.0 0.855 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mWeiss, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“Applications \u001b[48;2;0;0;259m\u001b[38;2;255;255;255mof \u001b[48;2;102;0;0m\u001b[38;2;255;255;255mmobile \u001b[48;2;0;0;107m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrecognition,” \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2012 \u001b[48;2;60;0;0m\u001b[38;2;255;255;255mACM \u001b[48;2;327;0;0m\u001b[38;2;255;255;255mUbiComp \u001b[48;2;0;0;99m\u001b[38;2;255;255;255min \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mProc. \u001b[48;2;0;0;259m\u001b[38;2;255;255;255mof \u001b[48;2;116;0;0m\u001b[38;2;255;255;255mInternational \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mWorkshop \u001b[48;2;0;0;10m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mSituation, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mActivity, \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mand \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mGoal \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mAwareness, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPittsburgh, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPA. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[9] \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mJ.\n",
            "97 0.0 0.909 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mWeiss, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“The \u001b[48;2;0;0;84m\u001b[38;2;255;255;255mbenefits \u001b[48;2;0;0;240m\u001b[38;2;255;255;255mof \u001b[48;2;441;0;0m\u001b[38;2;255;255;255mpersonalized \u001b[48;2;124;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;86m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartphone-based \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrecognition,” \u001b[48;2;0;0;98m\u001b[38;2;255;255;255min \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mProc, \u001b[48;2;0;0;240m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;93m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2014 \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mSIAM \u001b[48;2;27;0;0m\u001b[38;2;255;255;255mInternational \u001b[48;2;0;0;6m\u001b[38;2;255;255;255mConference \u001b[48;2;0;0;105m\u001b[38;2;255;255;255mon \u001b[48;2;283;0;0m\u001b[38;2;255;255;255mData \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mMining, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPhiladelphia, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPA, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpp. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m614–622. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[10] \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mJ.\n",
            "98 0.0 0.819 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mWillett, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“Epidemiology \u001b[48;2;0;0;213m\u001b[38;2;255;255;255mof \u001b[48;2;82;0;0m\u001b[38;2;255;255;255mhealth \u001b[48;2;129;0;0m\u001b[38;2;255;255;255mrisks \u001b[48;2;32;0;0m\u001b[38;2;255;255;255massociated \u001b[48;2;0;0;203m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mobesity”, \u001b[48;2;0;0;137m\u001b[38;2;255;255;255min \u001b[48;2;32;0;0m\u001b[38;2;255;255;255mEating \u001b[48;2;0;0;81m\u001b[38;2;255;255;255mdisorders \u001b[48;2;0;0;227m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mObesity, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mC.G \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFairburn, \u001b[48;2;0;0;227m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mk\\K.D.\n",
            "99 0.0 0.914 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBrownell, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mEd., \u001b[48;2;56;0;0m\u001b[38;2;255;255;255mNew \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mYork, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mGuilford \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mPublications, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2001. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[11] \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mU.\n",
            "100 0.0 0.649 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mDeisher, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“Activity \u001b[48;2;0;0;97m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;167m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;85m\u001b[38;2;255;255;255mmonitoring \u001b[48;2;0;0;138m\u001b[38;2;255;255;255musing \u001b[48;2;171;0;0m\u001b[38;2;255;255;255mmultiple \u001b[48;2;189;0;0m\u001b[38;2;255;255;255msensors \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mon \u001b[48;2;311;0;0m\u001b[38;2;255;255;255mdifferent \u001b[48;2;53;0;0m\u001b[38;2;255;255;255mbody \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpositions,” \u001b[48;2;0;0;0m\u001b[38;2;255;255;255min \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2006 \u001b[48;2;35;0;0m\u001b[38;2;255;255;255mIEEE \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mProc. \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mon \u001b[48;2;56;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;203;0;0m\u001b[38;2;255;255;255mInternational \u001b[48;2;0;0;18m\u001b[38;2;255;255;255mWorkshop \u001b[48;2;0;0;153m\u001b[38;2;255;255;255mon \u001b[48;2;167;0;0m\u001b[38;2;255;255;255mWearable \u001b[48;2;0;0;167m\u001b[38;2;255;255;255mand \u001b[48;2;117;0;0m\u001b[38;2;255;255;255mImplantable \u001b[48;2;117;0;0m\u001b[38;2;255;255;255mSensor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mNetworks, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m3(5). \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[12] \u001b[48;2;0;0;59m\u001b[38;2;255;255;255mPhysical \u001b[48;2;0;0;21m\u001b[38;2;255;255;255minactivity \u001b[48;2;0;0;109m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;19m\u001b[38;2;255;255;255mleading \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mcause \u001b[48;2;0;0;336m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;56m\u001b[38;2;255;255;255mdisease \u001b[48;2;0;0;167m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdisability, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mwarns \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mWHO.\n",
            "101 0.0 0.969 \u001b[48;2;129;0;0m\u001b[38;2;255;255;255mWorld \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mHealth \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mOrganization. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[http://www.who.int/mediacentre/ \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mnews/releases/release23/en/index.html], \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2002. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[13] \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mI.\n",
            "102 0.0 0.94 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFrank, \u001b[48;2;168;0;0m\u001b[38;2;255;255;255mData \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mMining: \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mPractical \u001b[48;2;220;0;0m\u001b[38;2;255;255;255mMachine \u001b[48;2;105;0;0m\u001b[38;2;255;255;255mLearning \u001b[48;2;14;0;0m\u001b[38;2;255;255;255mTools \u001b[48;2;0;0;88m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mTechniques, \u001b[48;2;0;0;170m\u001b[38;2;255;255;255m2nd \u001b[48;2;0;0;0m\u001b[38;2;255;255;255med., \u001b[48;2;154;0;0m\u001b[38;2;255;255;255mMorgan \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mKaufmann, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2005. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[14] \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mJ.\n",
            "103 0.0 0.705 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mYang, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“Toward \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mphysical \u001b[48;2;0;0;65m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdiary: \u001b[48;2;0;0;13m\u001b[38;2;255;255;255mMotion \u001b[48;2;0;0;98m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;181m\u001b[38;2;255;255;255musing \u001b[48;2;23;0;0m\u001b[38;2;255;255;255msimple \u001b[48;2;19;0;0m\u001b[38;2;255;255;255macceleration \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mfeatures \u001b[48;2;0;0;114m\u001b[38;2;255;255;255mwith \u001b[48;2;281;0;0m\u001b[38;2;255;255;255mmobile \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mphones,” \u001b[48;2;0;0;128m\u001b[38;2;255;255;255mIn \u001b[48;2;187;0;0m\u001b[38;2;255;255;255mFirst \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mInt.\n",
            "104 1.0 0.589 \u001b[48;2;126;0;0m\u001b[38;2;255;255;255mWorkshop \u001b[48;2;0;0;65m\u001b[38;2;255;255;255mon \u001b[48;2;62;0;0m\u001b[38;2;255;255;255mInteractive \u001b[48;2;0;0;41m\u001b[38;2;255;255;255mMultimedia \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;228;0;0m\u001b[38;2;255;255;255mConsumer \u001b[48;2;190;0;0m\u001b[38;2;255;255;255mElectronics \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mat \u001b[48;2;80;0;0m\u001b[38;2;255;255;255mACM \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mMultimedia, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpp. \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m1-10, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m2009. \u001b[48;2;9;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;3m\u001b[38;2;255;255;255mactivity \u001b[48;2;33;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;556;0;0m\u001b[38;2;255;255;255mmisclassified \u001b[48;2;0;0;178m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“eating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msoup” \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m10.9% \u001b[48;2;0;0;234m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtime, \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“eating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mchips” \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m9.4% \u001b[48;2;0;0;234m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtime, \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“eating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpasta” \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m5.8% \u001b[48;2;0;0;234m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mthe \u001b[48;2;39;0;0m\u001b[38;2;255;255;255mtime \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(other \u001b[48;2;0;0;112m\u001b[38;2;255;255;255mmisclassifications \u001b[48;2;0;0;175m\u001b[38;2;255;255;255moccur \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mless \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfrequently).\n",
            "105 1.0 0.71 \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mThis \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mshows \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mthat \u001b[48;2;95;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mcommon \u001b[48;2;198;0;0m\u001b[38;2;255;255;255mmistakes \u001b[48;2;0;0;148m\u001b[38;2;255;255;255minvolve \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mother \u001b[48;2;112;0;0m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities, \u001b[48;2;0;0;28m\u001b[38;2;255;255;255msuggesting \u001b[48;2;0;0;106m\u001b[38;2;255;255;255mthat \u001b[48;2;35;0;0m\u001b[38;2;255;255;255mmuch \u001b[48;2;128;0;0m\u001b[38;2;255;255;255mhigher \u001b[48;2;0;0;115m\u001b[38;2;255;255;255maccuracy \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mcould \u001b[48;2;0;0;87m\u001b[38;2;255;255;255mbe \u001b[48;2;208;0;0m\u001b[38;2;255;255;255machieved \u001b[48;2;0;0;102m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;18m\u001b[38;2;255;255;255mgrouping \u001b[48;2;92;0;0m\u001b[38;2;255;255;255mall \u001b[48;2;0;0;172m\u001b[38;2;255;255;255mof \u001b[48;2;95;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;112;0;0m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;4m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mtogether.\n",
            "106 0.0 0.707 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mSimilarly, \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mthe \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mimpersonal \u001b[48;2;0;0;84m\u001b[38;2;255;255;255mmodel \u001b[48;2;6;0;0m\u001b[38;2;255;255;255musing \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mthe \u001b[48;2;200;0;0m\u001b[38;2;255;255;255mphone \u001b[48;2;803;0;0m\u001b[38;2;255;255;255maccelerometer \u001b[48;2;0;0;140m\u001b[38;2;255;255;255mhas \u001b[48;2;0;0;124m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m0% \u001b[48;2;100;0;0m\u001b[38;2;255;255;255maccuracy \u001b[48;2;99;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“eating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msoup” \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mthe \u001b[48;2;30;0;0m\u001b[38;2;255;255;255munderlying \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mconfusion \u001b[48;2;178;0;0m\u001b[38;2;255;255;255mmatrix \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mshows \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mthe \u001b[48;2;64;0;0m\u001b[38;2;255;255;255msingle \u001b[48;2;85;0;0m\u001b[38;2;255;255;255mlargest \u001b[48;2;320;0;0m\u001b[38;2;255;255;255msource \u001b[48;2;0;0;173m\u001b[38;2;255;255;255mof \u001b[48;2;186;0;0m\u001b[38;2;255;255;255merrors \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;43m\u001b[38;2;255;255;255mdue \u001b[48;2;0;0;229m\u001b[38;2;255;255;255mto \u001b[48;2;370;0;0m\u001b[38;2;255;255;255mmisclassifying \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mthis \u001b[48;2;0;0;86m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;200m\u001b[38;2;255;255;255mas \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m“drinking.” \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mIt \u001b[48;2;0;0;68m\u001b[38;2;255;255;255mseems \u001b[48;2;0;0;43m\u001b[38;2;255;255;255mreasonable \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;67m\u001b[38;2;255;255;255mthese \u001b[48;2;0;0;124m\u001b[38;2;255;255;255mtwo \u001b[48;2;0;0;145m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;151m\u001b[38;2;255;255;255mwould \u001b[48;2;0;0;55m\u001b[38;2;255;255;255mappear \u001b[48;2;0;0;137m\u001b[38;2;255;255;255msimilar \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mbased \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;138m\u001b[38;2;255;255;255mmotion \u001b[48;2;104;0;0m\u001b[38;2;255;255;255mmeasured \u001b[48;2;0;0;279m\u001b[38;2;255;255;255mat \u001b[48;2;0;0;124m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mperson’s \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mupper \u001b[48;2;0;0;2m\u001b[38;2;255;255;255mthigh \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(i.e., \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mby \u001b[48;2;0;0;54m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpants \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mpocket).\n",
            "107 1.0 0.775 \u001b[48;2;79;0;0m\u001b[38;2;255;255;255mCONCLUSION \u001b[48;2;0;0;25m\u001b[38;2;255;255;255mAND \u001b[48;2;18;0;0m\u001b[38;2;255;255;255mFUTURE \u001b[48;2;0;0;22m\u001b[38;2;255;255;255mWORK \u001b[48;2;45;0;0m\u001b[38;2;255;255;255mThis \u001b[48;2;75;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;18;0;0m\u001b[38;2;255;255;255mdemonstrates \u001b[48;2;40;0;0m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartwatch-based \u001b[48;2;28;0;0m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;138m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;61m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;11m\u001b[38;2;255;255;255mcapable \u001b[48;2;0;0;302m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;281m\u001b[38;2;255;255;255mrecognizing \u001b[48;2;0;0;66m\u001b[38;2;255;255;255ma \u001b[48;2;108;0;0m\u001b[38;2;255;255;255mwide \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mvariety \u001b[48;2;0;0;302m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities—including \u001b[48;2;119;0;0m\u001b[38;2;255;255;255msome \u001b[48;2;0;0;87m\u001b[38;2;255;255;255mactivities \u001b[48;2;40;0;0m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;66m\u001b[38;2;255;255;255ma \u001b[48;2;108;0;0m\u001b[38;2;255;255;255msmartphone \u001b[48;2;150;0;0m\u001b[38;2;255;255;255mcannot \u001b[48;2;87;0;0m\u001b[38;2;255;255;255meffectively \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrecognize.\n",
            "108 0.0 0.546 \u001b[48;2;121;0;0m\u001b[38;2;255;255;255mThis \u001b[48;2;121;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;153;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mincludes \u001b[48;2;80;0;0m\u001b[38;2;255;255;255mwhat \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;118;0;0m\u001b[38;2;255;255;255mperhaps \u001b[48;2;17;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;91m\u001b[38;2;255;255;255mfirst \u001b[48;2;0;0;59m\u001b[38;2;255;255;255mresearch \u001b[48;2;0;0;144m\u001b[38;2;255;255;255mstudy \u001b[48;2;0;0;185m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;78m\u001b[38;2;255;255;255mtracking \u001b[48;2;35;0;0m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;43m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;252m\u001b[38;2;255;255;255mwith \u001b[48;2;0;0;188m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msmartwatch.\n",
            "109 1.0 0.968 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mOverall, \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mthe \u001b[48;2;111;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;11;0;0m\u001b[38;2;255;255;255min \u001b[48;2;97;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;84;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;49;0;0m\u001b[38;2;255;255;255msuggest \u001b[48;2;0;0;65m\u001b[38;2;255;255;255mthat \u001b[48;2;5;0;0m\u001b[38;2;255;255;255mcommercial \u001b[48;2;405;0;0m\u001b[38;2;255;255;255msmartwatches \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mcan \u001b[48;2;0;0;126m\u001b[38;2;255;255;255mrecognize \u001b[48;2;0;0;89m\u001b[38;2;255;255;255ma \u001b[48;2;129;0;0m\u001b[38;2;255;255;255mwide \u001b[48;2;0;0;35m\u001b[38;2;255;255;255mvariety \u001b[48;2;0;0;268m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;165m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;242m\u001b[38;2;255;255;255mwith \u001b[48;2;27;0;0m\u001b[38;2;255;255;255mrelatively \u001b[48;2;0;0;114m\u001b[38;2;255;255;255mgood \u001b[48;2;0;0;0m\u001b[38;2;255;255;255maccuracy.\n",
            "110 1.0 0.96 \u001b[48;2;0;0;127m\u001b[38;2;255;255;255mthe \u001b[48;2;24;0;0m\u001b[38;2;255;255;255mresults \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mfurther \u001b[48;2;0;0;16m\u001b[38;2;255;255;255mshow \u001b[48;2;0;0;136m\u001b[38;2;255;255;255mthat \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;122;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;0;0;183m\u001b[38;2;255;255;255mperform \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mbest—especially \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;127m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;82m\u001b[38;2;255;255;255meating \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities.\n",
            "111 1.0 0.876 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mThus, \u001b[48;2;37;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;0;0;58m\u001b[38;2;255;255;255mobservations \u001b[48;2;47;0;0m\u001b[38;2;255;255;255mabout \u001b[48;2;0;0;149m\u001b[38;2;255;255;255mthe \u001b[48;2;83;0;0m\u001b[38;2;255;255;255msuperiority \u001b[48;2;0;0;316m\u001b[38;2;255;255;255mof \u001b[48;2;247;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mmodels, \u001b[48;2;0;0;47m\u001b[38;2;255;255;255mpreviously \u001b[48;2;0;0;108m\u001b[38;2;255;255;255mdemonstrated \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mfor \u001b[48;2;22;0;0m\u001b[38;2;255;255;255msmartphones \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[9], \u001b[48;2;69;0;0m\u001b[38;2;255;255;255mis \u001b[48;2;202;0;0m\u001b[38;2;255;255;255mnow \u001b[48;2;40;0;0m\u001b[38;2;255;255;255mshown \u001b[48;2;0;0;14m\u001b[38;2;255;255;255mto \u001b[48;2;146;0;0m\u001b[38;2;255;255;255mhold \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mfor \u001b[48;2;292;0;0m\u001b[38;2;255;255;255msmartwatches \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;19m\u001b[38;2;255;255;255ma \u001b[48;2;95;0;0m\u001b[38;2;255;255;255mmuch \u001b[48;2;57;0;0m\u001b[38;2;255;255;255mmore \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mdiverse \u001b[48;2;0;0;53m\u001b[38;2;255;255;255mset \u001b[48;2;0;0;316m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivities.\n",
            "112 1.0 0.559 \u001b[48;2;65;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;55;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;226;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mthe \u001b[48;2;396;0;0m\u001b[38;2;255;255;255maccelerometer \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;80m\u001b[38;2;255;255;255mcompares \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mthe \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mwatch \u001b[48;2;0;0;329m\u001b[38;2;255;255;255mgyroscope \u001b[48;2;396;0;0m\u001b[38;2;255;255;255maccelerometer \u001b[48;2;0;0;76m\u001b[38;2;255;255;255mis \u001b[48;2;11;0;0m\u001b[38;2;255;255;255mshown \u001b[48;2;0;0;43m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;7m\u001b[38;2;255;255;255msignificantly \u001b[48;2;675;0;0m\u001b[38;2;255;255;255moutperform \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mthe \u001b[48;2;96;0;0m\u001b[38;2;255;255;255mwatch \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mgyroscope. \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mthe \u001b[48;2;119;0;0m\u001b[38;2;255;255;255mperformance \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;134m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrecognition, \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mthe \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mstudy \u001b[48;2;0;0;56m\u001b[38;2;255;255;255mdescribed \u001b[48;2;0;0;334m\u001b[38;2;255;255;255min \u001b[48;2;65;0;0m\u001b[38;2;255;255;255mthis \u001b[48;2;55;0;0m\u001b[38;2;255;255;255mpaper \u001b[48;2;0;0;76m\u001b[38;2;255;255;255mis \u001b[48;2;0;0;190m\u001b[38;2;255;255;255mat \u001b[48;2;0;0;10m\u001b[38;2;255;255;255man \u001b[48;2;238;0;0m\u001b[38;2;255;255;255mearly \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstage, \u001b[48;2;12;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;216;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;69;0;0m\u001b[38;2;255;255;255mexpect \u001b[48;2;0;0;43m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;33m\u001b[38;2;255;255;255mextend \u001b[48;2;0;0;146m\u001b[38;2;255;255;255mthe \u001b[48;2;125;0;0m\u001b[38;2;255;255;255mstudy \u001b[48;2;0;0;334m\u001b[38;2;255;255;255min \u001b[48;2;0;0;67m\u001b[38;2;255;255;255mseveral \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mkey \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mways.\n",
            "113 0.0 0.397 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFirst, \u001b[48;2;63;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mplan \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;226m\u001b[38;2;255;255;255mextend \u001b[48;2;0;0;89m\u001b[38;2;255;255;255mthe \u001b[48;2;163;0;0m\u001b[38;2;255;255;255mstudy \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;103m\u001b[38;2;255;255;255minclude \u001b[48;2;0;0;10m\u001b[38;2;255;255;255ma \u001b[48;2;193;0;0m\u001b[38;2;255;255;255mminimum \u001b[48;2;0;0;49m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m50-100 \u001b[48;2;0;0;107m\u001b[38;2;255;255;255mtest \u001b[48;2;0;0;40m\u001b[38;2;255;255;255msubjects \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(this \u001b[48;2;163;0;0m\u001b[38;2;255;255;255mstudy \u001b[48;2;77;0;0m\u001b[38;2;255;255;255mincluded \u001b[48;2;0;0;17m\u001b[38;2;255;255;255m17 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255msubjects).\n",
            "114 0.0 0.811 \u001b[48;2;0;0;92m\u001b[38;2;255;255;255mthe \u001b[48;2;101;0;0m\u001b[38;2;255;255;255mamount \u001b[48;2;0;0;250m\u001b[38;2;255;255;255mof \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mper \u001b[48;2;45;0;0m\u001b[38;2;255;255;255mactivity \u001b[48;2;135;0;0m\u001b[38;2;255;255;255mwill \u001b[48;2;23;0;0m\u001b[38;2;255;255;255mbe \u001b[48;2;265;0;0m\u001b[38;2;255;255;255mincreased \u001b[48;2;7;0;0m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;166m\u001b[38;2;255;255;255m3 \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mminutes \u001b[48;2;0;0;51m\u001b[38;2;255;255;255msince \u001b[48;2;0;0;131m\u001b[38;2;255;255;255mafter \u001b[48;2;4;0;0m\u001b[38;2;255;255;255mtrimming \u001b[48;2;0;0;92m\u001b[38;2;255;255;255mthe \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;73;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;33;0;0m\u001b[38;2;255;255;255mfell \u001b[48;2;46;0;0m\u001b[38;2;255;255;255mbelow \u001b[48;2;95;0;0m\u001b[38;2;255;255;255mour \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mgoal \u001b[48;2;0;0;250m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;132m\u001b[38;2;255;255;255mhaving \u001b[48;2;0;0;149m\u001b[38;2;255;255;255m2 \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mminutes \u001b[48;2;0;0;250m\u001b[38;2;255;255;255mof \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mper \u001b[48;2;45;0;0m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m(prior \u001b[48;2;114;0;0m\u001b[38;2;255;255;255mresearch \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m[9] \u001b[48;2;129;0;0m\u001b[38;2;255;255;255mindicates \u001b[48;2;0;0;171m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;37m\u001b[38;2;255;255;255mperformance \u001b[48;2;0;0;63m\u001b[38;2;255;255;255mplateaus \u001b[48;2;0;0;194m\u001b[38;2;255;255;255mat \u001b[48;2;0;0;149m\u001b[38;2;255;255;255m2 \u001b[48;2;1;0;0m\u001b[38;2;255;255;255mminutes \u001b[48;2;0;0;250m\u001b[38;2;255;255;255mof \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mpersonal \u001b[48;2;76;0;0m\u001b[38;2;255;255;255mtraining \u001b[48;2;74;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;26;0;0m\u001b[38;2;255;255;255mper \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mactivity).\n",
            "115 0.0 0.533 \u001b[48;2;44;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;183;0;0m\u001b[38;2;255;255;255malso \u001b[48;2;0;0;24m\u001b[38;2;255;255;255mexpect \u001b[48;2;0;0;48m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;70m\u001b[38;2;255;255;255movercome \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;26m\u001b[38;2;255;255;255mtechnical \u001b[48;2;106;0;0m\u001b[38;2;255;255;255mdifficulties \u001b[48;2;0;0;280m\u001b[38;2;255;255;255mwith \u001b[48;2;22;0;0m\u001b[38;2;255;255;255mcollecting \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mthe \u001b[48;2;15;0;0m\u001b[38;2;255;255;255mphone \u001b[48;2;0;0;147m\u001b[38;2;255;255;255mgyroscope \u001b[48;2;191;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;113;0;0m\u001b[38;2;255;255;255mso \u001b[48;2;44;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;70;0;0m\u001b[38;2;255;255;255mcan \u001b[48;2;251;0;0m\u001b[38;2;255;255;255mbetter \u001b[48;2;231;0;0m\u001b[38;2;255;255;255mcompare \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mutility \u001b[48;2;0;0;50m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mthe \u001b[48;2;144;0;0m\u001b[38;2;255;255;255mvarious \u001b[48;2;0;0;52m\u001b[38;2;255;255;255msensors \u001b[48;2;0;0;107m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;136m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mrecognition.\n",
            "116 0.0 0.918 \u001b[48;2;228;0;0m\u001b[38;2;255;255;255mFusing \u001b[48;2;0;0;180m\u001b[38;2;255;255;255mthe \u001b[48;2;55;0;0m\u001b[38;2;255;255;255msensor \u001b[48;2;75;0;0m\u001b[38;2;255;255;255mdata \u001b[48;2;0;0;13m\u001b[38;2;255;255;255mis \u001b[48;2;100;0;0m\u001b[38;2;255;255;255mlikely \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mto \u001b[48;2;0;0;58m\u001b[38;2;255;255;255myield \u001b[48;2;68;0;0m\u001b[38;2;255;255;255mimproved \u001b[48;2;0;0;119m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;377m\u001b[38;2;255;255;255mrecognition \u001b[48;2;0;0;121m\u001b[38;2;255;255;255mresults \u001b[48;2;37;0;0m\u001b[38;2;255;255;255mand \u001b[48;2;214;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mplan \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mto \u001b[48;2;29;0;0m\u001b[38;2;255;255;255mevaluate \u001b[48;2;0;0;56m\u001b[38;2;255;255;255msuch \u001b[48;2;31;0;0m\u001b[38;2;255;255;255mfusion \u001b[48;2;0;0;139m\u001b[38;2;255;255;255mstrategies \u001b[48;2;0;0;91m\u001b[38;2;255;255;255min \u001b[48;2;0;0;180m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mfuture, \u001b[48;2;49;0;0m\u001b[38;2;255;255;255mafter \u001b[48;2;0;0;60m\u001b[38;2;255;255;255mdeveloping \u001b[48;2;0;0;17m\u001b[38;2;255;255;255mmethods \u001b[48;2;0;0;28m\u001b[38;2;255;255;255mto \u001b[48;2;191;0;0m\u001b[38;2;255;255;255mbetter \u001b[48;2;318;0;0m\u001b[38;2;255;255;255msynchronize \u001b[48;2;0;0;180m\u001b[38;2;255;255;255mthe \u001b[48;2;55;0;0m\u001b[38;2;255;255;255msensor \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdata.\n",
            "117 0.0 0.534 \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mFinally, \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mour \u001b[48;2;0;0;80m\u001b[38;2;255;255;255mactivity \u001b[48;2;0;0;158m\u001b[38;2;255;255;255mrecognition \u001b[48;2;69;0;0m\u001b[38;2;255;255;255mmodels \u001b[48;2;220;0;0m\u001b[38;2;255;255;255mrely \u001b[48;2;20;0;0m\u001b[38;2;255;255;255mon \u001b[48;2;0;0;138m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0;48m\u001b[38;2;255;255;255mfact \u001b[48;2;0;0;125m\u001b[38;2;255;255;255mthat \u001b[48;2;0;0;124m\u001b[38;2;255;255;255ma \u001b[48;2;0;0;95m\u001b[38;2;255;255;255mclear \u001b[48;2;0;0;83m\u001b[38;2;255;255;255mpattern \u001b[48;2;0;0;27m\u001b[38;2;255;255;255mwill \u001b[48;2;0;0;38m\u001b[38;2;255;255;255moccur \u001b[48;2;66;0;0m\u001b[38;2;255;255;255mwithin \u001b[48;2;143;0;0m\u001b[38;2;255;255;255m10 \u001b[48;2;253;0;0m\u001b[38;2;255;255;255mseconds \u001b[48;2;0;0;147m\u001b[38;2;255;255;255mof \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mdata.\n",
            "118 0.0 0.418 \u001b[48;2;20;0;0m\u001b[38;2;255;255;255mThis \u001b[48;2;0;0;62m\u001b[38;2;255;255;255mwas \u001b[48;2;81;0;0m\u001b[38;2;255;255;255mvalid \u001b[48;2;172;0;0m\u001b[38;2;255;255;255mfor \u001b[48;2;0;0;49m\u001b[38;2;255;255;255mthe \u001b[48;2;151;0;0m\u001b[38;2;255;255;255mclearly \u001b[48;2;0;0;118m\u001b[38;2;255;255;255mrepetitive \u001b[48;2;0;0;215m\u001b[38;2;255;255;255mactivities \u001b[48;2;0;0;79m\u001b[38;2;255;255;255mthat \u001b[48;2;216;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;233;0;0m\u001b[38;2;255;255;255minitially \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mstudied—like \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mView \u001b[48;2;0;0;136m\u001b[38;2;255;255;255mpublication \u001b[48;2;64;0;0m\u001b[38;2;255;255;255mstats \u001b[48;2;0;0;32m\u001b[38;2;255;255;255mView \u001b[48;2;0;0;136m\u001b[38;2;255;255;255mpublication \u001b[48;2;64;0;0m\u001b[38;2;255;255;255mstats \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TzenijLfqxcX",
        "outputId": "a7b14704-a559-4625-d296-8259524613fc"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sentence   section  class  confidence  net score  net attention    neg  \\\n",
              "0          0  ABSTRACT    0.0       0.797      0.066      21.192471  0.001   \n",
              "0          1  ABSTRACT    1.0       0.953      0.315      22.240728  0.007   \n",
              "0          2  ABSTRACT    1.0       0.668      0.193      31.278921  0.089   \n",
              "0          3  ABSTRACT    0.0       0.502      0.102       7.899637  0.095   \n",
              "0          4  ABSTRACT    0.0       0.615      0.116      19.203249  0.018   \n",
              "..       ...       ...    ...         ...        ...            ...    ...   \n",
              "0        295  ABSTRACT    1.0       0.749      0.249       9.156259  0.001   \n",
              "0        296  ABSTRACT    0.0       0.523      0.104       4.544265  0.081   \n",
              "0        297  ABSTRACT    0.0       0.814      0.057       5.918126  0.005   \n",
              "0        298  ABSTRACT    0.0       0.458      0.115       4.598346  0.097   \n",
              "0        299  ABSTRACT    0.0       0.899      0.031       5.001428  0.002   \n",
              "\n",
              "      neu    pos                                               text  \\\n",
              "0   0.797  0.200  We propose a novel loss we term the Focal Loss...   \n",
              "0   0.039  0.953  As our experiments will demonstrate, the propo...   \n",
              "0   0.242  0.668  In contrast, one-stage detectors that are appl...   \n",
              "0   0.502  0.402  In this paper, we investigate why this is the ...   \n",
              "0   0.615  0.366  We discover that the ex- treme foreground-back...   \n",
              "..    ...    ...                                                ...   \n",
              "0   0.249  0.749  Rapid object detection using a boosted  cascad...   \n",
              "0   0.523  0.394                       In CVPR, 2001. 2, 3  [38] S.   \n",
              "0   0.814  0.179  Aggregated residual transformations for deep n...   \n",
              "0   0.458  0.443                          In CVPR, 2017. 8  [39] C.   \n",
              "0   0.899  0.098  Edge boxes: Locating object  proposals from ed...   \n",
              "\n",
              "                                              colored  \n",
              "0   \u001b[48;2;205;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;...  \n",
              "0   \u001b[48;2;33;0;0m\u001b[38;2;255;255;255mAs \u001b[48;2;105...  \n",
              "0   \u001b[48;2;0;0;289m\u001b[38;2;255;255;255mIn \u001b[48;2;0;...  \n",
              "0   \u001b[48;2;0;0;51m\u001b[38;2;255;255;255mIn \u001b[48;2;0;0...  \n",
              "0   \u001b[48;2;319;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;99...  \n",
              "..                                                ...  \n",
              "0   \u001b[48;2;75;0;0m\u001b[38;2;255;255;255mRapid \u001b[48;2;...  \n",
              "0   \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mIn \u001b[48;2;0;0...  \n",
              "0   \u001b[48;2;73;0;0m\u001b[38;2;255;255;255mAggregated \u001b[...  \n",
              "0   \u001b[48;2;0;0;12m\u001b[38;2;255;255;255mIn \u001b[48;2;0;0...  \n",
              "0   \u001b[48;2;0;0;29m\u001b[38;2;255;255;255mEdge \u001b[48;2;0...  \n",
              "\n",
              "[300 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ee50a87-dcbc-4aac-a9cb-89caf2927ad4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>section</th>\n",
              "      <th>class</th>\n",
              "      <th>confidence</th>\n",
              "      <th>net score</th>\n",
              "      <th>net attention</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>text</th>\n",
              "      <th>colored</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ABSTRACT</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.797</td>\n",
              "      <td>0.066</td>\n",
              "      <td>21.192471</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.797</td>\n",
              "      <td>0.200</td>\n",
              "      <td>We propose a novel loss we term the Focal Loss...</td>\n",
              "      <td>\u001b[48;2;205;0;0m\u001b[38;2;255;255;255mwe \u001b[48;2;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>ABSTRACT</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.953</td>\n",
              "      <td>0.315</td>\n",
              "      <td>22.240728</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.953</td>\n",
              "      <td>As our experiments will demonstrate, the propo...</td>\n",
              "      <td>\u001b[48;2;33;0;0m\u001b[38;2;255;255;255mAs \u001b[48;2;105...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>ABSTRACT</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.668</td>\n",
              "      <td>0.193</td>\n",
              "      <td>31.278921</td>\n",
              "      <td>0.089</td>\n",
              "      <td>0.242</td>\n",
              "      <td>0.668</td>\n",
              "      <td>In contrast, one-stage detectors that are appl...</td>\n",
              "      <td>\u001b[48;2;0;0;289m\u001b[38;2;255;255;255mIn \u001b[48;2;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>ABSTRACT</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.502</td>\n",
              "      <td>0.102</td>\n",
              "      <td>7.899637</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.502</td>\n",
              "      <td>0.402</td>\n",
              "      <td>In this paper, we investigate why this is the ...</td>\n",
              "      <td>\u001b[48;2;0;0;51m\u001b[38;2;255;255;255mIn \u001b[48;2;0;0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>ABSTRACT</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.615</td>\n",
              "      <td>0.116</td>\n",
              "      <td>19.203249</td>\n",
              "      <td>0.018</td>\n",
              "      <td>0.615</td>\n",
              "      <td>0.366</td>\n",
              "      <td>We discover that the ex- treme foreground-back...</td>\n",
              "      <td>\u001b[48;2;319;0;0m\u001b[38;2;255;255;255mWe \u001b[48;2;99...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>295</td>\n",
              "      <td>ABSTRACT</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.249</td>\n",
              "      <td>9.156259</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.249</td>\n",
              "      <td>0.749</td>\n",
              "      <td>Rapid object detection using a boosted  cascad...</td>\n",
              "      <td>\u001b[48;2;75;0;0m\u001b[38;2;255;255;255mRapid \u001b[48;2;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>296</td>\n",
              "      <td>ABSTRACT</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.523</td>\n",
              "      <td>0.104</td>\n",
              "      <td>4.544265</td>\n",
              "      <td>0.081</td>\n",
              "      <td>0.523</td>\n",
              "      <td>0.394</td>\n",
              "      <td>In CVPR, 2001. 2, 3  [38] S.</td>\n",
              "      <td>\u001b[48;2;0;0;29m\u001b[38;2;255;255;255mIn \u001b[48;2;0;0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>297</td>\n",
              "      <td>ABSTRACT</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.814</td>\n",
              "      <td>0.057</td>\n",
              "      <td>5.918126</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.814</td>\n",
              "      <td>0.179</td>\n",
              "      <td>Aggregated residual transformations for deep n...</td>\n",
              "      <td>\u001b[48;2;73;0;0m\u001b[38;2;255;255;255mAggregated \u001b[...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>298</td>\n",
              "      <td>ABSTRACT</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>0.115</td>\n",
              "      <td>4.598346</td>\n",
              "      <td>0.097</td>\n",
              "      <td>0.458</td>\n",
              "      <td>0.443</td>\n",
              "      <td>In CVPR, 2017. 8  [39] C.</td>\n",
              "      <td>\u001b[48;2;0;0;12m\u001b[38;2;255;255;255mIn \u001b[48;2;0;0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>299</td>\n",
              "      <td>ABSTRACT</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.899</td>\n",
              "      <td>0.031</td>\n",
              "      <td>5.001428</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.899</td>\n",
              "      <td>0.098</td>\n",
              "      <td>Edge boxes: Locating object  proposals from ed...</td>\n",
              "      <td>\u001b[48;2;0;0;29m\u001b[38;2;255;255;255mEdge \u001b[48;2;0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ee50a87-dcbc-4aac-a9cb-89caf2927ad4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ee50a87-dcbc-4aac-a9cb-89caf2927ad4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ee50a87-dcbc-4aac-a9cb-89caf2927ad4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_phocus.sort_values(by=['net score'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mPGTjJnCnr1k",
        "outputId": "35a1e5dc-1493-4f9f-84d1-c148b0ae6cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sentence       section  class  confidence  net score  net attention  \\\n",
              "0         31  RELATED WORK   -1.0       0.924     -0.305      19.884472   \n",
              "0        123   EXPERIMENTS   -1.0       0.917     -0.297      16.340233   \n",
              "0         10  INTRODUCTION   -1.0       0.764     -0.226      12.599020   \n",
              "0        141   EXPERIMENTS   -1.0       0.597     -0.192      10.496807   \n",
              "0         77  RELATED WORK   -1.0       0.597     -0.192      10.496807   \n",
              "..       ...           ...    ...         ...        ...            ...   \n",
              "0          0  INTRODUCTION    1.0       0.909      0.296       8.146835   \n",
              "0        115   METHODOLOGY    1.0       0.907      0.299       7.527385   \n",
              "0        125   EXPERIMENTS    1.0       0.915      0.303      16.606018   \n",
              "0        142   EXPERIMENTS    1.0       0.934      0.303       6.461682   \n",
              "0         79  RELATED WORK    1.0       0.960      0.311      10.534895   \n",
              "\n",
              "      neg    neu    pos                                               text  \\\n",
              "0   0.924  0.066  0.009  However, this method generates the overall sen...   \n",
              "0   0.917  0.055  0.027  However, we cannot complete this job yet out o...   \n",
              "0   0.764  0.145  0.089  Quantitative metrics could not evaluate the re...   \n",
              "0   0.597  0.378  0.023  Those metrics are derived from citations and d...   \n",
              "0   0.597  0.378  0.023  Those metrics are derived from citations and d...   \n",
              "..    ...    ...    ...                                                ...   \n",
              "0   0.020  0.070  0.909   The number of papers published each year has ...   \n",
              "0   0.009  0.082  0.907                The main idea is shown in Figure 3.   \n",
              "0   0.004  0.079  0.915  Besides, we also compare our modules to other ...   \n",
              "0   0.023  0.041  0.934  Semantic Scholar makes the first step towards ...   \n",
              "0   0.025  0.013  0.960  Espe- cially, Semantic Scholar makes the first...   \n",
              "\n",
              "                                              colored  \n",
              "0   \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHowever, \u001b[48;...  \n",
              "0   \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHowever, \u001b[48;...  \n",
              "0   \u001b[48;2;0;0;89m\u001b[38;2;255;255;255mQuantitative ...  \n",
              "0   \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mThose \u001b[48;2;4...  \n",
              "0   \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mThose \u001b[48;2;4...  \n",
              "..                                                ...  \n",
              "0   \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;8;...  \n",
              "0   \u001b[48;2;0;0;85m\u001b[38;2;255;255;255mThe \u001b[48;2;11...  \n",
              "0   \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBesides, \u001b[48;...  \n",
              "0   \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mSemantic \u001b[48...  \n",
              "0   \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mEspe- \u001b[48;2;0...  \n",
              "\n",
              "[176 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b335de30-6f3a-427b-81e7-5aefc25c4209\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>section</th>\n",
              "      <th>class</th>\n",
              "      <th>confidence</th>\n",
              "      <th>net score</th>\n",
              "      <th>net attention</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>text</th>\n",
              "      <th>colored</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31</td>\n",
              "      <td>RELATED WORK</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.924</td>\n",
              "      <td>-0.305</td>\n",
              "      <td>19.884472</td>\n",
              "      <td>0.924</td>\n",
              "      <td>0.066</td>\n",
              "      <td>0.009</td>\n",
              "      <td>However, this method generates the overall sen...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHowever, \u001b[48;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123</td>\n",
              "      <td>EXPERIMENTS</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.917</td>\n",
              "      <td>-0.297</td>\n",
              "      <td>16.340233</td>\n",
              "      <td>0.917</td>\n",
              "      <td>0.055</td>\n",
              "      <td>0.027</td>\n",
              "      <td>However, we cannot complete this job yet out o...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHowever, \u001b[48;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>INTRODUCTION</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.764</td>\n",
              "      <td>-0.226</td>\n",
              "      <td>12.599020</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.145</td>\n",
              "      <td>0.089</td>\n",
              "      <td>Quantitative metrics could not evaluate the re...</td>\n",
              "      <td>\u001b[48;2;0;0;89m\u001b[38;2;255;255;255mQuantitative ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>141</td>\n",
              "      <td>EXPERIMENTS</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.597</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>10.496807</td>\n",
              "      <td>0.597</td>\n",
              "      <td>0.378</td>\n",
              "      <td>0.023</td>\n",
              "      <td>Those metrics are derived from citations and d...</td>\n",
              "      <td>\u001b[48;2;0;0;5m\u001b[38;2;255;255;255mThose \u001b[48;2;4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>77</td>\n",
              "      <td>RELATED WORK</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.597</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>10.496807</td>\n",
              "      <td>0.597</td>\n",
              "      <td>0.378</td>\n",
              "      <td>0.023</td>\n",
              "      <td>Those metrics are derived from citations and d...</td>\n",
              "      <td>\u001b[48;2;0;0;5m\u001b[38;2;255;255;255mThose \u001b[48;2;4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>INTRODUCTION</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.909</td>\n",
              "      <td>0.296</td>\n",
              "      <td>8.146835</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.909</td>\n",
              "      <td>The number of papers published each year has ...</td>\n",
              "      <td>\u001b[48;2;72;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;8;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>115</td>\n",
              "      <td>METHODOLOGY</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.907</td>\n",
              "      <td>0.299</td>\n",
              "      <td>7.527385</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0.907</td>\n",
              "      <td>The main idea is shown in Figure 3.</td>\n",
              "      <td>\u001b[48;2;0;0;85m\u001b[38;2;255;255;255mThe \u001b[48;2;11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>125</td>\n",
              "      <td>EXPERIMENTS</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.915</td>\n",
              "      <td>0.303</td>\n",
              "      <td>16.606018</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.915</td>\n",
              "      <td>Besides, we also compare our modules to other ...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBesides, \u001b[48;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>142</td>\n",
              "      <td>EXPERIMENTS</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.934</td>\n",
              "      <td>0.303</td>\n",
              "      <td>6.461682</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.934</td>\n",
              "      <td>Semantic Scholar makes the first step towards ...</td>\n",
              "      <td>\u001b[48;2;72;0;0m\u001b[38;2;255;255;255mSemantic \u001b[48...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79</td>\n",
              "      <td>RELATED WORK</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.960</td>\n",
              "      <td>0.311</td>\n",
              "      <td>10.534895</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.960</td>\n",
              "      <td>Espe- cially, Semantic Scholar makes the first...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mEspe- \u001b[48;2;0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>176 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b335de30-6f3a-427b-81e7-5aefc25c4209')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b335de30-6f3a-427b-81e7-5aefc25c4209 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b335de30-6f3a-427b-81e7-5aefc25c4209');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 481
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_phocus.sort_values(by=['net attention'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_oWvI8tdC3RL",
        "outputId": "61a79857-3dae-4647-c44b-3762c6525f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sentence       section  class  confidence  net score  net attention  \\\n",
              "0        129   EXPERIMENTS   -1.0       0.437     -0.011       3.302047   \n",
              "0        119   METHODOLOGY    1.0       0.733      0.237       4.644296   \n",
              "0         74  RELATED WORK    0.0       0.599      0.055       4.656850   \n",
              "0        172    CONCLUSION    1.0       0.829      0.248       4.685307   \n",
              "0          5  INTRODUCTION   -1.0       0.631     -0.153       4.988726   \n",
              "..       ...           ...    ...         ...        ...            ...   \n",
              "0        117   METHODOLOGY    0.0       0.533      0.154      46.593880   \n",
              "0        116   METHODOLOGY    0.0       0.940      0.019      58.259689   \n",
              "0        144   EXPERIMENTS    0.0       0.940      0.012      60.146317   \n",
              "0         81  RELATED WORK    0.0       0.935      0.015      62.142685   \n",
              "0         23  RELATED WORK    1.0       0.565      0.180      83.631065   \n",
              "\n",
              "      neg    neu    pos                                               text  \\\n",
              "0   0.437  0.158  0.404                              As we emphasize, Pat.   \n",
              "0   0.020  0.246  0.733                   The first one is margin effects.   \n",
              "0   0.116  0.599  0.283                              higher or equal to ℎ.   \n",
              "0   0.083  0.086  0.829                    Phocus still need improvements.   \n",
              "0   0.631  0.193  0.174            They state this opinion in two aspects.   \n",
              "..    ...    ...    ...                                                ...   \n",
              "0   0.001  0.533  0.464  Then, the academic influential factor of 𝐴 is:...   \n",
              "0   0.000  0.940  0.058  𝐴 denote a citing paper with academic influent...   \n",
              "0   0.010  0.940  0.048  The features Seman- tic Scholar use are total ...   \n",
              "0   0.009  0.935  0.054  The features Semantic Scholar use are the tota...   \n",
              "0   0.023  0.411  0.565  Valenzuela et al. [35] divide citations into 4...   \n",
              "\n",
              "                                              colored  \n",
              "0   \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mAs \u001b[48;2;0;...  \n",
              "0   \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;21...  \n",
              "0   \u001b[48;2;199;0;0m\u001b[38;2;255;255;255mhigher \u001b[48;...  \n",
              "0   \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mPhocus \u001b[48;...  \n",
              "0   \u001b[48;2;0;0;39m\u001b[38;2;255;255;255mThey \u001b[48;2;2...  \n",
              "..                                                ...  \n",
              "0   \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mThen, \u001b[48;2;6...  \n",
              "0   \u001b[48;2;0;0;0m\u001b[38;2;255;255;255m𝐴 \u001b[48;2;24;0;...  \n",
              "0   \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0...  \n",
              "0   \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mthe \u001b[48;2;0;...  \n",
              "0   \u001b[48;2;222;0;0m\u001b[38;2;255;255;255mValenzuela \u001b...  \n",
              "\n",
              "[176 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2ff077e-be95-4b65-9452-f8e62b66ca67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>section</th>\n",
              "      <th>class</th>\n",
              "      <th>confidence</th>\n",
              "      <th>net score</th>\n",
              "      <th>net attention</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>text</th>\n",
              "      <th>colored</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>129</td>\n",
              "      <td>EXPERIMENTS</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.437</td>\n",
              "      <td>-0.011</td>\n",
              "      <td>3.302047</td>\n",
              "      <td>0.437</td>\n",
              "      <td>0.158</td>\n",
              "      <td>0.404</td>\n",
              "      <td>As we emphasize, Pat.</td>\n",
              "      <td>\u001b[48;2;123;0;0m\u001b[38;2;255;255;255mAs \u001b[48;2;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119</td>\n",
              "      <td>METHODOLOGY</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.733</td>\n",
              "      <td>0.237</td>\n",
              "      <td>4.644296</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.246</td>\n",
              "      <td>0.733</td>\n",
              "      <td>The first one is margin effects.</td>\n",
              "      <td>\u001b[48;2;83;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>74</td>\n",
              "      <td>RELATED WORK</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.599</td>\n",
              "      <td>0.055</td>\n",
              "      <td>4.656850</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.599</td>\n",
              "      <td>0.283</td>\n",
              "      <td>higher or equal to ℎ.</td>\n",
              "      <td>\u001b[48;2;199;0;0m\u001b[38;2;255;255;255mhigher \u001b[48;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>172</td>\n",
              "      <td>CONCLUSION</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.248</td>\n",
              "      <td>4.685307</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.086</td>\n",
              "      <td>0.829</td>\n",
              "      <td>Phocus still need improvements.</td>\n",
              "      <td>\u001b[48;2;0;0;182m\u001b[38;2;255;255;255mPhocus \u001b[48;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>INTRODUCTION</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.631</td>\n",
              "      <td>-0.153</td>\n",
              "      <td>4.988726</td>\n",
              "      <td>0.631</td>\n",
              "      <td>0.193</td>\n",
              "      <td>0.174</td>\n",
              "      <td>They state this opinion in two aspects.</td>\n",
              "      <td>\u001b[48;2;0;0;39m\u001b[38;2;255;255;255mThey \u001b[48;2;2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>117</td>\n",
              "      <td>METHODOLOGY</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.533</td>\n",
              "      <td>0.154</td>\n",
              "      <td>46.593880</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.533</td>\n",
              "      <td>0.464</td>\n",
              "      <td>Then, the academic influential factor of 𝐴 is:...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mThen, \u001b[48;2;6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>116</td>\n",
              "      <td>METHODOLOGY</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.019</td>\n",
              "      <td>58.259689</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.058</td>\n",
              "      <td>𝐴 denote a citing paper with academic influent...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255m𝐴 \u001b[48;2;24;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>144</td>\n",
              "      <td>EXPERIMENTS</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.012</td>\n",
              "      <td>60.146317</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.048</td>\n",
              "      <td>The features Seman- tic Scholar use are total ...</td>\n",
              "      <td>\u001b[48;2;3;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>81</td>\n",
              "      <td>RELATED WORK</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.935</td>\n",
              "      <td>0.015</td>\n",
              "      <td>62.142685</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.935</td>\n",
              "      <td>0.054</td>\n",
              "      <td>The features Semantic Scholar use are the tota...</td>\n",
              "      <td>\u001b[48;2;0;0;34m\u001b[38;2;255;255;255mthe \u001b[48;2;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>RELATED WORK</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.565</td>\n",
              "      <td>0.180</td>\n",
              "      <td>83.631065</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.411</td>\n",
              "      <td>0.565</td>\n",
              "      <td>Valenzuela et al. [35] divide citations into 4...</td>\n",
              "      <td>\u001b[48;2;222;0;0m\u001b[38;2;255;255;255mValenzuela \u001b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>176 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2ff077e-be95-4b65-9452-f8e62b66ca67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2ff077e-be95-4b65-9452-f8e62b66ca67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2ff077e-be95-4b65-9452-f8e62b66ca67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 482
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_paper_sentiment=np.mean(df_phocus['net attention'])\n",
        "overall_paper_sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEoqE8jJDklZ",
        "outputId": "7e692fb4-d04f-43fb-8312-507b3c0bd39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.59335708618164"
            ]
          },
          "metadata": {},
          "execution_count": 483
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_paper_sentiment=np.mean(df_phocus['net score'])\n",
        "overall_paper_sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e786wcE1nYsZ",
        "outputId": "c566043b-c8d1-4dbd-9817-1e1c1c36d1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08068181818181822"
            ]
          },
          "metadata": {},
          "execution_count": 484
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "input.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}