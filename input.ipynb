{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h7Lr7k5d1jd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ENEE439d-TEXTML/TextML/blob/master/input.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/ENEE439d-TEXTML/TextML/blob/master/input.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPiicLOUd1jj"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U \"tensorflow-text==2.8.*\" # A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q tf-models-official==2.7.0 # For adamW\n",
        "!pip install focal-loss # focal loss implmnetion for tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52FpqTzrPr-t",
        "outputId": "759c72fc-f90b-44c0-e5b1-a2ed9e3747a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 6.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 60.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 11.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 41.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 54.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 57.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 60.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting focal-loss\n",
            "  Downloading focal_loss-0.0.7-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal-loss) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.25.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (14.0.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.5.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.44.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (4.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.14.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.3.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal-loss) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2->focal-loss) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.3.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.2.0)\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BPnv0Vlcd3KI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #basic imports\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split # https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization, bert  # to create AdamW optimizer\n",
        "from focal_loss import SparseCategoricalFocalLoss\n",
        "import official.nlp.bert.tokenization"
      ],
      "metadata": {
        "id": "dkxbtcKbP4AU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data read in"
      ],
      "metadata": {
        "id": "Q-Dc1EsOuQA0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "465BADPxeNII",
        "outputId": "241f8a72-5d37-4cb6-8ef6-994a7d755b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Sk1zTIA6eOM5",
        "outputId": "8479483c-0152-494c-cad0-bd84aa5ee2db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  cited_paper  label                                               text\n",
              "0    A00-2024      0  We analyzed a set of articles and identified s...\n",
              "1    A00-2024      0  Table 3: Example compressions Compression AvgL...\n",
              "2    A00-2024      0  5.3 Related works and discussion Our two-step ...\n",
              "3    A00-2024      0  (1999) proposed a summarization system based o...\n",
              "4    A00-2024      0  We found that the deletion of lead parts did n..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98eb8afe-54aa-4dde-a4ab-9103b2ed15ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98eb8afe-54aa-4dde-a4ab-9103b2ed15ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98eb8afe-54aa-4dde-a4ab-9103b2ed15ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98eb8afe-54aa-4dde-a4ab-9103b2ed15ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "filepath = '/content/drive/MyDrive/Text-ML/full_sentiment_dataset.csv' #'data.csv'\n",
        "df= pd.read_csv(filepath)\n",
        "df1=df.drop(['no','paper','context_a','context_b'],axis=1)\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImSOYF6Py2J8",
        "outputId": "7a7f4241-e95c-418e-e8d5-2fd9adcf8baf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    7627\n",
              " 1     829\n",
              "-1     280\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filtering by regex"
      ],
      "metadata": {
        "id": "FHIvNaLfuUoe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytc03_FI-b5L",
        "outputId": "8ed4b90b-ee65-4730-ae65-5b1f9e7ef222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\[*\\]|\\(\\d{4}\\)|\\(?((\\(?((\\w+, )*(\\w+ )+)((and|&) ((\\w+ *))?)?,? \\(?\\d{4}\\)?|((\\w+, )*(\\w+ )+)et al\\. ?,? \\(?\\d{4}\\)?\\)?)((; )|( (and|&) ))*)+\n"
          ]
        }
      ],
      "source": [
        "context=df1['text']\n",
        "\n",
        "re1= \"\\(((([A-Za-z]+ *)+(, \\d+))+(; )*)+\\)\" # matches author and author, year\n",
        "re_year=\",? \\(?\\d{4}\\)?\" # match , {4 digits} which may be wrapped in () \n",
        "re_and=\"(and|&) \"\n",
        "re_auth=\"((\\w+, )*(\\w+ )+)\"\n",
        "re_et= re_auth+\"et al\\. ?\"+re_year # matches author et al. , year\n",
        "re_2a= re_auth+\"(\"+re_and+\"((\\w+ *))?)?\"+re_year # matches author and author, year\n",
        "re_sep=\"((; )|( \"+re_and+\"))*\"# match the '; ' gap or ' and ' gap\n",
        "re_para_year=\"\\(\\d{4}\\)\"\n",
        "re_in_brack=\"\\[*\\]\"\n",
        "re_apa =re_in_brack+\"|\"+re_para_year+\"|\"+\"\\(?(\"+\"(\\(?\"+re_2a+\"|\"+re_et+\"\\)?)\"+re_sep+\")+\"\n",
        "print(re_apa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NEZIAWQtykDg"
      },
      "outputs": [],
      "source": [
        "def remove_matches(text,regex=re_apa):\n",
        "  text1=text\n",
        "  rem_len=0\n",
        "  pattern= re.compile(regex)\n",
        "  while True:\n",
        "    matches=pattern.search(text1)\n",
        "    #print(matches)\n",
        "    if matches == None:\n",
        "      break\n",
        "\n",
        "    spn=matches.span()\n",
        "    text1=text1[0:spn[0]]+text1[spn[1]:-1]\n",
        "    cit_len=spn[1]-spn[0]\n",
        "    rem_len+=cit_len\n",
        "  \n",
        "  if len(text) >0:\n",
        "    percent_removed=rem_len/len(text)\n",
        "  else:\n",
        "    percent_removed=1\n",
        "  return text1,percent_removed \n",
        "\n",
        "# print(context[5])\n",
        "# remove_citation(context[5],regex=re_apa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TmjjH1gp9A6T"
      },
      "outputs": [],
      "source": [
        "output=df1['text'].apply(lambda x: remove_matches(text=x,regex=re_apa)) #df['col1'] = df.apply(lambda x: complex_function(x['col1']), axis=1)\n",
        "df_o = pd.DataFrame(list(output), columns =['clean','p_rem'])\n",
        "output_1=df_o['clean'].apply(lambda x: remove_matches(text=x,regex='[^\\w_0-9 ]+')) \n",
        "df_o_1 = pd.DataFrame(list(output_1), columns =['clean','p_rem'])\n",
        "#df_o.head()\n",
        "\n",
        "df1['text_clean']=df_o_1['clean']\n",
        "df1['text_clean_len']=df_o_1['clean'].apply(len)\n",
        "df1['p_rem']=df_o['p_rem']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OVt3NtaJDDrx",
        "outputId": "ae82e824-9a1f-43e5-d989-977d7dfcdbe8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cited_paper  label                                               text  \\\n",
              "0       A00-2024      0  We analyzed a set of articles and identified s...   \n",
              "1       A00-2024      0  Table 3: Example compressions Compression AvgL...   \n",
              "2       A00-2024      0  5.3 Related works and discussion Our two-step ...   \n",
              "3       A00-2024      0  (1999) proposed a summarization system based o...   \n",
              "4       A00-2024      0  We found that the deletion of lead parts did n...   \n",
              "...          ...    ...                                                ...   \n",
              "8731    W96-0213      1  He has achieved state-of-the art results by ap...   \n",
              "8732    W96-0213      0  B = (Brill and Wu, 1998); M = (Magerman, 1995)...   \n",
              "8733    W96-0213      0  The model we use is similar to that of (Ratnap...   \n",
              "8734    W96-0213      1  Our model exploits the same kind of tag-n-gram...   \n",
              "8735    W96-0213      0  In that table, TBL stands for Brill's transfor...   \n",
              "\n",
              "                                             text_clean  text_clean_len  \\\n",
              "0     We analyzed a set of articles and identified s...             425   \n",
              "1     Table 3 Example compressions Compression AvgLe...             229   \n",
              "2     53 Related works and discussion Our twostep mo...             105   \n",
              "3      proposed a summarization system based on the ...             321   \n",
              "4     We found that the deletion of lead parts did n...              73   \n",
              "...                                                 ...             ...   \n",
              "8731  He has achieved stateofthe art results by appl...             139   \n",
              "8732   B  M  Magerman 1995 O  our data R  Ratnaparkhi 1              48   \n",
              "8733  The model we use is similar to that of Ratnapa...              55   \n",
              "8734  Our model exploits the same kind of tagngram i...             157   \n",
              "8735  In that table TBL stands for Brills transforma...             288   \n",
              "\n",
              "         p_rem  \n",
              "0     0.098765  \n",
              "1     0.260745  \n",
              "2     0.308176  \n",
              "3     0.078804  \n",
              "4     0.408000  \n",
              "...        ...  \n",
              "8731  0.151515  \n",
              "8732  0.421488  \n",
              "8733  0.000000  \n",
              "8734  0.000000  \n",
              "8735  0.000000  \n",
              "\n",
              "[8736 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55423898-3b57-4f9c-a3e0-488d3753e7f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_clean_len</th>\n",
              "      <th>p_rem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "      <td>425</td>\n",
              "      <td>0.098765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "      <td>Table 3 Example compressions Compression AvgLe...</td>\n",
              "      <td>229</td>\n",
              "      <td>0.260745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "      <td>53 Related works and discussion Our twostep mo...</td>\n",
              "      <td>105</td>\n",
              "      <td>0.308176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "      <td>proposed a summarization system based on the ...</td>\n",
              "      <td>321</td>\n",
              "      <td>0.078804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "      <td>73</td>\n",
              "      <td>0.408000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>1</td>\n",
              "      <td>He has achieved state-of-the art results by ap...</td>\n",
              "      <td>He has achieved stateofthe art results by appl...</td>\n",
              "      <td>139</td>\n",
              "      <td>0.151515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8732</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>B = (Brill and Wu, 1998); M = (Magerman, 1995)...</td>\n",
              "      <td>B  M  Magerman 1995 O  our data R  Ratnaparkhi 1</td>\n",
              "      <td>48</td>\n",
              "      <td>0.421488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8733</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>The model we use is similar to that of (Ratnap...</td>\n",
              "      <td>The model we use is similar to that of Ratnapa...</td>\n",
              "      <td>55</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8734</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>1</td>\n",
              "      <td>Our model exploits the same kind of tag-n-gram...</td>\n",
              "      <td>Our model exploits the same kind of tagngram i...</td>\n",
              "      <td>157</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8735</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>In that table, TBL stands for Brill's transfor...</td>\n",
              "      <td>In that table TBL stands for Brills transforma...</td>\n",
              "      <td>288</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8736 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55423898-3b57-4f9c-a3e0-488d3753e7f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55423898-3b57-4f9c-a3e0-488d3753e7f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55423898-3b57-4f9c-a3e0-488d3753e7f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove under and over sized samples\n",
        "large samples appear to be poorly written"
      ],
      "metadata": {
        "id": "pkNPWqAHKLxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getMidLen(data,label,labelKey='label',lenKey='text_clean_len',lowMod=1,highMod=1):\n",
        "  df1 =data.loc[data[labelKey] == label]\n",
        "  neu_mean=np.mean(list(df1[lenKey]))\n",
        "  neu_std=np.std(list(df1[lenKey]))\n",
        "  df1_no_high = df1.loc[df1[lenKey] < highMod*(neu_mean +neu_std)]\n",
        "  # print(neu_mean)\n",
        "  # print(neu_std)\n",
        "\n",
        "  while neu_std > neu_mean:\n",
        "    neu_mean=np.mean(list(df1_no_high['text_clean_len']))\n",
        "    neu_std=np.std(list(df1_no_high['text_clean_len']))\n",
        "    # print(neu_mean)\n",
        "    # print(neu_std)\n",
        "    df1_no_high = df1.loc[df1['text_clean_len'] < highMod*(neu_mean +neu_std)]\n",
        "\n",
        "  df1_mid = df1_no_high.loc[df1_no_high['text_clean_len'] > lowMod*(neu_mean -neu_std)]\n",
        "\n",
        "  return df1_mid\n",
        "\n",
        "df2 = df1.loc[df1['p_rem'] < .5] #keep sampels with less than half of it are citation\n",
        "\n",
        "df_neu=getMidLen(df2,0,lowMod=2)\n",
        "df_pos=getMidLen(df2,1,lowMod=1,highMod=2)\n",
        "df_neg=getMidLen(df2,-1,lowMod=1,highMod=2)\n",
        "df3= pd.concat([df_neg,df_neu,df_pos])\n",
        "df3['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq-BsMfleXID",
        "outputId": "e3b8cf5d-1767-4daf-ebe4-74436b4ddc86"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    2524\n",
              " 1     746\n",
              "-1     246\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def catagorize(data,labelKey='label'):\n",
        "  rows=len(data.index)\n",
        "  onehots=np.zeros((rows,3),dtype=int)\n",
        "  for i,lab in enumerate(data[labelKey]):\n",
        "    onehots[i][lab+1]=1\n",
        "  return onehots\n",
        "\n",
        "hots=catagorize(df3)\n",
        "df3['label_onehot']=list(hots)\n",
        "df3['label_index']=df3['label']+1"
      ],
      "metadata": {
        "id": "VnsKnaB0AU4i"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq= np.array(list(df3['label_index'].value_counts(normalize=True,sort=False)))\n",
        "print(freq)\n",
        "class_ratio= 1/freq\n",
        "class_ratio"
      ],
      "metadata": {
        "id": "Mbn2dX1C2Ixs",
        "outputId": "d003d74b-e34d-47f0-b69f-e514aa08b4b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06996587 0.71786121 0.21217292]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14.29268293,  1.39302694,  4.71313673])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Model"
      ],
      "metadata": {
        "id": "QtrXZF4_unOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(list(df3['text_clean']), list(df3['label_index']), test_size=0.2, random_state=42)\n",
        "X_train= [[s] for s in X_train]\n",
        "X_test= [[s] for s in X_test]\n",
        "y_train=[[s] for s in list(y_train)]\n",
        "y_test=[[s] for s in list(y_test)]"
      ],
      "metadata": {
        "id": "kKtJq5Baj1Wl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose a BERT model to fine-tune (Taken from tutorial)\n",
        "\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "metadata": {
        "id": "9WK-J5dQpprm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9835c3c-9b3b-4a8f-fb88-3d1fb7885afd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check model passes"
      ],
      "metadata": {
        "id": "91uobQaIu-iE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "metadata": {
        "id": "YINTv-Uu8HP5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = X_train[1]\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGAgJwGg08-j",
        "outputId": "6c2fcacc-f59c-4f44-e068-6434f4b4c836"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_word_ids', 'input_type_ids', 'input_mask']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [  101  1999  5688 11416  6024  4275  2024  4738  2000 25845  1996  4101]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "metadata": {
        "id": "U2o1JW9b9MHu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW0iEt6Z9PKt",
        "outputId": "ceaa502a-7bd0-4264-a275-bf55bfdfa3c4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.99835694 -0.7678578  -0.21300124  0.08411987 -0.08593949  0.98550844\n",
            "  0.9732349  -0.8306031  -0.55687106 -0.95725054 -0.3960305  -0.94115573]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[ 3.8915187e-01  2.3267061e-01  6.1780311e-02 ... -9.2866874e-01\n",
            "   4.3027106e-01  8.3279318e-01]\n",
            " [ 4.5310837e-01  7.2308904e-01 -3.2866317e-01 ... -1.1163950e-04\n",
            "  -3.3482751e-01  5.7274055e-01]\n",
            " [-2.5876865e-01  1.4199525e+00 -4.2525381e-01 ...  4.9038833e-01\n",
            "   1.4491324e-01  5.7048750e-01]\n",
            " ...\n",
            " [ 2.6529512e-01 -2.3668993e-01  8.4921330e-02 ...  2.0211086e-02\n",
            "   3.9103544e-01  8.9449620e-01]\n",
            " [ 2.9499257e-01  5.8424294e-01 -6.7344594e-01 ... -1.6148384e+00\n",
            "   1.3211843e+00 -6.0517174e-01]\n",
            " [-1.8697177e-01  5.2527428e-01  9.2377967e-01 ... -5.6088662e-01\n",
            "   1.0293359e+00 -7.8856331e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## full model setup"
      ],
      "metadata": {
        "id": "GSyS6XhXvGXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(3, activation='softmax', name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "XWtmKUBu_3kJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = build_classifier_model()"
      ],
      "metadata": {
        "id": "Z17Cu4Awc3jA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check loss function"
      ],
      "metadata": {
        "id": "KgOUUHifvD3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(bert_raw_result)\n",
        "\n",
        "l =  SparseCategoricalFocalLoss(gamma=2,class_weight=class_ratio)\n",
        "test =tf.convert_to_tensor([1.0])\n",
        "l(test,bert_raw_result)"
      ],
      "metadata": {
        "id": "jHqpunBDTKym",
        "outputId": "9f0026ad-6a60-4800-dd67-b21d797f400e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.07656216 0.749452   0.1739859 ]], shape=(1, 3), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.02522065>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Save and Log"
      ],
      "metadata": {
        "id": "hTEGlj9RvLg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "steps_per_epoch = 200 #tf.data.experimental.cardinality(X_train).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 2e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n",
        "\n",
        "# def auc_wrapper(y_true,y_pred):\n",
        "#   print(y_true,y_pred)\n",
        "\n",
        "#   y_true=tf.reshape(y_true,[1])\n",
        "#   print(y_true)\n",
        "#   y_true= tf.cast(y_true, tf.int32)\n",
        "#   print(y_true)\n",
        "#   y_true=tf.one_hot(y_true,depth=3)\n",
        "#   print(y_true)\n",
        "#   return tf.keras.metrics.AUC(multi_label=True)(y_true,y_pred)\n",
        "\n",
        "\n",
        "loss =  SparseCategoricalFocalLoss(gamma=2,class_weight=class_ratio) #tf.keras.losses.MeanSquaredError()\n",
        "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]#, auc_wrapper]#, tf.keras.metrics.AUC(multi_label=True)]\n",
        "\n",
        "\n",
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"citation_BERT_{epoch}\",\n",
        "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
        "        monitor=\"val_sparse_categorical_accuracy\",\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n",
        "]\n"
      ],
      "metadata": {
        "id": "MB9Af5RMCuqP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Training model with {tfhub_handle_encoder}')\n",
        "# history = classifier_model.fit(x=X_train,y=y_train, validation_data=(X_test,y_test),epochs=epochs,callbacks= callbacks, verbose=True)"
      ],
      "metadata": {
        "id": "89v_3XqEE3HN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier_model.save_weights(''/content/drive/MyDrive/Text-ML/checkpoint1')"
      ],
      "metadata": {
        "id": "Pox0n2xZjdtX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect model"
      ],
      "metadata": {
        "id": "Z_fseNCGvY4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "00eGEQhDdMUK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorboard --logdir=logs"
      ],
      "metadata": {
        "id": "Gszh9ZNBbQXe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.load_weights('/content/drive/MyDrive/Text-ML/checkpoint')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMRXTmWvmBNn",
        "outputId": "3f084ea8-8e1f-44fa-aa41-9a742d9ff606"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fad54818f90>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=classifier_model.predict(X_train,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCgZJCYsvdMe",
        "outputId": "b066afa4-87bb-45cb-c5a3-dcf1083aea65"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/88 [==============================] - 197s 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_t=classifier_model.predict(X_test,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu5a35I1wlOi",
        "outputId": "b96d2fba-58d8-4ed7-ecb7-f273f0fd3410"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 [==============================] - 49s 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns; sns.set_theme()"
      ],
      "metadata": {
        "id": "Q-NxIjYJx8S1"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_mat=tf.math.confusion_matrix(np.argmax(preds,-1),y_train)\n",
        "ax = sns.heatmap(c_mat,annot=True,linewidths=.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "_5R4bXyzxoql",
        "outputId": "8124b216-f286-49b3-ea83-bcb09c6a2421"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_mat=tf.math.confusion_matrix(np.argmax(preds_t,-1),y_test)\n",
        "ax = sns.heatmap(c_mat,annot=True,linewidths=.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "RPkpGRdDyCz6",
        "outputId": "f4e79de6-c346-4063-925b-b34922941b2e"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get attention colorings"
      ],
      "metadata": {
        "id": "ZRca_y_Kvq86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1\n"
      ],
      "metadata": {
        "id": "aSNvnkyoJdqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.layers"
      ],
      "metadata": {
        "id": "PR_gDYEQofck",
        "outputId": "1a3c7f44-a31a-4764-f516-0b7901863e7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7fad57ceb3d0>,\n",
              " <tensorflow_hub.keras_layer.KerasLayer at 0x7fad57ca6710>,\n",
              " <tensorflow_hub.keras_layer.KerasLayer at 0x7fad57c0ab10>,\n",
              " <keras.layers.core.dropout.Dropout at 0x7fad569ae390>,\n",
              " <keras.layers.core.dense.Dense at 0x7fad56a6e650>]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from official.nlp import bert \n",
        "import official.nlp.bert.tokenization"
      ],
      "metadata": {
        "id": "bC2uW7zrx7VR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = bert.tokenization.FullTokenizer(vocab_file='/content/drive/MyDrive/Text-ML/vocab.txt')\n",
        "preprocesser_model = keras.Model(inputs=classifier_model.input,outputs=classifier_model.get_layer('preprocessing').output)\n",
        "encoder_model = keras.Model(inputs=classifier_model.input,outputs=classifier_model.get_layer('BERT_encoder').output)"
      ],
      "metadata": {
        "id": "Lnb_ie7zxpbc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocab size:\", len(tokenizer.vocab))"
      ],
      "metadata": {
        "id": "mjgJ0WAwRjYb",
        "outputId": "360e6c09-196d-43b7-a821-3999f910cb98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 30522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attnetion token mapping"
      ],
      "metadata": {
        "id": "z7DPKDmPI9yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attn(context,prep,encoder): # assume stirng array input\n",
        "  t_context=tf.convert_to_tensor(context)\n",
        "\n",
        "  p_out=prep(t_context)\n",
        "  #print(p_out)\n",
        "  stop_index=0\n",
        "  while(stop_index< p_out[\"input_mask\"].shape[1] and p_out[\"input_mask\"][0][stop_index] == 1):\n",
        "    stop_index+=1\n",
        "  \n",
        "  if stop_index >= 128:\n",
        "    stop_index=127\n",
        "\n",
        "  output = encoder(t_context)\n",
        "  #print(output[\"sequence_output\"].shape)\n",
        "  valid_entries=output[\"sequence_output\"][:,1:stop_index-1,:]\n",
        "  a=tf.math.reduce_mean(valid_entries,-1)\n",
        "  mean=tf.math.reduce_mean(a,-1,keepdims=True)\n",
        "  std=tf.math.reduce_std(a,-1,keepdims=True)\n",
        "  a1=(a-mean)/std\n",
        "\n",
        "  return a1"
      ],
      "metadata": {
        "id": "NC_Cyexu9TQI"
      },
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attn_for_words(context,tokenizer,prep,encoder):\n",
        "  attn = get_attn(context,prep,encoder).numpy()\n",
        "  tokens = tokenizer.tokenize(context[0]) \n",
        "\n",
        "  indicies=np.ones((len(tokens)),dtype=int)\n",
        "  for i,tok in enumerate(tokens):\n",
        "    if '##' in tok:\n",
        "      indicies[i]=0\n",
        "\n",
        "  full_words=tokens.copy()\n",
        "  ix=-1\n",
        "  for i,tok in enumerate(tokens):\n",
        "    if not indicies[i]:\n",
        "      attn[0][ix]+=attn[0][i]\n",
        "      full_words[ix]+=tok[2:]\n",
        "    else:\n",
        "      ix=i\n",
        "\n",
        "  t_f=tf.convert_to_tensor(full_words) #stores as byte string...\n",
        "  masked_f=tf.boolean_mask(t_f,indicies)\n",
        "  t_a=tf.convert_to_tensor(attn)[0]\n",
        "  masked_a=tf.boolean_mask(t_a[:len(indicies)],indicies)\n",
        "  \n",
        "\n",
        "  return masked_f.numpy(),masked_a.numpy()\n",
        "\n",
        "#words, at=get_attn_for_words(processed,tokenizer,preprocesser_model,encoder_model)"
      ],
      "metadata": {
        "id": "iyhKVIiY121W"
      },
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## converters and annotation"
      ],
      "metadata": {
        "id": "kj_6JUFQIvG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_for_input(raw_context):\n",
        "  c1,_ =remove_matches(text=raw_context,regex=re_apa)\n",
        "  c2,_ =remove_matches(text=c1,regex='[^\\w_\\-0-9 ]+')\n",
        "  return [c2]\n",
        "\n",
        "#process_for_input(example)"
      ],
      "metadata": {
        "id": "PTVxz5uFJZyI"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_bytes_strs(words):\n",
        "  return [w.decode('UTF-8') for w in list(words)]"
      ],
      "metadata": {
        "id": "uFUPhtLDH5SS"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_to_color(attn): #blue pos red neg\n",
        "  rgbs = np.zeros((len(attn),3),dtype=int)\n",
        "  for i,score in enumerate(attn):\n",
        "    if score > 0:\n",
        "      rgbs[i][0]=255*score//2\n",
        "    else:\n",
        "      rgbs[i][2]=-255*score//2\n",
        "  \n",
        "  return rgbs"
      ],
      "metadata": {
        "id": "yDhvZkOFMFJ3"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coloring(text,fore=None,back=None):\n",
        "    txt=text\n",
        "    if fore != None:\n",
        "      txt = \"\\033[38;2;{};{};{}m\".format(fore[0], fore[1], fore[2])+txt\n",
        "    if back != None:\n",
        "      txt = \"\\033[48;2;{};{};{}m\".format(back[0], back[1], back[2])+txt\n",
        "    return txt\n",
        "\n",
        "#print(coloring('Hello',back=[500,0,0]) + coloring('Hello', back=(0,0,255)))"
      ],
      "metadata": {
        "id": "X8GvqhLvOR8H"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## full pipeline"
      ],
      "metadata": {
        "id": "spUdAeqoI0Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def color_by_attn(text,toker,preper,encoder):\n",
        "  all_words_original=text.split()\n",
        "  all_words=text.lower().split()\n",
        "  processed= process_for_input(text)\n",
        "\n",
        "  words, at=get_attn_for_words(processed,tokenizer,preprocesser_model,encoder_model)\n",
        "\n",
        "  ws=conv_bytes_strs(words)\n",
        "  conv=conv_to_color(at)\n",
        "  mapping=dict(zip(ws,conv))\n",
        "  orig_mapping=dict(zip(all_words,all_words_original))\n",
        "\n",
        "  for i,w in enumerate(all_words):\n",
        "    if w not in mapping:\n",
        "      mapping[w]=[0,0,0]\n",
        "    else:\n",
        "      mapping[w]=list(mapping[w])\n",
        "\n",
        "  colored=[coloring(orig_mapping[word],back=mapping[word]) for word in all_words]\n",
        "  printed=' '.join(colored)\n",
        "  return printed\n",
        "\n",
        "example=list(df3['text'])[0]\n",
        "print(color_by_attn(example,tokenizer,preprocesser_model,encoder_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hossOHKtZ1Wn",
        "outputId": "7c63c409-9f9d-442f-bb32-018f39e43235"
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[48;2;0;0;12mMany \u001b[48;2;108;0;0mapproaches \u001b[48;2;102;0;0mfor \u001b[48;2;0;0;140mPOS \u001b[48;2;0;0;103mtagging \u001b[48;2;60;0;0mhave \u001b[48;2;0;0;22mbeen \u001b[48;2;0;0;188mdeveloped \u001b[48;2;46;0;0min \u001b[48;2;0;0;29mthe \u001b[48;2;0;0;0mpast, \u001b[48;2;281;0;0mincluding \u001b[48;2;0;0;0mrule-based \u001b[48;2;0;0;103mtagging \u001b[48;2;0;0;0m(Brill, \u001b[48;2;0;0;0m1995), \u001b[48;2;0;0;9mHMM \u001b[48;2;0;0;316mtaggers \u001b[48;2;0;0;0m(Brants, \u001b[48;2;0;0;0m2000; \u001b[48;2;0;0;0mCutting \u001b[48;2;0;0;0mand \u001b[48;2;0;0;0mothers, \u001b[48;2;0;0;0m1992), \u001b[48;2;0;0;0mmaximum-entropy \u001b[48;2;41;0;0mmodels \u001b[48;2;0;0;0m(Rathnaparki, \u001b[48;2;0;0;0m1996), \u001b[48;2;97;0;0mcyclic \u001b[48;2;0;0;61mdependency \u001b[48;2;45;0;0mnetworks \u001b[48;2;0;0;0m(Toutanova \u001b[48;2;0;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m, \u001b[48;2;0;0;0m2003), \u001b[48;2;0;0;0mmemory-based \u001b[48;2;84;0;0mlearning \u001b[48;2;0;0;0m(Daelemans \u001b[48;2;0;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m, \u001b[48;2;0;0;0m1996), \u001b[48;2;0;0;0metc. \u001b[48;2;15;0;0mall \u001b[48;2;258;0;0mof \u001b[48;2;186;0;0mthese \u001b[48;2;108;0;0mapproaches \u001b[48;2;110;0;0mrequire \u001b[48;2;0;0;215meither \u001b[48;2;217;0;0ma \u001b[48;2;0;0;207mlarge \u001b[48;2;46;0;0mamount \u001b[48;2;258;0;0mof \u001b[48;2;0;0;70mannotated \u001b[48;2;0;0;77mtraining \u001b[48;2;0;0;166mdata \u001b[48;2;0;0;0m(for \u001b[48;2;0;0;50msupervised \u001b[48;2;0;0;0mtagging) \u001b[48;2;93;0;0mor \u001b[48;2;217;0;0ma \u001b[48;2;0;0;467mlexicon \u001b[48;2;9;0;0mlisting \u001b[48;2;15;0;0mall \u001b[48;2;81;0;0mpossible \u001b[48;2;0;0;45mtags \u001b[48;2;102;0;0mfor \u001b[48;2;114;0;0meach \u001b[48;2;0;0;117mword \u001b[48;2;0;0;0m(for \u001b[48;2;0;0;0munsupervised \u001b[48;2;0;0;0mtagging).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF text extratction\n"
      ],
      "metadata": {
        "id": "TD_FQ6ioGFGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfminer.six"
      ],
      "metadata": {
        "id": "zPD706w-I9zR",
        "outputId": "22300c57-7c48-4a49-f48c-3e0e4b2e87be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20220319-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 9.0 MB/s \n",
            "\u001b[?25hCollecting cryptography\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 35.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (3.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six) (2.21)\n",
            "Installing collected packages: cryptography, pdfminer.six\n",
            "Successfully installed cryptography-37.0.2 pdfminer.six-20220319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import StringIO\n",
        "\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfdocument import PDFDocument\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.pdfparser import PDFParser"
      ],
      "metadata": {
        "id": "hKrdAGGRJPJB"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_pdf_to_string(file_path):\n",
        "\toutput_string = StringIO()\n",
        "\twith open(file_path, 'rb') as in_file:\n",
        "\t    parser = PDFParser(in_file)\n",
        "\t    doc = PDFDocument(parser)\n",
        "\t    rsrcmgr = PDFResourceManager()\n",
        "\t    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
        "\t    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "\t    for page in PDFPage.create_pages(doc):\n",
        "\t        interpreter.process_page(page)\n",
        "\n",
        "\treturn(output_string.getvalue())\n",
        " \n",
        "def sent_extract(sample):\n",
        "\tdelims=re.findall('\\. [A-Z]',sample)\n",
        "\tsents=re.split('\\. [A-Z]',sample)\n",
        "\n",
        "\tsents[0]=sents[0]+'.'\n",
        "\tfor i,s in enumerate(sents[1:]):\n",
        "\t\tsents[i+1]=delims[i][2]+s+'.'\n",
        "\treturn sents\n",
        "\n",
        "def pdf_text_extract(path):\n",
        "  text=convert_pdf_to_string(path)\n",
        "  text1 = text.replace('\\x0c','')\n",
        "  text2 = text1.split('.\\n\\n')\n",
        "  refine=[t.replace('\\n',' ') for t in text2]\n",
        "  r=[]\n",
        "  for t in refine:\n",
        "    r+=sent_extract(t)\n",
        "  return r\n",
        "\n",
        "path='/content/drive/MyDrive/Text-ML/phocus.pdf'\n",
        "text=pdf_text_extract(path)\n"
      ],
      "metadata": {
        "id": "HkUe38wlJSov"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_end=0\n",
        "ref_start=len(text)-1\n",
        "while '©' not in text[title_end]:\n",
        "  title_end+=1\n",
        "while 'REFERENCES' not in text[ref_start]:\n",
        "  ref_start-=1\n",
        "content=text[title_end+3:ref_start]\n"
      ],
      "metadata": {
        "id": "O9lsV2ij-2vn"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coloring of a PDF"
      ],
      "metadata": {
        "id": "_Td1mswaCOFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errs=[]\n",
        "for i,t in enumerate(content):\n",
        "  try:\n",
        "    print(color_by_attn(t,tokenizer,preprocesser_model,encoder_model))\n",
        "  except Exception:\n",
        "    errs.append(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcFhtVjoCRTh",
        "outputId": "6cd67190-8218-48d4-9420-ec1ef364ef4c"
      },
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[48;2;87;0;0mFrom \u001b[48;2;73;0;0mthe \u001b[48;2;100;0;0mscientific \u001b[48;2;0;0;0moutput, \u001b[48;2;0;0;0mresearch \u001b[48;2;0;0;0mfunding, \u001b[48;2;0;0;139mto \u001b[48;2;73;0;0mthe \u001b[48;2;0;0;238mevaluation \u001b[48;2;222;0;0mof \u001b[48;2;0;0;141mprofessional \u001b[48;2;0;0;0mrank, \u001b[48;2;157;0;0mpapers \u001b[48;2;5;0;0mplay \u001b[48;2;180;0;0ma \u001b[48;2;187;0;0mvery \u001b[48;2;39;0;0mimportant \u001b[48;2;0;0;0mrole, \u001b[48;2;21;0;0mand \u001b[48;2;73;0;0mthe \u001b[48;2;0;0;49mmore \u001b[48;2;0;0;0mpapers, \u001b[48;2;73;0;0mthe \u001b[48;2;0;0;0mbetter.\n",
            "\u001b[48;2;0;0;0mHowever, \u001b[48;2;121;0;0mIt \u001b[48;2;66;0;0mis \u001b[48;2;0;0;60mtime \u001b[48;2;24;0;0mto \u001b[48;2;178;0;0mmake \u001b[48;2;0;0;0mchanges.\n",
            "\u001b[48;2;89;0;0mQuantitative \u001b[48;2;69;0;0mmetrics \u001b[48;2;128;0;0mcould \u001b[48;2;0;0;279mnot \u001b[48;2;0;0;247mevaluate \u001b[48;2;52;0;0mthe \u001b[48;2;0;0;48mreal \u001b[48;2;0;0;14macademic \u001b[48;2;0;0;139mimpact \u001b[48;2;37;0;0mof \u001b[48;2;188;0;0ma \u001b[48;2;0;0;46mscholar \u001b[48;2;99;0;0mor \u001b[48;2;188;0;0ma \u001b[48;2;0;0;0mpaper.\n",
            "\u001b[48;2;0;0;27mThey \u001b[48;2;0;0;43mignore \u001b[48;2;51;0;0mthe \u001b[48;2;0;0;8messential \u001b[48;2;0;0;216mdifferences \u001b[48;2;0;0;149mbetween \u001b[48;2;0;0;0mcitations, \u001b[48;2;153;0;0mwhich \u001b[48;2;146;0;0mis \u001b[48;2;189;0;0ma \u001b[48;2;100;0;0mfatal \u001b[48;2;0;0;0merror.\n",
            "\u001b[48;2;0;0;632mSeglen \u001b[48;2;110;0;0mexpresses \u001b[48;2;0;0;23mstrong \u001b[48;2;29;0;0mopposition \u001b[48;2;0;0;11mto \u001b[48;2;0;0;0mim- \u001b[48;2;0;0;13mpact \u001b[48;2;56;0;0mfactors \u001b[48;2;158;0;0mthat \u001b[48;2;0;0;65mmeasure \u001b[48;2;111;0;0mthe \u001b[48;2;0;0;66macademic \u001b[48;2;0;0;114minfluence \u001b[48;2;126;0;0mof \u001b[48;2;0;0;86mjournals \u001b[48;2;7;0;0mfor \u001b[48;2;0;0;96mcommittees \u001b[48;2;64;0;0mseldom \u001b[48;2;101;0;0mhave \u001b[48;2;111;0;0mthe \u001b[48;2;0;0;0mspecialist’ \u001b[48;2;0;0;78minsights \u001b[48;2;0;0;11mto \u001b[48;2;79;0;0massess \u001b[48;2;0;0;78mprimary \u001b[48;2;0;0;0mresearches[31].\n",
            "\u001b[48;2;0;0;253mWe \u001b[48;2;106;0;0mpropose \u001b[48;2;0;0;0mPhocus, \u001b[48;2;164;0;0ma \u001b[48;2;0;0;141mnovel \u001b[48;2;0;0;140mevaluation \u001b[48;2;34;0;0mmechanism \u001b[48;2;2;0;0mfor \u001b[48;2;0;0;97mscholars \u001b[48;2;0;0;74mand \u001b[48;2;0;0;0mpublications.\n",
            "\u001b[48;2;0;0;326mPhocus \u001b[48;2;0;0;201manalyzes \u001b[48;2;99;0;0mthe \u001b[48;2;0;0;71msentence \u001b[48;2;0;0;59mcontaining \u001b[48;2;70;0;0ma \u001b[48;2;91;0;0mcitation \u001b[48;2;0;0;192mand \u001b[48;2;70;0;0mits \u001b[48;2;0;0;30mcontexts \u001b[48;2;142;0;0mto \u001b[48;2;0;0;185mpredict \u001b[48;2;99;0;0mthe \u001b[48;2;195;0;0msentiment \u001b[48;2;0;0;10mpolarity \u001b[48;2;0;0;81mtowards \u001b[48;2;99;0;0mthe \u001b[48;2;0;0;0mcorre- \u001b[48;2;178;0;0msponding \u001b[48;2;0;0;0mreference.\n",
            "\u001b[48;2;0;0;0mBesides, \u001b[48;2;0;0;53mPhocus \u001b[48;2;0;0;40malso \u001b[48;2;0;0;220mconsiders \u001b[48;2;0;0;6mthe \u001b[48;2;0;0;202mtotal \u001b[48;2;118;0;0mnumber \u001b[48;2;216;0;0mof \u001b[48;2;0;0;0mcitations, \u001b[48;2;0;0;6mthe \u001b[48;2;118;0;0mnumber \u001b[48;2;216;0;0mof \u001b[48;2;93;0;0mcitations \u001b[48;2;0;0;144mper \u001b[48;2;0;0;0msentence, \u001b[48;2;0;0;56mauthor \u001b[48;2;0;0;0moverlap, \u001b[48;2;0;0;147mand \u001b[48;2;0;0;6mthe \u001b[48;2;118;0;0mnumber \u001b[48;2;216;0;0mof \u001b[48;2;0;0;0mreferences, \u001b[48;2;0;0;35msimilar \u001b[48;2;0;0;0mto \u001b[48;2;0;0;0m[35].\n",
            "\u001b[48;2;0;0;74mGiven \u001b[48;2;112;0;0mthose \u001b[48;2;0;0;74mfactors \u001b[48;2;0;0;0mabove, \u001b[48;2;0;0;128mPhocus \u001b[48;2;104;0;0muses \u001b[48;2;0;0;25mNaive \u001b[48;2;0;0;454mBayesian \u001b[48;2;0;0;77mClassifier \u001b[48;2;134;0;0mto \u001b[48;2;0;0;14mdivide \u001b[48;2;0;0;16mcitations \u001b[48;2;0;0;295mcoarsely \u001b[48;2;0;0;39minto \u001b[48;2;0;0;140m4 \u001b[48;2;0;0;40mcategories \u001b[48;2;0;0;28mand \u001b[48;2;11;0;0mutilizes \u001b[48;2;100;0;0mthe \u001b[48;2;280;0;0mLambdaMART \u001b[48;2;121;0;0mmodel \u001b[48;2;134;0;0mto \u001b[48;2;74;0;0msort \u001b[48;2;0;0;33mall \u001b[48;2;9;0;0mreferences \u001b[48;2;126;0;0mwithin \u001b[48;2;239;0;0ma \u001b[48;2;0;0;0mpaper.\n",
            "\u001b[48;2;145;0;0mCombining \u001b[48;2;173;0;0mthe \u001b[48;2;71;0;0mcategories \u001b[48;2;84;0;0mand \u001b[48;2;173;0;0mthe \u001b[48;2;0;0;68mranking \u001b[48;2;0;0;0mresults, \u001b[48;2;33;0;0mevery \u001b[48;2;0;0;226mreference \u001b[48;2;0;0;63mgets \u001b[48;2;0;0;98mits \u001b[48;2;0;0;225mlocal \u001b[48;2;0;0;120minfluential \u001b[48;2;0;0;206mfactor \u001b[48;2;0;0;16mwithin \u001b[48;2;0;0;0m[−1, \u001b[48;2;0;0;0m1], \u001b[48;2;26;0;0mrelated \u001b[48;2;142;0;0mto \u001b[48;2;173;0;0mthe \u001b[48;2;63;0;0mciting \u001b[48;2;0;0;0mpaper.\n",
            "\u001b[48;2;61;0;0mthe \u001b[48;2;0;0;129mglobal \u001b[48;2;0;0;64minfluential \u001b[48;2;0;0;214mfactor \u001b[48;2;164;0;0mof \u001b[48;2;61;0;0mthe \u001b[48;2;0;0;45mreference \u001b[48;2;30;0;0mto \u001b[48;2;61;0;0mthe \u001b[48;2;116;0;0mciting \u001b[48;2;99;0;0mpaper \u001b[48;2;0;0;133mis \u001b[48;2;61;0;0mthe \u001b[48;2;0;0;202mproduct \u001b[48;2;164;0;0mof \u001b[48;2;61;0;0mthe \u001b[48;2;0;0;141mlocal \u001b[48;2;0;0;64minfluential \u001b[48;2;0;0;214mfactor \u001b[48;2;0;0;107mand \u001b[48;2;61;0;0mthe \u001b[48;2;0;0;196mtotal \u001b[48;2;0;0;64minfluential \u001b[48;2;0;0;214mfactor \u001b[48;2;164;0;0mof \u001b[48;2;61;0;0mthe \u001b[48;2;116;0;0mciting \u001b[48;2;0;0;0mpaper.\n",
            "\u001b[48;2;0;0;0mConsequently, \u001b[48;2;185;0;0man \u001b[48;2;0;0;0mauthor’s \u001b[48;2;0;0;45macademic \u001b[48;2;0;0;72minfluential \u001b[48;2;0;0;292mfactor \u001b[48;2;0;0;124mis \u001b[48;2;27;0;0mthe \u001b[48;2;14;0;0msum \u001b[48;2;227;0;0mof \u001b[48;2;28;0;0mhis \u001b[48;2;139;0;0mcontributions \u001b[48;2;128;0;0mto \u001b[48;2;155;0;0meach \u001b[48;2;0;0;5mpaper \u001b[48;2;0;0;185mhe \u001b[48;2;0;0;0mco-authors.\n",
            "\u001b[48;2;48;0;0m2 \u001b[48;2;92;0;0mRELATED \u001b[48;2;0;0;178mwork \u001b[48;2;80;0;0mOur \u001b[48;2;0;0;178mwork \u001b[48;2;88;0;0minvolves \u001b[48;2;0;0;181mcitation \u001b[48;2;0;0;0mclassification, \u001b[48;2;0;0;0maspect-based \u001b[48;2;10;0;0msentiment \u001b[48;2;0;0;0manalysis, \u001b[48;2;0;0;75mranking \u001b[48;2;31;0;0mmodel \u001b[48;2;0;0;24mand \u001b[48;2;0;0;124mevaluation \u001b[48;2;0;0;155mmetrics \u001b[48;2;0;0;28mfor \u001b[48;2;0;0;0macademics, \u001b[48;2;160;0;0mwhich \u001b[48;2;0;0;22mwill \u001b[48;2;137;0;0mbe \u001b[48;2;0;0;52mintroduced \u001b[48;2;275;0;0min \u001b[48;2;371;0;0msubsections \u001b[48;2;161;0;0mbelow \u001b[48;2;0;0;0mrespectively.\n",
            "\u001b[48;2;0;0;0m2.1 \u001b[48;2;12;0;0mcitation \u001b[48;2;91;0;0mClassification \u001b[48;2;233;0;0mIn \u001b[48;2;0;0;0mfact, \u001b[48;2;0;0;41mthere \u001b[48;2;0;0;61mare \u001b[48;2;0;0;261malready \u001b[48;2;0;0;216mmany \u001b[48;2;100;0;0mkinds \u001b[48;2;240;0;0mof \u001b[48;2;0;0;14mresearch \u001b[48;2;129;0;0mthat \u001b[48;2;65;0;0mhave \u001b[48;2;0;0;130mfocused \u001b[48;2;0;0;55mon \u001b[48;2;12;0;0mcitation \u001b[48;2;0;0;0mclassification.\n",
            "\u001b[48;2;6;0;0mFor \u001b[48;2;0;0;0mexample, \u001b[48;2;0;0;618mTeufel \u001b[48;2;187;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[33] \u001b[48;2;1;0;0mclassify \u001b[48;2;0;0;40mcitation \u001b[48;2;13;0;0mintents \u001b[48;2;0;0;15minto \u001b[48;2;0;0;195m12 \u001b[48;2;0;0;0mclasses, \u001b[48;2;200;0;0musing \u001b[48;2;57;0;0msimple \u001b[48;2;156;0;0mregular \u001b[48;2;45;0;0mmatch \u001b[48;2;9;0;0mto \u001b[48;2;0;0;0mex- \u001b[48;2;0;0;112mtract \u001b[48;2;0;0;0mfeatures.\n",
            "\u001b[48;2;0;0;222mValenzuela \u001b[48;2;138;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[35] \u001b[48;2;0;0;65mdivide \u001b[48;2;162;0;0mcitations \u001b[48;2;6;0;0minto \u001b[48;2;0;0;260m4 \u001b[48;2;0;0;0mclasses: \u001b[48;2;0;0;128mhighly \u001b[48;2;0;0;0minfluential, \u001b[48;2;0;0;0mbackground, \u001b[48;2;0;0;109mmethod \u001b[48;2;104;0;0mand \u001b[48;2;0;0;106mresults \u001b[48;2;0;0;0mcitations, \u001b[48;2;5;0;0musing \u001b[48;2;0;0;203mSVM \u001b[48;2;289;0;0mwith \u001b[48;2;0;0;173man \u001b[48;2;0;0;208mRBF \u001b[48;2;0;0;137mkernel \u001b[48;2;104;0;0mand \u001b[48;2;0;0;128mrandom \u001b[48;2;0;0;0mforests, \u001b[48;2;0;0;158mtaking \u001b[48;2;0;0;126m13 \u001b[48;2;38;0;0mfeatures \u001b[48;2;6;0;0minto \u001b[48;2;0;0;0mconsideration: \u001b[48;2;100;0;0mtotal \u001b[48;2;36;0;0mnumber \u001b[48;2;242;0;0mof \u001b[48;2;59;0;0mdirect \u001b[48;2;0;0;0mcitations, \u001b[48;2;36;0;0mnumber \u001b[48;2;242;0;0mof \u001b[48;2;59;0;0mdirect \u001b[48;2;0;0;0mcita- \u001b[48;2;0;0;157mtions \u001b[48;2;0;0;1mper \u001b[48;2;0;0;0msection, \u001b[48;2;68;0;0mthe \u001b[48;2;100;0;0mtotal \u001b[48;2;36;0;0mnumber \u001b[48;2;242;0;0mof \u001b[48;2;30;0;0mindirect \u001b[48;2;162;0;0mcitations \u001b[48;2;104;0;0mand \u001b[48;2;36;0;0mnumber \u001b[48;2;242;0;0mof \u001b[48;2;30;0;0mindirect \u001b[48;2;162;0;0mcitations \u001b[48;2;0;0;1mper \u001b[48;2;0;0;0msection, \u001b[48;2;0;0;8mauthor \u001b[48;2;0;0;0moverlap, \u001b[48;2;0;0;107mis \u001b[48;2;0;0;180mconsidered \u001b[48;2;0;0;0mhelp- \u001b[48;2;0;0;0mful, \u001b[48;2;88;0;0mcitation \u001b[48;2;0;0;72mappears \u001b[48;2;96;0;0min \u001b[48;2;0;0;83mtable \u001b[48;2;104;0;0mand \u001b[48;2;0;0;0mcaption, \u001b[48;2;0;0;0m1/number \u001b[48;2;242;0;0mof \u001b[48;2;0;0;0mreferences, \u001b[48;2;36;0;0mnumber \u001b[48;2;242;0;0mof \u001b[48;2;45;0;0mpaper \u001b[48;2;0;0;0mcitations/all \u001b[48;2;0;0;0mcitations, \u001b[48;2;68;0;0mthe \u001b[48;2;0;0;46msimilarity \u001b[48;2;0;0;145mbetween \u001b[48;2;0;0;0mab- \u001b[48;2;0;0;0mstracts, \u001b[48;2;0;0;0mPageRank[28], \u001b[48;2;36;0;0mnumber \u001b[48;2;242;0;0mof \u001b[48;2;100;0;0mtotal \u001b[48;2;195;0;0mciting \u001b[48;2;92;0;0mpapers \u001b[48;2;23;0;0mafter \u001b[48;2;456;0;0mtransitive \u001b[48;2;0;0;0mclosure, \u001b[48;2;104;0;0mand \u001b[48;2;0;0;0mfield \u001b[48;2;242;0;0mof \u001b[48;2;68;0;0mthe \u001b[48;2;0;0;0mcited \u001b[48;2;0;0;0mpaper.\n",
            "\u001b[48;2;0;0;62mWhile \u001b[48;2;332;0;0mJurgens \u001b[48;2;226;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[20] \u001b[48;2;63;0;0mdefine \u001b[48;2;0;0;96m7 \u001b[48;2;0;0;51mclasses \u001b[48;2;222;0;0mof \u001b[48;2;0;0;70mcitation \u001b[48;2;0;0;0mintents: \u001b[48;2;0;0;0mbackground, \u001b[48;2;0;0;0mmotivation, \u001b[48;2;0;0;0muses, \u001b[48;2;0;0;0mextension, \u001b[48;2;0;0;0mcontinuation, \u001b[48;2;50;0;0mcomparison \u001b[48;2;94;0;0mor \u001b[48;2;0;0;0mcontrast, \u001b[48;2;36;0;0mand \u001b[48;2;0;0;0mfuture, \u001b[48;2;184;0;0mwith \u001b[48;2;60;0;0ma \u001b[48;2;0;0;116mRandom \u001b[48;2;0;0;294mForest \u001b[48;2;0;0;40mclassifier \u001b[48;2;0;0;242mtrained \u001b[48;2;68;0;0musing \u001b[48;2;0;0;102m4 \u001b[48;2;0;0;7mtypes \u001b[48;2;222;0;0mof \u001b[48;2;0;0;0mfeatures: \u001b[48;2;30;0;0mstructural \u001b[48;2;0;0;0mfea- \u001b[48;2;0;0;0mtures, \u001b[48;2;0;0;0mlexical, \u001b[48;2;0;0;39mmorphological \u001b[48;2;36;0;0mand \u001b[48;2;0;0;41mgrammatical \u001b[48;2;0;0;0mfeatures, \u001b[48;2;0;0;0mfield, \u001b[48;2;36;0;0mand \u001b[48;2;0;0;0musage.\n",
            "\u001b[48;2;0;0;90mCohan \u001b[48;2;283;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[9] \u001b[48;2;175;0;0mpropose \u001b[48;2;107;0;0ma \u001b[48;2;0;0;728mmultitask \u001b[48;2;0;0;72mmodel \u001b[48;2;99;0;0musing \u001b[48;2;0;0;388mBiLSTM \u001b[48;2;51;0;0mand \u001b[48;2;0;0;47mattention \u001b[48;2;0;0;118mmechanism \u001b[48;2;92;0;0mto \u001b[48;2;0;0;115mclassify \u001b[48;2;80;0;0mcitation \u001b[48;2;220;0;0mintents \u001b[48;2;146;0;0mthat \u001b[48;2;214;0;0mis \u001b[48;2;0;0;36mthe \u001b[48;2;0;0;166mprimary \u001b[48;2;15;0;0mtask \u001b[48;2;51;0;0mand \u001b[48;2;0;0;84mpredict \u001b[48;2;0;0;36mthe \u001b[48;2;53;0;0msection \u001b[48;2;0;0;51mwhere \u001b[48;2;0;0;36mthe \u001b[48;2;80;0;0mcitation \u001b[48;2;0;0;11moccurs \u001b[48;2;51;0;0mand \u001b[48;2;0;0;51mwhere \u001b[48;2;107;0;0ma \u001b[48;2;0;0;3msentence \u001b[48;2;0;0;204mneeds \u001b[48;2;107;0;0ma \u001b[48;2;80;0;0mcitation \u001b[48;2;146;0;0mthat \u001b[48;2;214;0;0mis \u001b[48;2;0;0;154mauxiliary \u001b[48;2;0;0;76mtasks \u001b[48;2;51;0;0mand \u001b[48;2;214;0;0mis \u001b[48;2;59;0;0mused \u001b[48;2;92;0;0mto \u001b[48;2;0;0;125massist \u001b[48;2;0;0;36mthe \u001b[48;2;0;0;166mprimary \u001b[48;2;0;0;0mtask2.\n",
            "\u001b[48;2;0;0;23mThey \u001b[48;2;0;0;35mcategorize \u001b[48;2;277;0;0mintents \u001b[48;2;225;0;0minto \u001b[48;2;114;0;0m3 \u001b[48;2;0;0;0mclasses: \u001b[48;2;0;0;155mbackground \u001b[48;2;0;0;0minformation, \u001b[48;2;0;0;0mmethod, \u001b[48;2;146;0;0mand \u001b[48;2;0;0;24mresult \u001b[48;2;0;0;0mcomparison.\n",
            "\u001b[48;2;0;0;0mBesides, \u001b[48;2;197;0;0mCohan \u001b[48;2;121;0;0mbuilds \u001b[48;2;72;0;0ma \u001b[48;2;78;0;0mcitation \u001b[48;2;83;0;0mintent \u001b[48;2;0;0;435mdataset \u001b[48;2;0;0;0mSciCite.\n",
            "\u001b[48;2;5;0;0mThose \u001b[48;2;30;0;0mworks \u001b[48;2;0;0;0msim- \u001b[48;2;0;0;448mply \u001b[48;2;96;0;0mclassify \u001b[48;2;116;0;0mcitations \u001b[48;2;113;0;0maccording \u001b[48;2;4;0;0mto \u001b[48;2;158;0;0mintents \u001b[48;2;0;0;212mbut \u001b[48;2;0;0;103mignore \u001b[48;2;0;0;0mthe \u001b[48;2;17;0;0msentiment \u001b[48;2;131;0;0mciting \u001b[48;2;0;0;91mpaper \u001b[48;2;74;0;0mtowards \u001b[48;2;0;0;0mreferences, \u001b[48;2;279;0;0mwhich \u001b[48;2;142;0;0mis \u001b[48;2;0;0;0mvital.\n",
            "\u001b[48;2;7;0;0mButt \u001b[48;2;189;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[6] \u001b[48;2;280;0;0mutilize \u001b[48;2;0;0;0mNaive-Bayes \u001b[48;2;107;0;0mClassifier \u001b[48;2;162;0;0mto \u001b[48;2;0;0;57mpredict \u001b[48;2;106;0;0mthe \u001b[48;2;0;0;0msenti- \u001b[48;2;0;0;150mment \u001b[48;2;110;0;0mpolarity \u001b[48;2;92;0;0mof \u001b[48;2;62;0;0ma \u001b[48;2;0;0;137msentence \u001b[48;2;0;0;73mcontaining \u001b[48;2;62;0;0ma \u001b[48;2;0;0;0mcitation \u001b[48;2;0;0;236mand \u001b[48;2;0;0;17mits \u001b[48;2;0;0;0mcontexts.\n",
            "\u001b[48;2;0;0;220mWhereas \u001b[48;2;0;0;39mLiu \u001b[48;2;197;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[23] \u001b[48;2;256;0;0muse \u001b[48;2;29;0;0maveraged \u001b[48;2;0;0;159mword \u001b[48;2;0;0;178membeddings \u001b[48;2;50;0;0mto \u001b[48;2;0;0;44mrepresent \u001b[48;2;0;0;70msentence \u001b[48;2;0;0;72mvectors \u001b[48;2;13;0;0mand \u001b[48;2;50;0;0mto \u001b[48;2;90;0;0mclassify \u001b[48;2;93;0;0msentiment \u001b[48;2;0;0;0mpolarities.\n",
            "\u001b[48;2;0;0;0mHowever, \u001b[48;2;182;0;0mthis \u001b[48;2;71;0;0mmethod \u001b[48;2;0;0;212mgenerates \u001b[48;2;0;0;21mthe \u001b[48;2;0;0;266moverall \u001b[48;2;0;0;0msentiment \u001b[48;2;121;0;0mof \u001b[48;2;0;0;0mtext, \u001b[48;2;0;0;179mrather \u001b[48;2;0;0;60mthan \u001b[48;2;0;0;21mthe \u001b[48;2;0;0;4mprecise \u001b[48;2;0;0;0msentiment \u001b[48;2;0;0;121mtowards \u001b[48;2;0;0;21mthe \u001b[48;2;0;0;57mcited \u001b[48;2;0;0;0mpaper, \u001b[48;2;137;0;0mwhich \u001b[48;2;124;0;0mis \u001b[48;2;37;0;0munable \u001b[48;2;112;0;0mto \u001b[48;2;146;0;0mapply \u001b[48;2;0;0;0mdirectly.\n",
            "\u001b[48;2;0;0;0m2.2 \u001b[48;2;0;0;0mAspect-based \u001b[48;2;0;0;172msentiment \u001b[48;2;120;0;0manalysis \u001b[48;2;0;0;0mAspect-based \u001b[48;2;0;0;172msentiment \u001b[48;2;120;0;0manalysis \u001b[48;2;0;0;0m(ABSA) \u001b[48;2;175;0;0mis \u001b[48;2;50;0;0mproposed \u001b[48;2;0;0;26mto \u001b[48;2;0;0;55mdefine \u001b[48;2;0;0;5msuch \u001b[48;2;285;0;0ma \u001b[48;2;0;0;0mtask.\n",
            "\u001b[48;2;0;0;0mUsually, \u001b[48;2;0;0;132mABSA \u001b[48;2;0;0;11mconsists \u001b[48;2;166;0;0mof \u001b[48;2;0;0;93mtwo \u001b[48;2;0;0;0mstages: \u001b[48;2;202;0;0mlocating \u001b[48;2;0;0;16maspects \u001b[48;2;62;0;0mand \u001b[48;2;89;0;0manalyzing \u001b[48;2;0;0;0msentiment.\n",
            "\u001b[48;2;0;0;96msome \u001b[48;2;0;0;29mworks \u001b[48;2;0;0;155msolve \u001b[48;2;3;0;0mthis \u001b[48;2;0;0;29mproblem \u001b[48;2;0;0;39malso \u001b[48;2;252;0;0min \u001b[48;2;194;0;0ma \u001b[48;2;0;0;0mtwo- \u001b[48;2;0;0;170mstage \u001b[48;2;0;0;0mway, \u001b[48;2;0;0;45mwhile \u001b[48;2;0;0;96msome \u001b[48;2;0;0;0mjointly.\n",
            "\u001b[48;2;0;0;0mto \u001b[48;2;52;0;0mdetect \u001b[48;2;40;0;0mcitation \u001b[48;2;0;0;31mspan \u001b[48;2;222;0;0min \u001b[48;2;0;0;0mWikipedia, \u001b[48;2;0;0;352mFetahu \u001b[48;2;63;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[13] \u001b[48;2;182;0;0mpropose \u001b[48;2;182;0;0ma \u001b[48;2;0;0;109msequence \u001b[48;2;37;0;0mclassification \u001b[48;2;102;0;0mmethod \u001b[48;2;252;0;0musing \u001b[48;2;182;0;0ma \u001b[48;2;0;0;1mlinear \u001b[48;2;0;0;34mchain \u001b[48;2;0;0;5mCRF \u001b[48;2;0;0;0mto \u001b[48;2;0;0;184mdecide \u001b[48;2;0;0;28mwhich \u001b[48;2;0;0;115mtext \u001b[48;2;0;0;137mfragments \u001b[48;2;74;0;0mare \u001b[48;2;0;0;237mcovered \u001b[48;2;36;0;0mby \u001b[48;2;182;0;0ma \u001b[48;2;40;0;0mcitation \u001b[48;2;102;0;0mat \u001b[48;2;0;0;98mthe \u001b[48;2;0;0;0msub-sentence \u001b[48;2;0;0;0mlevel.\n",
            "\u001b[48;2;0;0;109mWhereas \u001b[48;2;1;0;0mKaplan \u001b[48;2;168;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[22] \u001b[48;2;131;0;0mdetect \u001b[48;2;0;0;0mnon-explicit \u001b[48;2;0;0;134mciting \u001b[48;2;177;0;0msentences \u001b[48;2;136;0;0mthat \u001b[48;2;77;0;0msurround \u001b[48;2;0;0;80man \u001b[48;2;0;0;145mexplicit \u001b[48;2;0;0;134mciting \u001b[48;2;0;0;0msentence, \u001b[48;2;64;0;0mutilizing \u001b[48;2;0;0;0mrelational, \u001b[48;2;0;0;0mentity, \u001b[48;2;0;0;0mlexical, \u001b[48;2;27;0;0mand \u001b[48;2;0;0;107mgrammatical \u001b[48;2;0;0;217mcoherence \u001b[48;2;0;0;220mbetween \u001b[48;2;0;0;0mthem. \u001b[48;2;0;0;0m[25][39]even \u001b[48;2;0;0;101mtry \u001b[48;2;0;0;81mto \u001b[48;2;0;0;106mfind \u001b[48;2;126;0;0mthe \u001b[48;2;114;0;0mmost \u001b[48;2;20;0;0mrelative \u001b[48;2;177;0;0msentences \u001b[48;2;206;0;0min \u001b[48;2;0;0;32mreference \u001b[48;2;153;0;0mpaper \u001b[48;2;239;0;0mwith \u001b[48;2;126;0;0mthe \u001b[48;2;0;0;134mciting \u001b[48;2;0;0;0msentences.\n",
            "\u001b[48;2;0;0;83mQazvinian \u001b[48;2;26;0;0mand \u001b[48;2;13;0;0mRadev \u001b[48;2;0;0;0m[29] \u001b[48;2;231;0;0mproposed \u001b[48;2;308;0;0ma \u001b[48;2;83;0;0mmethod \u001b[48;2;0;0;114mbased \u001b[48;2;100;0;0mon \u001b[48;2;0;0;638mprobabilistic \u001b[48;2;36;0;0minference \u001b[48;2;86;0;0mto \u001b[48;2;5;0;0mextract \u001b[48;2;0;0;0mnon-explicit \u001b[48;2;70;0;0mciting \u001b[48;2;93;0;0msentences \u001b[48;2;49;0;0mby \u001b[48;2;0;0;9mmodelling \u001b[48;2;137;0;0mthe \u001b[48;2;93;0;0msentences \u001b[48;2;196;0;0min \u001b[48;2;74;0;0man \u001b[48;2;0;0;63marticle \u001b[48;2;26;0;0mand \u001b[48;2;131;0;0mtheir \u001b[48;2;0;0;492mlexical \u001b[48;2;0;0;86msimilarities \u001b[48;2;66;0;0mas \u001b[48;2;308;0;0ma \u001b[48;2;0;0;16mMarkov \u001b[48;2;0;0;137mRandom \u001b[48;2;0;0;62mField \u001b[48;2;3;0;0mtuned \u001b[48;2;86;0;0mto \u001b[48;2;0;0;1mdetect \u001b[48;2;137;0;0mthe \u001b[48;2;0;0;76mpatterns \u001b[48;2;174;0;0mthat \u001b[48;2;0;0;87mcontext \u001b[48;2;0;0;347mdata \u001b[48;2;0;0;198mcreate \u001b[48;2;26;0;0mand \u001b[48;2;203;0;0memploy \u001b[48;2;308;0;0ma \u001b[48;2;0;0;91mBelief \u001b[48;2;0;0;31mPropagation \u001b[48;2;0;0;4mmechanism \u001b[48;2;86;0;0mto \u001b[48;2;0;0;1mdetect \u001b[48;2;14;0;0mlikely \u001b[48;2;0;0;87mcontext \u001b[48;2;0;0;0msentences.\n",
            "\u001b[48;2;0;0;0mAbu-Jbara \u001b[48;2;33;0;0mand \u001b[48;2;0;0;209mRadev \u001b[48;2;0;0;0m[1] \u001b[48;2;0;0;209mdetermine \u001b[48;2;102;0;0mthe \u001b[48;2;0;0;71mcitation \u001b[48;2;0;0;55mblock \u001b[48;2;162;0;0mby \u001b[48;2;4;0;0mfirst \u001b[48;2;0;0;249msegmenting \u001b[48;2;102;0;0mthe \u001b[48;2;0;0;11msentences \u001b[48;2;33;0;0mand \u001b[48;2;17;0;0mthen \u001b[48;2;140;0;0mclassifying \u001b[48;2;70;0;0meach \u001b[48;2;0;0;13mword \u001b[48;2;237;0;0min \u001b[48;2;102;0;0mthe \u001b[48;2;0;0;263msentence \u001b[48;2;323;0;0mas \u001b[48;2;10;0;0mbeing \u001b[48;2;84;0;0minside \u001b[48;2;0;0;3mor \u001b[48;2;93;0;0moutside \u001b[48;2;102;0;0mthe \u001b[48;2;0;0;71mcitation \u001b[48;2;0;0;0mblock.\n",
            "\u001b[48;2;0;0;0mFinally, \u001b[48;2;110;0;0mthey \u001b[48;2;2;0;0maggregate \u001b[48;2;182;0;0mthe \u001b[48;2;96;0;0mlabels \u001b[48;2;218;0;0mof \u001b[48;2;117;0;0mall \u001b[48;2;182;0;0mthe \u001b[48;2;47;0;0mwords \u001b[48;2;0;0;15mcontained \u001b[48;2;109;0;0min \u001b[48;2;0;0;0ma \u001b[48;2;0;0;165msegment \u001b[48;2;0;0;17mto \u001b[48;2;0;0;21massign \u001b[48;2;0;0;0ma \u001b[48;2;34;0;0mlabel \u001b[48;2;0;0;17mto \u001b[48;2;182;0;0mthe \u001b[48;2;0;0;127mwhole \u001b[48;2;0;0;165msegment \u001b[48;2;0;0;1musing \u001b[48;2;0;0;125mthree \u001b[48;2;0;0;65mdifferent \u001b[48;2;34;0;0mlabel \u001b[48;2;7;0;0maggregation \u001b[48;2;0;0;0mrules(majority \u001b[48;2;34;0;0mlabel \u001b[48;2;218;0;0mof \u001b[48;2;182;0;0mthe \u001b[48;2;0;0;0mwords, \u001b[48;2;133;0;0mat \u001b[48;2;0;0;170mleast \u001b[48;2;98;0;0mone \u001b[48;2;218;0;0mof \u001b[48;2;182;0;0mthe \u001b[48;2;0;0;0mwords, \u001b[48;2;0;0;27mor \u001b[48;2;117;0;0mall \u001b[48;2;218;0;0mof \u001b[48;2;0;0;0mthem).\n",
            "\u001b[48;2;25;0;0mKaplan \u001b[48;2;230;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[21] \u001b[48;2;193;0;0mproposed \u001b[48;2;88;0;0ma \u001b[48;2;0;0;47mnew \u001b[48;2;115;0;0mmethod \u001b[48;2;0;0;1mbased \u001b[48;2;105;0;0mon \u001b[48;2;0;0;0mcoreference-chains \u001b[48;2;65;0;0mfor \u001b[48;2;9;0;0mextracting \u001b[48;2;0;0;15mcitation \u001b[48;2;0;0;103mblocks \u001b[48;2;62;0;0mfrom \u001b[48;2;0;0;165mresearch \u001b[48;2;0;0;0mpapers.\n",
            "\u001b[48;2;27;0;0mGiven \u001b[48;2;0;0;0maspects, \u001b[48;2;171;0;0mSun \u001b[48;2;236;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[32] \u001b[48;2;0;0;24mconstruct \u001b[48;2;0;0;5man \u001b[48;2;0;0;141mauxiliary \u001b[48;2;0;0;99msentence \u001b[48;2;114;0;0mfrom \u001b[48;2;10;0;0ma \u001b[48;2;0;0;0maspect, \u001b[48;2;16;0;0mand \u001b[48;2;0;0;115mfeed \u001b[48;2;0;0;171mthe \u001b[48;2;0;0;0msentence-pair \u001b[48;2;0;0;21minto \u001b[48;2;0;0;0mBERT-based \u001b[48;2;0;0;0mmodel.\n",
            "\u001b[48;2;0;0;47mGao \u001b[48;2;203;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[14] \u001b[48;2;103;0;0mutilize \u001b[48;2;0;0;23mthree \u001b[48;2;0;0;0mtarget-dependent \u001b[48;2;0;0;145mvariations \u001b[48;2;145;0;0mof \u001b[48;2;39;0;0mthe \u001b[48;2;0;0;0m𝐵𝐸𝑅𝑇𝑏𝑎𝑠𝑒 \u001b[48;2;0;0;0mmodel.\n",
            "\u001b[48;2;0;0;4mBai \u001b[48;2;188;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[2] \u001b[48;2;220;0;0mpropose \u001b[48;2;73;0;0ma \u001b[48;2;0;0;174mnovel \u001b[48;2;0;0;11mrelational \u001b[48;2;0;0;20mgraph \u001b[48;2;0;0;13mattention \u001b[48;2;0;0;0mnetwork3, \u001b[48;2;102;0;0mwhich \u001b[48;2;0;0;10mintegrates \u001b[48;2;0;0;95mtyped \u001b[48;2;0;0;406msyntactic \u001b[48;2;0;0;240mdependency \u001b[48;2;0;0;0minformation.\n",
            "\u001b[48;2;0;0;32mAs \u001b[48;2;78;0;0mthe \u001b[48;2;0;0;120merrors \u001b[48;2;17;0;0mare \u001b[48;2;0;0;362mcumulated \u001b[48;2;134;0;0min \u001b[48;2;78;0;0mthe \u001b[48;2;0;0;0mpipeline, \u001b[48;2;0;0;65msome \u001b[48;2;0;0;237mresearchers \u001b[48;2;79;0;0mexplore \u001b[48;2;0;0;16msolutions \u001b[48;2;158;0;0mthat \u001b[48;2;71;0;0mdetect \u001b[48;2;101;0;0maspects \u001b[48;2;34;0;0mand \u001b[48;2;53;0;0mclassify \u001b[48;2;46;0;0msentiment \u001b[48;2;0;0;0mjointly.\n",
            "\u001b[48;2;14;0;0mWang \u001b[48;2;315;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[37] \u001b[48;2;121;0;0mpropose \u001b[48;2;141;0;0ma \u001b[48;2;0;0;238mlatent \u001b[48;2;40;0;0maspect \u001b[48;2;0;0;57mrating \u001b[48;2;78;0;0manalysis \u001b[48;2;0;0;4mproblem \u001b[48;2;46;0;0mthat \u001b[48;2;0;0;113maims \u001b[48;2;61;0;0mat \u001b[48;2;0;0;84manalyzing \u001b[48;2;0;0;0mreviewers’ \u001b[48;2;0;0;238mlatent \u001b[48;2;0;0;48mopinions \u001b[48;2;24;0;0mon \u001b[48;2;0;0;92man \u001b[48;2;0;0;226mentity \u001b[48;2;89;0;0mfrom \u001b[48;2;0;0;176mseveral \u001b[48;2;0;0;0maspects.\n",
            "\u001b[48;2;16;0;0mFor \u001b[48;2;38;0;0ma \u001b[48;2;55;0;0mcertain \u001b[48;2;0;0;0mentity, \u001b[48;2;35;0;0mthey \u001b[48;2;0;0;61mdefine \u001b[48;2;38;0;0ma \u001b[48;2;0;0;124mset \u001b[48;2;259;0;0mof \u001b[48;2;0;0;380mkeywords \u001b[48;2;259;0;0mof \u001b[48;2;0;0;55maspects \u001b[48;2;71;0;0mand \u001b[48;2;114;0;0msegment \u001b[48;2;0;0;9mreviews \u001b[48;2;0;0;112minto \u001b[48;2;16;0;0mthe \u001b[48;2;0;0;175maspect \u001b[48;2;0;0;0mlevel.\n",
            "\u001b[48;2;0;0;58mGiven \u001b[48;2;0;0;0mas- \u001b[48;2;0;0;212mpect \u001b[48;2;266;0;0msegmentation \u001b[48;2;0;0;0mresults, \u001b[48;2;0;0;145mthey \u001b[48;2;87;0;0muse \u001b[48;2;199;0;0ma \u001b[48;2;0;0;152mnovel \u001b[48;2;0;0;226mlatent \u001b[48;2;26;0;0mrating \u001b[48;2;0;0;88mregression \u001b[48;2;0;0;9mmodel \u001b[48;2;10;0;0mto \u001b[48;2;0;0;69mcalculate \u001b[48;2;7;0;0maspect \u001b[48;2;68;0;0mratings \u001b[48;2;85;0;0mand \u001b[48;2;125;0;0mcorresponding \u001b[48;2;0;0;0mweights.\n",
            "\u001b[48;2;0;0;0mHow- \u001b[48;2;0;0;0mever, \u001b[48;2;95;0;0mWang \u001b[48;2;129;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;156;0;0mignore \u001b[48;2;130;0;0mthe \u001b[48;2;0;0;0minter-dependencies \u001b[48;2;0;0;174mbetween \u001b[48;2;0;0;100mwords \u001b[48;2;0;0;164mand \u001b[48;2;0;0;0msentences, \u001b[48;2;234;0;0mwhich \u001b[48;2;33;0;0mcauses \u001b[48;2;0;0;11mgreat \u001b[48;2;0;0;173minformation \u001b[48;2;0;0;0mloss.\n",
            "\u001b[48;2;69;0;0mThis \u001b[48;2;221;0;0mclass \u001b[48;2;0;0;0mprob- \u001b[48;2;0;0;419mlem \u001b[48;2;145;0;0mis \u001b[48;2;0;0;68malso \u001b[48;2;0;0;96mcalled \u001b[48;2;0;0;0maspect-based \u001b[48;2;0;0;27msentiment \u001b[48;2;30;0;0manalysis \u001b[48;2;0;0;0m(ABSA).\n",
            "\u001b[48;2;14;0;0mRuder \u001b[48;2;0;0;0m2https://github.com/allenai/scicite \u001b[48;2;0;0;0m3https://github.com/muyeby/RGAT-ABSA \u001b[48;2;0;0;0mPhocus: \u001b[48;2;123;0;0mPicking \u001b[48;2;0;0;114mValuable \u001b[48;2;0;0;115mResearch \u001b[48;2;0;0;50mfrom \u001b[48;2;29;0;0ma \u001b[48;2;0;0;247mSea \u001b[48;2;195;0;0mof \u001b[48;2;67;0;0mCitations \u001b[48;2;0;0;0m, \u001b[48;2;0;0;0m, \u001b[48;2;145;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[30] \u001b[48;2;68;0;0mproposes \u001b[48;2;29;0;0ma \u001b[48;2;0;0;106mhierarchical \u001b[48;2;0;0;609mbidirectional \u001b[48;2;109;0;0mLSTM \u001b[48;2;0;0;15mto \u001b[48;2;0;0;155mmodel \u001b[48;2;0;0;94mthe \u001b[48;2;0;0;0minter-dependencies \u001b[48;2;195;0;0mof \u001b[48;2;0;0;121msentences \u001b[48;2;0;0;0mwithin \u001b[48;2;29;0;0ma \u001b[48;2;0;0;0mreview.\n",
            "\u001b[48;2;75;0;0mthe \u001b[48;2;0;0;188maspect \u001b[48;2;41;0;0mis \u001b[48;2;0;0;147mrepresented \u001b[48;2;20;0;0mby \u001b[48;2;75;0;0mthe \u001b[48;2;0;0;250maverage \u001b[48;2;199;0;0mof \u001b[48;2;0;0;26mits \u001b[48;2;0;0;14mentity \u001b[48;2;192;0;0mand \u001b[48;2;0;0;18mattribute \u001b[48;2;0;0;0membeddings.\n",
            "\u001b[48;2;0;0;399mHoang \u001b[48;2;207;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[18] \u001b[48;2;254;0;0mpropose \u001b[48;2;27;0;0mto \u001b[48;2;43;0;0muse \u001b[48;2;146;0;0ma \u001b[48;2;0;0;126msentence \u001b[48;2;0;0;154mpair \u001b[48;2;0;0;2mclassifier \u001b[48;2;0;0;92mmodel \u001b[48;2;43;0;0mfrom \u001b[48;2;0;0;0mBERT[11] \u001b[48;2;27;0;0mto \u001b[48;2;0;0;7msolve \u001b[48;2;193;0;0mABSA \u001b[48;2;33;0;0mat \u001b[48;2;0;0;126msentence \u001b[48;2;0;0;6mand \u001b[48;2;0;0;114mtext \u001b[48;2;0;0;0mlevels.\n",
            "\u001b[48;2;51;0;0mHu \u001b[48;2;184;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[19] \u001b[48;2;239;0;0mpropose \u001b[48;2;60;0;0ma \u001b[48;2;0;0;0mspan-based \u001b[48;2;0;0;0mextract-then-classify \u001b[48;2;34;0;0mframework \u001b[48;2;3;0;0mbased \u001b[48;2;28;0;0mon \u001b[48;2;0;0;0mBERT4.\n",
            "\u001b[48;2;0;0;6mXu \u001b[48;2;194;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[38] \u001b[48;2;0;0;41mbuild \u001b[48;2;60;0;0ma \u001b[48;2;0;0;0mdataset, \u001b[48;2;0;0;0mReviewRC5, \u001b[48;2;0;0;79mand \u001b[48;2;91;0;0mextend \u001b[48;2;0;0;8mBERT \u001b[48;2;158;0;0mwith \u001b[48;2;66;0;0man \u001b[48;2;0;0;31mextra \u001b[48;2;0;0;0mtasking-specific \u001b[48;2;0;0;186mlayer \u001b[48;2;148;0;0mto \u001b[48;2;0;0;88mtune \u001b[48;2;0;0;43meach \u001b[48;2;0;0;0mtask.\n",
            "\u001b[48;2;0;0;0mWal- \u001b[48;2;0;0;318mlaart \u001b[48;2;150;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[36] \u001b[48;2;44;0;0mpropose \u001b[48;2;48;0;0ma \u001b[48;2;0;0;0mtwo-stage \u001b[48;2;19;0;0malgorithm \u001b[48;2;0;0;0mto \u001b[48;2;0;0;114msolve \u001b[48;2;140;0;0mthe \u001b[48;2;0;0;107mABSA \u001b[48;2;113;0;0mfor \u001b[48;2;0;0;0mrestaurant \u001b[48;2;0;0;0mreviews: \u001b[48;2;0;0;38mpredicting \u001b[48;2;140;0;0mthe \u001b[48;2;0;0;18msentiment \u001b[48;2;254;0;0mwith \u001b[48;2;48;0;0ma \u001b[48;2;0;0;775mlexicalized \u001b[48;2;0;0;117mdomain \u001b[48;2;0;0;0montology, \u001b[48;2;22;0;0mand \u001b[48;2;88;0;0musing \u001b[48;2;48;0;0ma \u001b[48;2;0;0;229mneural \u001b[48;2;0;0;123mnetwork \u001b[48;2;254;0;0mwith \u001b[48;2;48;0;0ma \u001b[48;2;0;0;20mrotatory \u001b[48;2;0;0;0mat- \u001b[48;2;0;0;21mtention \u001b[48;2;76;0;0mmechanism \u001b[48;2;0;0;0m(LCR-Rot) \u001b[48;2;182;0;0mas \u001b[48;2;48;0;0ma \u001b[48;2;0;0;53mbackup \u001b[48;2;0;0;0malgorithm.\n",
            "\u001b[48;2;131;0;0mthe \u001b[48;2;0;0;112morder \u001b[48;2;337;0;0mof \u001b[48;2;0;0;4mrotatory \u001b[48;2;16;0;0mattention \u001b[48;2;57;0;0mmechanism \u001b[48;2;217;0;0moperation \u001b[48;2;1;0;0mis \u001b[48;2;0;0;246mchanged \u001b[48;2;0;0;56mand \u001b[48;2;131;0;0mthe \u001b[48;2;0;0;0mro- \u001b[48;2;0;0;87mtatory \u001b[48;2;16;0;0mattention \u001b[48;2;57;0;0mmechanism \u001b[48;2;1;0;0mis \u001b[48;2;0;0;219miterated \u001b[48;2;0;0;21mmultiple \u001b[48;2;0;0;0mtimes.\n",
            "\u001b[48;2;0;0;168mTrusca \u001b[48;2;212;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;184;0;0mextend \u001b[48;2;0;0;0m[36] \u001b[48;2;196;0;0mwith \u001b[48;2;0;0;163mdeep \u001b[48;2;0;0;52mcontextual \u001b[48;2;0;0;136mword \u001b[48;2;0;0;175membeddings \u001b[48;2;10;0;0mand \u001b[48;2;163;0;0madd \u001b[48;2;0;0;1man \u001b[48;2;0;0;54mextra \u001b[48;2;42;0;0mattention \u001b[48;2;0;0;158mlayer \u001b[48;2;0;0;109mto \u001b[48;2;0;0;89mits \u001b[48;2;0;0;0mhigh-level \u001b[48;2;0;0;0mrepresentations[34].\n",
            "\u001b[48;2;0;0;181mTo \u001b[48;2;0;0;0mad- \u001b[48;2;0;0;231mdress \u001b[48;2;44;0;0mthe \u001b[48;2;0;0;263mimbalance \u001b[48;2;0;0;93missue \u001b[48;2;0;0;20mand \u001b[48;2;165;0;0mutilize \u001b[48;2;44;0;0mthe \u001b[48;2;0;0;152minteraction \u001b[48;2;47;0;0mbetween \u001b[48;2;0;0;6maspect \u001b[48;2;0;0;0mterms, \u001b[48;2;7;0;0mLuo \u001b[48;2;203;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[24] \u001b[48;2;209;0;0mpropose \u001b[48;2;220;0;0ma \u001b[48;2;0;0;212mgradient \u001b[48;2;0;0;146mharmonized \u001b[48;2;0;0;20mand \u001b[48;2;72;0;0mcascaded \u001b[48;2;218;0;0mlabelling \u001b[48;2;83;0;0mmodel \u001b[48;2;0;0;34mbased \u001b[48;2;233;0;0mon \u001b[48;2;0;0;0mBERT.\n",
            "\u001b[48;2;54;0;0mChen \u001b[48;2;235;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[7] \u001b[48;2;186;0;0mutilize \u001b[48;2;15;0;0mdirectional \u001b[48;2;0;0;51mgraph \u001b[48;2;0;0;601mconvolutional \u001b[48;2;50;0;0mnetworks \u001b[48;2;0;0;54mto \u001b[48;2;119;0;0mperform \u001b[48;2;0;0;0mend-to-end \u001b[48;2;158;0;0mABSA \u001b[48;2;0;0;0mtask.\n",
            "\u001b[48;2;0;0;0m2.3 \u001b[48;2;0;0;216mranking \u001b[48;2;73;0;0mmodel \u001b[48;2;0;0;78mthe \u001b[48;2;0;0;216mranking \u001b[48;2;73;0;0mmodel \u001b[48;2;14;0;0mis \u001b[48;2;0;0;262mbased \u001b[48;2;75;0;0mon \u001b[48;2;0;0;0mLambdaMART, \u001b[48;2;164;0;0mwhich \u001b[48;2;14;0;0mis \u001b[48;2;0;0;78mthe \u001b[48;2;0;0;6mboosted \u001b[48;2;0;0;226mtree \u001b[48;2;0;0;36mversion \u001b[48;2;209;0;0mof \u001b[48;2;0;0;0mLambdaRank[5].\n",
            "\u001b[48;2;0;0;49mThis \u001b[48;2;26;0;0malgorithm \u001b[48;2;0;0;275msolves \u001b[48;2;0;0;28mthe \u001b[48;2;0;0;32mgradients \u001b[48;2;250;0;0mof \u001b[48;2;0;0;0mnon-smooth \u001b[48;2;0;0;103mcost \u001b[48;2;0;0;11mfunctions \u001b[48;2;136;0;0mused \u001b[48;2;174;0;0min \u001b[48;2;0;0;243mranking \u001b[48;2;0;0;0mmodels.\n",
            "\u001b[48;2;0;0;112mBurges \u001b[48;2;199;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[4] \u001b[48;2;0;0;62mgive \u001b[48;2;0;0;83ma \u001b[48;2;0;0;197mreview \u001b[48;2;0;0;37mon \u001b[48;2;0;0;0mRankNet, \u001b[48;2;0;0;0mLambdaRank, \u001b[48;2;126;0;0mand \u001b[48;2;0;0;0mLambdaMART.\n",
            "\u001b[48;2;98;0;0mto \u001b[48;2;0;0;26millustrate \u001b[48;2;38;0;0mthe \u001b[48;2;0;0;158mranking \u001b[48;2;0;0;0mnetwork, \u001b[48;2;0;0;219mwe \u001b[48;2;22;0;0muse \u001b[48;2;0;0;0m𝑐𝑖 \u001b[48;2;0;0;0m𝑗 \u001b[48;2;98;0;0mto \u001b[48;2;0;0;146mdenote \u001b[48;2;38;0;0mthe \u001b[48;2;0;0;0m𝑗-th \u001b[48;2;0;0;0mci- \u001b[48;2;0;0;105mtation \u001b[48;2;145;0;0mof \u001b[48;2;38;0;0mthe \u001b[48;2;0;0;0m𝑖-th \u001b[48;2;0;0;68mreference \u001b[48;2;0;0;0mpaper.\n",
            "\u001b[48;2;0;0;158mOur \u001b[48;2;0;0;244mranking \u001b[48;2;0;0;75mnetwork \u001b[48;2;0;0;46mreceives \u001b[48;2;0;0;164man \u001b[48;2;0;0;208mmatrix \u001b[48;2;0;0;65mof \u001b[48;2;19;0;0mshape \u001b[48;2;0;0;0m((cid:205)𝑖 \u001b[48;2;0;0;0m𝑛_𝑐𝑖𝑡𝑖, \u001b[48;2;0;0;0m4), \u001b[48;2;53;0;0mwhere \u001b[48;2;75;0;0m4 \u001b[48;2;91;0;0mstands \u001b[48;2;0;0;4mfor \u001b[48;2;0;0;35mthe \u001b[48;2;0;0;70mfeature \u001b[48;2;0;0;0mquater- \u001b[48;2;32;0;0mnion \u001b[48;2;0;0;65mof \u001b[48;2;0;0;0m(au_overlap, \u001b[48;2;0;0;0mn_cit, \u001b[48;2;0;0;0mcit_word, \u001b[48;2;0;0;0msen_label).\n",
            "\u001b[48;2;87;0;0mAmong \u001b[48;2;126;0;0mwhich \u001b[48;2;0;0;0mcit_word \u001b[48;2;120;0;0mis \u001b[48;2;0;0;247mcalculated \u001b[48;2;0;0;91mas \u001b[48;2;0;0;24mthe \u001b[48;2;0;0;174mtotal \u001b[48;2;0;0;1mnumber \u001b[48;2;230;0;0mof \u001b[48;2;10;0;0mwords \u001b[48;2;238;0;0min \u001b[48;2;0;0;0m𝑐𝑜𝑛𝑡𝑒𝑥𝑡_𝑎 \u001b[48;2;0;0;0m+ \u001b[48;2;0;0;0m𝑠𝑒𝑛𝑡𝑒𝑛𝑐𝑒 \u001b[48;2;0;0;0m+ \u001b[48;2;0;0;0m𝑐𝑜𝑛𝑡𝑒𝑥𝑡_𝑏.\n",
            "\u001b[48;2;0;0;93mThe \u001b[48;2;0;0;195mnetwork \u001b[48;2;0;0;63mcalculate \u001b[48;2;98;0;0ma \u001b[48;2;0;0;19mscore \u001b[48;2;0;0;0m𝑠𝑖 \u001b[48;2;0;0;0m𝑗 \u001b[48;2;223;0;0mon \u001b[48;2;82;0;0meach \u001b[48;2;0;0;25mtime \u001b[48;2;158;0;0mof \u001b[48;2;0;0;31mcitation \u001b[48;2;0;0;0m𝑐𝑖 \u001b[48;2;0;0;0m𝑗 \u001b[48;2;0;0;0mindividually, \u001b[48;2;0;0;135maveraging \u001b[48;2;223;0;0mon \u001b[48;2;67;0;0mduplicate \u001b[48;2;214;0;0mcitations \u001b[48;2;0;0;86mto \u001b[48;2;0;0;0m(cid:205)𝑗 \u001b[48;2;0;0;0m𝑠𝑖 \u001b[48;2;0;0;0m𝑗 \u001b[48;2;0;0;0m.\n",
            "\u001b[48;2;0;0;131mThen \u001b[48;2;0;0;0m𝑠𝑖 \u001b[48;2;0;0;31mis \u001b[48;2;0;0;146mget \u001b[48;2;215;0;0mthe \u001b[48;2;0;0;275mscore \u001b[48;2;242;0;0mof \u001b[48;2;123;0;0meach \u001b[48;2;35;0;0mreference \u001b[48;2;123;0;0mpaper \u001b[48;2;0;0;0m𝑠𝑖 \u001b[48;2;0;0;0m= \u001b[48;2;0;0;58mused \u001b[48;2;173;0;0mto \u001b[48;2;0;0;95mrank \u001b[48;2;0;0;18mall \u001b[48;2;215;0;0mthe \u001b[48;2;35;0;0mreference \u001b[48;2;0;0;0mpaper, \u001b[48;2;0;0;33moutputting \u001b[48;2;0;0;0m𝑟𝑖 \u001b[48;2;0;0;0m.\n",
            "\u001b[48;2;158;0;0m1 \u001b[48;2;0;0;0m𝑛_𝑐𝑖𝑡𝑖 \u001b[48;2;0;0;0m2.4 \u001b[48;2;104;0;0mEvaluation \u001b[48;2;0;0;51mmetrics \u001b[48;2;71;0;0mIn \u001b[48;2;90;0;0mthe \u001b[48;2;28;0;0macademic \u001b[48;2;0;0;0mfield, \u001b[48;2;0;0;7mthere \u001b[48;2;90;0;0mare \u001b[48;2;0;0;0mjournal-level, \u001b[48;2;0;0;0mauthor-level \u001b[48;2;0;0;78mand \u001b[48;2;0;0;0mpaper- \u001b[48;2;132;0;0mlevel \u001b[48;2;0;0;51mmetrics \u001b[48;2;153;0;0mthat \u001b[48;2;147;0;0mmeasure \u001b[48;2;0;0;92mtheir \u001b[48;2;0;0;0mimpacts.\n",
            "\u001b[48;2;0;0;146mthe \u001b[48;2;0;0;116mimpact \u001b[48;2;0;0;66mFactor \u001b[48;2;0;0;0m(IF)[26] \u001b[48;2;0;0;22mand \u001b[48;2;150;0;0mCiteScore6 \u001b[48;2;126;0;0mare \u001b[48;2;30;0;0mused \u001b[48;2;92;0;0mto \u001b[48;2;0;0;188mmeasure \u001b[48;2;0;0;146mthe \u001b[48;2;0;0;116mimpact \u001b[48;2;207;0;0mof \u001b[48;2;193;0;0ma \u001b[48;2;0;0;136mjournal \u001b[48;2;0;0;148mbased \u001b[48;2;3;0;0mon \u001b[48;2;0;0;146mthe \u001b[48;2;135;0;0mnumber \u001b[48;2;207;0;0mof \u001b[48;2;0;0;112mtimes \u001b[48;2;144;0;0marticles \u001b[48;2;99;0;0mcited \u001b[48;2;0;0;79mduring \u001b[48;2;193;0;0ma \u001b[48;2;27;0;0mfixed \u001b[48;2;0;0;73mperiod \u001b[48;2;82;0;0mpublished \u001b[48;2;81;0;0mby \u001b[48;2;0;0;146mthe \u001b[48;2;0;0;0mjournal.\n",
            "\u001b[48;2;0;0;0mBesides, \u001b[48;2;0;0;36mJournal \u001b[48;2;0;0;0mCita- \u001b[48;2;0;0;363mtion \u001b[48;2;51;0;0mReports \u001b[48;2;0;0;0m(JCR) \u001b[48;2;0;0;23mgive \u001b[48;2;0;0;67mranking \u001b[48;2;74;0;0mfor \u001b[48;2;0;0;0mjournals7, \u001b[48;2;0;0;734mEigenfactor \u001b[48;2;0;0;0mscores[3] \u001b[48;2;0;0;258mmeasure \u001b[48;2;0;0;27mhow \u001b[48;2;0;0;92mlikely \u001b[48;2;86;0;0ma \u001b[48;2;0;0;36mJournal \u001b[48;2;0;0;65mis \u001b[48;2;0;0;277mto \u001b[48;2;34;0;0mbe \u001b[48;2;0;0;0mused, \u001b[48;2;0;0;71mand \u001b[48;2;0;0;78mSCImago \u001b[48;2;0;0;36mJournal \u001b[48;2;0;0;15mRank \u001b[48;2;0;0;0m(SJR)[15] \u001b[48;2;0;0;188mregards \u001b[48;2;91;0;0mthe \u001b[48;2;83;0;0mcitations \u001b[48;2;37;0;0missued \u001b[48;2;157;0;0mby \u001b[48;2;19;0;0mmore \u001b[48;2;159;0;0mimport \u001b[48;2;0;0;0mjour- \u001b[48;2;0;0;122mnals \u001b[48;2;293;0;0mas \u001b[48;2;19;0;0mmore \u001b[48;2;25;0;0mimportant \u001b[48;2;45;0;0mthan \u001b[48;2;181;0;0mthose \u001b[48;2;37;0;0missued \u001b[48;2;157;0;0mby \u001b[48;2;69;0;0mless \u001b[48;2;25;0;0mimportant \u001b[48;2;0;0;0mones.\n",
            "\u001b[48;2;0;0;28mWhereas \u001b[48;2;95;0;0mSource \u001b[48;2;335;0;0mNormalized \u001b[48;2;73;0;0mImpact \u001b[48;2;24;0;0mper \u001b[48;2;0;0;138mPaper \u001b[48;2;0;0;0m(SNIP)[27] \u001b[48;2;0;0;80mindicates \u001b[48;2;5;0;0mthat \u001b[48;2;72;0;0ma \u001b[48;2;11;0;0msingle \u001b[48;2;0;0;132mcitation \u001b[48;2;0;0;114mis \u001b[48;2;0;0;174mmuch \u001b[48;2;0;0;224mmore \u001b[48;2;0;0;222mimportant \u001b[48;2;212;0;0min \u001b[48;2;31;0;0msubject \u001b[48;2;44;0;0mareas \u001b[48;2;136;0;0mwhere \u001b[48;2;60;0;0mcitations \u001b[48;2;119;0;0mare \u001b[48;2;0;0;0mless, \u001b[48;2;0;0;35mand \u001b[48;2;0;0;1mvice \u001b[48;2;0;0;0mversa.\n",
            "\u001b[48;2;0;0;0mAuthor-level \u001b[48;2;0;0;15mmetrics \u001b[48;2;104;0;0minclude \u001b[48;2;0;0;0mh-index, \u001b[48;2;0;0;0mg-index, \u001b[48;2;0;0;0mi10-index \u001b[48;2;3;0;0mand \u001b[48;2;0;0;189mso \u001b[48;2;0;0;0mon.\n",
            "\u001b[48;2;0;0;0mH-index \u001b[48;2;49;0;0malso \u001b[48;2;0;0;17mcalled \u001b[48;2;0;0;127mindex \u001b[48;2;0;0;0mℎ, \u001b[48;2;185;0;0mis \u001b[48;2;129;0;0mproposed \u001b[48;2;126;0;0mby \u001b[48;2;0;0;92mJorge \u001b[48;2;0;0;0mE.\n",
            "\u001b[48;2;0;0;0mHirsch[17], \u001b[48;2;0;0;32mand \u001b[48;2;155;0;0mits \u001b[48;2;0;0;81mdefinition \u001b[48;2;0;0;198mis \u001b[48;2;0;0;202mthe \u001b[48;2;0;0;221mnumber \u001b[48;2;20;0;0mof \u001b[48;2;0;0;143mpapers \u001b[48;2;211;0;0mwith \u001b[48;2;0;0;151mcitation \u001b[48;2;0;0;285mnumbers \u001b[48;2;0;0;0m4https://github.com/huminghao16/SpanABSA \u001b[48;2;0;0;0m5https://howardhsu.github.io/dataset/ \u001b[48;2;0;0;0m6https://service.elsevier.com/app/answers/detail/a_id/14880/supporthub/scopus/ \u001b[48;2;0;0;0m7https://jcr.clarivate.com/jcr/home \u001b[48;2;0;0;0mFigure \u001b[48;2;0;0;0m2: \u001b[48;2;0;0;202mthe \u001b[48;2;0;0;0moverview \u001b[48;2;20;0;0mof \u001b[48;2;0;0;0mPhocus.\n",
            "\u001b[48;2;0;0;199mhigher \u001b[48;2;119;0;0mor \u001b[48;2;57;0;0mequal \u001b[48;2;119;0;0mto \u001b[48;2;0;0;0mℎ.\n",
            "\u001b[48;2;244;0;0mthe \u001b[48;2;0;0;0mg-index \u001b[48;2;15;0;0mis \u001b[48;2;0;0;227mdefined \u001b[48;2;6;0;0mas \u001b[48;2;244;0;0mthe \u001b[48;2;0;0;217mlargest \u001b[48;2;62;0;0mnumber \u001b[48;2;0;0;38msuch \u001b[48;2;175;0;0mthat \u001b[48;2;244;0;0mthe \u001b[48;2;0;0;74mtop \u001b[48;2;0;0;0m𝑔 \u001b[48;2;99;0;0marticles \u001b[48;2;0;0;0mreceived \u001b[48;2;0;0;206mtogether \u001b[48;2;205;0;0mat \u001b[48;2;0;0;90mleast \u001b[48;2;0;0;0m𝑔2 \u001b[48;2;0;0;0mcitations[12].\n",
            "\u001b[48;2;0;0;107mGoogle \u001b[48;2;0;0;21mScholar \u001b[48;2;33;0;0mproposes \u001b[48;2;0;0;29mthe \u001b[48;2;0;0;0mi10-index \u001b[48;2;186;0;0mthat \u001b[48;2;0;0;74mis \u001b[48;2;0;0;29mthe \u001b[48;2;0;0;70mnumber \u001b[48;2;229;0;0mof \u001b[48;2;91;0;0ma \u001b[48;2;4;0;0mpublication \u001b[48;2;227;0;0mwith \u001b[48;2;132;0;0mat \u001b[48;2;0;0;165mleast \u001b[48;2;0;0;109m10 \u001b[48;2;0;0;0mcitations.\n",
            "\u001b[48;2;5;0;0mThose \u001b[48;2;0;0;4mmetrics \u001b[48;2;189;0;0mare \u001b[48;2;0;0;276mderived \u001b[48;2;127;0;0mfrom \u001b[48;2;0;0;96mcitations \u001b[48;2;0;0;8mand \u001b[48;2;0;0;55mdo \u001b[48;2;0;0;111mnot \u001b[48;2;51;0;0mreveal \u001b[48;2;233;0;0mthe \u001b[48;2;0;0;37mtruth \u001b[48;2;0;0;79mamong \u001b[48;2;0;0;0mcitations.\n",
            "\u001b[48;2;0;0;0mPaper-level \u001b[48;2;112;0;0mmetrics \u001b[48;2;31;0;0mare \u001b[48;2;0;0;214musually \u001b[48;2;0;0;24mthe \u001b[48;2;28;0;0mnumber \u001b[48;2;216;0;0mof \u001b[48;2;0;0;0mcitations.\n",
            "\u001b[48;2;0;0;0mEspe- \u001b[48;2;0;0;0mcially, \u001b[48;2;99;0;0mSemantic \u001b[48;2;10;0;0mScholar \u001b[48;2;0;0;86mmakes \u001b[48;2;10;0;0mthe \u001b[48;2;0;0;5mfirst \u001b[48;2;242;0;0mstep \u001b[48;2;15;0;0mtowards \u001b[48;2;3;0;0mcitation \u001b[48;2;0;0;0mclassi- \u001b[48;2;0;0;0mfication.\n",
            "\u001b[48;2;16;0;0mIt \u001b[48;2;0;0;13mdivided \u001b[48;2;99;0;0mcitations \u001b[48;2;28;0;0minto \u001b[48;2;0;0;144m4 \u001b[48;2;0;0;0mclasses: \u001b[48;2;0;0;57mhighly \u001b[48;2;0;0;0minfluential, \u001b[48;2;0;0;0mback- \u001b[48;2;0;0;0mground, \u001b[48;2;136;0;0mmethod \u001b[48;2;0;0;14mand \u001b[48;2;0;0;66mresults \u001b[48;2;0;0;0mcitations[35], \u001b[48;2;85;0;0musing \u001b[48;2;0;0;129mSVM \u001b[48;2;344;0;0mwith \u001b[48;2;27;0;0man \u001b[48;2;16;0;0mRBF \u001b[48;2;6;0;0mkernel \u001b[48;2;0;0;14mand \u001b[48;2;0;0;42mrandom \u001b[48;2;0;0;0mforests.\n",
            "\u001b[48;2;34;0;0mthe \u001b[48;2;47;0;0mfeatures \u001b[48;2;25;0;0mSemantic \u001b[48;2;0;0;294mScholar \u001b[48;2;90;0;0muse \u001b[48;2;0;0;51mare \u001b[48;2;34;0;0mthe \u001b[48;2;47;0;0mtotal \u001b[48;2;11;0;0mnumber \u001b[48;2;257;0;0mof \u001b[48;2;0;0;44mdirect \u001b[48;2;0;0;0mcitations, \u001b[48;2;11;0;0mnumber \u001b[48;2;257;0;0mof \u001b[48;2;0;0;44mdirect \u001b[48;2;133;0;0mcitations \u001b[48;2;0;0;112mper \u001b[48;2;0;0;0msection, \u001b[48;2;34;0;0mthe \u001b[48;2;47;0;0mtotal \u001b[48;2;11;0;0mnumber \u001b[48;2;257;0;0mof \u001b[48;2;0;0;41mindirect \u001b[48;2;133;0;0mcitations \u001b[48;2;107;0;0mand \u001b[48;2;11;0;0mnumber \u001b[48;2;257;0;0mof \u001b[48;2;0;0;41mindirect \u001b[48;2;133;0;0mcitations \u001b[48;2;0;0;112mper \u001b[48;2;0;0;0msection, \u001b[48;2;0;0;120mauthor \u001b[48;2;0;0;0moverlap, \u001b[48;2;0;0;102mis \u001b[48;2;0;0;216mconsidered \u001b[48;2;0;0;0mhelp- \u001b[48;2;0;0;0mful, \u001b[48;2;54;0;0mcitation \u001b[48;2;0;0;140mappears \u001b[48;2;143;0;0min \u001b[48;2;0;0;76mtable \u001b[48;2;107;0;0mand \u001b[48;2;0;0;0mcaption, \u001b[48;2;0;0;0m1/number \u001b[48;2;257;0;0mof \u001b[48;2;0;0;0mreferences, \u001b[48;2;11;0;0mnumber \u001b[48;2;257;0;0mof \u001b[48;2;0;0;9mpaper \u001b[48;2;0;0;0mcitations/all \u001b[48;2;0;0;0mcitations, \u001b[48;2;34;0;0mthe \u001b[48;2;0;0;31msimilarity \u001b[48;2;0;0;98mbetween \u001b[48;2;0;0;0mab- \u001b[48;2;0;0;0mstracts, \u001b[48;2;0;0;0mPageRank[28], \u001b[48;2;11;0;0mnumber \u001b[48;2;257;0;0mof \u001b[48;2;47;0;0mtotal \u001b[48;2;152;0;0mciting \u001b[48;2;70;0;0mpapers \u001b[48;2;0;0;11mafter \u001b[48;2;368;0;0mtransitive \u001b[48;2;0;0;0mclosure, \u001b[48;2;107;0;0mand \u001b[48;2;0;0;29mfield \u001b[48;2;257;0;0mof \u001b[48;2;34;0;0mthe \u001b[48;2;0;0;0mcited \u001b[48;2;0;0;0mpaper.\n",
            "\u001b[48;2;85;0;0m3 \u001b[48;2;159;0;0mMETHODOLOGY \u001b[48;2;242;0;0mAs \u001b[48;2;103;0;0mshown \u001b[48;2;283;0;0min \u001b[48;2;0;0;91mFigure \u001b[48;2;0;0;0m??, \u001b[48;2;0;0;6mour \u001b[48;2;0;0;109malgorithm \u001b[48;2;0;0;0mconsists \u001b[48;2;198;0;0mof \u001b[48;2;63;0;0m4 \u001b[48;2;0;0;0mstages: \u001b[48;2;0;0;0mpre- \u001b[48;2;0;0;0mprocessing, \u001b[48;2;54;0;0mcalculating \u001b[48;2;0;0;0mfactors, \u001b[48;2;0;0;57mevaluating \u001b[48;2;0;0;0mcontribution, \u001b[48;2;28;0;0mand \u001b[48;2;0;0;0mprop- \u001b[48;2;0;0;395magating \u001b[48;2;79;0;0minfluential \u001b[48;2;0;0;0mfactors.\n",
            "\u001b[48;2;194;0;0mIn \u001b[48;2;0;0;0mpre-processing \u001b[48;2;0;0;0mstage, \u001b[48;2;0;0;166mwe \u001b[48;2;0;0;123mclean \u001b[48;2;0;0;111mraw \u001b[48;2;0;0;0mdata, \u001b[48;2;0;0;5mand \u001b[48;2;19;0;0mobtain \u001b[48;2;91;0;0msimple \u001b[48;2;0;0;0mfactors.\n",
            "\u001b[48;2;7;0;0mComplex \u001b[48;2;0;0;0mfactors, \u001b[48;2;93;0;0mlike \u001b[48;2;203;0;0msentiment \u001b[48;2;60;0;0mpolarity \u001b[48;2;136;0;0mare \u001b[48;2;0;0;231mcalculated \u001b[48;2;76;0;0min \u001b[48;2;0;0;72msecond \u001b[48;2;0;0;0mstage.\n",
            "\u001b[48;2;0;0;187mWhen \u001b[48;2;113;0;0mget \u001b[48;2;175;0;0mall \u001b[48;2;111;0;0mfactors \u001b[48;2;0;0;0mneeded, \u001b[48;2;0;0;135mwe \u001b[48;2;0;0;14mclassify \u001b[48;2;101;0;0mcitations \u001b[48;2;108;0;0minto \u001b[48;2;0;0;10mfour \u001b[48;2;28;0;0mclasses \u001b[48;2;0;0;38mand \u001b[48;2;52;0;0mrank \u001b[48;2;175;0;0mall \u001b[48;2;0;0;0mreferences, \u001b[48;2;0;0;38mand \u001b[48;2;0;0;148mfigure \u001b[48;2;63;0;0mout \u001b[48;2;222;0;0mthe \u001b[48;2;0;0;183mlocal \u001b[48;2;0;0;53mcontribution \u001b[48;2;0;0;129mfactor \u001b[48;2;183;0;0mof \u001b[48;2;75;0;0meach \u001b[48;2;0;0;0mreference.\n",
            "\u001b[48;2;0;0;226mWe \u001b[48;2;0;0;0mini- \u001b[48;2;0;0;76mtialize \u001b[48;2;171;0;0mall \u001b[48;2;35;0;0mnew \u001b[48;2;123;0;0mpaper \u001b[48;2;139;0;0mto \u001b[48;2;46;0;0mthe \u001b[48;2;0;0;107mdatabase \u001b[48;2;329;0;0mwith \u001b[48;2;56;0;0man \u001b[48;2;0;0;121macademic \u001b[48;2;0;0;132minfluential \u001b[48;2;0;0;145mfactor \u001b[48;2;0;0;0m1.0, \u001b[48;2;0;0;42mand \u001b[48;2;0;0;313mpropagate \u001b[48;2;155;0;0mits \u001b[48;2;0;0;26mimpact \u001b[48;2;93;0;0mon \u001b[48;2;15;0;0mreferences \u001b[48;2;0;0;0miteratively.\n",
            "\u001b[48;2;37;0;0mthe \u001b[48;2;0;0;134mfactors \u001b[48;2;0;0;143mextracted \u001b[48;2;207;0;0mfrom \u001b[48;2;0;0;121mpapers \u001b[48;2;90;0;0mare \u001b[48;2;0;0;162mlisted \u001b[48;2;0;0;45mout \u001b[48;2;74;0;0min \u001b[48;2;0;0;125mTable \u001b[48;2;169;0;0m1 \u001b[48;2;0;0;0m3.1 \u001b[48;2;0;0;0mPre-processing \u001b[48;2;0;0;97mGiven \u001b[48;2;107;0;0ma \u001b[48;2;0;0;73mpaper \u001b[48;2;311;0;0mof \u001b[48;2;0;0;201mstring \u001b[48;2;0;0;0mformat, \u001b[48;2;107;0;0ma \u001b[48;2;19;0;0mseries \u001b[48;2;311;0;0mof \u001b[48;2;0;0;0msteps \u001b[48;2;0;0;108mprocess \u001b[48;2;37;0;0mthe \u001b[48;2;0;0;218mraw \u001b[48;2;0;0;179mdata \u001b[48;2;0;0;19mfor \u001b[48;2;37;0;0mthe \u001b[48;2;25;0;0mnext \u001b[48;2;0;0;0mstage: \u001b[48;2;0;0;0mparsing, \u001b[48;2;0;0;0msegmentation, \u001b[48;2;43;0;0mand \u001b[48;2;0;0;0mmatching.\n",
            "\u001b[48;2;0;0;118mParing \u001b[48;2;296;0;0mis \u001b[48;2;56;0;0maimed \u001b[48;2;261;0;0mat \u001b[48;2;0;0;91mdividing \u001b[48;2;0;0;52mthe \u001b[48;2;0;0;153minput \u001b[48;2;0;0;74mtext \u001b[48;2;0;0;0minto \u001b[48;2;0;0;0mtitle, \u001b[48;2;0;0;0mauthors, \u001b[48;2;0;0;0msections, \u001b[48;2;0;0;46mand \u001b[48;2;0;0;0mreferences.\n",
            "\u001b[48;2;0;0;265mWe \u001b[48;2;111;0;0mutilize \u001b[48;2;0;0;7mflari8 \u001b[48;2;48;0;0mto \u001b[48;2;0;0;395mparse \u001b[48;2;97;0;0mthe \u001b[48;2;0;0;0mtitle, \u001b[48;2;45;0;0mauthors \u001b[48;2;81;0;0mand \u001b[48;2;75;0;0mpublish \u001b[48;2;0;0;78myear \u001b[48;2;201;0;0mof \u001b[48;2;97;0;0mthe \u001b[48;2;0;0;108minput \u001b[48;2;19;0;0mpaper \u001b[48;2;81;0;0mand \u001b[48;2;215;0;0mits \u001b[48;2;0;0;0mreferences.\n",
            "\u001b[48;2;0;0;205mWe \u001b[48;2;0;0;77msegment \u001b[48;2;34;0;0mthe \u001b[48;2;0;0;222minput \u001b[48;2;13;0;0mpaper \u001b[48;2;32;0;0minto \u001b[48;2;0;0;0mtwo-level: \u001b[48;2;94;0;0msection \u001b[48;2;1;0;0mlevel \u001b[48;2;16;0;0mand \u001b[48;2;0;0;77msentence \u001b[48;2;0;0;0mlevel.\n",
            "\u001b[48;2;0;0;52mSection \u001b[48;2;0;0;0mseg- \u001b[48;2;0;0;171mmentation \u001b[48;2;31;0;0mis \u001b[48;2;0;0;212mbased \u001b[48;2;23;0;0mon \u001b[48;2;0;0;57mkeywords \u001b[48;2;81;0;0mmatching \u001b[48;2;8;0;0mand \u001b[48;2;0;0;214mclassified \u001b[48;2;33;0;0minto \u001b[48;2;0;0;85mthree \u001b[48;2;0;0;0m8https://pypi.org/project/flair/ \u001b[48;2;47;0;0mTable \u001b[48;2;0;0;0m1: \u001b[48;2;0;0;224mfactor \u001b[48;2;0;0;115mlist \u001b[48;2;47;0;0mTable \u001b[48;2;0;0;0m2: \u001b[48;2;0;0;75mthe \u001b[48;2;0;0;157mclassifying \u001b[48;2;0;0;78mstandards \u001b[48;2;95;0;0mof \u001b[48;2;0;0;0mPhocus.\n",
            "\u001b[48;2;19;0;0mDefinition \u001b[48;2;0;0;38mRanges \u001b[48;2;100;0;0mLabel \u001b[48;2;56;0;0mDescription \u001b[48;2;0;0;93mZhang \u001b[48;2;0;0;121mand \u001b[48;2;0;0;231mWen \u001b[48;2;212;0;0met \u001b[48;2;0;0;0mal.\n",
            "\u001b[48;2;0;0;260mSentences \u001b[48;2;107;0;0mare \u001b[48;2;0;0;122msegmented \u001b[48;2;231;0;0musing \u001b[48;2;126;0;0mregular \u001b[48;2;0;0;24mexpression \u001b[48;2;182;0;0mmatching \u001b[48;2;114;0;0mand \u001b[48;2;107;0;0mare \u001b[48;2;0;0;88mthen \u001b[48;2;0;0;135mlabelled \u001b[48;2;0;0;57mby \u001b[48;2;0;0;5mtheir \u001b[48;2;0;0;244mID \u001b[48;2;0;0;43maccording \u001b[48;2;54;0;0mto \u001b[48;2;0;0;5mtheir \u001b[48;2;23;0;0mappearing \u001b[48;2;0;0;0morder.\n",
            "\u001b[48;2;29;0;0mReference \u001b[48;2;0;0;0mparsing \u001b[48;2;188;0;0mgenerates \u001b[48;2;0;0;0mtitle, \u001b[48;2;0;0;0mauthors, \u001b[48;2;0;0;31mpublish \u001b[48;2;14;0;0myear \u001b[48;2;12;0;0mand \u001b[48;2;0;0;80meven \u001b[48;2;91;0;0mtheir \u001b[48;2;89;0;0mcitation \u001b[48;2;0;0;39mmarkers \u001b[48;2;185;0;0min \u001b[48;2;0;0;12mthe \u001b[48;2;0;0;0mpaper.\n",
            "\u001b[48;2;0;0;95mGiven \u001b[48;2;253;0;0mthat \u001b[48;2;0;0;0minformation, \u001b[48;2;0;0;320mwe \u001b[48;2;0;0;6mlocate \u001b[48;2;0;0;77mcitations \u001b[48;2;51;0;0min \u001b[48;2;34;0;0meach \u001b[48;2;48;0;0msentence \u001b[48;2;0;0;21mand \u001b[48;2;0;0;44mmatch \u001b[48;2;63;0;0mcitation \u001b[48;2;0;0;30mmarkers \u001b[48;2;273;0;0mwith \u001b[48;2;0;0;15mtheir \u001b[48;2;0;0;47mcorresponding \u001b[48;2;0;0;106mreference \u001b[48;2;0;0;0mpapers.\n",
            "\u001b[48;2;0;0;233mThen \u001b[48;2;0;0;126mwe \u001b[48;2;0;0;2mcould \u001b[48;2;0;0;182measily \u001b[48;2;0;0;183mget \u001b[48;2;140;0;0mthe \u001b[48;2;0;0;38mfactor \u001b[48;2;0;0;0mn_cit \u001b[48;2;82;0;0mand \u001b[48;2;0;0;0mcit_text.\n",
            "\u001b[48;2;0;0;120mFactor \u001b[48;2;0;0;0mau_overlap \u001b[48;2;0;0;121mis \u001b[48;2;0;0;344mcalculated \u001b[48;2;0;0;278maccording \u001b[48;2;2;0;0mto \u001b[48;2;116;0;0mthe \u001b[48;2;0;0;1mfollowing \u001b[48;2;0;0;0mequation: \u001b[48;2;0;0;0m𝑎𝑢_𝑜𝑣𝑒𝑟𝑙𝑎𝑝 \u001b[48;2;0;0;0m= \u001b[48;2;201;0;0m2 \u001b[48;2;0;0;0m× \u001b[48;2;0;0;0m𝐴∩𝐵 \u001b[48;2;0;0;0m|𝐴 \u001b[48;2;0;0;0m|+|𝐵 \u001b[48;2;0;0;0m| \u001b[48;2;0;0;0m(1) \u001b[48;2;0;0;18mwhere \u001b[48;2;121;0;0mA \u001b[48;2;0;0;121mis \u001b[48;2;116;0;0mthe \u001b[48;2;0;0;13mauthor \u001b[48;2;62;0;0mset \u001b[48;2;183;0;0mof \u001b[48;2;45;0;0mciting \u001b[48;2;0;0;0mpaper, \u001b[48;2;0;0;105mand \u001b[48;2;39;0;0mB \u001b[48;2;0;0;121mis \u001b[48;2;116;0;0mthe \u001b[48;2;0;0;13mauthor \u001b[48;2;62;0;0mset \u001b[48;2;183;0;0mof \u001b[48;2;0;0;0mreference \u001b[48;2;0;0;0mpaper.\n",
            "\u001b[48;2;0;0;0m3.2 \u001b[48;2;177;0;0mCalculating \u001b[48;2;27;0;0mfactors \u001b[48;2;121;0;0mThere \u001b[48;2;0;0;26mare \u001b[48;2;0;0;309mstill \u001b[48;2;124;0;0mthree \u001b[48;2;27;0;0mfactors \u001b[48;2;0;0;0munsolved: \u001b[48;2;0;0;0mcontext_a, \u001b[48;2;0;0;0mcontext_b, \u001b[48;2;0;0;102mand \u001b[48;2;0;0;0msen_label.\n",
            "\u001b[48;2;0;0;215mWe \u001b[48;2;41;0;0mobtain \u001b[48;2;0;0;0mcontext_a, \u001b[48;2;0;0;0mcontext_b \u001b[48;2;318;0;0mwith \u001b[48;2;0;0;0mBERT, \u001b[48;2;0;0;43mand \u001b[48;2;147;0;0mpropose \u001b[48;2;170;0;0ma \u001b[48;2;0;0;145mnovel \u001b[48;2;0;0;0maspect-based \u001b[48;2;0;0;123msentiment \u001b[48;2;153;0;0manalysis \u001b[48;2;65;0;0malgorithm \u001b[48;2;111;0;0mto \u001b[48;2;41;0;0mclassify \u001b[48;2;36;0;0mcitation \u001b[48;2;0;0;0msentiment.\n",
            "\u001b[48;2;0;0;202mWe \u001b[48;2;0;0;0mfine-tune \u001b[48;2;0;0;50mBERT \u001b[48;2;169;0;0mon \u001b[48;2;82;0;0ma \u001b[48;2;0;0;91mmanually \u001b[48;2;72;0;0mannotated \u001b[48;2;0;0;368mdataset \u001b[48;2;0;0;0mcontain- \u001b[48;2;0;0;182ming \u001b[48;2;0;0;137mover \u001b[48;2;0;0;0m1,000 \u001b[48;2;123;0;0msentence \u001b[48;2;140;0;0mpairs \u001b[48;2;0;0;5mlabelled \u001b[48;2;298;0;0mas \u001b[48;2;0;0;0m\"related\" \u001b[48;2;122;0;0mor \u001b[48;2;0;0;0m\"irrelevant\".\n",
            "\u001b[48;2;114;0;0mEach \u001b[48;2;12;0;0msentence \u001b[48;2;0;0;42mpair \u001b[48;2;202;0;0mis \u001b[48;2;0;0;227mgenerated \u001b[48;2;131;0;0mfrom \u001b[48;2;79;0;0ma \u001b[48;2;0;0;26msingle \u001b[48;2;0;0;140macademic \u001b[48;2;0;0;0mpaper.\n",
            "\u001b[48;2;0;0;302mWe \u001b[48;2;0;0;2mget \u001b[48;2;28;0;0man \u001b[48;2;0;0;13maccuracy \u001b[48;2;96;0;0mof \u001b[48;2;0;0;0m94.5% \u001b[48;2;208;0;0mon \u001b[48;2;95;0;0mthe \u001b[48;2;0;0;132mevaluation \u001b[48;2;0;0;0mdataset.\n",
            "\u001b[48;2;0;0;11mTo \u001b[48;2;0;0;0mob- \u001b[48;2;0;0;323mtain \u001b[48;2;71;0;0mthe \u001b[48;2;0;0;106mcontext \u001b[48;2;368;0;0mof \u001b[48;2;0;0;0mcit_context, \u001b[48;2;0;0;130mwe \u001b[48;2;80;0;0mapply \u001b[48;2;71;0;0mthe \u001b[48;2;0;0;128mabove \u001b[48;2;119;0;0mclassifier \u001b[48;2;0;0;0mit- \u001b[48;2;126;0;0meratively \u001b[48;2;102;0;0mon \u001b[48;2;66;0;0msentence \u001b[48;2;104;0;0mpair \u001b[48;2;0;0;0m(𝑆 \u001b[48;2;0;0;0m[𝑠𝑒𝑛𝑡_𝑖𝑑 \u001b[48;2;0;0;0m− \u001b[48;2;0;0;0m𝑖], \u001b[48;2;0;0;0m𝑆 \u001b[48;2;0;0;0m[𝑠𝑒𝑛𝑡_𝑖𝑑]) \u001b[48;2;0;0;0m(𝑆 \u001b[48;2;0;0;0mrepresent- \u001b[48;2;0;0;207ming \u001b[48;2;71;0;0mthe \u001b[48;2;0;0;57mlist \u001b[48;2;368;0;0mof \u001b[48;2;76;0;0mall \u001b[48;2;135;0;0msentences \u001b[48;2;200;0;0min \u001b[48;2;71;0;0mthe \u001b[48;2;0;0;0mpaper) \u001b[48;2;0;0;71mwhere \u001b[48;2;0;0;0m𝑖 \u001b[48;2;0;0;0mincreases \u001b[48;2;0;0;0mfrom \u001b[48;2;0;0;0m1.\n",
            "\u001b[48;2;0;0;217mOnce \u001b[48;2;155;0;0man \u001b[48;2;0;0;0m\"irrelevant\" \u001b[48;2;80;0;0mpair \u001b[48;2;218;0;0mis \u001b[48;2;0;0;0mreported, \u001b[48;2;35;0;0mthe \u001b[48;2;0;0;15miteration \u001b[48;2;218;0;0mis \u001b[48;2;0;0;16maborted \u001b[48;2;0;0;76mand \u001b[48;2;0;0;88mwe \u001b[48;2;104;0;0mtake \u001b[48;2;0;0;0m𝑆 \u001b[48;2;0;0;0m[𝑠𝑒𝑛𝑡_𝑖𝑑 \u001b[48;2;0;0;0m− \u001b[48;2;0;0;0m𝑖 \u001b[48;2;0;0;0m: \u001b[48;2;0;0;0m𝑠𝑒𝑛𝑡_𝑖𝑑] \u001b[48;2;200;0;0mas \u001b[48;2;0;0;0mcontext_a.\n",
            "\u001b[48;2;91;0;0mAnother \u001b[48;2;0;0;0mstop- \u001b[48;2;0;0;147mping \u001b[48;2;150;0;0mcriterion \u001b[48;2;81;0;0mis \u001b[48;2;85;0;0mthat \u001b[48;2;0;0;0m𝑆 \u001b[48;2;0;0;0m[𝑠𝑒𝑛𝑡_𝑖𝑑 \u001b[48;2;0;0;0m− \u001b[48;2;0;0;0m𝑖] \u001b[48;2;0;0;93mshould \u001b[48;2;0;0;252malways \u001b[48;2;0;0;22mbe \u001b[48;2;0;0;8min \u001b[48;2;146;0;0mthe \u001b[48;2;108;0;0msame \u001b[48;2;41;0;0mparagraph \u001b[48;2;246;0;0mwith \u001b[48;2;0;0;0m𝑆 \u001b[48;2;0;0;0m[𝑠𝑒𝑛𝑡_𝑖𝑑].\n",
            "\u001b[48;2;183;0;0mA \u001b[48;2;118;0;0msimilar \u001b[48;2;202;0;0mprocedure \u001b[48;2;117;0;0mis \u001b[48;2;56;0;0mperformed \u001b[48;2;104;0;0mon \u001b[48;2;0;0;0m(𝑆 \u001b[48;2;0;0;0m[𝑠𝑒𝑛𝑡_𝑖𝑑 \u001b[48;2;0;0;0m+ \u001b[48;2;0;0;0m𝑖], \u001b[48;2;0;0;0m𝑆 \u001b[48;2;0;0;0m[𝑠𝑒𝑛𝑡_𝑖𝑑]) \u001b[48;2;48;0;0mto \u001b[48;2;0;0;36mget \u001b[48;2;0;0;0mcontext_b.\n",
            "\u001b[48;2;0;0;0m3.3 \u001b[48;2;0;0;9mEvaluating \u001b[48;2;71;0;0mContribution \u001b[48;2;0;0;21mAfter \u001b[48;2;26;0;0mgathering \u001b[48;2;0;0;2mall \u001b[48;2;0;0;87mneeded \u001b[48;2;0;0;0mfactors, \u001b[48;2;0;0;190mwe \u001b[48;2;0;0;102mtrain \u001b[48;2;0;0;76ma \u001b[48;2;0;0;113mclassifier \u001b[48;2;0;0;60mto \u001b[48;2;0;0;40mcategorize \u001b[48;2;274;0;0mcitation \u001b[48;2;293;0;0minto \u001b[48;2;0;0;30m4 \u001b[48;2;0;0;0mclasses: \u001b[48;2;68;0;0mvery \u001b[48;2;0;0;0mimportant, \u001b[48;2;0;0;0mimportant, \u001b[48;2;0;0;0mneutral, \u001b[48;2;92;0;0mand \u001b[48;2;0;0;0mterrible.\n",
            "\u001b[48;2;0;0;175mAnd \u001b[48;2;0;0;166mwe \u001b[48;2;0;0;33malso \u001b[48;2;0;0;112mtrain \u001b[48;2;11;0;0ma \u001b[48;2;0;0;201mranking \u001b[48;2;0;0;105mmodel \u001b[48;2;0;0;11mto \u001b[48;2;0;0;101mpredict \u001b[48;2;52;0;0mthe \u001b[48;2;0;0;62mrelated \u001b[48;2;44;0;0morder \u001b[48;2;215;0;0mof \u001b[48;2;0;0;134mreferences \u001b[48;2;199;0;0min \u001b[48;2;52;0;0mterms \u001b[48;2;215;0;0mof \u001b[48;2;96;0;0mtheir \u001b[48;2;59;0;0mcontributions \u001b[48;2;0;0;11mto \u001b[48;2;52;0;0mthe \u001b[48;2;0;0;0mpaper.\n",
            "\u001b[48;2;0;0;0mFirst, \u001b[48;2;0;0;1mwe \u001b[48;2;78;0;0mclassify \u001b[48;2;115;0;0mcitations \u001b[48;2;63;0;0minto \u001b[48;2;0;0;32mfour \u001b[48;2;0;0;25mcategories \u001b[48;2;187;0;0mwith \u001b[48;2;162;0;0ma \u001b[48;2;0;0;104mNaive \u001b[48;2;0;0;341mBayesian \u001b[48;2;0;0;0mclassifier.\n",
            "\u001b[48;2;0;0;14mThe \u001b[48;2;0;0;12mclassifying \u001b[48;2;0;0;79mstandards \u001b[48;2;188;0;0mare \u001b[48;2;0;0;60mshown \u001b[48;2;112;0;0min \u001b[48;2;0;0;68mTable \u001b[48;2;0;0;0m2, \u001b[48;2;0;0;48mand \u001b[48;2;0;0;39ma \u001b[48;2;0;0;273mlarger \u001b[48;2;64;0;0mnumber \u001b[48;2;207;0;0mof \u001b[48;2;62;0;0mlabels \u001b[48;2;0;0;20mrepresents \u001b[48;2;0;0;174mmore \u001b[48;2;0;0;0mcontributions.\n",
            "\u001b[48;2;0;0;81mthe \u001b[48;2;0;0;216mranking \u001b[48;2;66;0;0mmodel \u001b[48;2;12;0;0mis \u001b[48;2;0;0;217mbased \u001b[48;2;96;0;0mon \u001b[48;2;0;0;0mLambdaMART, \u001b[48;2;147;0;0mwhich \u001b[48;2;12;0;0mis \u001b[48;2;0;0;81mthe \u001b[48;2;0;0;10mboosted \u001b[48;2;0;0;228mtree \u001b[48;2;0;0;39mversion \u001b[48;2;216;0;0mof \u001b[48;2;0;0;0mLambdaRank[5].\n",
            "\u001b[48;2;0;0;49mThis \u001b[48;2;26;0;0malgorithm \u001b[48;2;0;0;275msolves \u001b[48;2;0;0;28mthe \u001b[48;2;0;0;32mgradients \u001b[48;2;250;0;0mof \u001b[48;2;0;0;0mnon-smooth \u001b[48;2;0;0;103mcost \u001b[48;2;0;0;11mfunctions \u001b[48;2;136;0;0mused \u001b[48;2;174;0;0min \u001b[48;2;0;0;243mranking \u001b[48;2;0;0;0mmodels.\n",
            "\u001b[48;2;22;0;0mBurges \u001b[48;2;199;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[4] \u001b[48;2;21;0;0mgive \u001b[48;2;0;0;6ma \u001b[48;2;0;0;50mreview \u001b[48;2;32;0;0mon \u001b[48;2;0;0;0mRankNet, \u001b[48;2;0;0;0mLambdaRank, \u001b[48;2;74;0;0mand \u001b[48;2;0;0;0mLamb- \u001b[48;2;0;0;0mdaMART.\n",
            "\u001b[48;2;0;0;231mBased \u001b[48;2;100;0;0mon \u001b[48;2;220;0;0mthe \u001b[48;2;74;0;0mclasses \u001b[48;2;70;0;0mand \u001b[48;2;26;0;0morder \u001b[48;2;270;0;0mof \u001b[48;2;0;0;0mreferences, \u001b[48;2;0;0;159mwe \u001b[48;2;37;0;0mproject \u001b[48;2;0;0;79mthem \u001b[48;2;54;0;0minto \u001b[48;2;0;0;0m[0, \u001b[48;2;0;0;0m1] \u001b[48;2;0;0;12mto \u001b[48;2;0;0;175mget \u001b[48;2;0;0;96mtheir \u001b[48;2;0;0;34minfluential \u001b[48;2;0;0;0mfactors.\n",
            "\u001b[48;2;0;0;0mPhocus: \u001b[48;2;74;0;0mPicking \u001b[48;2;0;0;14mValuable \u001b[48;2;0;0;114mResearch \u001b[48;2;33;0;0mfrom \u001b[48;2;8;0;0ma \u001b[48;2;0;0;109mSea \u001b[48;2;75;0;0mof \u001b[48;2;34;0;0mCitations \u001b[48;2;0;0;0m, \u001b[48;2;0;0;0m, \u001b[48;2;0;0;0m3.4 \u001b[48;2;0;0;312mPropagating \u001b[48;2;73;0;0minfluential \u001b[48;2;0;0;193mfactors \u001b[48;2;0;0;250mGiven \u001b[48;2;8;0;0ma \u001b[48;2;0;0;124mlist \u001b[48;2;75;0;0mof \u001b[48;2;64;0;0mreferences \u001b[48;2;0;0;75mand \u001b[48;2;168;0;0mtheir \u001b[48;2;73;0;0minfluential \u001b[48;2;0;0;193mfactors \u001b[48;2;75;0;0mof \u001b[48;2;0;0;45mthe \u001b[48;2;127;0;0mciting \u001b[48;2;0;0;0mpaper, \u001b[48;2;0;0;93mwe \u001b[48;2;48;0;0mdesign \u001b[48;2;0;0;0msome \u001b[48;2;19;0;0mrules \u001b[48;2;103;0;0mto \u001b[48;2;106;0;0mpropagate \u001b[48;2;168;0;0mtheir \u001b[48;2;0;0;0minfluence.\n",
            "\u001b[48;2;85;0;0mThe \u001b[48;2;0;0;112mmain \u001b[48;2;55;0;0midea \u001b[48;2;84;0;0mis \u001b[48;2;0;0;181mshown \u001b[48;2;125;0;0min \u001b[48;2;0;0;186mFigure \u001b[48;2;0;0;0m3.\n",
            "\u001b[48;2;0;0;0m𝐴 \u001b[48;2;0;0;24mdenote \u001b[48;2;53;0;0ma \u001b[48;2;181;0;0mciting \u001b[48;2;47;0;0mpaper \u001b[48;2;298;0;0mwith \u001b[48;2;0;0;197macademic \u001b[48;2;0;0;147minfluential \u001b[48;2;0;0;141mfactor \u001b[48;2;0;0;0m𝐴𝐹𝐴 \u001b[48;2;0;0;319minitialized \u001b[48;2;0;0;108mas \u001b[48;2;0;0;0m1, \u001b[48;2;0;0;58mset \u001b[48;2;0;0;0m𝑅𝐴, \u001b[48;2;0;0;0m𝐼 \u001b[48;2;0;0;0m𝐹 \u001b[48;2;0;0;0m𝑙 \u001b[48;2;0;0;0m𝐴 \u001b[48;2;0;0;24mdenote \u001b[48;2;308;0;0mall \u001b[48;2;0;0;27mreferences \u001b[48;2;0;0;31mof \u001b[48;2;0;0;0m𝐴, \u001b[48;2;93;0;0mand \u001b[48;2;0;0;79mtheir \u001b[48;2;129;0;0mcorresponding \u001b[48;2;88;0;0mlocal \u001b[48;2;0;0;193mcontribution \u001b[48;2;0;0;159mto \u001b[48;2;0;0;0m𝐴, \u001b[48;2;93;0;0mand \u001b[48;2;0;0;0m𝐼 \u001b[48;2;0;0;0m𝐹 \u001b[48;2;0;0;0m𝑙 \u001b[48;2;0;0;0m𝐴𝑖 \u001b[48;2;0;0;0m∈ \u001b[48;2;0;0;0m[−1, \u001b[48;2;0;0;0m1] \u001b[48;2;0;0;111mis \u001b[48;2;0;0;188mthe \u001b[48;2;88;0;0mlocal \u001b[48;2;0;0;193mcontribution \u001b[48;2;0;0;31mof \u001b[48;2;380;0;0mreference \u001b[48;2;0;0;131mi \u001b[48;2;0;0;159mto \u001b[48;2;0;0;0m𝐴. \u001b[48;2;0;0;0m𝐶𝐴 \u001b[48;2;0;0;111mis \u001b[48;2;0;0;188mthe \u001b[48;2;0;0;58mset \u001b[48;2;0;0;31mof \u001b[48;2;308;0;0mall \u001b[48;2;0;0;72mpapers \u001b[48;2;158;0;0mthat \u001b[48;2;242;0;0mcite \u001b[48;2;0;0;0m𝐴, \u001b[48;2;93;0;0mand \u001b[48;2;102;0;0mfor \u001b[48;2;0;0;0m𝑗 \u001b[48;2;0;0;0m∈ \u001b[48;2;0;0;0m𝐶𝐴, \u001b[48;2;0;0;0m𝐼 \u001b[48;2;0;0;0m𝐹 \u001b[48;2;0;0;0m𝑙 \u001b[48;2;0;0;0m𝑗𝐴 \u001b[48;2;0;0;0m∈ \u001b[48;2;0;0;0m[−1, \u001b[48;2;0;0;0m1] \u001b[48;2;0;0;111mis \u001b[48;2;0;0;0mA’s \u001b[48;2;88;0;0mlocal \u001b[48;2;0;0;193mcontribution \u001b[48;2;0;0;159mto \u001b[48;2;0;0;0m𝑗.\n",
            "\u001b[48;2;0;0;0mThen, \u001b[48;2;0;0;66mthe \u001b[48;2;0;0;47macademic \u001b[48;2;0;0;138minfluential \u001b[48;2;0;0;60mfactor \u001b[48;2;1;0;0mof \u001b[48;2;0;0;0m𝐴 \u001b[48;2;0;0;0mis: \u001b[48;2;0;0;0m𝐴𝐹𝐴 \u001b[48;2;0;0;0m= \u001b[48;2;0;0;0m∑︁ \u001b[48;2;0;0;0m𝐴𝐹 \u001b[48;2;0;0;0m𝑗 \u001b[48;2;0;0;0m𝐼 \u001b[48;2;0;0;0m𝐹 \u001b[48;2;0;0;0m𝑙 \u001b[48;2;0;0;0m𝑗𝐴 \u001b[48;2;0;0;0m(2) \u001b[48;2;0;0;0m𝑗 \u001b[48;2;0;0;0m∈𝐶𝐴 \u001b[48;2;0;0;58mFor \u001b[48;2;88;0;0mauthor \u001b[48;2;0;0;0m𝑎 \u001b[48;2;16;0;0mwho \u001b[48;2;0;0;137mpublishes \u001b[48;2;45;0;0ma \u001b[48;2;100;0;0mset \u001b[48;2;1;0;0mof \u001b[48;2;253;0;0mpapers \u001b[48;2;0;0;0m𝑃𝑎, \u001b[48;2;0;0;92mand \u001b[48;2;154;0;0mhis \u001b[48;2;109;0;0mcontribution \u001b[48;2;60;0;0mto \u001b[48;2;102;0;0mpaper \u001b[48;2;0;0;0m𝑖 \u001b[48;2;0;0;0m∈ \u001b[48;2;0;0;0m𝑃𝑎 \u001b[48;2;0;0;94mis \u001b[48;2;0;0;0m𝐶𝑖𝑎 \u001b[48;2;0;0;0m∈ \u001b[48;2;0;0;0m[0, \u001b[48;2;0;0;0m1], \u001b[48;2;154;0;0mhis \u001b[48;2;0;0;47macademic \u001b[48;2;0;0;138minfluential \u001b[48;2;0;0;60mfactor \u001b[48;2;0;0;0mis: \u001b[48;2;0;0;0m∑︁ \u001b[48;2;0;0;0m𝐴𝐹𝑎 \u001b[48;2;0;0;0m= \u001b[48;2;0;0;0m𝐶𝑖𝑎𝐴𝐹𝑖 \u001b[48;2;0;0;0m(3) \u001b[48;2;0;0;0m𝑖 \u001b[48;2;0;0;0m∈𝑃𝑎 \u001b[48;2;0;0;58mFor \u001b[48;2;102;0;0mpaper \u001b[48;2;0;0;0m𝐴, \u001b[48;2;0;0;92mand \u001b[48;2;63;0;0mits \u001b[48;2;0;0;0m𝑁 \u001b[48;2;0;0;0mauthors, \u001b[48;2;0;0;0m(cid:205)𝑁 \u001b[48;2;0;0;0m𝑖 \u001b[48;2;0;0;0m𝐶𝐴𝑖 \u001b[48;2;0;0;0m≡ \u001b[48;2;0;0;0m1.\n",
            "\u001b[48;2;119;0;0mThere \u001b[48;2;159;0;0mare \u001b[48;2;108;0;0mtwo \u001b[48;2;0;0;5mproblems \u001b[48;2;0;0;43mto \u001b[48;2;0;0;92mprove \u001b[48;2;0;0;43mto \u001b[48;2;0;0;78mensure \u001b[48;2;161;0;0mthat \u001b[48;2;0;0;39mour \u001b[48;2;0;0;79mmethod \u001b[48;2;151;0;0mis \u001b[48;2;0;0;0mlogical.\n",
            "\u001b[48;2;0;0;83mThe \u001b[48;2;0;0;212mfirst \u001b[48;2;66;0;0mone \u001b[48;2;14;0;0mis \u001b[48;2;201;0;0mmargin \u001b[48;2;0;0;0meffects.\n",
            "\u001b[48;2;0;0;213mAnd \u001b[48;2;105;0;0mthe \u001b[48;2;0;0;39msecond \u001b[48;2;202;0;0mone \u001b[48;2;105;0;0mthe \u001b[48;2;0;0;101mpropagation \u001b[48;2;0;0;0mrules.\n",
            "\u001b[48;2;110;0;0m4 \u001b[48;2;108;0;0mexperiments \u001b[48;2;0;0;64mWe \u001b[48;2;283;0;0mconduct \u001b[48;2;73;0;0mseveral \u001b[48;2;108;0;0mexperiments \u001b[48;2;150;0;0mto \u001b[48;2;0;0;30mdemonstrate \u001b[48;2;0;0;41mour \u001b[48;2;0;0;156mnew \u001b[48;2;105;0;0mmetrics \u001b[48;2;260;0;0mthat \u001b[48;2;0;0;158mmeasure \u001b[48;2;11;0;0mthe \u001b[48;2;0;0;172minfluential \u001b[48;2;0;0;265mfactors \u001b[48;2;69;0;0mof \u001b[48;2;31;0;0man \u001b[48;2;0;0;158mindividual \u001b[48;2;0;0;72mscientist \u001b[48;2;0;0;16mor \u001b[48;2;0;0;98mscholar \u001b[48;2;0;0;99mand \u001b[48;2;11;0;0mthe \u001b[48;2;0;0;26mcitation \u001b[48;2;0;0;73mimpact \u001b[48;2;69;0;0mof \u001b[48;2;11;0;0mthe \u001b[48;2;0;0;0mpublications.\n",
            "\u001b[48;2;0;0;23mAs \u001b[48;2;3;0;0mthe \u001b[48;2;0;0;141minfluential \u001b[48;2;0;0;231mfactor \u001b[48;2;252;0;0mof \u001b[48;2;81;0;0ma \u001b[48;2;0;0;38mpaper \u001b[48;2;0;0;6mis \u001b[48;2;3;0;0mthe \u001b[48;2;0;0;345mweighted \u001b[48;2;0;0;92msum \u001b[48;2;252;0;0mof \u001b[48;2;0;0;79mall \u001b[48;2;0;0;23mpapers \u001b[48;2;43;0;0mthat \u001b[48;2;0;0;4mcite \u001b[48;2;68;0;0mit \u001b[48;2;56;0;0mand \u001b[48;2;185;0;0mits \u001b[48;2;58;0;0mcorresponding \u001b[48;2;78;0;0mcontribution \u001b[48;2;64;0;0mto \u001b[48;2;0;0;0mthem, \u001b[48;2;3;0;0mthe \u001b[48;2;0;0;206mfinal \u001b[48;2;56;0;0mand \u001b[48;2;161;0;0mfull \u001b[48;2;36;0;0mnetwork \u001b[48;2;252;0;0mof \u001b[48;2;0;0;38mpaper \u001b[48;2;56;0;0mand \u001b[48;2;36;0;0mnetwork \u001b[48;2;0;0;67mshould \u001b[48;2;174;0;0mbe \u001b[48;2;0;0;0mconstructed.\n",
            "\u001b[48;2;0;0;0mHowever, \u001b[48;2;0;0;86mwe \u001b[48;2;0;0;106mcannot \u001b[48;2;245;0;0mcomplete \u001b[48;2;74;0;0mthis \u001b[48;2;27;0;0mjob \u001b[48;2;0;0;90myet \u001b[48;2;20;0;0mout \u001b[48;2;207;0;0mof \u001b[48;2;0;0;64mno \u001b[48;2;114;0;0maccess \u001b[48;2;116;0;0mto \u001b[48;2;49;0;0msome \u001b[48;2;0;0;0mdatabases, \u001b[48;2;0;0;215mnot \u001b[48;2;156;0;0menough \u001b[48;2;0;0;12mtime \u001b[48;2;0;0;185mor \u001b[48;2;0;0;31mcomputational \u001b[48;2;0;0;0mresources.\n",
            "\u001b[48;2;0;0;263mWe \u001b[48;2;0;0;209mwill \u001b[48;2;0;0;117mselect \u001b[48;2;0;0;3msome \u001b[48;2;0;0;85mscholars \u001b[48;2;133;0;0mand \u001b[48;2;132;0;0mtheir \u001b[48;2;0;0;24mpublications \u001b[48;2;60;0;0mas \u001b[48;2;0;0;0mtargets, \u001b[48;2;133;0;0mand \u001b[48;2;205;0;0mutilize \u001b[48;2;0;0;158mprimary \u001b[48;2;94;0;0mcitation \u001b[48;2;133;0;0mand \u001b[48;2;13;0;0msecondary \u001b[48;2;94;0;0mcitation \u001b[48;2;0;0;0mrelationships.\n",
            "\u001b[48;2;0;0;0mBesides, \u001b[48;2;0;0;148mwe \u001b[48;2;0;0;80malso \u001b[48;2;36;0;0mcompare \u001b[48;2;0;0;41mour \u001b[48;2;44;0;0mmodules \u001b[48;2;156;0;0mto \u001b[48;2;0;0;50mother \u001b[48;2;0;0;0mstate-of-art \u001b[48;2;245;0;0malgorithms \u001b[48;2;156;0;0mto \u001b[48;2;9;0;0mshow \u001b[48;2;156;0;0mthe \u001b[48;2;0;0;85mimprovement \u001b[48;2;0;0;148mwe \u001b[48;2;0;0;0machieve.\n",
            "\u001b[48;2;0;0;0m4.1 \u001b[48;2;0;0;112mPeer \u001b[48;2;0;0;84mComparison \u001b[48;2;5;0;0mScholar \u001b[48;2;90;0;0mand \u001b[48;2;243;0;0mtheir \u001b[48;2;0;0;0mpublications.\n",
            "\u001b[48;2;0;0;91mLet \u001b[48;2;0;0;64mScholar \u001b[48;2;0;0;183mY \u001b[48;2;43;0;0mdenote \u001b[48;2;94;0;0msome \u001b[48;2;0;0;0mscholar.\n",
            "\u001b[48;2;0;0;155mWe \u001b[48;2;0;0;68mwill \u001b[48;2;0;0;176mshow \u001b[48;2;195;0;0mthe \u001b[48;2;0;0;166mdifference \u001b[48;2;10;0;0mbetween \u001b[48;2;65;0;0mScholar \u001b[48;2;0;0;25mY \u001b[48;2;125;0;0mand \u001b[48;2;195;0;0mthe \u001b[48;2;0;0;105mTuring \u001b[48;2;52;0;0mAward \u001b[48;2;185;0;0mwinner \u001b[48;2;0;0;0mPat.\n",
            "\u001b[48;2;0;0;0mHanrahan9.\n",
            "\u001b[48;2;0;0;123mAs \u001b[48;2;205;0;0mwe \u001b[48;2;0;0;0memphasize, \u001b[48;2;0;0;0mPat.\n",
            "\u001b[48;2;0;0;293mHanrahan \u001b[48;2;177;0;0mis \u001b[48;2;0;0;41mmuch \u001b[48;2;0;0;86mmore \u001b[48;2;0;0;48minfluential \u001b[48;2;92;0;0mthan \u001b[48;2;68;0;0mscholar \u001b[48;2;0;0;9mY \u001b[48;2;177;0;0mis \u001b[48;2;0;0;273mnot \u001b[48;2;0;0;172monly \u001b[48;2;77;0;0mfor \u001b[48;2;287;0;0mthat \u001b[48;2;36;0;0mhe \u001b[48;2;0;0;20mwins \u001b[48;2;0;0;157mTuring \u001b[48;2;0;0;0mAward, \u001b[48;2;6;0;0mbut \u001b[48;2;136;0;0malso \u001b[48;2;177;0;0mis \u001b[48;2;0;0;106mbased \u001b[48;2;141;0;0mon \u001b[48;2;0;0;84msolid \u001b[48;2;0;0;35mstatistics \u001b[48;2;265;0;0mof \u001b[48;2;0;0;0mcitations.\n",
            "\u001b[48;2;21;0;0mFor \u001b[48;2;0;0;0mexample, \u001b[48;2;0;0;0mHe \u001b[48;2;122;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m[16] \u001b[48;2;82;0;0mtake \u001b[48;2;272;0;0mone \u001b[48;2;0;0;49mpaper \u001b[48;2;251;0;0mof \u001b[48;2;0;0;116mscholar \u001b[48;2;0;0;184mY \u001b[48;2;49;0;0mas \u001b[48;2;22;0;0ma \u001b[48;2;0;0;0mbase- \u001b[48;2;0;0;154mline \u001b[48;2;120;0;0mthat \u001b[48;2;142;0;0mperforms \u001b[48;2;0;0;40monly \u001b[48;2;23;0;0mbetter \u001b[48;2;0;0;50mthan \u001b[48;2;272;0;0mone \u001b[48;2;32;0;0mbaseline \u001b[48;2;79;0;0mamong \u001b[48;2;0;0;0meleven.\n",
            "\u001b[48;2;0;0;240mTable \u001b[48;2;76;0;0m4 \u001b[48;2;131;0;0mshows \u001b[48;2;0;0;26mevaluation \u001b[48;2;54;0;0mresults \u001b[48;2;120;0;0mof \u001b[48;2;0;0;237mscholar \u001b[48;2;6;0;0mY \u001b[48;2;48;0;0mand \u001b[48;2;0;0;0mPat.\n",
            "\u001b[48;2;0;0;537mHanrahan \u001b[48;2;175;0;0mon \u001b[48;2;0;0;0mAminer10, \u001b[48;2;0;0;14mGoogle \u001b[48;2;0;0;0mScholar11, \u001b[48;2;89;0;0mSemantic \u001b[48;2;100;0;0mScholar12 \u001b[48;2;2;0;0mand \u001b[48;2;0;0;0mPhocus.\n",
            "\u001b[48;2;0;0;185mTable \u001b[48;2;42;0;0m3 \u001b[48;2;0;0;204mlists \u001b[48;2;0;0;90mthe \u001b[48;2;18;0;0mnumber \u001b[48;2;216;0;0mof \u001b[48;2;50;0;0mpublications \u001b[48;2;12;0;0mand \u001b[48;2;213;0;0mcitations \u001b[48;2;216;0;0mof \u001b[48;2;0;0;138mscholar \u001b[48;2;0;0;29mY \u001b[48;2;12;0;0mand \u001b[48;2;0;0;0mPat.\n",
            "\u001b[48;2;0;0;0mHanrahan.\n",
            "\u001b[48;2;0;0;0mIt’s \u001b[48;2;87;0;0mobviously \u001b[48;2;269;0;0mthat \u001b[48;2;135;0;0mscholar \u001b[48;2;0;0;95mY \u001b[48;2;30;0;0mis \u001b[48;2;0;0;38mmore \u001b[48;2;0;0;0mproduc- \u001b[48;2;0;0;303mtive \u001b[48;2;107;0;0mthan \u001b[48;2;0;0;0mPat.\n",
            "\u001b[48;2;0;0;0mHanrahan.\n",
            "\u001b[48;2;0;0;163mis \u001b[48;2;0;0;205mthe \u001b[48;2;0;0;31mnumber \u001b[48;2;96;0;0mof \u001b[48;2;76;0;0mhighly \u001b[48;2;149;0;0minfluential \u001b[48;2;0;0;0mcitations.\n",
            "\u001b[48;2;0;0;0mH-index, \u001b[48;2;31;0;0malso \u001b[48;2;0;0;41mcalled \u001b[48;2;0;0;189mindex \u001b[48;2;0;0;0mℎ, \u001b[48;2;214;0;0mis \u001b[48;2;95;0;0mproposed \u001b[48;2;78;0;0mby \u001b[48;2;0;0;115mJorge \u001b[48;2;0;0;0mE.\n",
            "\u001b[48;2;0;0;0mHirsch[17], \u001b[48;2;87;0;0mand \u001b[48;2;237;0;0mits \u001b[48;2;40;0;0mdefinition \u001b[48;2;0;0;20mis \u001b[48;2;0;0;10mthe \u001b[48;2;0;0;71mnumber \u001b[48;2;124;0;0mof \u001b[48;2;0;0;120mpapers \u001b[48;2;251;0;0mwith \u001b[48;2;0;0;57mcitation \u001b[48;2;0;0;71mnumber \u001b[48;2;0;0;246mhigher \u001b[48;2;63;0;0mor \u001b[48;2;0;0;91mequal \u001b[48;2;0;0;103mto \u001b[48;2;0;0;0mℎ \u001b[48;2;0;0;0m.\n",
            "\u001b[48;2;244;0;0mthe \u001b[48;2;0;0;0mg-index \u001b[48;2;15;0;0mis \u001b[48;2;0;0;227mdefined \u001b[48;2;6;0;0mas \u001b[48;2;244;0;0mthe \u001b[48;2;0;0;217mlargest \u001b[48;2;62;0;0mnumber \u001b[48;2;0;0;38msuch \u001b[48;2;175;0;0mthat \u001b[48;2;244;0;0mthe \u001b[48;2;0;0;74mtop \u001b[48;2;0;0;0m𝑔 \u001b[48;2;99;0;0marticles \u001b[48;2;0;0;0mreceived \u001b[48;2;0;0;206mtogether \u001b[48;2;205;0;0mat \u001b[48;2;0;0;90mleast \u001b[48;2;0;0;0m𝑔2 \u001b[48;2;0;0;0mcitations[12].\n",
            "\u001b[48;2;0;0;46mGoogle \u001b[48;2;31;0;0mScholar \u001b[48;2;63;0;0mproposes \u001b[48;2;0;0;0mi10-index \u001b[48;2;185;0;0mthat \u001b[48;2;0;0;96mis \u001b[48;2;0;0;76mthe \u001b[48;2;0;0;40mnumber \u001b[48;2;217;0;0mof \u001b[48;2;138;0;0ma \u001b[48;2;68;0;0mpublication \u001b[48;2;232;0;0mwith \u001b[48;2;111;0;0mat \u001b[48;2;0;0;158mleast \u001b[48;2;0;0;76m10 \u001b[48;2;0;0;0mcita- \u001b[48;2;0;0;0mtions.\n",
            "\u001b[48;2;5;0;0mThose \u001b[48;2;0;0;4mmetrics \u001b[48;2;189;0;0mare \u001b[48;2;0;0;276mderived \u001b[48;2;127;0;0mfrom \u001b[48;2;0;0;96mcitations \u001b[48;2;0;0;8mand \u001b[48;2;0;0;55mdo \u001b[48;2;0;0;111mnot \u001b[48;2;51;0;0mreveal \u001b[48;2;233;0;0mthe \u001b[48;2;0;0;37mtruth \u001b[48;2;0;0;79mamong \u001b[48;2;0;0;0mcitations.\n",
            "\u001b[48;2;0;0;72mSemantic \u001b[48;2;0;0;83mScholar \u001b[48;2;0;0;125mmakes \u001b[48;2;24;0;0mthe \u001b[48;2;0;0;7mfirst \u001b[48;2;322;0;0mstep \u001b[48;2;0;0;28mtowards \u001b[48;2;0;0;94mcitation \u001b[48;2;0;0;0mclassification.\n",
            "\u001b[48;2;0;0;29mIt \u001b[48;2;0;0;46mdivided \u001b[48;2;34;0;0mcitations \u001b[48;2;2;0;0minto \u001b[48;2;0;0;206m4 \u001b[48;2;0;0;0mclasses: \u001b[48;2;0;0;66mhighly \u001b[48;2;0;0;0minfluential, \u001b[48;2;0;0;0mbackground, \u001b[48;2;53;0;0mmethod \u001b[48;2;0;0;43mand \u001b[48;2;0;0;90mresults \u001b[48;2;0;0;0mcitations[35], \u001b[48;2;0;0;0mus- \u001b[48;2;0;0;270ming \u001b[48;2;0;0;148mSVM \u001b[48;2;399;0;0mwith \u001b[48;2;223;0;0ma \u001b[48;2;32;0;0mRBF \u001b[48;2;0;0;7mkernel \u001b[48;2;0;0;43mand \u001b[48;2;0;0;16mrandom \u001b[48;2;0;0;0mforests.\n",
            "\u001b[48;2;0;0;3mthe \u001b[48;2;67;0;0mfeatures \u001b[48;2;0;0;0mSeman- \u001b[48;2;0;0;411mtic \u001b[48;2;0;0;118mScholar \u001b[48;2;66;0;0muse \u001b[48;2;93;0;0mare \u001b[48;2;53;0;0mtotal \u001b[48;2;19;0;0mnumber \u001b[48;2;231;0;0mof \u001b[48;2;0;0;29mdirect \u001b[48;2;0;0;0mcitations, \u001b[48;2;19;0;0mnumber \u001b[48;2;231;0;0mof \u001b[48;2;0;0;29mdirect \u001b[48;2;126;0;0mcitations \u001b[48;2;0;0;51mper \u001b[48;2;0;0;0msection, \u001b[48;2;53;0;0mtotal \u001b[48;2;19;0;0mnumber \u001b[48;2;231;0;0mof \u001b[48;2;0;0;37mindirect \u001b[48;2;126;0;0mcitations \u001b[48;2;110;0;0mand \u001b[48;2;19;0;0mnumber \u001b[48;2;231;0;0mof \u001b[48;2;0;0;37mindirect \u001b[48;2;126;0;0mcitations \u001b[48;2;0;0;51mper \u001b[48;2;0;0;0msection, \u001b[48;2;0;0;56mauthor \u001b[48;2;0;0;0moverlap, \u001b[48;2;0;0;123mis \u001b[48;2;0;0;173mconsidered \u001b[48;2;0;0;0mhelp- \u001b[48;2;0;0;0mful, \u001b[48;2;42;0;0mcitation \u001b[48;2;0;0;98mappears \u001b[48;2;147;0;0min \u001b[48;2;0;0;84mtable \u001b[48;2;110;0;0mand \u001b[48;2;0;0;0mcaption, \u001b[48;2;0;0;0m1/number \u001b[48;2;231;0;0mof \u001b[48;2;0;0;0mreferences, \u001b[48;2;19;0;0mnumber \u001b[48;2;231;0;0mof \u001b[48;2;29;0;0mpaper \u001b[48;2;0;0;0mcitations/all \u001b[48;2;0;0;0mcitations, \u001b[48;2;0;0;11msimilarity \u001b[48;2;0;0;33mbetween \u001b[48;2;0;0;0mabstracts, \u001b[48;2;0;0;0mPageRank[28], \u001b[48;2;19;0;0mnumber \u001b[48;2;231;0;0mof \u001b[48;2;53;0;0mtotal \u001b[48;2;149;0;0mciting \u001b[48;2;97;0;0mpapers \u001b[48;2;0;0;19mafter \u001b[48;2;318;0;0mtransitive \u001b[48;2;0;0;0mclosure, \u001b[48;2;110;0;0mand \u001b[48;2;11;0;0mfield \u001b[48;2;231;0;0mof \u001b[48;2;0;0;3mthe \u001b[48;2;0;0;0mcited \u001b[48;2;0;0;0mpaper.\n",
            "\u001b[48;2;0;0;360mWe \u001b[48;2;0;0;125mcollect \u001b[48;2;0;0;51mXX \u001b[48;2;84;0;0mpapers \u001b[48;2;141;0;0mthat \u001b[48;2;0;0;42mcite \u001b[48;2;75;0;0mscholar \u001b[48;2;0;0;149mY \u001b[48;2;69;0;0mfrom \u001b[48;2;0;0;0m78663, \u001b[48;2;0;0;156mand \u001b[48;2;0;0;51mXX \u001b[48;2;84;0;0mpapers \u001b[48;2;141;0;0mthat \u001b[48;2;0;0;42mcite \u001b[48;2;10;0;0mPatrick \u001b[48;2;0;0;194mHanrahan \u001b[48;2;69;0;0mfrom \u001b[48;2;0;0;0m56383.\n",
            "\u001b[48;2;0;0;38mOnly \u001b[48;2;257;0;0mutilizing \u001b[48;2;106;0;0mprimary \u001b[48;2;0;0;0mcitations, \u001b[48;2;0;0;185mwe \u001b[48;2;0;0;116mget \u001b[48;2;51;0;0mthe \u001b[48;2;0;0;67mglobal \u001b[48;2;0;0;57macademic \u001b[48;2;0;0;0minflu- \u001b[48;2;0;0;197mential \u001b[48;2;0;0;23mfactors \u001b[48;2;224;0;0mof \u001b[48;2;2;0;0mscholar \u001b[48;2;20;0;0mY \u001b[48;2;0;0;86mand \u001b[48;2;40;0;0mPatrick \u001b[48;2;0;0;124mHanrahan \u001b[48;2;0;0;4mis \u001b[48;2;0;0;0m0.40 \u001b[48;2;0;0;86mand \u001b[48;2;0;0;0m0.52 \u001b[48;2;0;0;0mrespectively.\n",
            "\u001b[48;2;0;0;178mFigure \u001b[48;2;210;0;0m4 \u001b[48;2;0;0;0m4.2 \u001b[48;2;64;0;0mMathematical \u001b[48;2;0;0;245mInvariance \u001b[48;2;0;0;6mto \u001b[48;2;0;0;24mverify \u001b[48;2;121;0;0mthe \u001b[48;2;0;0;0mmodel, \u001b[48;2;0;0;228mwe \u001b[48;2;60;0;0mconduct \u001b[48;2;76;0;0ma \u001b[48;2;0;0;112mseries \u001b[48;2;266;0;0mof \u001b[48;2;16;0;0mexperiments \u001b[48;2;0;0;6mto \u001b[48;2;0;0;100mprove \u001b[48;2;0;0;0mit’s \u001b[48;2;0;0;0mreasonable.\n",
            "\u001b[48;2;0;0;0mFirst, \u001b[48;2;0;0;80mgiven \u001b[48;2;129;0;0ma \u001b[48;2;0;0;41mset \u001b[48;2;296;0;0mof \u001b[48;2;0;0;5mreferences \u001b[48;2;97;0;0mwithin \u001b[48;2;129;0;0ma \u001b[48;2;0;0;0mpaper, \u001b[48;2;117;0;0mremoving \u001b[48;2;0;0;17manyone \u001b[48;2;0;0;71mreference \u001b[48;2;138;0;0mfrom \u001b[48;2;75;0;0mthe \u001b[48;2;0;0;41mset \u001b[48;2;0;0;0mwon’t \u001b[48;2;0;0;12mchange \u001b[48;2;75;0;0mthe \u001b[48;2;0;0;120mrelated \u001b[48;2;110;0;0morder \u001b[48;2;296;0;0mof \u001b[48;2;0;0;119mleft \u001b[48;2;0;0;0mrefer- \u001b[48;2;0;0;0mences.\n",
            "\u001b[48;2;0;0;64mAnd \u001b[48;2;0;0;1mwhen \u001b[48;2;153;0;0mremoving \u001b[48;2;66;0;0ma \u001b[48;2;71;0;0mreference \u001b[48;2;147;0;0mat \u001b[48;2;66;0;0ma \u001b[48;2;0;0;0mtime, \u001b[48;2;0;0;164mthe \u001b[48;2;0;0;89mleft \u001b[48;2;0;0;121mreferences \u001b[48;2;0;0;132malso \u001b[48;2;0;0;99mkeep \u001b[48;2;0;0;49mrelated \u001b[48;2;0;0;0morders.\n",
            "\u001b[48;2;0;0;0m, \u001b[48;2;0;0;0m, \u001b[48;2;0;0;147mZhang \u001b[48;2;0;0;67mand \u001b[48;2;0;0;50mWen \u001b[48;2;225;0;0met \u001b[48;2;0;0;0mal.\n",
            "\u001b[48;2;0;0;66mTable \u001b[48;2;0;0;0m5: \u001b[48;2;230;0;0mfeatures \u001b[48;2;232;0;0mused \u001b[48;2;142;0;0mfor \u001b[48;2;0;0;2mcitation \u001b[48;2;36;0;0mspan \u001b[48;2;134;0;0mFeature \u001b[48;2;39;0;0mDescription \u001b[48;2;0;0;140mdistance \u001b[48;2;0;0;22mposition \u001b[48;2;0;0;118msegment \u001b[48;2;108;0;0mthe \u001b[48;2;0;0;140mdistance \u001b[48;2;0;0;0m(in \u001b[48;2;0;0;0mwords) \u001b[48;2;0;0;129mbetween \u001b[48;2;108;0;0mthe \u001b[48;2;0;0;221mword \u001b[48;2;0;0;73mand \u001b[48;2;108;0;0mthe \u001b[48;2;0;0;143mtarget \u001b[48;2;0;0;0mcitaion.\n",
            "\u001b[48;2;200;0;0mThis \u001b[48;2;66;0;0mfeature \u001b[48;2;145;0;0mtakes \u001b[48;2;70;0;0mthe \u001b[48;2;59;0;0mvalue \u001b[48;2;68;0;0m1 \u001b[48;2;0;0;40mif \u001b[48;2;70;0;0mthe \u001b[48;2;0;0;236mword \u001b[48;2;42;0;0mcomes \u001b[48;2;0;0;265mbefore \u001b[48;2;70;0;0mthe \u001b[48;2;0;0;188mtarget \u001b[48;2;0;0;0mcitation, \u001b[48;2;0;0;78mand \u001b[48;2;0;0;47m0 \u001b[48;2;0;0;0motherwise.\n",
            "\u001b[48;2;0;0;59mAfter \u001b[48;2;0;0;37msplitting \u001b[48;2;91;0;0mthe \u001b[48;2;0;0;171msentence \u001b[48;2;0;0;10minto \u001b[48;2;0;0;301msegments \u001b[48;2;101;0;0mby \u001b[48;2;155;0;0mpunctuation \u001b[48;2;15;0;0mand \u001b[48;2;211;0;0mcoordination \u001b[48;2;0;0;0mconjunctions, \u001b[48;2;0;0;76mthis \u001b[48;2;0;0;182mfeature \u001b[48;2;0;0;81mtakes \u001b[48;2;91;0;0mthe \u001b[48;2;0;0;101mvalue \u001b[48;2;0;0;70m1 \u001b[48;2;0;0;112mif \u001b[48;2;91;0;0mthe \u001b[48;2;0;0;181mword \u001b[48;2;40;0;0moccurs \u001b[48;2;138;0;0min \u001b[48;2;91;0;0mthe \u001b[48;2;0;0;58msame \u001b[48;2;0;0;108msegment \u001b[48;2;206;0;0mwith \u001b[48;2;91;0;0mthe \u001b[48;2;0;0;216mtarget \u001b[48;2;0;0;0mreference, \u001b[48;2;15;0;0mand \u001b[48;2;0;0;28m0 \u001b[48;2;0;0;0motherwise.\n",
            "\u001b[48;2;0;0;0mpos_tag \u001b[48;2;213;0;0mthe \u001b[48;2;12;0;0mpart \u001b[48;2;150;0;0mof \u001b[48;2;0;0;81mspeech \u001b[48;2;0;0;121mtag \u001b[48;2;150;0;0mof \u001b[48;2;213;0;0mthe \u001b[48;2;0;0;0mword, \u001b[48;2;213;0;0mthe \u001b[48;2;32;0;0mword \u001b[48;2;0;0;0mbefore, \u001b[48;2;0;0;122mand \u001b[48;2;213;0;0mthe \u001b[48;2;32;0;0mword \u001b[48;2;0;0;0mafter.\n",
            "\u001b[48;2;179;0;0mdTreeDistance \u001b[48;2;0;0;124mLength \u001b[48;2;103;0;0mof \u001b[48;2;158;0;0mthe \u001b[48;2;32;0;0mshortest \u001b[48;2;0;0;182mdependency \u001b[48;2;22;0;0mpath \u001b[48;2;0;0;0m(in \u001b[48;2;158;0;0mthe \u001b[48;2;0;0;182mdependency \u001b[48;2;0;0;154mparse \u001b[48;2;0;0;0mtree) \u001b[48;2;204;0;0mthat \u001b[48;2;96;0;0mconnects \u001b[48;2;158;0;0mthe \u001b[48;2;0;0;295mword \u001b[48;2;54;0;0mto \u001b[48;2;158;0;0mthe \u001b[48;2;0;0;177mtarget \u001b[48;2;1;0;0mreference \u001b[48;2;0;0;62mor \u001b[48;2;0;0;26mits \u001b[48;2;0;0;0mrepresentative.\n",
            "\u001b[48;2;97;0;0mlca \u001b[48;2;235;0;0mthe \u001b[48;2;0;0;114mtype \u001b[48;2;232;0;0mof \u001b[48;2;235;0;0mthe \u001b[48;2;0;0;194mnode \u001b[48;2;63;0;0min \u001b[48;2;235;0;0mthe \u001b[48;2;0;0;193mdependency \u001b[48;2;0;0;263mparse \u001b[48;2;0;0;159mtree \u001b[48;2;6;0;0mthat \u001b[48;2;35;0;0mis \u001b[48;2;235;0;0mthe \u001b[48;2;0;0;6mleast \u001b[48;2;42;0;0mcommon \u001b[48;2;0;0;57mancestor \u001b[48;2;232;0;0mof \u001b[48;2;235;0;0mthe \u001b[48;2;0;0;220mword \u001b[48;2;50;0;0mand \u001b[48;2;235;0;0mthe \u001b[48;2;0;0;125mtarget \u001b[48;2;0;0;0mreference.\n",
            "\u001b[48;2;0;0;195mTable \u001b[48;2;0;0;0m6: \u001b[48;2;0;0;70mresults \u001b[48;2;93;0;0mfor \u001b[48;2;0;0;102mthree \u001b[48;2;0;0;243mdifferent \u001b[48;2;0;0;124mmodels \u001b[48;2;93;0;0mfor \u001b[48;2;60;0;0mcitation \u001b[48;2;0;0;22mspan \u001b[48;2;0;0;22mModel \u001b[48;2;183;0;0mPrecision \u001b[48;2;129;0;0mRecall \u001b[48;2;2;0;0mF1 \u001b[48;2;0;0;189mSVM \u001b[48;2;0;0;105mLR \u001b[48;2;105;0;0mCRF \u001b[48;2;0;0;0m0.78 \u001b[48;2;0;0;0m0.68 \u001b[48;2;0;0;0m0.65 \u001b[48;2;0;0;0m0.56 \u001b[48;2;0;0;0m0.67 \u001b[48;2;0;0;0m0.64 \u001b[48;2;0;0;0m0.65 \u001b[48;2;0;0;0m0.67 \u001b[48;2;0;0;0m0.64 \u001b[48;2;0;0;0mAlso, \u001b[48;2;66;0;0mthe \u001b[48;2;0;0;111mfinal \u001b[48;2;235;0;0mscore \u001b[48;2;0;0;114mshould \u001b[48;2;101;0;0mbe \u001b[48;2;0;0;128mstable \u001b[48;2;139;0;0mand \u001b[48;2;248;0;0minsensitive \u001b[48;2;216;0;0mto \u001b[48;2;0;0;0mpropa- \u001b[48;2;0;0;158mgating \u001b[48;2;143;0;0morder \u001b[48;2;226;0;0munder \u001b[48;2;230;0;0ma \u001b[48;2;0;0;13mcertain \u001b[48;2;0;0;0mpaper \u001b[48;2;0;0;0mpool.\n",
            "\u001b[48;2;0;0;127mOur \u001b[48;2;0;0;10mstrategy \u001b[48;2;0;0;186mstarts \u001b[48;2;87;0;0mfrom \u001b[48;2;161;0;0ma \u001b[48;2;0;0;4mdefault \u001b[48;2;0;0;43minfluential \u001b[48;2;0;0;75mfactor \u001b[48;2;0;0;0m1.0, \u001b[48;2;208;0;0mtraversing \u001b[48;2;181;0;0mthrough \u001b[48;2;136;0;0meach \u001b[48;2;0;0;66mpaper \u001b[48;2;149;0;0mand \u001b[48;2;0;0;335mupdating \u001b[48;2;64;0;0mthe \u001b[48;2;0;0;43minfluential \u001b[48;2;0;0;75mfactor \u001b[48;2;0;0;0msuccessively.\n",
            "\u001b[48;2;35;0;0mIt \u001b[48;2;166;0;0mis \u001b[48;2;0;0;47mproven \u001b[48;2;186;0;0mthrough \u001b[48;2;40;0;0mexperiments \u001b[48;2;157;0;0mthat \u001b[48;2;0;0;125mregardless \u001b[48;2;151;0;0mof \u001b[48;2;161;0;0mthe \u001b[48;2;0;0;300mupdating \u001b[48;2;0;0;0morder, \u001b[48;2;161;0;0mthe \u001b[48;2;0;0;78mfinal \u001b[48;2;0;0;82mscore \u001b[48;2;151;0;0mof \u001b[48;2;23;0;0meach \u001b[48;2;0;0;173mpaper \u001b[48;2;0;0;237mremains \u001b[48;2;161;0;0mthe \u001b[48;2;0;0;0msame.\n",
            "\u001b[48;2;0;0;0m4.3 \u001b[48;2;108;0;0mCitation \u001b[48;2;0;0;19mSpan \u001b[48;2;0;0;260mWe \u001b[48;2;244;0;0mconduct \u001b[48;2;0;0;162msome \u001b[48;2;87;0;0mexperiments \u001b[48;2;24;0;0mguided \u001b[48;2;58;0;0mby \u001b[48;2;0;0;0m[1] \u001b[48;2;78;0;0mas \u001b[48;2;0;0;86mour \u001b[48;2;0;0;0mbaseline.\n",
            "\u001b[48;2;0;0;144mWe \u001b[48;2;0;0;149mannotate \u001b[48;2;162;0;0mthe \u001b[48;2;29;0;0mcitation \u001b[48;2;0;0;43mspan \u001b[48;2;174;0;0mfor \u001b[48;2;0;0;61mabout \u001b[48;2;246;0;0m345 \u001b[48;2;188;0;0mciting \u001b[48;2;18;0;0msentences \u001b[48;2;50;0;0mas \u001b[48;2;0;0;145mour \u001b[48;2;0;0;236mdata \u001b[48;2;0;0;178mset \u001b[48;2;0;0;58mto \u001b[48;2;0;0;89mtrain \u001b[48;2;50;0;0mand \u001b[48;2;0;0;27mtest \u001b[48;2;162;0;0mthe \u001b[48;2;0;0;85mbaseline \u001b[48;2;0;0;0mmodel.\n",
            "\u001b[48;2;0;0;0mFirst, \u001b[48;2;0;0;171mwe \u001b[48;2;137;0;0muse \u001b[48;2;0;0;25mthe \u001b[48;2;0;0;122mtokenizer \u001b[48;2;143;0;0mtool \u001b[48;2;169;0;0mthat \u001b[48;2;100;0;0mSpaCy13 \u001b[48;2;0;0;142mprovides \u001b[48;2;26;0;0mto \u001b[48;2;0;0;253msegment \u001b[48;2;0;0;25mthe \u001b[48;2;0;0;157mtext \u001b[48;2;163;0;0mof \u001b[48;2;114;0;0meach \u001b[48;2;0;0;0mciting \u001b[48;2;1;0;0msentence \u001b[48;2;0;0;51minto \u001b[48;2;0;0;0mtokens, \u001b[48;2;185;0;0mand \u001b[48;2;137;0;0muse \u001b[48;2;0;0;194mtagger \u001b[48;2;185;0;0mand \u001b[48;2;233;0;0mparser \u001b[48;2;143;0;0mtool \u001b[48;2;26;0;0mto \u001b[48;2;66;0;0massign \u001b[48;2;0;0;0mpart-of-speech-tags \u001b[48;2;185;0;0mand \u001b[48;2;50;0;0mdependency \u001b[48;2;63;0;0mlabels \u001b[48;2;26;0;0mto \u001b[48;2;114;0;0meach \u001b[48;2;0;0;0mtoken.\n",
            "\u001b[48;2;0;0;0mThen, \u001b[48;2;0;0;4mwe \u001b[48;2;0;0;77mextract \u001b[48;2;35;0;0mfeatures \u001b[48;2;0;0;145mlisted \u001b[48;2;109;0;0min \u001b[48;2;0;0;24mTable \u001b[48;2;0;0;0m5. \u001b[48;2;140;0;0mas \u001b[48;2;67;0;0mthe \u001b[48;2;0;0;145minput \u001b[48;2;110;0;0mof \u001b[48;2;67;0;0mthe \u001b[48;2;0;0;178mbaseline \u001b[48;2;0;0;0mmodel.\n",
            "\u001b[48;2;0;0;77mThe \u001b[48;2;0;0;264mtraining \u001b[48;2;114;0;0mis \u001b[48;2;0;0;94mperformed \u001b[48;2;113;0;0musing \u001b[48;2;0;0;0mSVM, \u001b[48;2;0;0;156mLogistic \u001b[48;2;0;0;0mRegression, \u001b[48;2;60;0;0mand \u001b[48;2;0;0;0mCRF, \u001b[48;2;0;0;0mrespectively.\n",
            "\u001b[48;2;0;0;283mWe \u001b[48;2;0;0;14muse \u001b[48;2;0;0;0m10-fold \u001b[48;2;0;0;0mcross-validation \u001b[48;2;107;0;0mfor \u001b[48;2;4;0;0mtraining \u001b[48;2;71;0;0mand \u001b[48;2;0;0;0mtesting.\n",
            "\u001b[48;2;0;0;207mTable \u001b[48;2;0;0;39m6 \u001b[48;2;0;0;199mlists \u001b[48;2;53;0;0mthe \u001b[48;2;0;0;0mprecision, \u001b[48;2;0;0;0mrecall, \u001b[48;2;104;0;0mand \u001b[48;2;0;0;76mF1 \u001b[48;2;83;0;0mfor \u001b[48;2;53;0;0mthe \u001b[48;2;13;0;0mthree \u001b[48;2;0;0;0mmodel.\n",
            "\u001b[48;2;0;0;0m13https://spacy.io/ \u001b[48;2;142;0;0m5 \u001b[48;2;4;0;0mRESULTS \u001b[48;2;93;0;0mAs \u001b[48;2;11;0;0mshown \u001b[48;2;156;0;0min \u001b[48;2;0;0;152mTable \u001b[48;2;0;0;0m4, \u001b[48;2;0;0;278mPhocus \u001b[48;2;0;0;2mfigures \u001b[48;2;2;0;0mout \u001b[48;2;150;0;0mthat \u001b[48;2;114;0;0mthe \u001b[48;2;0;0;139mglobal \u001b[48;2;46;0;0macademic \u001b[48;2;0;0;116minfluential \u001b[48;2;0;0;283mfactors \u001b[48;2;148;0;0mof \u001b[48;2;0;0;105mscholar \u001b[48;2;0;0;63mY \u001b[48;2;0;0;88mand \u001b[48;2;95;0;0mPatrick \u001b[48;2;136;0;0mHanrahan \u001b[48;2;79;0;0mare \u001b[48;2;0;0;0m0.40 \u001b[48;2;0;0;88mand \u001b[48;2;0;0;0m0.52 \u001b[48;2;0;0;0mrespectively, \u001b[48;2;0;0;88mand \u001b[48;2;95;0;0mPatrick \u001b[48;2;136;0;0mHanrahan \u001b[48;2;0;0;55mis \u001b[48;2;0;0;0m30% \u001b[48;2;0;0;383mhigher \u001b[48;2;22;0;0mthan \u001b[48;2;0;0;105mscholar \u001b[48;2;0;0;0mY.\n",
            "\u001b[48;2;0;0;0mIt’s \u001b[48;2;154;0;0mthe \u001b[48;2;44;0;0mresults \u001b[48;2;167;0;0mthat \u001b[48;2;14;0;0monly \u001b[48;2;116;0;0mutilize \u001b[48;2;0;0;174mprimary \u001b[48;2;0;0;63mcitation \u001b[48;2;0;0;0mdata.\n",
            "\u001b[48;2;0;0;336mWhile \u001b[48;2;109;0;0mthe \u001b[48;2;35;0;0mevaluation \u001b[48;2;21;0;0mresults \u001b[48;2;155;0;0mfrom \u001b[48;2;0;0;0mAminer, \u001b[48;2;139;0;0mGoogle \u001b[48;2;32;0;0mscholar \u001b[48;2;0;0;15mand \u001b[48;2;0;0;14meven \u001b[48;2;96;0;0mSemantic \u001b[48;2;32;0;0mscholar \u001b[48;2;0;0;41mshows \u001b[48;2;264;0;0mthat \u001b[48;2;32;0;0mscholar \u001b[48;2;0;0;55mY \u001b[48;2;0;0;139mis \u001b[48;2;0;0;176mmore \u001b[48;2;0;0;211mproductive \u001b[48;2;0;0;15mand \u001b[48;2;0;0;78minfluential \u001b[48;2;0;0;12mthan \u001b[48;2;53;0;0mPatrick \u001b[48;2;0;0;0mHanrahan.\n",
            "\u001b[48;2;90;0;0m6 \u001b[48;2;130;0;0mCONCLUSION \u001b[48;2;194;0;0mIn \u001b[48;2;51;0;0mthis \u001b[48;2;0;0;0mpaper, \u001b[48;2;0;0;230mwe \u001b[48;2;0;0;184mcome \u001b[48;2;0;0;294mup \u001b[48;2;181;0;0mwith \u001b[48;2;0;0;0mPhocus, \u001b[48;2;99;0;0ma \u001b[48;2;0;0;334mnovel \u001b[48;2;0;0;83mset \u001b[48;2;194;0;0mof \u001b[48;2;0;0;81macademic \u001b[48;2;0;0;134mevaluation \u001b[48;2;0;0;18mmetrics \u001b[48;2;67;0;0mfor \u001b[48;2;62;0;0mauthors \u001b[48;2;0;0;81mand \u001b[48;2;0;0;46mpublications \u001b[48;2;10;0;0mbased \u001b[48;2;88;0;0mon \u001b[48;2;85;0;0mcitation \u001b[48;2;127;0;0mjudgements \u001b[48;2;116;0;0mthat \u001b[48;2;200;0;0mutilize \u001b[48;2;0;0;0maspect-based \u001b[48;2;0;0;36msentiment \u001b[48;2;0;0;0manalysis.\n",
            "\u001b[48;2;0;0;156mTo \u001b[48;2;0;0;66mverify \u001b[48;2;0;0;169mour \u001b[48;2;28;0;0mevaluation \u001b[48;2;0;0;0mmechanism, \u001b[48;2;0;0;140mpeer \u001b[48;2;120;0;0mcomparison \u001b[48;2;101;0;0mand \u001b[48;2;288;0;0mablation \u001b[48;2;81;0;0mstudies \u001b[48;2;64;0;0mhave \u001b[48;2;0;0;179mbeen \u001b[48;2;0;0;0mconducted.\n",
            "\u001b[48;2;117;0;0mthe \u001b[48;2;0;0;122mresults \u001b[48;2;74;0;0mshow \u001b[48;2;94;0;0mthat \u001b[48;2;0;0;109mour \u001b[48;2;66;0;0mmetrics \u001b[48;2;49;0;0mare \u001b[48;2;0;0;64mable \u001b[48;2;95;0;0mto \u001b[48;2;0;0;140midentify \u001b[48;2;117;0;0mthe \u001b[48;2;0;0;251mtruly \u001b[48;2;0;0;391mworthiness \u001b[48;2;26;0;0mof \u001b[48;2;203;0;0ma \u001b[48;2;0;0;70mpaper \u001b[48;2;0;0;41mor \u001b[48;2;203;0;0ma \u001b[48;2;0;0;0mscholar, \u001b[48;2;126;0;0mwhich \u001b[48;2;109;0;0mis \u001b[48;2;0;0;35mdifficult \u001b[48;2;95;0;0mto \u001b[48;2;0;0;83mcitation \u001b[48;2;0;0;128mtimes \u001b[48;2;0;0;97mbased \u001b[48;2;0;0;0mmetrics, \u001b[48;2;165;0;0mlike \u001b[48;2;0;0;0mh-index, \u001b[48;2;0;0;0mg-index \u001b[48;2;100;0;0mand \u001b[48;2;0;0;0mothers.\n",
            "\u001b[48;2;182;0;0mPhocus \u001b[48;2;0;0;108mstill \u001b[48;2;116;0;0mneed \u001b[48;2;0;0;0mimprovements.\n",
            "\u001b[48;2;34;0;0mAs \u001b[48;2;29;0;0mshown \u001b[48;2;263;0;0min \u001b[48;2;114;0;0mSection \u001b[48;2;0;0;0mExper- \u001b[48;2;0;0;0miments, \u001b[48;2;0;0;183mwe \u001b[48;2;0;0;215monly \u001b[48;2;166;0;0muse \u001b[48;2;0;0;123mprimary \u001b[48;2;37;0;0mcitation \u001b[48;2;0;0;0mdata, \u001b[48;2;143;0;0mwhich \u001b[48;2;29;0;0mis \u001b[48;2;0;0;201mnot \u001b[48;2;0;0;16menough \u001b[48;2;159;0;0mto \u001b[48;2;0;0;52mfully \u001b[48;2;0;0;226mprove \u001b[48;2;0;0;31mthe \u001b[48;2;82;0;0mreliability \u001b[48;2;134;0;0mof \u001b[48;2;0;0;0mPhocus.\n",
            "\u001b[48;2;0;0;0mBesides, \u001b[48;2;250;0;0musing \u001b[48;2;0;0;5mmore \u001b[48;2;0;0;131mdata \u001b[48;2;0;0;151msuch \u001b[48;2;235;0;0mas \u001b[48;2;0;0;44msecondary \u001b[48;2;60;0;0mand \u001b[48;2;0;0;2mtertiary \u001b[48;2;78;0;0mcitations \u001b[48;2;11;0;0mcould \u001b[48;2;0;0;166mfurther \u001b[48;2;0;0;128mreflect \u001b[48;2;98;0;0mthe \u001b[48;2;0;0;168mgaps \u001b[48;2;0;0;154mbetween \u001b[48;2;0;0;59mscholars \u001b[48;2;60;0;0mand \u001b[48;2;0;0;154mbetween \u001b[48;2;0;0;0mmetrics.\n",
            "\u001b[48;2;137;0;0mThere \u001b[48;2;21;0;0mare \u001b[48;2;0;0;295mstill \u001b[48;2;0;0;97mmany \u001b[48;2;0;0;55mproblems \u001b[48;2;0;0;0munsolved, \u001b[48;2;2;0;0msuch \u001b[48;2;237;0;0mas \u001b[48;2;0;0;0m“citation \u001b[48;2;0;0;0mcircles” \u001b[48;2;0;0;0m(groups \u001b[48;2;173;0;0mof \u001b[48;2;0;0;79mresearchers \u001b[48;2;0;0;60mwho \u001b[48;2;77;0;0mcite \u001b[48;2;0;0;58mone \u001b[48;2;0;0;0manother’s \u001b[48;2;0;0;0mwork), \u001b[48;2;44;0;0mand \u001b[48;2;0;0;0mself-citation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errs"
      ],
      "metadata": {
        "id": "sfr8lMzYMJNq",
        "outputId": "7cbcb58c-e58d-48ee-ca48-3d9585639fc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[86, 134]"
            ]
          },
          "metadata": {},
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(color_by_attn(content[86],tokenizer,preprocesser_model,encoder_model))"
      ],
      "metadata": {
        "id": "5W-uSOK4MKgk",
        "outputId": "d7e87630-4cba-4c75-8a37-c76049917b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-362-9a638c6f8473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_by_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m86\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocesser_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-361-3697131c6e28>\u001b[0m in \u001b[0;36mcolor_by_attn\u001b[0;34m(text, toker, preper, encoder)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprocessed\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mprocess_for_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_attn_for_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocesser_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_bytes_strs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-328-3ba09b0bc540>\u001b[0m in \u001b[0;36mget_attn_for_words\u001b[0;34m(context, tokenizer, prep, encoder)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindicies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mattn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mfull_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 131 is out of bounds for axis 0 with size 125"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content[134]"
      ],
      "metadata": {
        "id": "igoZJhU3MWaO",
        "outputId": "1a020f2c-b586-41b2-ea66-68dceb56cca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'However, those numbers covers up some significant truths that not all papers are equal influential and not all citations mean agreement with the cited ones. where h repre- sents h-index, g represents g-index, i10 means i10-index, and HIC  9https://scholar.google.com/citations?hl=zh-CN&user=RzEnQmgAAAAJ 10https://www.aminer.cn/ 11https://scholar.google.com/ 12https://www.semanticscholar.org/  Table 3: statistics of Y and Hanrahan  Scholar  Aminer  Google Scholar  publications citations citations  Y  1146  77903  78663  Hanrahan 381  52214  50568  Semantic Scholar publications citations  771  315  59679  56383  Table 4: evaluation results from several platforms  Scholar  Aminer  Google Scholar  Semantic Scholar  h  131  Y  Hanrahan 97  g  258  228  h  123  93  i10  723  200  h  HIC  119  5843  88  3741  Phocus (Primary)  0.40  0.52  Figure 4: for paper A, paper B and C cite it directly, called primary citations, D to A is secondary and E to A is tertiary.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.split('\\d{1,}https:',content[134]) #remove subscripts"
      ],
      "metadata": {
        "id": "_BQ6mWooOfj5",
        "outputId": "4a17b3f1-440c-4b16-8fee-b9d76068bcef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['However, those numbers covers up some significant truths that not all papers are equal influential and not all citations mean agreement with the cited ones. where h repre- sents h-index, g represents g-index, i10 means i10-index, and HIC  ',\n",
              " '//scholar.google.com/citations?hl=zh-CN&user=RzEnQmgAAAAJ ',\n",
              " '//www.aminer.cn/ ',\n",
              " '//scholar.google.com/ ',\n",
              " '//www.semanticscholar.org/  Table 3: statistics of Y and Hanrahan  Scholar  Aminer  Google Scholar  publications citations citations  Y  1146  77903  78663  Hanrahan 381  52214  50568  Semantic Scholar publications citations  771  315  59679  56383  Table 4: evaluation results from several platforms  Scholar  Aminer  Google Scholar  Semantic Scholar  h  131  Y  Hanrahan 97  g  258  228  h  123  93  i10  723  200  h  HIC  119  5843  88  3741  Phocus (Primary)  0.40  0.52  Figure 4: for paper A, paper B and C cite it directly, called primary citations, D to A is secondary and E to A is tertiary.']"
            ]
          },
          "metadata": {},
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.split('Table \\d{1,}:',content[134]) #remove tables"
      ],
      "metadata": {
        "id": "mwEOZ1WSPiAc",
        "outputId": "20a6bca6-7456-40b9-e889-17a17ddde6c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['However, those numbers covers up some significant truths that not all papers are equal influential and not all citations mean agreement with the cited ones. where h repre- sents h-index, g represents g-index, i10 means i10-index, and HIC  9https://scholar.google.com/citations?hl=zh-CN&user=RzEnQmgAAAAJ 10https://www.aminer.cn/ 11https://scholar.google.com/ 12https://www.semanticscholar.org/  ',\n",
              " ' statistics of Y and Hanrahan  Scholar  Aminer  Google Scholar  publications citations citations  Y  1146  77903  78663  Hanrahan 381  52214  50568  Semantic Scholar publications citations  771  315  59679  56383  ',\n",
              " ' evaluation results from several platforms  Scholar  Aminer  Google Scholar  Semantic Scholar  h  131  Y  Hanrahan 97  g  258  228  h  123  93  i10  723  200  h  HIC  119  5843  88  3741  Phocus (Primary)  0.40  0.52  Figure 4: for paper A, paper B and C cite it directly, called primary citations, D to A is secondary and E to A is tertiary.']"
            ]
          },
          "metadata": {},
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.split('Figure \\d{1,}:',content[134]) #remove tables"
      ],
      "metadata": {
        "id": "YtulqK88P_wX",
        "outputId": "e900e6d3-9f8a-4c19-ba5b-78459de0ebe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['However, those numbers covers up some significant truths that not all papers are equal influential and not all citations mean agreement with the cited ones. where h repre- sents h-index, g represents g-index, i10 means i10-index, and HIC  9https://scholar.google.com/citations?hl=zh-CN&user=RzEnQmgAAAAJ 10https://www.aminer.cn/ 11https://scholar.google.com/ 12https://www.semanticscholar.org/  Table 3: statistics of Y and Hanrahan  Scholar  Aminer  Google Scholar  publications citations citations  Y  1146  77903  78663  Hanrahan 381  52214  50568  Semantic Scholar publications citations  771  315  59679  56383  Table 4: evaluation results from several platforms  Scholar  Aminer  Google Scholar  Semantic Scholar  h  131  Y  Hanrahan 97  g  258  228  h  123  93  i10  723  200  h  HIC  119  5843  88  3741  Phocus (Primary)  0.40  0.52  ',\n",
              " ' for paper A, paper B and C cite it directly, called primary citations, D to A is secondary and E to A is tertiary.']"
            ]
          },
          "metadata": {},
          "execution_count": 366
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "input.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}