{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h7Lr7k5d1jd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ENEE439d-TEXTML/TextML/blob/master/input.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/ENEE439d-TEXTML/TextML/blob/master/input.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPiicLOUd1jj"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U \"tensorflow-text==2.8.*\" # A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q tf-models-official==2.7.0 # For adamW\n",
        "!pip install focal-loss # focal loss implmnetion for tf\n",
        "!pip install pdfminer.six #pdf text extratction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52FpqTzrPr-t",
        "outputId": "7bffe4bc-dda5-4a06-ecbc-2623a0cd2692"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: focal-loss in /usr/local/lib/python3.7/dist-packages (0.0.7)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal-loss) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (4.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.0.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (14.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.44.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.25.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal-loss) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2->focal-loss) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.2.0)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.7/dist-packages (20220506)\n",
            "Requirement already satisfied: cryptography~=36.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (36.0.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (2.0.12)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography~=36.0.0->pdfminer.six) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography~=36.0.0->pdfminer.six) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "BPnv0Vlcd3KI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #basic imports\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split # https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization, bert  # to create AdamW optimizer\n",
        "from focal_loss import SparseCategoricalFocalLoss\n",
        "import official.nlp.bert.tokenization"
      ],
      "metadata": {
        "id": "dkxbtcKbP4AU"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import StringIO\n",
        "\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfdocument import PDFDocument\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.pdfparser import PDFParser"
      ],
      "metadata": {
        "id": "Xx7DXy_KYgAE"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns; sns.set_theme()"
      ],
      "metadata": {
        "id": "C8Bp4YVOR8JZ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data read in"
      ],
      "metadata": {
        "id": "Q-Dc1EsOuQA0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "465BADPxeNII",
        "outputId": "f90b7cbd-ce9b-4872-f510-2861ce483e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Sk1zTIA6eOM5",
        "outputId": "538c5a1a-85e2-4f45-8bb8-83a771bdb50b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  cited_paper  label                                               text\n",
              "0    A00-2024      0  We analyzed a set of articles and identified s...\n",
              "1    A00-2024      0  Table 3: Example compressions Compression AvgL...\n",
              "2    A00-2024      0  5.3 Related works and discussion Our two-step ...\n",
              "3    A00-2024      0  (1999) proposed a summarization system based o...\n",
              "4    A00-2024      0  We found that the deletion of lead parts did n..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f61e96f-e1b8-4e24-b35a-d49254ec39b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f61e96f-e1b8-4e24-b35a-d49254ec39b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f61e96f-e1b8-4e24-b35a-d49254ec39b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f61e96f-e1b8-4e24-b35a-d49254ec39b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "filepath = '/content/drive/MyDrive/Text-ML/full_sentiment_dataset.csv' #'data.csv'\n",
        "df= pd.read_csv(filepath)\n",
        "df1=df.drop(['no','paper','context_a','context_b'],axis=1)\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImSOYF6Py2J8",
        "outputId": "d45cbc00-08b2-430f-932e-9ddbf96bc1ae"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    7627\n",
              " 1     829\n",
              "-1     280\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filtering by regex"
      ],
      "metadata": {
        "id": "FHIvNaLfuUoe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytc03_FI-b5L",
        "outputId": "5bc3e17f-daf8-4273-a68f-8b60ac652a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\[*\\]|\\(\\d{4}\\)|\\(?((\\(?((\\w+, )*(\\w+ )+)((and|&) ((\\w+ *))?)?,? \\(?\\d{4}\\)?|((\\w+, )*(\\w+ )+)et al\\. ?,? \\(?\\d{4}\\)?\\)?)((; )|( (and|&) ))*)+\n"
          ]
        }
      ],
      "source": [
        "context=df1['text']\n",
        "\n",
        "re1= \"\\(((([A-Za-z]+ *)+(, \\d+))+(; )*)+\\)\" # matches author and author, year\n",
        "re_year=\",? \\(?\\d{4}\\)?\" # match , {4 digits} which may be wrapped in () \n",
        "re_and=\"(and|&) \"\n",
        "re_auth=\"((\\w+, )*(\\w+ )+)\"\n",
        "re_et= re_auth+\"et al\\. ?\"+re_year # matches author et al. , year\n",
        "re_2a= re_auth+\"(\"+re_and+\"((\\w+ *))?)?\"+re_year # matches author and author, year\n",
        "re_sep=\"((; )|( \"+re_and+\"))*\"# match the '; ' gap or ' and ' gap\n",
        "re_para_year=\"\\(\\d{4}\\)\"\n",
        "re_in_brack=\"\\[*\\]\"\n",
        "re_apa =re_in_brack+\"|\"+re_para_year+\"|\"+\"\\(?(\"+\"(\\(?\"+re_2a+\"|\"+re_et+\"\\)?)\"+re_sep+\")+\"\n",
        "print(re_apa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "NEZIAWQtykDg"
      },
      "outputs": [],
      "source": [
        "def remove_matches(text,regex=re_apa):\n",
        "  text1=text\n",
        "  rem_len=0\n",
        "  pattern= re.compile(regex)\n",
        "  while True:\n",
        "    matches=pattern.search(text1)\n",
        "    #print(matches)\n",
        "    if matches == None:\n",
        "      break\n",
        "\n",
        "    spn=matches.span()\n",
        "    text1=text1[0:spn[0]]+text1[spn[1]:-1]\n",
        "    cit_len=spn[1]-spn[0]\n",
        "    rem_len+=cit_len\n",
        "  \n",
        "  if len(text) >0:\n",
        "    percent_removed=rem_len/len(text)\n",
        "  else:\n",
        "    percent_removed=1\n",
        "  return text1,percent_removed \n",
        "\n",
        "# print(context[5])\n",
        "# remove_citation(context[5],regex=re_apa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "TmjjH1gp9A6T"
      },
      "outputs": [],
      "source": [
        "output=df1['text'].apply(lambda x: remove_matches(text=x,regex=re_apa)) #df['col1'] = df.apply(lambda x: complex_function(x['col1']), axis=1)\n",
        "df_o = pd.DataFrame(list(output), columns =['clean','p_rem'])\n",
        "output_1=df_o['clean'].apply(lambda x: remove_matches(text=x,regex='[^\\w_0-9 ]+')) \n",
        "df_o_1 = pd.DataFrame(list(output_1), columns =['clean','p_rem'])\n",
        "#df_o.head()\n",
        "\n",
        "df1['text_clean']=df_o_1['clean']\n",
        "df1['text_clean_len']=df_o_1['clean'].apply(len)\n",
        "df1['p_rem']=df_o['p_rem']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OVt3NtaJDDrx",
        "outputId": "284f4f0d-d5cd-4bc2-e074-617563693737"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cited_paper  label                                               text  \\\n",
              "0       A00-2024      0  We analyzed a set of articles and identified s...   \n",
              "1       A00-2024      0  Table 3: Example compressions Compression AvgL...   \n",
              "2       A00-2024      0  5.3 Related works and discussion Our two-step ...   \n",
              "3       A00-2024      0  (1999) proposed a summarization system based o...   \n",
              "4       A00-2024      0  We found that the deletion of lead parts did n...   \n",
              "...          ...    ...                                                ...   \n",
              "8731    W96-0213      1  He has achieved state-of-the art results by ap...   \n",
              "8732    W96-0213      0  B = (Brill and Wu, 1998); M = (Magerman, 1995)...   \n",
              "8733    W96-0213      0  The model we use is similar to that of (Ratnap...   \n",
              "8734    W96-0213      1  Our model exploits the same kind of tag-n-gram...   \n",
              "8735    W96-0213      0  In that table, TBL stands for Brill's transfor...   \n",
              "\n",
              "                                             text_clean  text_clean_len  \\\n",
              "0     We analyzed a set of articles and identified s...             425   \n",
              "1     Table 3 Example compressions Compression AvgLe...             229   \n",
              "2     53 Related works and discussion Our twostep mo...             105   \n",
              "3      proposed a summarization system based on the ...             321   \n",
              "4     We found that the deletion of lead parts did n...              73   \n",
              "...                                                 ...             ...   \n",
              "8731  He has achieved stateofthe art results by appl...             139   \n",
              "8732   B  M  Magerman 1995 O  our data R  Ratnaparkhi 1              48   \n",
              "8733  The model we use is similar to that of Ratnapa...              55   \n",
              "8734  Our model exploits the same kind of tagngram i...             157   \n",
              "8735  In that table TBL stands for Brills transforma...             288   \n",
              "\n",
              "         p_rem  \n",
              "0     0.098765  \n",
              "1     0.260745  \n",
              "2     0.308176  \n",
              "3     0.078804  \n",
              "4     0.408000  \n",
              "...        ...  \n",
              "8731  0.151515  \n",
              "8732  0.421488  \n",
              "8733  0.000000  \n",
              "8734  0.000000  \n",
              "8735  0.000000  \n",
              "\n",
              "[8736 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-604cb39d-63bb-4e8b-8453-458046b0a2ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_clean_len</th>\n",
              "      <th>p_rem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "      <td>425</td>\n",
              "      <td>0.098765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "      <td>Table 3 Example compressions Compression AvgLe...</td>\n",
              "      <td>229</td>\n",
              "      <td>0.260745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "      <td>53 Related works and discussion Our twostep mo...</td>\n",
              "      <td>105</td>\n",
              "      <td>0.308176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "      <td>proposed a summarization system based on the ...</td>\n",
              "      <td>321</td>\n",
              "      <td>0.078804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "      <td>73</td>\n",
              "      <td>0.408000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>1</td>\n",
              "      <td>He has achieved state-of-the art results by ap...</td>\n",
              "      <td>He has achieved stateofthe art results by appl...</td>\n",
              "      <td>139</td>\n",
              "      <td>0.151515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8732</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>B = (Brill and Wu, 1998); M = (Magerman, 1995)...</td>\n",
              "      <td>B  M  Magerman 1995 O  our data R  Ratnaparkhi 1</td>\n",
              "      <td>48</td>\n",
              "      <td>0.421488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8733</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>The model we use is similar to that of (Ratnap...</td>\n",
              "      <td>The model we use is similar to that of Ratnapa...</td>\n",
              "      <td>55</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8734</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>1</td>\n",
              "      <td>Our model exploits the same kind of tag-n-gram...</td>\n",
              "      <td>Our model exploits the same kind of tagngram i...</td>\n",
              "      <td>157</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8735</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>In that table, TBL stands for Brill's transfor...</td>\n",
              "      <td>In that table TBL stands for Brills transforma...</td>\n",
              "      <td>288</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8736 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-604cb39d-63bb-4e8b-8453-458046b0a2ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-604cb39d-63bb-4e8b-8453-458046b0a2ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-604cb39d-63bb-4e8b-8453-458046b0a2ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove under and over sized samples\n",
        "large samples appear to be poorly written"
      ],
      "metadata": {
        "id": "pkNPWqAHKLxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getMidLen(data,label,labelKey='label',lenKey='text_clean_len',lowMod=1,highMod=1):\n",
        "  df1 =data.loc[data[labelKey] == label]\n",
        "  neu_mean=np.mean(list(df1[lenKey]))\n",
        "  neu_std=np.std(list(df1[lenKey]))\n",
        "  df1_no_high = df1.loc[df1[lenKey] < highMod*(neu_mean +neu_std)]\n",
        "  # print(neu_mean)\n",
        "  # print(neu_std)\n",
        "\n",
        "  while neu_std > neu_mean:\n",
        "    neu_mean=np.mean(list(df1_no_high['text_clean_len']))\n",
        "    neu_std=np.std(list(df1_no_high['text_clean_len']))\n",
        "    # print(neu_mean)\n",
        "    # print(neu_std)\n",
        "    df1_no_high = df1.loc[df1['text_clean_len'] < highMod*(neu_mean +neu_std)]\n",
        "\n",
        "  df1_mid = df1_no_high.loc[df1_no_high['text_clean_len'] > lowMod*(neu_mean -neu_std)]\n",
        "\n",
        "  return df1_mid\n",
        "\n",
        "df2 = df1.loc[df1['p_rem'] < .5] #keep sampels with less than half of it are citation\n",
        "\n",
        "df_neu=getMidLen(df2,0,lowMod=2)\n",
        "df_pos=getMidLen(df2,1,lowMod=1,highMod=2)\n",
        "df_neg=getMidLen(df2,-1,lowMod=1,highMod=2)\n",
        "df3= pd.concat([df_neg,df_neu,df_pos])\n",
        "df3['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq-BsMfleXID",
        "outputId": "f6971ec9-6bed-4a61-c3e6-aecabdcb4566"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    2524\n",
              " 1     746\n",
              "-1     246\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def catagorize(data,labelKey='label'):\n",
        "  rows=len(data.index)\n",
        "  onehots=np.zeros((rows,3),dtype=int)\n",
        "  for i,lab in enumerate(data[labelKey]):\n",
        "    onehots[i][lab+1]=1\n",
        "  return onehots\n",
        "\n",
        "hots=catagorize(df3)\n",
        "df3['label_onehot']=list(hots)\n",
        "df3['label_index']=df3['label']+1"
      ],
      "metadata": {
        "id": "VnsKnaB0AU4i"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq= np.array(list(df3['label_index'].value_counts(normalize=True,sort=False)))\n",
        "print(freq)\n",
        "class_ratio= 1/freq\n",
        "class_ratio"
      ],
      "metadata": {
        "id": "Mbn2dX1C2Ixs",
        "outputId": "cb3a8be5-46b5-4e1f-aa7a-9d7fd3180fac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06996587 0.71786121 0.21217292]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14.29268293,  1.39302694,  4.71313673])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Model"
      ],
      "metadata": {
        "id": "QtrXZF4_unOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(list(df3['text_clean']), list(df3['label_index']), test_size=0.2, random_state=42)\n",
        "X_train= [[s] for s in X_train]\n",
        "X_test= [[s] for s in X_test]\n",
        "y_train=[[s] for s in list(y_train)]\n",
        "y_test=[[s] for s in list(y_test)]"
      ],
      "metadata": {
        "id": "kKtJq5Baj1Wl"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose a BERT model to fine-tune (Taken from tutorial)\n",
        "\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "metadata": {
        "id": "9WK-J5dQpprm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e70fa8-8720-4bbb-a3b3-02a3f597322c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check model passes"
      ],
      "metadata": {
        "id": "91uobQaIu-iE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "metadata": {
        "id": "YINTv-Uu8HP5"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = X_train[1]\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGAgJwGg08-j",
        "outputId": "bc61c4c7-9a9e-428a-b8e0-0521f5aea241"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_word_ids', 'input_type_ids', 'input_mask']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [  101  1999  5688 11416  6024  4275  2024  4738  2000 25845  1996  4101]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "metadata": {
        "id": "U2o1JW9b9MHu"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW0iEt6Z9PKt",
        "outputId": "b400717b-887e-4d81-f0ca-2b687b1d0bb6"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.99835694 -0.7678578  -0.21300124  0.08411987 -0.08593949  0.98550844\n",
            "  0.9732349  -0.8306031  -0.55687106 -0.95725054 -0.3960305  -0.94115573]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[ 3.8915187e-01  2.3267061e-01  6.1780311e-02 ... -9.2866874e-01\n",
            "   4.3027106e-01  8.3279318e-01]\n",
            " [ 4.5310837e-01  7.2308904e-01 -3.2866317e-01 ... -1.1163950e-04\n",
            "  -3.3482751e-01  5.7274055e-01]\n",
            " [-2.5876865e-01  1.4199525e+00 -4.2525381e-01 ...  4.9038833e-01\n",
            "   1.4491324e-01  5.7048750e-01]\n",
            " ...\n",
            " [ 2.6529512e-01 -2.3668993e-01  8.4921330e-02 ...  2.0211086e-02\n",
            "   3.9103544e-01  8.9449620e-01]\n",
            " [ 2.9499257e-01  5.8424294e-01 -6.7344594e-01 ... -1.6148384e+00\n",
            "   1.3211843e+00 -6.0517174e-01]\n",
            " [-1.8697177e-01  5.2527428e-01  9.2377967e-01 ... -5.6088662e-01\n",
            "   1.0293359e+00 -7.8856331e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## full model setup"
      ],
      "metadata": {
        "id": "GSyS6XhXvGXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(3, activation='softmax', name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "XWtmKUBu_3kJ"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = build_classifier_model()"
      ],
      "metadata": {
        "id": "Z17Cu4Awc3jA"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check loss function"
      ],
      "metadata": {
        "id": "KgOUUHifvD3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(bert_raw_result)\n",
        "\n",
        "l =  SparseCategoricalFocalLoss(gamma=2,class_weight=class_ratio)\n",
        "test =tf.convert_to_tensor([1.0])\n",
        "l(test,bert_raw_result)"
      ],
      "metadata": {
        "id": "jHqpunBDTKym",
        "outputId": "163d1b08-54ad-4f74-c295-5ee7b028f75c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.1488465 0.2751187 0.5760347]], shape=(1, 3), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.9446458>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Save and Log"
      ],
      "metadata": {
        "id": "hTEGlj9RvLg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "steps_per_epoch = 200 #tf.data.experimental.cardinality(X_train).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 2e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n",
        "\n",
        "# def auc_wrapper(y_true,y_pred):\n",
        "#   print(y_true,y_pred)\n",
        "\n",
        "#   y_true=tf.reshape(y_true,[1])\n",
        "#   print(y_true)\n",
        "#   y_true= tf.cast(y_true, tf.int32)\n",
        "#   print(y_true)\n",
        "#   y_true=tf.one_hot(y_true,depth=3)\n",
        "#   print(y_true)\n",
        "#   return tf.keras.metrics.AUC(multi_label=True)(y_true,y_pred)\n",
        "\n",
        "\n",
        "loss =  SparseCategoricalFocalLoss(gamma=2,class_weight=class_ratio) #tf.keras.losses.MeanSquaredError()\n",
        "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]#, auc_wrapper]#, tf.keras.metrics.AUC(multi_label=True)]\n",
        "\n",
        "\n",
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"citation_BERT_{epoch}\",\n",
        "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
        "        monitor=\"val_sparse_categorical_accuracy\",\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n",
        "]\n"
      ],
      "metadata": {
        "id": "MB9Af5RMCuqP"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Training model with {tfhub_handle_encoder}')\n",
        "# history = classifier_model.fit(x=X_train,y=y_train, validation_data=(X_test,y_test),epochs=epochs,callbacks= callbacks, verbose=True)"
      ],
      "metadata": {
        "id": "89v_3XqEE3HN"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier_model.save_weights(''/content/drive/MyDrive/Text-ML/checkpoint1')"
      ],
      "metadata": {
        "id": "Pox0n2xZjdtX"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect model"
      ],
      "metadata": {
        "id": "Z_fseNCGvY4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "00eGEQhDdMUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017c83e9-ffed-4efb-cffc-1af71865c8f9"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorboard --logdir=logs"
      ],
      "metadata": {
        "id": "Gszh9ZNBbQXe"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.load_weights('/content/drive/MyDrive/Text-ML/checkpoint')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMRXTmWvmBNn",
        "outputId": "9dc583b1-fc08-42c2-e8d1-fab4a2371ed0"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f28fb9c16d0>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preds=classifier_model.predict(X_train,verbose=1)"
      ],
      "metadata": {
        "id": "vCgZJCYsvdMe"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preds_t=classifier_model.predict(X_test,verbose=1)"
      ],
      "metadata": {
        "id": "Wu5a35I1wlOi"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c_mat=tf.math.confusion_matrix(np.argmax(preds,-1),y_train)\n",
        "# ax = sns.heatmap(c_mat,annot=True,linewidths=.5)"
      ],
      "metadata": {
        "id": "_5R4bXyzxoql"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c_mat=tf.math.confusion_matrix(np.argmax(preds_t,-1),y_test)\n",
        "# ax = sns.heatmap(c_mat,annot=True,linewidths=.5)"
      ],
      "metadata": {
        "id": "RPkpGRdDyCz6"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get attention colorings"
      ],
      "metadata": {
        "id": "ZRca_y_Kvq86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1\n"
      ],
      "metadata": {
        "id": "aSNvnkyoJdqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.layers"
      ],
      "metadata": {
        "id": "PR_gDYEQofck",
        "outputId": "931b02d6-c22d-4b3b-ee8e-a1913451d1d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f28e777bd90>,\n",
              " <tensorflow_hub.keras_layer.KerasLayer at 0x7f28e77c58d0>,\n",
              " <tensorflow_hub.keras_layer.KerasLayer at 0x7f28f4fe8a90>,\n",
              " <keras.layers.core.dropout.Dropout at 0x7f28e722e3d0>,\n",
              " <keras.layers.core.dense.Dense at 0x7f28e7160b10>]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from official.nlp import bert \n",
        "import official.nlp.bert.tokenization"
      ],
      "metadata": {
        "id": "bC2uW7zrx7VR"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = bert.tokenization.FullTokenizer(vocab_file='/content/drive/MyDrive/Text-ML/vocab.txt')\n",
        "preprocesser_model = keras.Model(inputs=classifier_model.input,outputs=classifier_model.get_layer('preprocessing').output)\n",
        "encoder_model = keras.Model(inputs=classifier_model.input,outputs=classifier_model.get_layer('BERT_encoder').output)"
      ],
      "metadata": {
        "id": "Lnb_ie7zxpbc"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocab size:\", len(tokenizer.vocab))"
      ],
      "metadata": {
        "id": "mjgJ0WAwRjYb",
        "outputId": "8e21bbb7-8b64-4870-e912-65bed4f7049d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 30522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attnetion token mapping"
      ],
      "metadata": {
        "id": "z7DPKDmPI9yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attn(context,prep,encoder): # assume stirng array input\n",
        "  t_context=tf.convert_to_tensor(context)\n",
        "\n",
        "  p_out=prep(t_context)\n",
        "  #print(p_out)\n",
        "  stop_index=0\n",
        "  while(stop_index< p_out[\"input_mask\"].shape[1] and p_out[\"input_mask\"][0][stop_index] == 1):\n",
        "    stop_index+=1\n",
        "  \n",
        "  if stop_index >= 128:\n",
        "    stop_index=127\n",
        "\n",
        "  output = encoder(t_context)\n",
        "  #print(output[\"sequence_output\"].shape)\n",
        "  valid_entries=output[\"sequence_output\"][:,1:stop_index-1,:]\n",
        "  a=tf.math.reduce_mean(valid_entries,-1)\n",
        "  mean=tf.math.reduce_mean(a,-1,keepdims=True)\n",
        "  std=tf.math.reduce_std(a,-1,keepdims=True)\n",
        "  a1=(a-mean)/std\n",
        "\n",
        "  return a1"
      ],
      "metadata": {
        "id": "NC_Cyexu9TQI"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attn_for_words(context,tokenizer,prep,encoder):\n",
        "  attn = get_attn(context,prep,encoder).numpy()\n",
        "  tokens = tokenizer.tokenize(context[0]) \n",
        "\n",
        "  indicies=np.ones((len(tokens)),dtype=int)\n",
        "  for i,tok in enumerate(tokens):\n",
        "    if '##' in tok:\n",
        "      indicies[i]=0\n",
        "\n",
        "  full_words=tokens.copy()\n",
        "  ix=-1\n",
        "  for i,tok in enumerate(tokens):\n",
        "    if not indicies[i]:\n",
        "      attn[0][ix]+=attn[0][i]\n",
        "      full_words[ix]+=tok[2:]\n",
        "    else:\n",
        "      ix=i\n",
        "\n",
        "  t_f=tf.convert_to_tensor(full_words) #stores as byte string...\n",
        "  masked_f=tf.boolean_mask(t_f,indicies)\n",
        "  t_a=tf.convert_to_tensor(attn)[0]\n",
        "  masked_a=tf.boolean_mask(t_a[:len(indicies)],indicies)\n",
        "  \n",
        "\n",
        "  return masked_f.numpy(),masked_a.numpy()\n",
        "\n",
        "#words, at=get_attn_for_words(processed,tokenizer,preprocesser_model,encoder_model)"
      ],
      "metadata": {
        "id": "iyhKVIiY121W"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## converters and annotation"
      ],
      "metadata": {
        "id": "kj_6JUFQIvG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_for_input(raw_context):\n",
        "  c1,_ =remove_matches(text=raw_context,regex=re_apa)\n",
        "  c2,_ =remove_matches(text=c1,regex='[^\\w_\\-0-9 ]+')\n",
        "  return [c2]\n",
        "\n",
        "#process_for_input(example)"
      ],
      "metadata": {
        "id": "PTVxz5uFJZyI"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_bytes_strs(words):\n",
        "  return [w.decode('UTF-8') for w in list(words)]"
      ],
      "metadata": {
        "id": "uFUPhtLDH5SS"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_to_color(attn): #blue pos red neg\n",
        "  rgbs = np.zeros((len(attn),3),dtype=int)\n",
        "  for i,score in enumerate(attn):\n",
        "    if score < 0:\n",
        "      rgbs[i][0]=-255*score//2\n",
        "    else:\n",
        "      rgbs[i][2]=255*score//2\n",
        "  \n",
        "  return rgbs"
      ],
      "metadata": {
        "id": "yDhvZkOFMFJ3"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coloring(text,fore=None,back=None):\n",
        "    txt=text\n",
        "    if fore != None and fore[0] != -1:\n",
        "      txt = \"\\033[38;2;{};{};{}m\".format(fore[0], fore[1], fore[2])+txt\n",
        "    if back != None and back[0] != -1:\n",
        "      txt = \"\\033[48;2;{};{};{}m\".format(back[0], back[1], back[2])+txt\n",
        "    return txt\n",
        "\n",
        "#print(coloring('Hello',back=[500,0,0]) + coloring('Hello', back=(0,0,255)))"
      ],
      "metadata": {
        "id": "X8GvqhLvOR8H"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_class(text,model,d=3):\n",
        "  codes=tf.constant([[-1.0,0.0,1.0]])\n",
        "  pred=model.predict(text)[0]\n",
        "  i=tf.argmax(pred)\n",
        "  res=codes*pred\n",
        "  def roundDown(n, d=2):\n",
        "    d = int('1' + ('0' * d))\n",
        "    return np.floor(np.array(n) * d) / d\n",
        "  pred=roundDown(pred,d)\n",
        "  score=tf.math.reduce_mean(res,-1)[0].numpy()\n",
        "  classification=roundDown(codes[0,i].numpy(),d)\n",
        "  max_confidence=pred[i]\n",
        "  return classification,max_confidence,roundDown(score,d),list(pred)"
      ],
      "metadata": {
        "id": "Uc5Sg-uKYigY"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## full pipeline"
      ],
      "metadata": {
        "id": "spUdAeqoI0Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def color_by_attn(text,toker,preper,encoder):\n",
        "  all_words_original=text.split()\n",
        "  all_words=text.lower().split()\n",
        "  processed= process_for_input(text)\n",
        "\n",
        "  words, at=get_attn_for_words(processed,tokenizer,preprocesser_model,encoder_model)\n",
        "\n",
        "  total_at_abs=np.sum(np.absolute(at))\n",
        "\n",
        "  ws=conv_bytes_strs(words)\n",
        "  conv=conv_to_color(at)\n",
        "  mapping=dict(zip(ws,conv))\n",
        "  orig_mapping=dict(zip(all_words,all_words_original))\n",
        "\n",
        "  for i,w in enumerate(all_words):\n",
        "    if w not in mapping:\n",
        "      mapping[w]=[0,0,0] #make black\n",
        "    else:\n",
        "      mapping[w]=list(mapping[w])\n",
        "\n",
        "  colored=[coloring(orig_mapping[word],fore=[255,255,255],back=mapping[word]) for word in all_words]\n",
        "  printed=' '.join(colored)\n",
        "  return printed,total_at_abs"
      ],
      "metadata": {
        "id": "hossOHKtZ1Wn"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF text extratction\n"
      ],
      "metadata": {
        "id": "TD_FQ6ioGFGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_pdf_to_string(file_path):\n",
        "\toutput_string = StringIO()\n",
        "\twith open(file_path, 'rb') as in_file:\n",
        "\t    parser = PDFParser(in_file)\n",
        "\t    doc = PDFDocument(parser)\n",
        "\t    rsrcmgr = PDFResourceManager()\n",
        "\t    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
        "\t    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "\t    for page in PDFPage.create_pages(doc):\n",
        "\t        interpreter.process_page(page)\n",
        "\n",
        "\treturn(output_string.getvalue())\n",
        " \n",
        "def sent_extract(sample):\n",
        "\tdelims=re.findall('\\. [A-Z]',sample)\n",
        "\tsents=re.split('\\. [A-Z]',sample)\n",
        "\n",
        "\tsents[0]=sents[0]+'.'\n",
        "\tfor i,s in enumerate(sents[1:]):\n",
        "\t\tsents[i+1]=delims[i][2]+s+'.'\n",
        "\tfor i,s in enumerate(sents):\n",
        "\t\tsents[i]=re.sub('\\d+https(\\w|\\:|\\/|\\.|\\?|\\=|\\-|\\&)+','',s)\n",
        "\t\n",
        "\treturn sents\n",
        "\n",
        "def pdf_text_extract(path):\n",
        "  text=convert_pdf_to_string(path)\n",
        "  text1 = text.replace('\\x0c','')\n",
        "  text2 = text1.split('.\\n\\n')\n",
        "  refine=[t.replace('\\n',' ') for t in text2]\n",
        "  r=[]\n",
        "  for t in refine:\n",
        "    r+=sent_extract(t)\n",
        "  return r"
      ],
      "metadata": {
        "id": "HkUe38wlJSov"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_content(text):\n",
        "  abs_end=0\n",
        "  ref_start=len(text)-1\n",
        "  while abs_end< len(text) and '1 INTRODUCTION' not in text[abs_end]: #start at the intro\n",
        "    abs_end+=1\n",
        "  end_first=abs_end\n",
        "  while  end_first< len(text) and 'âˆ—' not in text[end_first]: #start at the intro\n",
        "    end_first+=1\n",
        "  copy_mark=end_first\n",
        "  while  copy_mark< len(text) and 'Â©' not in text[copy_mark]: #start at the intro\n",
        "    copy_mark+=1\n",
        "  while  ref_start> 0 and 'REFERENCES' not in text[ref_start]: \n",
        "    ref_start-=1\n",
        "  \n",
        "  if abs_end == len(text): #fail and return\n",
        "    return text\n",
        "  return text[abs_end:end_first]+text[copy_mark+1:ref_start]"
      ],
      "metadata": {
        "id": "O9lsV2ij-2vn"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coloring of a PDF"
      ],
      "metadata": {
        "id": "_Td1mswaCOFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/Text-ML/phocus.pdf'\n",
        "text=pdf_text_extract(path)"
      ],
      "metadata": {
        "id": "h_EqFHH0E359"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content=get_content(text)"
      ],
      "metadata": {
        "id": "D3RjXhrfE9Ex"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_text(content,p=True,print_err=False):\n",
        "  errs=[]\n",
        "  dfs=[]\n",
        "  sect='ABSTRACT'\n",
        "  cols=['sentence','section','class','confidence','net score','net attention','neg','neu','pos','text','colored']\n",
        "  i=0\n",
        "  for t in content:\n",
        "    try:\n",
        "      if ', ,' in t or len(t) < 20:\n",
        "        continue\n",
        "      match =re.match('^\\d+ [A-Z]+ ?(\\w+)? [A-Z]',t)\n",
        "      sp=1\n",
        "      if match != None:\n",
        "        sp=match.span()[1]-2\n",
        "        if p:\n",
        "          print(t[:sp])\n",
        "        sect=re.split('\\d+ ',t[:sp])[1]\n",
        "        t=t[sp:]\n",
        "\n",
        "      c,conf,sc,raw=text_class([t],classifier_model)\n",
        "      colored,abs_at=color_by_attn(t,tokenizer,preprocesser_model,encoder_model)\n",
        "      df_t = pd.DataFrame([[i,sect,c,conf,sc,abs_at,raw[0],raw[1],raw[2],t,colored]],columns=cols)\n",
        "      if p:\n",
        "        print(i,c,conf,colored)\n",
        "      dfs.append(df_t)\n",
        "      i+=1\n",
        "        \n",
        "    except Exception:\n",
        "      if print_err:\n",
        "        print('err:', t)\n",
        "  \n",
        "  return pd.concat(dfs)"
      ],
      "metadata": {
        "id": "AcFhtVjoCRTh"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_phocus=label_text(content)"
      ],
      "metadata": {
        "id": "HCuOwjdTFXMc"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_phocus"
      ],
      "metadata": {
        "id": "tovj8h9QN3Ft"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full paper labeling pipeline"
      ],
      "metadata": {
        "id": "TUncqdGaHkrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label(path,p=True,print_err=False):\n",
        "  text=pdf_text_extract(path)\n",
        "  content=get_content(text)\n",
        "  return text,content,label_text(content,p,print_err)"
      ],
      "metadata": {
        "id": "6u0N5kqAHqs3"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Click the run button to upload the pdf you want to scan.\n",
        "from google.colab import files\n",
        "! cd \"/content\"\n",
        "uploaded = files.upload()\n",
        "\n",
        "pdf = \"/content/\" + list(uploaded.keys())[0]"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "96qyZyoLCMfb",
        "outputId": "4d3d30a4-6abc-4b87-9005-5a96c7c9991d"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bef1895a-722c-49bf-8f67-8e69673df62b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bef1895a-722c-49bf-8f67-8e69673df62b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bhi-ar-2016.pdf to bhi-ar-2016 (1).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c=label(pdf,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "w7vcuukHRaPp",
        "outputId": "03e94b37-8586-45a9-ad22-fd9def54a93f"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-2b59822dcd96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-138-6746a28fd4da>\u001b[0m in \u001b[0;36mlabel\u001b[0;34m(path, p, print_err)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_err\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpdf_text_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-137-47f4488eb27b>\u001b[0m in \u001b[0;36mget_content\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mabs_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mref_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0;34m'1 INTRODUCTION'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabs_end\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mabs_end\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#start at the intro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mabs_end\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mend_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabs_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_phocus.sort_values(by=['net score'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mPGTjJnCnr1k",
        "outputId": "35a1e5dc-1493-4f9f-84d1-c148b0ae6cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sentence       section  class  confidence  net score  net attention  \\\n",
              "0         31  RELATED WORK   -1.0       0.924     -0.305      19.884472   \n",
              "0        123   EXPERIMENTS   -1.0       0.917     -0.297      16.340233   \n",
              "0         10  INTRODUCTION   -1.0       0.764     -0.226      12.599020   \n",
              "0        141   EXPERIMENTS   -1.0       0.597     -0.192      10.496807   \n",
              "0         77  RELATED WORK   -1.0       0.597     -0.192      10.496807   \n",
              "..       ...           ...    ...         ...        ...            ...   \n",
              "0          0  INTRODUCTION    1.0       0.909      0.296       8.146835   \n",
              "0        115   METHODOLOGY    1.0       0.907      0.299       7.527385   \n",
              "0        125   EXPERIMENTS    1.0       0.915      0.303      16.606018   \n",
              "0        142   EXPERIMENTS    1.0       0.934      0.303       6.461682   \n",
              "0         79  RELATED WORK    1.0       0.960      0.311      10.534895   \n",
              "\n",
              "      neg    neu    pos                                               text  \\\n",
              "0   0.924  0.066  0.009  However, this method generates the overall sen...   \n",
              "0   0.917  0.055  0.027  However, we cannot complete this job yet out o...   \n",
              "0   0.764  0.145  0.089  Quantitative metrics could not evaluate the re...   \n",
              "0   0.597  0.378  0.023  Those metrics are derived from citations and d...   \n",
              "0   0.597  0.378  0.023  Those metrics are derived from citations and d...   \n",
              "..    ...    ...    ...                                                ...   \n",
              "0   0.020  0.070  0.909   The number of papers published each year has ...   \n",
              "0   0.009  0.082  0.907                The main idea is shown in Figure 3.   \n",
              "0   0.004  0.079  0.915  Besides, we also compare our modules to other ...   \n",
              "0   0.023  0.041  0.934  Semantic Scholar makes the first step towards ...   \n",
              "0   0.025  0.013  0.960  Espe- cially, Semantic Scholar makes the first...   \n",
              "\n",
              "                                              colored  \n",
              "0   \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHowever, \u001b[48;...  \n",
              "0   \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHowever, \u001b[48;...  \n",
              "0   \u001b[48;2;0;0;89m\u001b[38;2;255;255;255mQuantitative ...  \n",
              "0   \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mThose \u001b[48;2;4...  \n",
              "0   \u001b[48;2;0;0;5m\u001b[38;2;255;255;255mThose \u001b[48;2;4...  \n",
              "..                                                ...  \n",
              "0   \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;8;...  \n",
              "0   \u001b[48;2;0;0;85m\u001b[38;2;255;255;255mThe \u001b[48;2;11...  \n",
              "0   \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBesides, \u001b[48;...  \n",
              "0   \u001b[48;2;72;0;0m\u001b[38;2;255;255;255mSemantic \u001b[48...  \n",
              "0   \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mEspe- \u001b[48;2;0...  \n",
              "\n",
              "[176 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b335de30-6f3a-427b-81e7-5aefc25c4209\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>section</th>\n",
              "      <th>class</th>\n",
              "      <th>confidence</th>\n",
              "      <th>net score</th>\n",
              "      <th>net attention</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>text</th>\n",
              "      <th>colored</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31</td>\n",
              "      <td>RELATED WORK</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.924</td>\n",
              "      <td>-0.305</td>\n",
              "      <td>19.884472</td>\n",
              "      <td>0.924</td>\n",
              "      <td>0.066</td>\n",
              "      <td>0.009</td>\n",
              "      <td>However, this method generates the overall sen...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHowever, \u001b[48;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123</td>\n",
              "      <td>EXPERIMENTS</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.917</td>\n",
              "      <td>-0.297</td>\n",
              "      <td>16.340233</td>\n",
              "      <td>0.917</td>\n",
              "      <td>0.055</td>\n",
              "      <td>0.027</td>\n",
              "      <td>However, we cannot complete this job yet out o...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mHowever, \u001b[48;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>INTRODUCTION</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.764</td>\n",
              "      <td>-0.226</td>\n",
              "      <td>12.599020</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.145</td>\n",
              "      <td>0.089</td>\n",
              "      <td>Quantitative metrics could not evaluate the re...</td>\n",
              "      <td>\u001b[48;2;0;0;89m\u001b[38;2;255;255;255mQuantitative ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>141</td>\n",
              "      <td>EXPERIMENTS</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.597</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>10.496807</td>\n",
              "      <td>0.597</td>\n",
              "      <td>0.378</td>\n",
              "      <td>0.023</td>\n",
              "      <td>Those metrics are derived from citations and d...</td>\n",
              "      <td>\u001b[48;2;0;0;5m\u001b[38;2;255;255;255mThose \u001b[48;2;4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>77</td>\n",
              "      <td>RELATED WORK</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.597</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>10.496807</td>\n",
              "      <td>0.597</td>\n",
              "      <td>0.378</td>\n",
              "      <td>0.023</td>\n",
              "      <td>Those metrics are derived from citations and d...</td>\n",
              "      <td>\u001b[48;2;0;0;5m\u001b[38;2;255;255;255mThose \u001b[48;2;4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>INTRODUCTION</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.909</td>\n",
              "      <td>0.296</td>\n",
              "      <td>8.146835</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.909</td>\n",
              "      <td>The number of papers published each year has ...</td>\n",
              "      <td>\u001b[48;2;72;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;8;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>115</td>\n",
              "      <td>METHODOLOGY</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.907</td>\n",
              "      <td>0.299</td>\n",
              "      <td>7.527385</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0.907</td>\n",
              "      <td>The main idea is shown in Figure 3.</td>\n",
              "      <td>\u001b[48;2;0;0;85m\u001b[38;2;255;255;255mThe \u001b[48;2;11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>125</td>\n",
              "      <td>EXPERIMENTS</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.915</td>\n",
              "      <td>0.303</td>\n",
              "      <td>16.606018</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.915</td>\n",
              "      <td>Besides, we also compare our modules to other ...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mBesides, \u001b[48;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>142</td>\n",
              "      <td>EXPERIMENTS</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.934</td>\n",
              "      <td>0.303</td>\n",
              "      <td>6.461682</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.934</td>\n",
              "      <td>Semantic Scholar makes the first step towards ...</td>\n",
              "      <td>\u001b[48;2;72;0;0m\u001b[38;2;255;255;255mSemantic \u001b[48...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79</td>\n",
              "      <td>RELATED WORK</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.960</td>\n",
              "      <td>0.311</td>\n",
              "      <td>10.534895</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.960</td>\n",
              "      <td>Espe- cially, Semantic Scholar makes the first...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mEspe- \u001b[48;2;0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>176 rows Ã— 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b335de30-6f3a-427b-81e7-5aefc25c4209')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b335de30-6f3a-427b-81e7-5aefc25c4209 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b335de30-6f3a-427b-81e7-5aefc25c4209');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 481
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_phocus.sort_values(by=['net attention'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_oWvI8tdC3RL",
        "outputId": "61a79857-3dae-4647-c44b-3762c6525f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sentence       section  class  confidence  net score  net attention  \\\n",
              "0        129   EXPERIMENTS   -1.0       0.437     -0.011       3.302047   \n",
              "0        119   METHODOLOGY    1.0       0.733      0.237       4.644296   \n",
              "0         74  RELATED WORK    0.0       0.599      0.055       4.656850   \n",
              "0        172    CONCLUSION    1.0       0.829      0.248       4.685307   \n",
              "0          5  INTRODUCTION   -1.0       0.631     -0.153       4.988726   \n",
              "..       ...           ...    ...         ...        ...            ...   \n",
              "0        117   METHODOLOGY    0.0       0.533      0.154      46.593880   \n",
              "0        116   METHODOLOGY    0.0       0.940      0.019      58.259689   \n",
              "0        144   EXPERIMENTS    0.0       0.940      0.012      60.146317   \n",
              "0         81  RELATED WORK    0.0       0.935      0.015      62.142685   \n",
              "0         23  RELATED WORK    1.0       0.565      0.180      83.631065   \n",
              "\n",
              "      neg    neu    pos                                               text  \\\n",
              "0   0.437  0.158  0.404                              As we emphasize, Pat.   \n",
              "0   0.020  0.246  0.733                   The first one is margin effects.   \n",
              "0   0.116  0.599  0.283                              higher or equal to â„Ž.   \n",
              "0   0.083  0.086  0.829                    Phocus still need improvements.   \n",
              "0   0.631  0.193  0.174            They state this opinion in two aspects.   \n",
              "..    ...    ...    ...                                                ...   \n",
              "0   0.001  0.533  0.464  Then, the academic influential factor of ð´ is:...   \n",
              "0   0.000  0.940  0.058  ð´ denote a citing paper with academic influent...   \n",
              "0   0.010  0.940  0.048  The features Seman- tic Scholar use are total ...   \n",
              "0   0.009  0.935  0.054  The features Semantic Scholar use are the tota...   \n",
              "0   0.023  0.411  0.565  Valenzuela et al. [35] divide citations into 4...   \n",
              "\n",
              "                                              colored  \n",
              "0   \u001b[48;2;123;0;0m\u001b[38;2;255;255;255mAs \u001b[48;2;0;...  \n",
              "0   \u001b[48;2;83;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;21...  \n",
              "0   \u001b[48;2;199;0;0m\u001b[38;2;255;255;255mhigher \u001b[48;...  \n",
              "0   \u001b[48;2;0;0;182m\u001b[38;2;255;255;255mPhocus \u001b[48;...  \n",
              "0   \u001b[48;2;0;0;39m\u001b[38;2;255;255;255mThey \u001b[48;2;2...  \n",
              "..                                                ...  \n",
              "0   \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mThen, \u001b[48;2;6...  \n",
              "0   \u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´ \u001b[48;2;24;0;...  \n",
              "0   \u001b[48;2;3;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0...  \n",
              "0   \u001b[48;2;0;0;34m\u001b[38;2;255;255;255mthe \u001b[48;2;0;...  \n",
              "0   \u001b[48;2;222;0;0m\u001b[38;2;255;255;255mValenzuela \u001b...  \n",
              "\n",
              "[176 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2ff077e-be95-4b65-9452-f8e62b66ca67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>section</th>\n",
              "      <th>class</th>\n",
              "      <th>confidence</th>\n",
              "      <th>net score</th>\n",
              "      <th>net attention</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>text</th>\n",
              "      <th>colored</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>129</td>\n",
              "      <td>EXPERIMENTS</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.437</td>\n",
              "      <td>-0.011</td>\n",
              "      <td>3.302047</td>\n",
              "      <td>0.437</td>\n",
              "      <td>0.158</td>\n",
              "      <td>0.404</td>\n",
              "      <td>As we emphasize, Pat.</td>\n",
              "      <td>\u001b[48;2;123;0;0m\u001b[38;2;255;255;255mAs \u001b[48;2;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119</td>\n",
              "      <td>METHODOLOGY</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.733</td>\n",
              "      <td>0.237</td>\n",
              "      <td>4.644296</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.246</td>\n",
              "      <td>0.733</td>\n",
              "      <td>The first one is margin effects.</td>\n",
              "      <td>\u001b[48;2;83;0;0m\u001b[38;2;255;255;255mThe \u001b[48;2;21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>74</td>\n",
              "      <td>RELATED WORK</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.599</td>\n",
              "      <td>0.055</td>\n",
              "      <td>4.656850</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.599</td>\n",
              "      <td>0.283</td>\n",
              "      <td>higher or equal to â„Ž.</td>\n",
              "      <td>\u001b[48;2;199;0;0m\u001b[38;2;255;255;255mhigher \u001b[48;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>172</td>\n",
              "      <td>CONCLUSION</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.248</td>\n",
              "      <td>4.685307</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.086</td>\n",
              "      <td>0.829</td>\n",
              "      <td>Phocus still need improvements.</td>\n",
              "      <td>\u001b[48;2;0;0;182m\u001b[38;2;255;255;255mPhocus \u001b[48;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>INTRODUCTION</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.631</td>\n",
              "      <td>-0.153</td>\n",
              "      <td>4.988726</td>\n",
              "      <td>0.631</td>\n",
              "      <td>0.193</td>\n",
              "      <td>0.174</td>\n",
              "      <td>They state this opinion in two aspects.</td>\n",
              "      <td>\u001b[48;2;0;0;39m\u001b[38;2;255;255;255mThey \u001b[48;2;2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>117</td>\n",
              "      <td>METHODOLOGY</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.533</td>\n",
              "      <td>0.154</td>\n",
              "      <td>46.593880</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.533</td>\n",
              "      <td>0.464</td>\n",
              "      <td>Then, the academic influential factor of ð´ is:...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mThen, \u001b[48;2;6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>116</td>\n",
              "      <td>METHODOLOGY</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.019</td>\n",
              "      <td>58.259689</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.058</td>\n",
              "      <td>ð´ denote a citing paper with academic influent...</td>\n",
              "      <td>\u001b[48;2;0;0;0m\u001b[38;2;255;255;255mð´ \u001b[48;2;24;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>144</td>\n",
              "      <td>EXPERIMENTS</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.012</td>\n",
              "      <td>60.146317</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.048</td>\n",
              "      <td>The features Seman- tic Scholar use are total ...</td>\n",
              "      <td>\u001b[48;2;3;0;0m\u001b[38;2;255;255;255mthe \u001b[48;2;0;0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>81</td>\n",
              "      <td>RELATED WORK</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.935</td>\n",
              "      <td>0.015</td>\n",
              "      <td>62.142685</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.935</td>\n",
              "      <td>0.054</td>\n",
              "      <td>The features Semantic Scholar use are the tota...</td>\n",
              "      <td>\u001b[48;2;0;0;34m\u001b[38;2;255;255;255mthe \u001b[48;2;0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>RELATED WORK</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.565</td>\n",
              "      <td>0.180</td>\n",
              "      <td>83.631065</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.411</td>\n",
              "      <td>0.565</td>\n",
              "      <td>Valenzuela et al. [35] divide citations into 4...</td>\n",
              "      <td>\u001b[48;2;222;0;0m\u001b[38;2;255;255;255mValenzuela \u001b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>176 rows Ã— 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2ff077e-be95-4b65-9452-f8e62b66ca67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2ff077e-be95-4b65-9452-f8e62b66ca67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2ff077e-be95-4b65-9452-f8e62b66ca67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 482
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_paper_sentiment=np.mean(df_phocus['net attention'])\n",
        "overall_paper_sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEoqE8jJDklZ",
        "outputId": "7e692fb4-d04f-43fb-8312-507b3c0bd39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.59335708618164"
            ]
          },
          "metadata": {},
          "execution_count": 483
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_paper_sentiment=np.mean(df_phocus['net score'])\n",
        "overall_paper_sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e786wcE1nYsZ",
        "outputId": "c566043b-c8d1-4dbd-9817-1e1c1c36d1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08068181818181822"
            ]
          },
          "metadata": {},
          "execution_count": 484
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "input.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}