{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h7Lr7k5d1jd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ENEE439d-TEXTML/TextML/blob/master/input.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/ENEE439d-TEXTML/TextML/blob/master/input.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPiicLOUd1jj"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U \"tensorflow-text==2.8.*\" # A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q tf-models-official==2.7.0 # For adamW\n",
        "!pip install focal-loss # focal loss implmnetion for tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52FpqTzrPr-t",
        "outputId": "759c72fc-f90b-44c0-e5b1-a2ed9e3747a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 6.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 60.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 11.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 41.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 54.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 57.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 60.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting focal-loss\n",
            "  Downloading focal_loss-0.0.7-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal-loss) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.25.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (14.0.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.5.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.44.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (4.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.14.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.3.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal-loss) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2->focal-loss) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.3.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.2.0)\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BPnv0Vlcd3KI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #basic imports\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split # https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization, bert  # to create AdamW optimizer\n",
        "from focal_loss import SparseCategoricalFocalLoss\n",
        "import official.nlp.bert.tokenization"
      ],
      "metadata": {
        "id": "dkxbtcKbP4AU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data read in"
      ],
      "metadata": {
        "id": "Q-Dc1EsOuQA0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "465BADPxeNII",
        "outputId": "241f8a72-5d37-4cb6-8ef6-994a7d755b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Sk1zTIA6eOM5",
        "outputId": "8479483c-0152-494c-cad0-bd84aa5ee2db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  cited_paper  label                                               text\n",
              "0    A00-2024      0  We analyzed a set of articles and identified s...\n",
              "1    A00-2024      0  Table 3: Example compressions Compression AvgL...\n",
              "2    A00-2024      0  5.3 Related works and discussion Our two-step ...\n",
              "3    A00-2024      0  (1999) proposed a summarization system based o...\n",
              "4    A00-2024      0  We found that the deletion of lead parts did n..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98eb8afe-54aa-4dde-a4ab-9103b2ed15ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98eb8afe-54aa-4dde-a4ab-9103b2ed15ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98eb8afe-54aa-4dde-a4ab-9103b2ed15ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98eb8afe-54aa-4dde-a4ab-9103b2ed15ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "filepath = '/content/drive/MyDrive/Text-ML/full_sentiment_dataset.csv' #'data.csv'\n",
        "df= pd.read_csv(filepath)\n",
        "df1=df.drop(['no','paper','context_a','context_b'],axis=1)\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImSOYF6Py2J8",
        "outputId": "7a7f4241-e95c-418e-e8d5-2fd9adcf8baf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    7627\n",
              " 1     829\n",
              "-1     280\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filtering by regex"
      ],
      "metadata": {
        "id": "FHIvNaLfuUoe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytc03_FI-b5L",
        "outputId": "8ed4b90b-ee65-4730-ae65-5b1f9e7ef222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\[*\\]|\\(\\d{4}\\)|\\(?((\\(?((\\w+, )*(\\w+ )+)((and|&) ((\\w+ *))?)?,? \\(?\\d{4}\\)?|((\\w+, )*(\\w+ )+)et al\\. ?,? \\(?\\d{4}\\)?\\)?)((; )|( (and|&) ))*)+\n"
          ]
        }
      ],
      "source": [
        "context=df1['text']\n",
        "\n",
        "re1= \"\\(((([A-Za-z]+ *)+(, \\d+))+(; )*)+\\)\" # matches author and author, year\n",
        "re_year=\",? \\(?\\d{4}\\)?\" # match , {4 digits} which may be wrapped in () \n",
        "re_and=\"(and|&) \"\n",
        "re_auth=\"((\\w+, )*(\\w+ )+)\"\n",
        "re_et= re_auth+\"et al\\. ?\"+re_year # matches author et al. , year\n",
        "re_2a= re_auth+\"(\"+re_and+\"((\\w+ *))?)?\"+re_year # matches author and author, year\n",
        "re_sep=\"((; )|( \"+re_and+\"))*\"# match the '; ' gap or ' and ' gap\n",
        "re_para_year=\"\\(\\d{4}\\)\"\n",
        "re_in_brack=\"\\[*\\]\"\n",
        "re_apa =re_in_brack+\"|\"+re_para_year+\"|\"+\"\\(?(\"+\"(\\(?\"+re_2a+\"|\"+re_et+\"\\)?)\"+re_sep+\")+\"\n",
        "print(re_apa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NEZIAWQtykDg"
      },
      "outputs": [],
      "source": [
        "def remove_matches(text,regex=re_apa):\n",
        "  text1=text\n",
        "  rem_len=0\n",
        "  pattern= re.compile(regex)\n",
        "  while True:\n",
        "    matches=pattern.search(text1)\n",
        "    #print(matches)\n",
        "    if matches == None:\n",
        "      break\n",
        "\n",
        "    spn=matches.span()\n",
        "    text1=text1[0:spn[0]]+text1[spn[1]:-1]\n",
        "    cit_len=spn[1]-spn[0]\n",
        "    rem_len+=cit_len\n",
        "  \n",
        "  if len(text) >0:\n",
        "    percent_removed=rem_len/len(text)\n",
        "  else:\n",
        "    percent_removed=1\n",
        "  return text1,percent_removed \n",
        "\n",
        "# print(context[5])\n",
        "# remove_citation(context[5],regex=re_apa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TmjjH1gp9A6T"
      },
      "outputs": [],
      "source": [
        "output=df1['text'].apply(lambda x: remove_matches(text=x,regex=re_apa)) #df['col1'] = df.apply(lambda x: complex_function(x['col1']), axis=1)\n",
        "df_o = pd.DataFrame(list(output), columns =['clean','p_rem'])\n",
        "output_1=df_o['clean'].apply(lambda x: remove_matches(text=x,regex='[^\\w_0-9 ]+')) \n",
        "df_o_1 = pd.DataFrame(list(output_1), columns =['clean','p_rem'])\n",
        "#df_o.head()\n",
        "\n",
        "df1['text_clean']=df_o_1['clean']\n",
        "df1['text_clean_len']=df_o_1['clean'].apply(len)\n",
        "df1['p_rem']=df_o['p_rem']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OVt3NtaJDDrx",
        "outputId": "ae82e824-9a1f-43e5-d989-977d7dfcdbe8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cited_paper  label                                               text  \\\n",
              "0       A00-2024      0  We analyzed a set of articles and identified s...   \n",
              "1       A00-2024      0  Table 3: Example compressions Compression AvgL...   \n",
              "2       A00-2024      0  5.3 Related works and discussion Our two-step ...   \n",
              "3       A00-2024      0  (1999) proposed a summarization system based o...   \n",
              "4       A00-2024      0  We found that the deletion of lead parts did n...   \n",
              "...          ...    ...                                                ...   \n",
              "8731    W96-0213      1  He has achieved state-of-the art results by ap...   \n",
              "8732    W96-0213      0  B = (Brill and Wu, 1998); M = (Magerman, 1995)...   \n",
              "8733    W96-0213      0  The model we use is similar to that of (Ratnap...   \n",
              "8734    W96-0213      1  Our model exploits the same kind of tag-n-gram...   \n",
              "8735    W96-0213      0  In that table, TBL stands for Brill's transfor...   \n",
              "\n",
              "                                             text_clean  text_clean_len  \\\n",
              "0     We analyzed a set of articles and identified s...             425   \n",
              "1     Table 3 Example compressions Compression AvgLe...             229   \n",
              "2     53 Related works and discussion Our twostep mo...             105   \n",
              "3      proposed a summarization system based on the ...             321   \n",
              "4     We found that the deletion of lead parts did n...              73   \n",
              "...                                                 ...             ...   \n",
              "8731  He has achieved stateofthe art results by appl...             139   \n",
              "8732   B  M  Magerman 1995 O  our data R  Ratnaparkhi 1              48   \n",
              "8733  The model we use is similar to that of Ratnapa...              55   \n",
              "8734  Our model exploits the same kind of tagngram i...             157   \n",
              "8735  In that table TBL stands for Brills transforma...             288   \n",
              "\n",
              "         p_rem  \n",
              "0     0.098765  \n",
              "1     0.260745  \n",
              "2     0.308176  \n",
              "3     0.078804  \n",
              "4     0.408000  \n",
              "...        ...  \n",
              "8731  0.151515  \n",
              "8732  0.421488  \n",
              "8733  0.000000  \n",
              "8734  0.000000  \n",
              "8735  0.000000  \n",
              "\n",
              "[8736 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55423898-3b57-4f9c-a3e0-488d3753e7f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cited_paper</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_clean_len</th>\n",
              "      <th>p_rem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "      <td>We analyzed a set of articles and identified s...</td>\n",
              "      <td>425</td>\n",
              "      <td>0.098765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
              "      <td>Table 3 Example compressions Compression AvgLe...</td>\n",
              "      <td>229</td>\n",
              "      <td>0.260745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
              "      <td>53 Related works and discussion Our twostep mo...</td>\n",
              "      <td>105</td>\n",
              "      <td>0.308176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>(1999) proposed a summarization system based o...</td>\n",
              "      <td>proposed a summarization system based on the ...</td>\n",
              "      <td>321</td>\n",
              "      <td>0.078804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A00-2024</td>\n",
              "      <td>0</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "      <td>We found that the deletion of lead parts did n...</td>\n",
              "      <td>73</td>\n",
              "      <td>0.408000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>1</td>\n",
              "      <td>He has achieved state-of-the art results by ap...</td>\n",
              "      <td>He has achieved stateofthe art results by appl...</td>\n",
              "      <td>139</td>\n",
              "      <td>0.151515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8732</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>B = (Brill and Wu, 1998); M = (Magerman, 1995)...</td>\n",
              "      <td>B  M  Magerman 1995 O  our data R  Ratnaparkhi 1</td>\n",
              "      <td>48</td>\n",
              "      <td>0.421488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8733</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>The model we use is similar to that of (Ratnap...</td>\n",
              "      <td>The model we use is similar to that of Ratnapa...</td>\n",
              "      <td>55</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8734</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>1</td>\n",
              "      <td>Our model exploits the same kind of tag-n-gram...</td>\n",
              "      <td>Our model exploits the same kind of tagngram i...</td>\n",
              "      <td>157</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8735</th>\n",
              "      <td>W96-0213</td>\n",
              "      <td>0</td>\n",
              "      <td>In that table, TBL stands for Brill's transfor...</td>\n",
              "      <td>In that table TBL stands for Brills transforma...</td>\n",
              "      <td>288</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8736 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55423898-3b57-4f9c-a3e0-488d3753e7f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55423898-3b57-4f9c-a3e0-488d3753e7f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55423898-3b57-4f9c-a3e0-488d3753e7f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove under and over sized samples\n",
        "large samples appear to be poorly written"
      ],
      "metadata": {
        "id": "pkNPWqAHKLxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getMidLen(data,label,labelKey='label',lenKey='text_clean_len',lowMod=1,highMod=1):\n",
        "  df1 =data.loc[data[labelKey] == label]\n",
        "  neu_mean=np.mean(list(df1[lenKey]))\n",
        "  neu_std=np.std(list(df1[lenKey]))\n",
        "  df1_no_high = df1.loc[df1[lenKey] < highMod*(neu_mean +neu_std)]\n",
        "  # print(neu_mean)\n",
        "  # print(neu_std)\n",
        "\n",
        "  while neu_std > neu_mean:\n",
        "    neu_mean=np.mean(list(df1_no_high['text_clean_len']))\n",
        "    neu_std=np.std(list(df1_no_high['text_clean_len']))\n",
        "    # print(neu_mean)\n",
        "    # print(neu_std)\n",
        "    df1_no_high = df1.loc[df1['text_clean_len'] < highMod*(neu_mean +neu_std)]\n",
        "\n",
        "  df1_mid = df1_no_high.loc[df1_no_high['text_clean_len'] > lowMod*(neu_mean -neu_std)]\n",
        "\n",
        "  return df1_mid\n",
        "\n",
        "df2 = df1.loc[df1['p_rem'] < .5] #keep sampels with less than half of it are citation\n",
        "\n",
        "df_neu=getMidLen(df2,0,lowMod=2)\n",
        "df_pos=getMidLen(df2,1,lowMod=1,highMod=2)\n",
        "df_neg=getMidLen(df2,-1,lowMod=1,highMod=2)\n",
        "df3= pd.concat([df_neg,df_neu,df_pos])\n",
        "df3['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq-BsMfleXID",
        "outputId": "e3b8cf5d-1767-4daf-ebe4-74436b4ddc86"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    2524\n",
              " 1     746\n",
              "-1     246\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def catagorize(data,labelKey='label'):\n",
        "  rows=len(data.index)\n",
        "  onehots=np.zeros((rows,3),dtype=int)\n",
        "  for i,lab in enumerate(data[labelKey]):\n",
        "    onehots[i][lab+1]=1\n",
        "  return onehots\n",
        "\n",
        "hots=catagorize(df3)\n",
        "df3['label_onehot']=list(hots)\n",
        "df3['label_index']=df3['label']+1"
      ],
      "metadata": {
        "id": "VnsKnaB0AU4i"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq= np.array(list(df3['label_index'].value_counts(normalize=True,sort=False)))\n",
        "print(freq)\n",
        "class_ratio= 1/freq\n",
        "class_ratio"
      ],
      "metadata": {
        "id": "Mbn2dX1C2Ixs",
        "outputId": "d003d74b-e34d-47f0-b69f-e514aa08b4b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06996587 0.71786121 0.21217292]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14.29268293,  1.39302694,  4.71313673])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Model"
      ],
      "metadata": {
        "id": "QtrXZF4_unOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(list(df3['text_clean']), list(df3['label_index']), test_size=0.2, random_state=42)\n",
        "X_train= [[s] for s in X_train]\n",
        "X_test= [[s] for s in X_test]\n",
        "y_train=[[s] for s in list(y_train)]\n",
        "y_test=[[s] for s in list(y_test)]"
      ],
      "metadata": {
        "id": "kKtJq5Baj1Wl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose a BERT model to fine-tune (Taken from tutorial)\n",
        "\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "metadata": {
        "id": "9WK-J5dQpprm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9835c3c-9b3b-4a8f-fb88-3d1fb7885afd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check model passes"
      ],
      "metadata": {
        "id": "91uobQaIu-iE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "metadata": {
        "id": "YINTv-Uu8HP5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = X_train[1]\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGAgJwGg08-j",
        "outputId": "6c2fcacc-f59c-4f44-e068-6434f4b4c836"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_word_ids', 'input_type_ids', 'input_mask']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [  101  1999  5688 11416  6024  4275  2024  4738  2000 25845  1996  4101]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "metadata": {
        "id": "U2o1JW9b9MHu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW0iEt6Z9PKt",
        "outputId": "ceaa502a-7bd0-4264-a275-bf55bfdfa3c4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.99835694 -0.7678578  -0.21300124  0.08411987 -0.08593949  0.98550844\n",
            "  0.9732349  -0.8306031  -0.55687106 -0.95725054 -0.3960305  -0.94115573]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[ 3.8915187e-01  2.3267061e-01  6.1780311e-02 ... -9.2866874e-01\n",
            "   4.3027106e-01  8.3279318e-01]\n",
            " [ 4.5310837e-01  7.2308904e-01 -3.2866317e-01 ... -1.1163950e-04\n",
            "  -3.3482751e-01  5.7274055e-01]\n",
            " [-2.5876865e-01  1.4199525e+00 -4.2525381e-01 ...  4.9038833e-01\n",
            "   1.4491324e-01  5.7048750e-01]\n",
            " ...\n",
            " [ 2.6529512e-01 -2.3668993e-01  8.4921330e-02 ...  2.0211086e-02\n",
            "   3.9103544e-01  8.9449620e-01]\n",
            " [ 2.9499257e-01  5.8424294e-01 -6.7344594e-01 ... -1.6148384e+00\n",
            "   1.3211843e+00 -6.0517174e-01]\n",
            " [-1.8697177e-01  5.2527428e-01  9.2377967e-01 ... -5.6088662e-01\n",
            "   1.0293359e+00 -7.8856331e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## full model setup"
      ],
      "metadata": {
        "id": "GSyS6XhXvGXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(3, activation='softmax', name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "XWtmKUBu_3kJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = build_classifier_model()"
      ],
      "metadata": {
        "id": "Z17Cu4Awc3jA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check loss function"
      ],
      "metadata": {
        "id": "KgOUUHifvD3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(bert_raw_result)\n",
        "\n",
        "l =  SparseCategoricalFocalLoss(gamma=2,class_weight=class_ratio)\n",
        "test =tf.convert_to_tensor([1.0])\n",
        "l(test,bert_raw_result)"
      ],
      "metadata": {
        "id": "jHqpunBDTKym",
        "outputId": "9f0026ad-6a60-4800-dd67-b21d797f400e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.07656216 0.749452   0.1739859 ]], shape=(1, 3), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.02522065>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Save and Log"
      ],
      "metadata": {
        "id": "hTEGlj9RvLg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "steps_per_epoch = 200 #tf.data.experimental.cardinality(X_train).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 2e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n",
        "\n",
        "# def auc_wrapper(y_true,y_pred):\n",
        "#   print(y_true,y_pred)\n",
        "\n",
        "#   y_true=tf.reshape(y_true,[1])\n",
        "#   print(y_true)\n",
        "#   y_true= tf.cast(y_true, tf.int32)\n",
        "#   print(y_true)\n",
        "#   y_true=tf.one_hot(y_true,depth=3)\n",
        "#   print(y_true)\n",
        "#   return tf.keras.metrics.AUC(multi_label=True)(y_true,y_pred)\n",
        "\n",
        "\n",
        "loss =  SparseCategoricalFocalLoss(gamma=2,class_weight=class_ratio) #tf.keras.losses.MeanSquaredError()\n",
        "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]#, auc_wrapper]#, tf.keras.metrics.AUC(multi_label=True)]\n",
        "\n",
        "\n",
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"citation_BERT_{epoch}\",\n",
        "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
        "        monitor=\"val_sparse_categorical_accuracy\",\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n",
        "]\n"
      ],
      "metadata": {
        "id": "MB9Af5RMCuqP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Training model with {tfhub_handle_encoder}')\n",
        "# history = classifier_model.fit(x=X_train,y=y_train, validation_data=(X_test,y_test),epochs=epochs,callbacks= callbacks, verbose=True)"
      ],
      "metadata": {
        "id": "89v_3XqEE3HN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier_model.save_weights(''/content/drive/MyDrive/Text-ML/checkpoint1')"
      ],
      "metadata": {
        "id": "Pox0n2xZjdtX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect model"
      ],
      "metadata": {
        "id": "Z_fseNCGvY4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "00eGEQhDdMUK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorboard --logdir=logs"
      ],
      "metadata": {
        "id": "Gszh9ZNBbQXe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.load_weights('/content/drive/MyDrive/Text-ML/checkpoint')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMRXTmWvmBNn",
        "outputId": "3f084ea8-8e1f-44fa-aa41-9a742d9ff606"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fad54818f90>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=classifier_model.predict(X_train,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCgZJCYsvdMe",
        "outputId": "b066afa4-87bb-45cb-c5a3-dcf1083aea65"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/88 [==============================] - 197s 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_t=classifier_model.predict(X_test,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu5a35I1wlOi",
        "outputId": "b96d2fba-58d8-4ed7-ecb7-f273f0fd3410"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 [==============================] - 49s 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns; sns.set_theme()"
      ],
      "metadata": {
        "id": "Q-NxIjYJx8S1"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_mat=tf.math.confusion_matrix(np.argmax(preds,-1),y_train)\n",
        "ax = sns.heatmap(c_mat,annot=True,linewidths=.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "_5R4bXyzxoql",
        "outputId": "8124b216-f286-49b3-ea83-bcb09c6a2421"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_mat=tf.math.confusion_matrix(np.argmax(preds_t,-1),y_test)\n",
        "ax = sns.heatmap(c_mat,annot=True,linewidths=.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "RPkpGRdDyCz6",
        "outputId": "f4e79de6-c346-4063-925b-b34922941b2e"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get attention colorings"
      ],
      "metadata": {
        "id": "ZRca_y_Kvq86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1\n"
      ],
      "metadata": {
        "id": "aSNvnkyoJdqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.layers"
      ],
      "metadata": {
        "id": "PR_gDYEQofck",
        "outputId": "1a3c7f44-a31a-4764-f516-0b7901863e7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7fad57ceb3d0>,\n",
              " <tensorflow_hub.keras_layer.KerasLayer at 0x7fad57ca6710>,\n",
              " <tensorflow_hub.keras_layer.KerasLayer at 0x7fad57c0ab10>,\n",
              " <keras.layers.core.dropout.Dropout at 0x7fad569ae390>,\n",
              " <keras.layers.core.dense.Dense at 0x7fad56a6e650>]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from official.nlp import bert \n",
        "import official.nlp.bert.tokenization"
      ],
      "metadata": {
        "id": "bC2uW7zrx7VR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = bert.tokenization.FullTokenizer(vocab_file='/content/drive/MyDrive/Text-ML/vocab.txt')\n",
        "preprocesser_model = keras.Model(inputs=classifier_model.input,outputs=classifier_model.get_layer('preprocessing').output)\n",
        "encoder_model = keras.Model(inputs=classifier_model.input,outputs=classifier_model.get_layer('BERT_encoder').output)"
      ],
      "metadata": {
        "id": "Lnb_ie7zxpbc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocab size:\", len(tokenizer.vocab))"
      ],
      "metadata": {
        "id": "mjgJ0WAwRjYb",
        "outputId": "360e6c09-196d-43b7-a821-3999f910cb98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 30522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attnetion token mapping"
      ],
      "metadata": {
        "id": "z7DPKDmPI9yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attn(context,prep,encoder): # assume stirng array input\n",
        "  t_context=tf.convert_to_tensor(context)\n",
        "\n",
        "  p_out=prep(t_context)\n",
        "  stop_index=0\n",
        "  while(p_out[\"input_mask\"][0][stop_index] == 1):\n",
        "    stop_index+=1\n",
        "\n",
        "  output = encoder(t_context)\n",
        "  valid_entries=output[\"sequence_output\"][:,1:stop_index-1,:]\n",
        "  a=tf.math.reduce_mean(valid_entries,-1)\n",
        "  mean=tf.math.reduce_mean(a,-1,keepdims=True)\n",
        "  std=tf.math.reduce_std(a,-1,keepdims=True)\n",
        "  a1=(a-mean)/std\n",
        "\n",
        "  return a1"
      ],
      "metadata": {
        "id": "NC_Cyexu9TQI"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attn_for_words(context,tokenizer,prep,encoder):\n",
        "  attn = get_attn(context,prep,encoder).numpy()\n",
        "  tokens = tokenizer.tokenize(context[0]) \n",
        "  print(tokens)\n",
        "\n",
        "  indicies=np.ones((len(tokens)),dtype=int)\n",
        "  for i,tok in enumerate(tokens):\n",
        "    if '##' in tok:\n",
        "      indicies[i]=0\n",
        "\n",
        "  full_words=tokens.copy()\n",
        "  ix=-1\n",
        "  for i,tok in enumerate(tokens):\n",
        "    if not indicies[i]:\n",
        "      attn[0][ix]+=attn[0][i]\n",
        "      full_words[ix]+=tok[2:]\n",
        "    else:\n",
        "      ix=i\n",
        "  print('got here',len(full_words),len(indicies))\n",
        "\n",
        "  t_f=tf.convert_to_tensor(full_words) #stores as byte string...\n",
        "  print(t_f)\n",
        "  print(indicies)\n",
        "  masked_f=tf.boolean_mask(t_f,indicies)\n",
        "\n",
        "  t_a=tf.convert_to_tensor(attn)[0]\n",
        "  masked_a=tf.boolean_mask(t_a,indicies)\n",
        "  print('got here',len(full_words),t_f.shape,len(indicies))\n",
        "\n",
        "  return masked_f.numpy(),masked_a.numpy()\n",
        "\n",
        "#words, at=get_attn_for_words(processed,tokenizer,preprocesser_model,encoder_model)"
      ],
      "metadata": {
        "id": "iyhKVIiY121W"
      },
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## converters and annotation"
      ],
      "metadata": {
        "id": "kj_6JUFQIvG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_for_input(raw_context):\n",
        "  c1,_ =remove_matches(text=raw_context,regex=re_apa)\n",
        "  c2,_ =remove_matches(text=c1,regex='[^\\w_\\-0-9 ]+')\n",
        "  return [c2]\n",
        "\n",
        "#process_for_input(example)"
      ],
      "metadata": {
        "id": "PTVxz5uFJZyI"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_bytes_strs(words):\n",
        "  return [w.decode('UTF-8') for w in list(words)]"
      ],
      "metadata": {
        "id": "uFUPhtLDH5SS"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_to_color(attn): #blue pos red neg\n",
        "  rgbs = np.zeros((len(attn),3),dtype=int)\n",
        "  for i,score in enumerate(attn):\n",
        "    if score > 0:\n",
        "      rgbs[i][0]=255*score//2\n",
        "    else:\n",
        "      rgbs[i][2]=-255*score//2\n",
        "  \n",
        "  return rgbs"
      ],
      "metadata": {
        "id": "yDhvZkOFMFJ3"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coloring(text,fore=None,back=None):\n",
        "    txt=text\n",
        "    if fore != None:\n",
        "      txt = \"\\033[38;2;{};{};{}m\".format(fore[0], fore[1], fore[2])+txt\n",
        "    if back != None:\n",
        "      txt = \"\\033[48;2;{};{};{}m\".format(back[0], back[1], back[2])+txt\n",
        "    return txt\n",
        "\n",
        "#print(coloring('Hello',back=[500,0,0]) + coloring('Hello', back=(0,0,255)))"
      ],
      "metadata": {
        "id": "X8GvqhLvOR8H"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## full pipeline"
      ],
      "metadata": {
        "id": "spUdAeqoI0Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def color_by_attn(text,toker,preper,encoder):\n",
        "  all_words_original=text.split()\n",
        "  all_words=text.lower().split()\n",
        "  processed= process_for_input(text)\n",
        "  print('saw:',text)\n",
        "  print('saw:',processed)\n",
        "  words, at=get_attn_for_words(processed,tokenizer,preprocesser_model,encoder_model)\n",
        "  print('attn_recived')\n",
        "  ws=conv_bytes_strs(words)\n",
        "  conv=conv_to_color(at)\n",
        "  mapping=dict(zip(ws,conv))\n",
        "  orig_mapping=dict(zip(all_words,all_words_original))\n",
        "\n",
        "  for i,w in enumerate(all_words):\n",
        "    if w not in mapping:\n",
        "      mapping[w]=[0,0,0]\n",
        "    else:\n",
        "      mapping[w]=list(mapping[w])\n",
        "\n",
        "  colored=[coloring(orig_mapping[word],back=mapping[word]) for word in all_words]\n",
        "  printed=' '.join(colored)\n",
        "  return printed\n",
        "\n",
        "example=list(df3['text'])[0]\n",
        "print(color_by_attn(example,tokenizer,preprocesser_model,encoder_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hossOHKtZ1Wn",
        "outputId": "d5033e75-4be8-4166-9fa9-8cee9576ed4f"
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saw: Many approaches for POS tagging have been developed in the past, including rule-based tagging (Brill, 1995), HMM taggers (Brants, 2000; Cutting and others, 1992), maximum-entropy models (Rathnaparki, 1996), cyclic dependency networks (Toutanova et al. , 2003), memory-based learning (Daelemans et al. , 1996), etc. All of these approaches require either a large amount of annotated training data (for supervised tagging) or a lexicon listing all possible tags for each word (for unsupervised tagging).\n",
            "saw: ['Many approaches for POS tagging have been developed in the past including rulebased tagging Brill 1995 HMM taggers Brants 2000  maximumentropy models Rathnaparki 1996 cyclic dependency networks  memorybased learning  etc All of these approaches require either a large amount of annotated training data for supervised tagging or a lexicon listing all possible tags for each word for']\n",
            "['many', 'approaches', 'for', 'po', '##s', 'tag', '##ging', 'have', 'been', 'developed', 'in', 'the', 'past', 'including', 'rule', '##base', '##d', 'tag', '##ging', 'br', '##ill', '1995', 'hmm', 'tag', '##gers', 'brant', '##s', '2000', 'maximum', '##ent', '##rop', '##y', 'models', 'rat', '##hn', '##apa', '##rk', '##i', '1996', 'cyclic', 'dependency', 'networks', 'memory', '##base', '##d', 'learning', 'etc', 'all', 'of', 'these', 'approaches', 'require', 'either', 'a', 'large', 'amount', 'of', 'ann', '##ota', '##ted', 'training', 'data', 'for', 'supervised', 'tag', '##ging', 'or', 'a', 'lexi', '##con', 'listing', 'all', 'possible', 'tags', 'for', 'each', 'word', 'for']\n",
            "got here\n",
            "attn_recived\n",
            "\u001b[48;2;0;0;14mMany \u001b[48;2;94;0;0mapproaches \u001b[48;2;30;0;0mfor \u001b[48;2;0;0;127mPOS \u001b[48;2;0;0;104mtagging \u001b[48;2;62;0;0mhave \u001b[48;2;0;0;13mbeen \u001b[48;2;0;0;201mdeveloped \u001b[48;2;46;0;0min \u001b[48;2;0;0;15mthe \u001b[48;2;0;0;0mpast, \u001b[48;2;262;0;0mincluding \u001b[48;2;0;0;0mrule-based \u001b[48;2;0;0;104mtagging \u001b[48;2;0;0;0m(Brill, \u001b[48;2;0;0;0m1995), \u001b[48;2;32;0;0mHMM \u001b[48;2;0;0;306mtaggers \u001b[48;2;0;0;0m(Brants, \u001b[48;2;0;0;0m2000; \u001b[48;2;0;0;0mCutting \u001b[48;2;0;0;0mand \u001b[48;2;0;0;0mothers, \u001b[48;2;0;0;0m1992), \u001b[48;2;0;0;0mmaximum-entropy \u001b[48;2;0;0;80mmodels \u001b[48;2;0;0;0m(Rathnaparki, \u001b[48;2;0;0;0m1996), \u001b[48;2;107;0;0mcyclic \u001b[48;2;0;0;69mdependency \u001b[48;2;38;0;0mnetworks \u001b[48;2;0;0;0m(Toutanova \u001b[48;2;0;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m, \u001b[48;2;0;0;0m2003), \u001b[48;2;0;0;0mmemory-based \u001b[48;2;73;0;0mlearning \u001b[48;2;0;0;0m(Daelemans \u001b[48;2;0;0;0met \u001b[48;2;0;0;0mal. \u001b[48;2;0;0;0m, \u001b[48;2;0;0;0m1996), \u001b[48;2;0;0;0metc. \u001b[48;2;26;0;0mall \u001b[48;2;254;0;0mof \u001b[48;2;172;0;0mthese \u001b[48;2;94;0;0mapproaches \u001b[48;2;80;0;0mrequire \u001b[48;2;0;0;212meither \u001b[48;2;211;0;0ma \u001b[48;2;0;0;209mlarge \u001b[48;2;28;0;0mamount \u001b[48;2;254;0;0mof \u001b[48;2;0;0;55mannotated \u001b[48;2;0;0;66mtraining \u001b[48;2;0;0;167mdata \u001b[48;2;0;0;0m(for \u001b[48;2;0;0;69msupervised \u001b[48;2;0;0;0mtagging) \u001b[48;2;91;0;0mor \u001b[48;2;211;0;0ma \u001b[48;2;0;0;505mlexicon \u001b[48;2;13;0;0mlisting \u001b[48;2;26;0;0mall \u001b[48;2;84;0;0mpossible \u001b[48;2;0;0;45mtags \u001b[48;2;30;0;0mfor \u001b[48;2;72;0;0meach \u001b[48;2;0;0;192mword \u001b[48;2;0;0;0m(for \u001b[48;2;0;0;0munsupervised \u001b[48;2;0;0;0mtagging).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF text extratction\n"
      ],
      "metadata": {
        "id": "TD_FQ6ioGFGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfminer.six"
      ],
      "metadata": {
        "id": "zPD706w-I9zR",
        "outputId": "22300c57-7c48-4a49-f48c-3e0e4b2e87be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20220319-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 9.0 MB/s \n",
            "\u001b[?25hCollecting cryptography\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 35.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (3.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six) (2.21)\n",
            "Installing collected packages: cryptography, pdfminer.six\n",
            "Successfully installed cryptography-37.0.2 pdfminer.six-20220319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import StringIO\n",
        "\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfdocument import PDFDocument\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.pdfparser import PDFParser"
      ],
      "metadata": {
        "id": "hKrdAGGRJPJB"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_pdf_to_string(file_path):\n",
        "\toutput_string = StringIO()\n",
        "\twith open(file_path, 'rb') as in_file:\n",
        "\t    parser = PDFParser(in_file)\n",
        "\t    doc = PDFDocument(parser)\n",
        "\t    rsrcmgr = PDFResourceManager()\n",
        "\t    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
        "\t    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "\t    for page in PDFPage.create_pages(doc):\n",
        "\t        interpreter.process_page(page)\n",
        "\n",
        "\treturn(output_string.getvalue())\n",
        " \n",
        "def sent_extract(sample):\n",
        "\tdelims=re.findall('\\. [A-Z]',sample)\n",
        "\tsents=re.split('\\. [A-Z]',sample)\n",
        "\n",
        "\tsents[0]=sents[0]+'.'\n",
        "\tfor i,s in enumerate(sents[1:]):\n",
        "\t\tsents[i+1]=delims[i][2]+s+'.'\n",
        "\treturn sents\n",
        "\n",
        "def pdf_text_extract(path):\n",
        "  text=convert_pdf_to_string(path)\n",
        "  text1 = text.replace('\\x0c','')\n",
        "  text2 = text1.split('.\\n\\n')\n",
        "  refine=[t.replace('\\n',' ') for t in text2]\n",
        "  r=[]\n",
        "  for t in refine:\n",
        "    r+=sent_extract(t)\n",
        "  return r\n",
        "\n",
        "path='/content/drive/MyDrive/Text-ML/phocus.pdf'\n",
        "text=pdf_text_extract(path)\n"
      ],
      "metadata": {
        "id": "HkUe38wlJSov"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_end=0\n",
        "ref_start=len(text)-1\n",
        "while '©' not in text[title_end]:\n",
        "  title_end+=1\n",
        "while 'REFERENCES' not in text[ref_start]:\n",
        "  ref_start-=1\n",
        "content=text[title_end+3:ref_start]\n"
      ],
      "metadata": {
        "id": "O9lsV2ij-2vn"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coloring of a PDF"
      ],
      "metadata": {
        "id": "_Td1mswaCOFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for t in content[34:35]:\n",
        "  print(color_by_attn(t,tokenizer,preprocesser_model,encoder_model))"
      ],
      "metadata": {
        "id": "AcFhtVjoCRTh",
        "outputId": "7b2c3e50-1176-4038-c259-2a2bf43b5526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saw: Gao et al. [14] utilize three target-dependent variations of the 𝐵𝐸𝑅𝑇𝑏𝑎𝑠𝑒 model.\n",
            "saw: ['Gao et al 14 utilize three target-dependent variations of the 𝐵𝐸𝑅𝑇𝑏𝑎𝑠𝑒 mod']\n",
            "['gao', 'et', 'al', '14', 'utilize', 'three', 'target', '-', 'dependent', 'variations', 'of', 'the', '[UNK]', 'mod']\n",
            "got here 14 14\n",
            "tf.Tensor(\n",
            "[b'gao' b'et' b'al' b'14' b'utilize' b'three' b'target' b'-' b'dependent'\n",
            " b'variations' b'of' b'the' b'[UNK]' b'mod'], shape=(14,), dtype=string)\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-311-5b0a9a42f0ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_by_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocesser_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-292-4be94c388fbd>\u001b[0m in \u001b[0;36mcolor_by_attn\u001b[0;34m(text, toker, preper, encoder)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saw:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saw:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_attn_for_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocesser_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attn_recived'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_bytes_strs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-306-f12a0d4c6641>\u001b[0m in \u001b[0;36mget_attn_for_words\u001b[0;34m(context, tokenizer, prep, encoder)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mt_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mmasked_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindicies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'got here'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \"\"\"\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shapes (15,) and (14,) are incompatible"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "input.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}